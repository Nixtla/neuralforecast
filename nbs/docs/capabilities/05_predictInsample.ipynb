{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Insample\n",
    "> Tutorial on how to produce insample predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial provides and example on how to use the `predict_insample` function of the `core` class to produce forecasts of the train and validation sets. In this example we will train the `NHITS` model on the AirPassengers data, and show how to recover the insample predictions after model is fitted.\n",
    "\n",
    "*Predict Insample*: The process of producing forecasts of the train and validation sets.\n",
    "\n",
    "*Use Cases*: \n",
    "* Debugging: producing insample predictions is useful for debugging purposes. For example, to check if the model is able to fit the train set.\n",
    "* Training convergence: check if the the model has converged.\n",
    "* Anomaly detection: insample predictions can be used to detect anomalous behavior in the train set (e.g. outliers). (Note: if a model is too flexible it might be able to perfectly forecast outliers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run these experiments using GPU with Google Colab.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/Nixtla/neuralforecast/blob/main/nbs/examples/PredictInsample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing NeuralForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install neuralforecast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading AirPassengers Data\n",
    "\n",
    "The `core.NeuralForecast` class contains shared, `fit`, `predict` and other methods that take as inputs pandas DataFrames with columns `['unique_id', 'ds', 'y']`, where `unique_id` identifies individual time series from the dataset, `ds` is the date, and `y` is the target variable. \n",
    "\n",
    "In this example dataset consists of a set of a single series, but you can easily fit your model to larger datasets in long format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.utils import AirPassengersDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df = AirPassengersDF\n",
    "Y_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we train the `NHITS` models on the AirPassengers data. We will use the `fit` method of the `core` class to train the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NHITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('pytorch_lightning').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 12\n",
    "\n",
    "# Try different hyperparameters to improve accuracy.\n",
    "models = [NHITS(h=horizon,                      # Forecast horizon\n",
    "                input_size=2 * horizon,         # Length of input sequence\n",
    "                max_steps=100,                  # Number of steps to train\n",
    "                n_freq_downsample=[2, 1, 1],    # Downsampling factors for each stack output\n",
    "                mlp_units = 3 * [[1024, 1024]],\n",
    "               ) # Number of units in each block.\n",
    "          ]\n",
    "nf = NeuralForecast(models=models, freq='ME')\n",
    "nf.fit(df=Y_df, val_size=horizon)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predict Insample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `NeuralForecast.predict_insample` method you can obtain the forecasts for the train and validation sets after the models are fitted. The function will always take the last dataset used for training in either the `fit` or `cross_validation` methods.\n",
    "\n",
    "With the `step_size` parameter you can specify the step size between consecutive windows to produce the forecasts. In this example we will set `step_size=horizon` to produce non-overlapping forecasts.\n",
    "\n",
    "The following diagram shows how the forecasts are produced based on the `step_size` parameter and `h` (horizon) of the model. In the diagram we set `step_size=2` and `h=4`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../imgs_indx/predict_insample.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_insample = nf.predict_insample(step_size=horizon)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `predict_insample` function returns a pandas DataFrame with the following columns:\n",
    "* `unique_id`: the unique identifier of the time series.\n",
    "* `ds`: the datestamp of the forecast for each row.\n",
    "* `cutoff`: the datestamp at which the forecast was made.\n",
    "* `y`: the actual value of the target variable.\n",
    "* `model_name`: the forecasted values for the models. In this case, `NHITS`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_insample.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "The function will produce forecasts from the first timestamp of the time series. For these initial timestamps, the forecasts might not be accurate given that models have very limited input information to produce forecasts.\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot Predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we plot the forecasts for the train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsforecast.plotting import plot_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_series(forecasts_df=Y_hat_insample.drop(columns='cutoff'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Insample predictions with prediction intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can optionally include prediction intervals for models trained with a distribution loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.losses.pytorch import DistributionLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 12\n",
    "\n",
    "# Try different hyperparameters to improve accuracy.\n",
    "models = [NHITS(h=horizon,\n",
    "                input_size=2 * horizon,\n",
    "                loss=DistributionLoss(distribution=\"Poisson\", num_samples=50),\n",
    "                max_steps=100,\n",
    "                n_freq_downsample=[2, 1, 1],\n",
    "                mlp_units = 3 * [[1024, 1024]],\n",
    "               )\n",
    "          ]\n",
    "nf = NeuralForecast(models=models, freq='ME')\n",
    "nf.fit(df=Y_df, val_size=horizon)\n",
    "\n",
    "Y_hat_insample = nf.predict_insample(\n",
    "    step_size=horizon,\n",
    "    keep_distribution=True  # Get the insample prediction intervals\n",
    ")\n",
    "plot_series(forecasts_df=Y_hat_insample.drop(columns=['cutoff', 'NHITS-median']), level=[80, 90])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Cristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2021). NHITS: Neural Hierarchical Interpolation for Time Series Forecasting. Accepted at AAAI 2023.](https://arxiv.org/abs/2201.12886)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
