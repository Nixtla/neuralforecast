{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524620c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp tsdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15392f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa25a4",
   "metadata": {},
   "source": [
    "# PyTorch Dataset/Loader\n",
    "> Torch Dataset for Time Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508f7a9-1433-4ad8-8f2f-0078c6ed6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq\n",
    "from nbdev.showdoc import show_doc\n",
    "from neuralforecast.utils import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44065066-e72a-431f-938f-1528adef9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from collections.abc import Mapping\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323a7a6e-38c3-496d-8f1e-cad05f643d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TimeSeriesLoader(DataLoader):\n",
    "    \"\"\"TimeSeriesLoader DataLoader.\n",
    "    [Source code](https://github.com/Nixtla/neuralforecast1/blob/main/neuralforecast/tsdataset.py).\n",
    "\n",
    "    Small change to PyTorch's Data loader. \n",
    "    Combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
    "\n",
    "    The class `~torch.utils.data.DataLoader` supports both map-style and\n",
    "    iterable-style datasets with single- or multi-process loading, customizing\n",
    "    loading order and optional automatic batching (collation) and memory pinning.    \n",
    "    \n",
    "    **Parameters:**<br>\n",
    "    `batch_size`: (int, optional): how many samples per batch to load (default: 1).<br>\n",
    "    `shuffle`: (bool, optional): set to `True` to have the data reshuffled at every epoch (default: `False`).<br>\n",
    "    `sampler`: (Sampler or Iterable, optional): defines the strategy to draw samples from the dataset.<br>\n",
    "                Can be any `Iterable` with `__len__` implemented. If specified, `shuffle` must not be specified.<br>\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, **kwargs):\n",
    "        if 'collate_fn' in kwargs:\n",
    "            kwargs.pop('collate_fn')\n",
    "        kwargs_ = {**kwargs, **dict(collate_fn=self._collate_fn)}\n",
    "        DataLoader.__init__(self, dataset=dataset, **kwargs_)\n",
    "    \n",
    "    def _collate_fn(self, batch):\n",
    "        elem = batch[0]\n",
    "        elem_type = type(elem)\n",
    "\n",
    "        if isinstance(elem, torch.Tensor):\n",
    "            out = None\n",
    "            if torch.utils.data.get_worker_info() is not None:\n",
    "                # If we're in a background process, concatenate directly into a\n",
    "                # shared memory tensor to avoid an extra copy\n",
    "                numel = sum(x.numel() for x in batch)\n",
    "                storage = elem.storage()._new_shared(numel, device=elem.device)\n",
    "                out = elem.new(storage).resize_(len(batch), *list(elem.size()))\n",
    "            return torch.stack(batch, 0, out=out)\n",
    "\n",
    "        elif isinstance(elem, Mapping):\n",
    "            if elem['static'] is None:\n",
    "                return dict(temporal=self.collate_fn([d['temporal'] for d in batch]),\n",
    "                            temporal_cols = elem['temporal_cols'])\n",
    "            \n",
    "            return dict(static=self.collate_fn([d['static'] for d in batch]),\n",
    "                        static_cols = elem['static_cols'],\n",
    "                        temporal=self.collate_fn([d['temporal'] for d in batch]),\n",
    "                        temporal_cols = elem['temporal_cols'])\n",
    "\n",
    "        raise TypeError(f'Unknown {elem_type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e94050-0290-43ad-9a73-c4626bba9541",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TimeSeriesLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05687429-c139-44c0-adb9-097c616908cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TimeSeriesDataset(Dataset):\n",
    "\n",
    "    def __init__(self,\n",
    "                 temporal,\n",
    "                 temporal_cols,\n",
    "                 indptr,\n",
    "                 max_size: int,\n",
    "                 min_size: int,\n",
    "                 static=None,\n",
    "                 static_cols=None,\n",
    "                 sorted=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.temporal = torch.tensor(temporal, dtype=torch.float)\n",
    "        self.temporal_cols = pd.Index(list(temporal_cols)+\\\n",
    "                                      ['available_mask'])\n",
    "        if static is not None:\n",
    "            self.static = torch.tensor(static, dtype=torch.float)\n",
    "            self.static_cols = static_cols\n",
    "        else:\n",
    "            self.static = static\n",
    "            self.static_cols = static_cols\n",
    "\n",
    "        self.indptr = indptr\n",
    "        self.n_groups = self.indptr.size - 1\n",
    "        self.max_size = max_size\n",
    "        self.min_size = min_size\n",
    "\n",
    "        # Upadated flag. To protect consistency, dataset can only be updated once\n",
    "        self.updated = False\n",
    "        self.sorted = sorted\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, int):\n",
    "            # Parse temporal data and pad its left\n",
    "            temporal = torch.zeros(size=(len(self.temporal_cols), self.max_size),\n",
    "                                   dtype=torch.float32)\n",
    "            ts = self.temporal[self.indptr[idx] : self.indptr[idx + 1], :]\n",
    "            temporal[:len(self.temporal_cols)-1, -len(ts):] = ts.permute(1, 0)\n",
    "\n",
    "            # Add available_mask\n",
    "            temporal[len(self.temporal_cols)-1, -len(ts):] = 1\n",
    "\n",
    "            # Add static data if available\n",
    "            static = None if self.static is None else self.static[idx,:]\n",
    "\n",
    "            item = dict(temporal=temporal, temporal_cols=self.temporal_cols,\n",
    "                        static=static, static_cols=self.static_cols)\n",
    "\n",
    "            return item\n",
    "        raise ValueError(f'idx must be int, got {type(idx)}')\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_groups\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'TimeSeriesDataset(n_data={self.data.size:,}, n_groups={self.n_groups:,})'\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not hasattr(other, 'data') or not hasattr(other, 'indptr'):\n",
    "            return False\n",
    "        return np.allclose(self.data, other.data) and np.array_equal(self.indptr, other.indptr)\n",
    "\n",
    "    @staticmethod\n",
    "    def update_dataset(dataset, future_df):\n",
    "        \"\"\"Add future observations to the dataset.\n",
    "        \"\"\"        \n",
    "\n",
    "        # Add Nones to missing columns (without available_mask)\n",
    "        temporal_cols = dataset.temporal_cols.copy()\n",
    "        temporal_cols = temporal_cols.delete(len(temporal_cols)-1)\n",
    "        for col in temporal_cols:\n",
    "            if col not in future_df.columns:\n",
    "                future_df[col] = None\n",
    "        \n",
    "        # Sort columns to match self.temporal_cols\n",
    "        future_df = future_df[ ['unique_id','ds'] + temporal_cols.tolist() ]\n",
    "\n",
    "        # Process future_df\n",
    "        futr_dataset, indices, futr_dates, futr_index = dataset.from_df(df=future_df, sort_df=dataset.sorted)\n",
    "\n",
    "        # Define and fill new temporal with updated information\n",
    "        len_temporal, col_temporal = dataset.temporal.shape\n",
    "        new_temporal = torch.zeros(size=(len_temporal+len(future_df), col_temporal))\n",
    "        new_indptr = [0]\n",
    "        new_max_size = 0\n",
    "\n",
    "        acum = 0\n",
    "        for i in range(dataset.n_groups):\n",
    "            series_length = dataset.indptr[i + 1] - dataset.indptr[i]\n",
    "            new_length = series_length + futr_dataset.indptr[i + 1] - futr_dataset.indptr[i]\n",
    "            new_temporal[acum:(acum+series_length), :] = dataset.temporal[dataset.indptr[i] : dataset.indptr[i + 1], :]\n",
    "            new_temporal[(acum+series_length):(acum+new_length), :] = \\\n",
    "                                 futr_dataset.temporal[futr_dataset.indptr[i] : futr_dataset.indptr[i + 1], :]\n",
    "            \n",
    "            acum += new_length\n",
    "            new_indptr.append(acum)\n",
    "            if new_length > new_max_size:\n",
    "                new_max_size = new_length\n",
    "        \n",
    "        # Define new dataset\n",
    "        updated_dataset = TimeSeriesDataset(temporal=new_temporal,\n",
    "                                            temporal_cols=temporal_cols,\n",
    "                                            indptr=np.array(new_indptr).astype(np.int32),\n",
    "                                            max_size=new_max_size,\n",
    "                                            min_size=dataset.min_size,\n",
    "                                            static=dataset.static,\n",
    "                                            static_cols=dataset.static_cols,\n",
    "                                            sorted=dataset.sorted)\n",
    "\n",
    "        return updated_dataset\n",
    "    \n",
    "    @staticmethod\n",
    "    def trim_dataset(dataset, left_trim: int = 0, right_trim: int = 0):\n",
    "        \"\"\"\n",
    "        Trim temporal information from a dataset.\n",
    "        Returns temporal indexes [t+left:t-right] for all series.\n",
    "        \"\"\"\n",
    "        if dataset.min_size <= left_trim + right_trim:\n",
    "            raise Exception(f'left_trim + right_trim ({left_trim} + {right_trim}) \\\n",
    "                                must be lower than the shorter time series ({dataset.min_size})')\n",
    "\n",
    "\n",
    "        # Remove available mask from temporal_cols\n",
    "        temporal_cols = dataset.temporal_cols.copy()\n",
    "        temporal_cols = temporal_cols.delete(len(temporal_cols)-1)\n",
    "\n",
    "        # Define and fill new temporal with trimmed information        \n",
    "        len_temporal, col_temporal = dataset.temporal.shape\n",
    "        total_trim = (left_trim + right_trim) * dataset.n_groups\n",
    "        new_temporal = torch.zeros(size=(len_temporal-total_trim, col_temporal))\n",
    "        new_indptr = [0]\n",
    "\n",
    "        acum = 0\n",
    "        for i in range(dataset.n_groups):\n",
    "            series_length = dataset.indptr[i + 1] - dataset.indptr[i]\n",
    "            new_length = series_length - left_trim - right_trim\n",
    "            new_temporal[acum:(acum+new_length), :] = dataset.temporal[dataset.indptr[i]+left_trim : \\\n",
    "                                                                       dataset.indptr[i + 1]-right_trim, :]\n",
    "            acum += new_length\n",
    "            new_indptr.append(acum)\n",
    "\n",
    "        new_max_size = dataset.max_size-left_trim-right_trim\n",
    "        new_min_size = dataset.min_size-left_trim-right_trim\n",
    "        \n",
    "        # Define new dataset\n",
    "        updated_dataset = TimeSeriesDataset(temporal=new_temporal,\n",
    "                                            temporal_cols=temporal_cols,\n",
    "                                            indptr=np.array(new_indptr).astype(np.int32),\n",
    "                                            max_size=new_max_size,\n",
    "                                            min_size=new_min_size,\n",
    "                                            static=dataset.static,\n",
    "                                            static_cols=dataset.static_cols,\n",
    "                                            sorted=dataset.sorted)\n",
    "\n",
    "        return updated_dataset\n",
    "\n",
    "    @staticmethod\n",
    "    def from_df(df, static_df=None, sort_df=False):\n",
    "        # TODO: protect on equality of static_df + df indexes\n",
    "        # Define indexes if not given\n",
    "        if df.index.name != 'unique_id':\n",
    "            df = df.set_index('unique_id')\n",
    "            if static_df is not None:\n",
    "                static_df = static_df.set_index('unique_id')\n",
    "\n",
    "        df = df.set_index('ds', append=True)\n",
    "        \n",
    "        # Sort data by index\n",
    "        if not df.index.is_monotonic_increasing and sort_df:\n",
    "            df = df.sort_index()\n",
    "\n",
    "            if static_df is not None:\n",
    "                static_df = static_df.sort_index()\n",
    "\n",
    "        # Create auxiliary temporal indices 'indptr'\n",
    "        temporal = df.values.astype(np.float32)\n",
    "        temporal_cols = df.columns\n",
    "        indices_sizes = df.index.get_level_values('unique_id').value_counts(sort=False)\n",
    "        indices = indices_sizes.index\n",
    "        sizes = indices_sizes.values\n",
    "        max_size = max(sizes)\n",
    "        min_size = min(sizes)\n",
    "        cum_sizes = sizes.cumsum()\n",
    "        dates = df.index.get_level_values('ds')[cum_sizes - 1]\n",
    "        indptr = np.append(0, cum_sizes).astype(np.int32)\n",
    "\n",
    "        # Static features\n",
    "        if static_df is not None:\n",
    "            static = static_df.values\n",
    "            static_cols = static_df.columns\n",
    "        else:\n",
    "            static = None\n",
    "            static_cols = None\n",
    "\n",
    "        dataset = TimeSeriesDataset(\n",
    "                    temporal=temporal, temporal_cols=temporal_cols,\n",
    "                    static=static, static_cols=static_cols,\n",
    "                    indptr=indptr, max_size=max_size, min_size=min_size, sorted=sort_df)\n",
    "        return dataset, indices, dates, df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a818bf-28d2-4561-8036-475f6fe78d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TimeSeriesDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c07552-b6fa-4d10-8792-71743dcdfd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# Testing sort_df=True functionality\n",
    "temporal_df = generate_series(n_series=1000, \n",
    "                         n_temporal_features=0, equal_ends=False)\n",
    "sorted_temporal_df = temporal_df.sort_values(['unique_id', 'ds'])\n",
    "unsorted_temporal_df = sorted_temporal_df.sample(frac=1.0)\n",
    "dataset, indices, dates, ds = TimeSeriesDataset.from_df(df=unsorted_temporal_df,\n",
    "                                                        sort_df=True)\n",
    "\n",
    "np.testing.assert_allclose(dataset.temporal, \n",
    "                           sorted_temporal_df.drop(columns='ds').values)\n",
    "test_eq(indices, sorted_temporal_df.index.unique(level='unique_id'))\n",
    "test_eq(dates, temporal_df.groupby('unique_id')['ds'].max().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dae43c-4d11-4bbc-a431-ac33b004859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TimeSeriesDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            dataset: TimeSeriesDataset,\n",
    "            batch_size=32, \n",
    "            valid_batch_size=1024,\n",
    "            num_workers=0,\n",
    "            drop_last=False\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.valid_batch_size = valid_batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.drop_last = drop_last\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        loader = TimeSeriesLoader(\n",
    "            self.dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "            drop_last=self.drop_last\n",
    "        )\n",
    "        return loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        loader = TimeSeriesLoader(\n",
    "            self.dataset, \n",
    "            batch_size=self.valid_batch_size, \n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            drop_last=self.drop_last\n",
    "        )\n",
    "        return loader\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        loader = TimeSeriesLoader(\n",
    "            self.dataset,\n",
    "            batch_size=self.valid_batch_size, \n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False\n",
    "        )\n",
    "        return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8535a15f-b5cf-4ca1-bfa2-e53a9e8c3bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(TimeSeriesDataModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b534d29d-eecc-43ba-8468-c23305fa24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "batch_size = 128\n",
    "data = TimeSeriesDataModule(dataset=dataset, \n",
    "                            batch_size=batch_size, drop_last=True)\n",
    "for batch in data.train_dataloader():\n",
    "    test_eq(batch['temporal'].shape, (batch_size, 2, 500))\n",
    "    test_eq(batch['temporal_cols'], ['y', 'available_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4481272a-ea3a-4b63-8f14-9445d8f41338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "batch_size = 128\n",
    "n_static_features = 2\n",
    "n_temporal_features = 4\n",
    "temporal_df, static_df = generate_series(n_series=1000,\n",
    "                                         n_static_features=n_static_features,\n",
    "                                         n_temporal_features=n_temporal_features, \n",
    "                                         equal_ends=False)\n",
    "\n",
    "dataset, indices, dates, ds = TimeSeriesDataset.from_df(df=temporal_df,\n",
    "                                                        static_df=static_df,\n",
    "                                                        sort_df=True)\n",
    "data = TimeSeriesDataModule(dataset=dataset,\n",
    "                            batch_size=batch_size, drop_last=True)\n",
    "\n",
    "for batch in data.train_dataloader():\n",
    "    test_eq(batch['temporal'].shape, (batch_size, n_temporal_features + 2, 500))\n",
    "    test_eq(batch['temporal_cols'],\n",
    "            ['y'] + [f'temporal_{i}' for i in range(n_temporal_features)] + ['available_mask'])\n",
    "    \n",
    "    test_eq(batch['static'].shape, (batch_size, n_static_features))\n",
    "    test_eq(batch['static_cols'], [f'static_{i}' for i in range(n_static_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252b59f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# Testing sort_df=True functionality\n",
    "temporal_df = generate_series(n_series=2,\n",
    "                              n_temporal_features=2, equal_ends=True)\n",
    "temporal_df = temporal_df.groupby('unique_id').tail(10)\n",
    "temporal_df = temporal_df.reset_index()\n",
    "temporal_full_df = temporal_df.sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "temporal_full_df.loc[temporal_full_df.ds > '2001-05-11', ['y', 'temporal_0']] = None\n",
    "\n",
    "split1_df = temporal_full_df.loc[temporal_full_df.ds <= '2001-05-11']\n",
    "split2_df = temporal_full_df.loc[temporal_full_df.ds > '2001-05-11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d23f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test correct future_df wrangling of the `update_df` method\n",
    "# We are checking that we are able to recover the AirPassengers dataset\n",
    "# using the dataframe or splitting it into parts and initializing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f999c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# FULL DATASET\n",
    "dataset_full, indices_full, dates_full, ds_full = TimeSeriesDataset.from_df(df=temporal_full_df,\n",
    "                                                                            sort_df=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b3b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# SPLIT_1 DATASET\n",
    "dataset_1, indices_1, dates_1, ds_1 = TimeSeriesDataset.from_df(df=split1_df,\n",
    "                                                                sort_df=False)\n",
    "dataset_1 = dataset_1.update_dataset(dataset_1, split2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d12062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "np.testing.assert_almost_equal(dataset_full.temporal.numpy(), dataset_1.temporal.numpy())\n",
    "test_eq(dataset_full.max_size, dataset_1.max_size)\n",
    "test_eq(dataset_full.indptr, dataset_1.indptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72f3b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# Testing trim_dataset functionality\n",
    "n_static_features = 0\n",
    "n_temporal_features = 2\n",
    "temporal_df = generate_series(n_series=100,\n",
    "                              min_length=50,\n",
    "                              max_length=100,\n",
    "                              n_static_features=n_static_features,\n",
    "                              n_temporal_features=n_temporal_features, \n",
    "                              equal_ends=False)\n",
    "dataset, indices, dates, ds = TimeSeriesDataset.from_df(df=temporal_df,\n",
    "                                                        static_df=static_df,\n",
    "                                                        sort_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9be28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "left_trim = 10\n",
    "right_trim = 20\n",
    "dataset_trimmed = dataset.trim_dataset(dataset, left_trim=left_trim, right_trim=right_trim)\n",
    "\n",
    "np.testing.assert_almost_equal(dataset.temporal[dataset.indptr[50]+left_trim:dataset.indptr[51]-right_trim].numpy(),\n",
    "                               dataset_trimmed.temporal[dataset_trimmed.indptr[50]:dataset_trimmed.indptr[51]].numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
