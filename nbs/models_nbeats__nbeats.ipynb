{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# os.chdir('./drive/MyDrive/nixtlats')\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-lightning\n",
    "# !pip install torchinfo\n",
    "# !pip install fastcore\n",
    "# !pip install s3fs\n",
    "# !pip install patool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.nbeats.nbeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-BEATS: Neural Basis Expansion Analysis\n",
    "\n",
    "> API details.\n",
    "\n",
    "The N-BEATS model decomposes the objective signal by performing separate local nonlinear projections of the target data onto basis functions across its different blocks. Each block of the architecture consists of a multi layer perceptron that learns expansion coefficients for the backcast and forecast elements. The backcast model is used to clean the inputs of subsequent blocks, while the forecasts are summed to compose the final prediction. The blocks are grouped in stacks. Each of the potentially multiple stacks specializes in a different variant of basis functions. Depending on the basis functions the outputs of the model can be interpretable. The [original model](https://github.com/ElementAI/N-BEATS) is implemented in both pytorch and tensorflow.\n",
    "\n",
    "[Oreshkin, B. N., Carpov, D., Chapados, N., & Bengio, Y. (2020). N-BEATS: neural basis expansion analysisfor interpretable time series forecasting.  In 8th  International Conference on Learning Representations, ICLR 2020.](https://openreview.net/forum?id=r1ecqn4YwB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import Tuple\n",
    "from functools import partial\n",
    "\n",
    "from nixtlats.models.components.tcn import _TemporalConvNet\n",
    "from nixtlats.models.components.common import Chomp1d, RepeatVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _StaticFeaturesEncoder(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(_StaticFeaturesEncoder, self).__init__()\n",
    "        layers = [nn.Dropout(p=0.5),\n",
    "                  nn.Linear(in_features=in_features, out_features=out_features),\n",
    "                  nn.ReLU()]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "class _sEncoder(nn.Module):\n",
    "    def __init__(self, in_features, out_features, n_time_in):\n",
    "        super(_sEncoder, self).__init__()\n",
    "        layers = [nn.Dropout(p=0.5),\n",
    "                  nn.Linear(in_features=in_features, out_features=out_features),\n",
    "                  nn.ReLU()]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "        self.repeat = RepeatVector(repeats=n_time_in)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode and repeat values to match time\n",
    "        x = self.encoder(x)\n",
    "        x = self.repeat(x) # [N,S_out] -> [N,S_out,T]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IdentityBasis(nn.Module):\n",
    "    def __init__(self, backcast_size: int, forecast_size: int):\n",
    "        super().__init__()\n",
    "        self.forecast_size = forecast_size\n",
    "        self.backcast_size = backcast_size\n",
    " \n",
    "    def forward(self, theta: t.Tensor, insample_x_t: t.Tensor, outsample_x_t: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "        backcast = theta[:, :self.backcast_size]\n",
    "        forecast = theta[:, -self.forecast_size:]\n",
    "        return backcast, forecast\n",
    "\n",
    "class TrendBasis(nn.Module):\n",
    "    def __init__(self, degree_of_polynomial: int, backcast_size: int, forecast_size: int):\n",
    "        super().__init__()\n",
    "        polynomial_size = degree_of_polynomial + 1\n",
    "        self.backcast_basis = nn.Parameter(\n",
    "            t.tensor(np.concatenate([np.power(np.arange(backcast_size, dtype=float) / backcast_size, i)[None, :]\n",
    "                                    for i in range(polynomial_size)]), dtype=t.float32), requires_grad=False)\n",
    "        self.forecast_basis = nn.Parameter(\n",
    "            t.tensor(np.concatenate([np.power(np.arange(forecast_size, dtype=float) / forecast_size, i)[None, :]\n",
    "                                    for i in range(polynomial_size)]), dtype=t.float32), requires_grad=False)\n",
    "    \n",
    "    def forward(self, theta: t.Tensor, insample_x_t: t.Tensor, outsample_x_t: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "        cut_point = self.forecast_basis.shape[0]\n",
    "        backcast = t.einsum('bp,pt->bt', theta[:, cut_point:], self.backcast_basis)\n",
    "        forecast = t.einsum('bp,pt->bt', theta[:, :cut_point], self.forecast_basis)\n",
    "        return backcast, forecast\n",
    "\n",
    "class SeasonalityBasis(nn.Module):\n",
    "    def __init__(self, harmonics: int, backcast_size: int, forecast_size: int):\n",
    "        super().__init__()\n",
    "        frequency = np.append(np.zeros(1, dtype=float),\n",
    "                                        np.arange(harmonics, harmonics / 2 * forecast_size,\n",
    "                                                    dtype=float) / harmonics)[None, :]\n",
    "        backcast_grid = -2 * np.pi * (\n",
    "                np.arange(backcast_size, dtype=float)[:, None] / forecast_size) * frequency\n",
    "        forecast_grid = 2 * np.pi * (\n",
    "                np.arange(forecast_size, dtype=float)[:, None] / forecast_size) * frequency\n",
    "\n",
    "        backcast_cos_template = t.tensor(np.transpose(np.cos(backcast_grid)), dtype=t.float32)\n",
    "        backcast_sin_template = t.tensor(np.transpose(np.sin(backcast_grid)), dtype=t.float32)\n",
    "        backcast_template = t.cat([backcast_cos_template, backcast_sin_template], dim=0)\n",
    "\n",
    "        forecast_cos_template = t.tensor(np.transpose(np.cos(forecast_grid)), dtype=t.float32)\n",
    "        forecast_sin_template = t.tensor(np.transpose(np.sin(forecast_grid)), dtype=t.float32)\n",
    "        forecast_template = t.cat([forecast_cos_template, forecast_sin_template], dim=0)\n",
    "\n",
    "        self.backcast_basis = nn.Parameter(backcast_template, requires_grad=False)\n",
    "        self.forecast_basis = nn.Parameter(forecast_template, requires_grad=False)\n",
    "\n",
    "    def forward(self, theta: t.Tensor, insample_x_t: t.Tensor, outsample_x_t: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "        cut_point = self.forecast_basis.shape[0]\n",
    "        backcast = t.einsum('bp,pt->bt', theta[:, cut_point:], self.backcast_basis)\n",
    "        forecast = t.einsum('bp,pt->bt', theta[:, :cut_point], self.forecast_basis)\n",
    "        return backcast, forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ExogenousBasisInterpretable(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, theta: t.Tensor, insample_x_t: t.Tensor, outsample_x_t: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "        backcast_basis = insample_x_t\n",
    "        forecast_basis = outsample_x_t\n",
    "\n",
    "        cut_point = forecast_basis.shape[1]\n",
    "        backcast = t.einsum('bp,bpt->bt', theta[:, cut_point:], backcast_basis)\n",
    "        forecast = t.einsum('bp,bpt->bt', theta[:, :cut_point], forecast_basis)\n",
    "        return backcast, forecast\n",
    "\n",
    "class ExogenousBasisWavenet(nn.Module):\n",
    "    def __init__(self, out_features, in_features, num_levels=4, kernel_size=3, dropout_prob=0):\n",
    "        super().__init__()\n",
    "        # Shape of (1, in_features, 1) to broadcast over b and t\n",
    "        self.weight = nn.Parameter(t.Tensor(1, in_features, 1), requires_grad=True)\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(0.5))\n",
    "\n",
    "        padding = (kernel_size - 1) * (2**0)\n",
    "        input_layer = [nn.Conv1d(in_channels=in_features, out_channels=out_features,\n",
    "                                 kernel_size=kernel_size, padding=padding, dilation=2**0),\n",
    "                                 Chomp1d(padding),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(dropout_prob)]\n",
    "        conv_layers = []\n",
    "        for i in range(1, num_levels):\n",
    "            dilation = 2**i\n",
    "            padding = (kernel_size - 1) * dilation\n",
    "            conv_layers.append(nn.Conv1d(in_channels=out_features, out_channels=out_features,\n",
    "                                         padding=padding, kernel_size=3, dilation=dilation))\n",
    "            conv_layers.append(Chomp1d(padding))\n",
    "            conv_layers.append(nn.ReLU())\n",
    "        conv_layers = input_layer + conv_layers\n",
    "\n",
    "        self.wavenet = nn.Sequential(*conv_layers)\n",
    "        \n",
    "    def transform(self, insample_x_t, outsample_x_t):\n",
    "        n_time_in = insample_x_t.shape[2]\n",
    "        \n",
    "        x_t = t.cat([insample_x_t, outsample_x_t], dim=2)\n",
    "        \n",
    "        x_t = x_t * self.weight # Element-wise multiplication, broadcasted on b and t. Weights used in L1 regularization\n",
    "        x_t = self.wavenet(x_t)[:]\n",
    "\n",
    "        backcast_basis = x_t[:,:, :n_time_in]\n",
    "        forecast_basis = x_t[:,:, n_time_in:]\n",
    "\n",
    "        return backcast_basis, forecast_basis\n",
    "\n",
    "    def forward(self, theta: t.Tensor, insample_x_t: t.Tensor, outsample_x_t: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "        backcast_basis, forecast_basis = self.transform(insample_x_t, outsample_x_t)\n",
    "\n",
    "        cut_point = forecast_basis.shape[1]\n",
    "        backcast = t.einsum('bp,bpt->bt', theta[:, cut_point:], backcast_basis)\n",
    "        forecast = t.einsum('bp,bpt->bt', theta[:, :cut_point], forecast_basis)\n",
    "        return backcast, forecast\n",
    "\n",
    "class ExogenousBasisTCN(nn.Module):\n",
    "    def __init__(self, out_features, in_features, num_levels = 4, kernel_size=2, dropout_prob=0):\n",
    "        super().__init__()\n",
    "        n_channels = num_levels * [out_features]\n",
    "        self.tcn = _TemporalConvNet(num_inputs=in_features, num_channels=n_channels, kernel_size=kernel_size, dropout=dropout_prob)\n",
    "        \n",
    "    def transform(self, insample_x_t, outsample_x_t):\n",
    "        n_time_in = insample_x_t.shape[2]\n",
    "        \n",
    "        x_t = t.cat([insample_x_t, outsample_x_t], dim=2)\n",
    "        \n",
    "        x_t = self.tcn(x_t)[:]\n",
    "        backcast_basis = x_t[:,:, :n_time_in]\n",
    "        forecast_basis = x_t[:,:, n_time_in:]\n",
    "\n",
    "        return backcast_basis, forecast_basis\n",
    "\n",
    "    def forward(self, theta: t.Tensor, insample_x_t: t.Tensor, outsample_x_t: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "        backcast_basis, forecast_basis = self.transform(insample_x_t, outsample_x_t)\n",
    "\n",
    "        cut_point = forecast_basis.shape[1]\n",
    "        backcast = t.einsum('bp,bpt->bt', theta[:, cut_point:], backcast_basis)\n",
    "        forecast = t.einsum('bp,bpt->bt', theta[:, :cut_point], forecast_basis)\n",
    "        return backcast, forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def init_weights(module, initialization):\n",
    "    if type(module) == t.nn.Linear:\n",
    "        if initialization == 'orthogonal':\n",
    "            t.nn.init.orthogonal_(module.weight)\n",
    "        elif initialization == 'he_uniform':\n",
    "            t.nn.init.kaiming_uniform_(module.weight)\n",
    "        elif initialization == 'he_normal':\n",
    "            t.nn.init.kaiming_normal_(module.weight)\n",
    "        elif initialization == 'glorot_uniform':\n",
    "            t.nn.init.xavier_uniform_(module.weight)\n",
    "        elif initialization == 'glorot_normal':\n",
    "            t.nn.init.xavier_normal_(module.weight)\n",
    "        elif initialization == 'lecun_normal':\n",
    "            pass #t.nn.init.normal_(module.weight, 0.0, std=1/np.sqrt(module.weight.numel()))\n",
    "        else:\n",
    "            assert 1<0, f'Initialization {initialization} not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "ACTIVATIONS = ['ReLU',\n",
    "               'Softplus',\n",
    "               'Tanh',\n",
    "               'SELU',\n",
    "               'LeakyReLU',\n",
    "               'PReLU',\n",
    "               'Sigmoid']\n",
    "\n",
    "class _NBEATSBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    N-BEATS block which takes a basis function as an argument.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_time_in: int, n_time_out: int, n_x: int,\n",
    "                 n_s: int, n_s_hidden: int, n_theta: int, n_theta_hidden: list,\n",
    "                 basis: nn.Module, \n",
    "                 n_layers: int,  batch_normalization: bool, dropout_prob: float, activation: str):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        if n_s == 0:\n",
    "            n_s_hidden = 0\n",
    "        n_theta_hidden = [n_time_in + (n_time_in+n_time_out)*n_x + n_s_hidden] + n_theta_hidden\n",
    "        \n",
    "        self.n_time_in = n_time_in\n",
    "        self.n_time_out = n_time_out\n",
    "        self.n_s = n_s\n",
    "        self.n_s_hidden = n_s_hidden\n",
    "        self.n_x = n_x\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.dropout_prob = dropout_prob\n",
    "        \n",
    "        assert activation in ACTIVATIONS, f'{activation} is not in {ACTIVATIONS}'\n",
    "        activ = getattr(nn, activation)()\n",
    "\n",
    "        hidden_layers = []\n",
    "        for i in range(n_layers):\n",
    "            hidden_layers.append(nn.Linear(in_features=n_theta_hidden[i], out_features=n_theta_hidden[i+1]))\n",
    "            hidden_layers.append(activ)\n",
    "\n",
    "            if self.batch_normalization:\n",
    "                hidden_layers.append(nn.BatchNorm1d(num_features=n_theta_hidden[i+1]))\n",
    "\n",
    "            if self.dropout_prob>0:\n",
    "                hidden_layers.append(nn.Dropout(p=self.dropout_prob))\n",
    "\n",
    "        output_layer = [nn.Linear(in_features=n_theta_hidden[-1], out_features=n_theta)]\n",
    "        layers = hidden_layers + output_layer\n",
    "\n",
    "        # n_s is computed with data, n_s_hidden is provided by user, if 0 no statics are used\n",
    "        if (self.n_s > 0) and (self.n_s_hidden > 0):\n",
    "            self.static_encoder = _StaticFeaturesEncoder(in_features=n_s, out_features=n_s_hidden)\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.basis = basis\n",
    "\n",
    "    def forward(self, insample_y: t.Tensor, insample_x_t: t.Tensor,\n",
    "                outsample_x_t: t.Tensor, x_s: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "\n",
    "        batch_size = len(insample_y)\n",
    "        if self.n_x>0:\n",
    "            insample_y = t.cat(( insample_y, insample_x_t.reshape(batch_size, -1) ), 1)\n",
    "            insample_y = t.cat(( insample_y, outsample_x_t.reshape(batch_size, -1) ), 1)\n",
    "        \n",
    "        # Static exogenous\n",
    "        if (self.n_s > 0) and (self.n_s_hidden > 0):\n",
    "            x_s = self.static_encoder(x_s)\n",
    "            insample_y = t.cat((insample_y, x_s), 1)\n",
    "\n",
    "        # Compute local projection weights and projection\n",
    "        theta = self.layers(insample_y)\n",
    "        backcast, forecast = self.basis(theta, insample_x_t, outsample_x_t)\n",
    "\n",
    "        return backcast, forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _NBEATS(nn.Module):\n",
    "    \"\"\"\n",
    "    N-Beats Model.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 n_time_in,\n",
    "                 n_time_out,\n",
    "                 n_s,\n",
    "                 n_x,\n",
    "                 n_s_hidden,\n",
    "                 n_x_hidden,\n",
    "                 n_polynomials,\n",
    "                 n_harmonics,\n",
    "                 stack_types: list,\n",
    "                 n_blocks: list,\n",
    "                 n_layers: list,\n",
    "                 n_theta_hidden: list,\n",
    "                 dropout_prob_theta,\n",
    "                 activation,\n",
    "                 initialization,\n",
    "                 batch_normalization,\n",
    "                 shared_weights):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_time_out = n_time_out\n",
    "\n",
    "        blocks = self.create_stack(stack_types=stack_types, \n",
    "                                   n_blocks=n_blocks,\n",
    "                                   n_time_in=n_time_in,\n",
    "                                   n_time_out=n_time_out,\n",
    "                                   n_x=n_x,\n",
    "                                   n_x_hidden=n_x_hidden,\n",
    "                                   n_s=n_s,\n",
    "                                   n_s_hidden=n_s_hidden,\n",
    "                                   n_layers=n_layers,\n",
    "                                   n_theta_hidden=n_theta_hidden,\n",
    "                                   batch_normalization=batch_normalization,\n",
    "                                   dropout_prob_theta=dropout_prob_theta,\n",
    "                                   activation=activation,\n",
    "                                   shared_weights=shared_weights,\n",
    "                                   n_polynomials=n_polynomials, \n",
    "                                   n_harmonics=n_harmonics,\n",
    "                                   initialization=initialization)\n",
    "        self.blocks = t.nn.ModuleList(blocks)\n",
    "\n",
    "    def create_stack(self, stack_types, n_blocks, \n",
    "                     n_time_in, n_time_out, \n",
    "                     n_x, n_x_hidden, n_s, n_s_hidden, \n",
    "                     n_layers, n_theta_hidden, batch_normalization, dropout_prob_theta, \n",
    "                     activation, shared_weights,\n",
    "                     n_polynomials, n_harmonics, initialization):                     \n",
    "\n",
    "        block_list = []\n",
    "        for i in range(len(stack_types)):\n",
    "            #print(f'| --  Stack {stack_types[i]} (#{i})')\n",
    "            for block_id in range(n_blocks[i]):\n",
    "                \n",
    "                # Batch norm only on first block\n",
    "                if (len(block_list)==0) and (batch_normalization):\n",
    "                    batch_normalization_block = True\n",
    "                else:\n",
    "                    batch_normalization_block = False\n",
    "\n",
    "                # Shared weights\n",
    "                if shared_weights and block_id>0:\n",
    "                    nbeats_block = block_list[-1]\n",
    "                else:\n",
    "                    if stack_types[i] == 'seasonality':\n",
    "                        n_theta = 4 * int(np.ceil(n_harmonics / 2 * n_time_out) - (n_harmonics - 1))\n",
    "                        basis = SeasonalityBasis(harmonics=n_harmonics,\n",
    "                                                 backcast_size=n_time_in,\n",
    "                                                 forecast_size=n_time_out)\n",
    "\n",
    "                    elif stack_types[i] == 'trend':\n",
    "                        n_theta = 2 * (n_polynomials + 1)\n",
    "                        basis = TrendBasis(degree_of_polynomial=n_polynomials,\n",
    "                                           backcast_size=n_time_in,\n",
    "                                           forecast_size=n_time_out)\n",
    "\n",
    "                    elif stack_types[i] == 'identity':\n",
    "                        n_theta = n_time_in + n_time_out\n",
    "                        basis = IdentityBasis(backcast_size=n_time_in,\n",
    "                                              forecast_size=n_time_out)                        \n",
    "\n",
    "                    elif stack_types[i] == 'exogenous':\n",
    "                        n_theta = 2 * n_x\n",
    "                        basis = ExogenousBasisInterpretable()\n",
    "\n",
    "                    elif stack_types[i] == 'exogenous_tcn':\n",
    "                        n_theta = 2 * n_x_hidden\n",
    "                        basis = ExogenousBasisTCN(n_x_hidden, n_x)\n",
    "\n",
    "                    elif stack_types[i] == 'exogenous_wavenet':\n",
    "                        n_theta = 2 * n_x_hidden\n",
    "                        basis = ExogenousBasisWavenet(n_x_hidden, n_x)\n",
    "\n",
    "                    else:\n",
    "                        assert 1<0, f'Block type not found!'\n",
    "\n",
    "                    nbeats_block = _NBEATSBlock(n_time_in=n_time_in,\n",
    "                                                n_time_out=n_time_out,\n",
    "                                                n_x=n_x,\n",
    "                                                n_s=n_s,\n",
    "                                                n_s_hidden=n_s_hidden,\n",
    "                                                n_theta=n_theta,\n",
    "                                                n_theta_hidden=n_theta_hidden[i],\n",
    "                                                basis=basis,\n",
    "                                                n_layers=n_layers[i],\n",
    "                                                batch_normalization=batch_normalization_block,\n",
    "                                                dropout_prob=dropout_prob_theta,\n",
    "                                                activation=activation)\n",
    "\n",
    "                # Select type of evaluation and apply it to all layers of block\n",
    "                init_function = partial(init_weights, initialization=initialization)                                             \n",
    "                nbeats_block.layers.apply(init_function)\n",
    "                #print(f'     | -- {nbeats_block}')\n",
    "                block_list.append(nbeats_block)\n",
    "        return block_list\n",
    "\n",
    "    def forward(self, S: t.Tensor, Y: t.Tensor, X: t.Tensor, \n",
    "                insample_mask: t.Tensor, return_decomposition: bool=False):\n",
    "        \n",
    "        # insample\n",
    "        insample_y    = Y[:, :-self.n_time_out]\n",
    "        insample_x_t  = X[:, :, :-self.n_time_out]\n",
    "        insample_mask = insample_mask[:, :-self.n_time_out]\n",
    "        outsample_mask = insample_mask[:, -self.n_time_out:]\n",
    "        \n",
    "        # outsample\n",
    "        outsample_y   = Y[:, -self.n_time_out:]\n",
    "        outsample_x_t = X[:, :, -self.n_time_out:]\n",
    "\n",
    "        if return_decomposition:\n",
    "            forecast, block_forecasts = self.forecast_decomposition(insample_y=insample_y, \n",
    "                                                                    insample_x_t=insample_x_t, \n",
    "                                                                    insample_mask=insample_mask,\n",
    "                                                                    outsample_x_t=outsample_x_t,\n",
    "                                                                    x_s=S)\n",
    "            return outsample_y, forecast, block_forecasts, outsample_mask\n",
    "        \n",
    "        else:\n",
    "            forecast = self.forecast(insample_y=insample_y,\n",
    "                                     insample_x_t=insample_x_t, \n",
    "                                     insample_mask=insample_mask,\n",
    "                                     outsample_x_t=outsample_x_t,\n",
    "                                     x_s=S)\n",
    "            return outsample_y, forecast, outsample_mask\n",
    "\n",
    "    def forecast(self, insample_y: t.Tensor, insample_x_t: t.Tensor, insample_mask: t.Tensor,\n",
    "                 outsample_x_t: t.Tensor, x_s: t.Tensor):\n",
    "\n",
    "        residuals = insample_y.flip(dims=(-1,))\n",
    "        insample_x_t = insample_x_t.flip(dims=(-1,))\n",
    "        insample_mask = insample_mask.flip(dims=(-1,))\n",
    "\n",
    "        forecast = insample_y[:, -1:] # Level with Naive1\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            backcast, block_forecast = block(insample_y=residuals, insample_x_t=insample_x_t,\n",
    "                                             outsample_x_t=outsample_x_t, x_s=x_s)\n",
    "            residuals = (residuals - backcast) * insample_mask\n",
    "            forecast = forecast + block_forecast\n",
    "\n",
    "        return forecast\n",
    "\n",
    "    def forecast_decomposition(self, insample_y: t.Tensor, insample_x_t: t.Tensor, insample_mask: t.Tensor,\n",
    "                               outsample_x_t: t.Tensor, x_s: t.Tensor):\n",
    "\n",
    "        residuals = insample_y.flip(dims=(-1,))\n",
    "        insample_x_t = insample_x_t.flip(dims=(-1,))\n",
    "        insample_mask = insample_mask.flip(dims=(-1,))\n",
    "        \n",
    "        n_batch, n_channels, n_t = outsample_x_t.size(0), outsample_x_t.size(1), outsample_x_t.size(2)\n",
    "        \n",
    "        level = insample_y[:, -1:] # Level with Naive1\n",
    "        block_forecasts = [ level.repeat(1, n_t) ]\n",
    "                \n",
    "        forecast = level\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            backcast, block_forecast = block(insample_y=residuals, insample_x_t=insample_x_t,\n",
    "                                             outsample_x_t=outsample_x_t, x_s=x_s)\n",
    "            residuals = (residuals - backcast) * insample_mask\n",
    "            forecast = forecast + block_forecast\n",
    "            block_forecasts.append(block_forecast)\n",
    "            \n",
    "        # (n_batch, n_blocks, n_t)\n",
    "        block_forecasts = t.stack(block_forecasts)\n",
    "        block_forecasts = block_forecasts.permute(1,0,2)\n",
    "\n",
    "        return forecast, block_forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = _NBEATS(n_time_in=168,\n",
    "                n_time_out=24,\n",
    "                n_s=1,\n",
    "                n_x=10,\n",
    "                n_s_hidden=100,\n",
    "                n_x_hidden=30,\n",
    "                n_polynomials=2,\n",
    "                n_harmonics=4,\n",
    "                stack_types=['trend', 'seasonality', 'exogenous_wavenet'],\n",
    "                n_blocks=[1, 1, 1],\n",
    "                n_layers=[2, 2, 2],\n",
    "                n_theta_hidden=3 * [[128, 128]],\n",
    "                dropout_prob_theta=0,\n",
    "                activation='SELU',\n",
    "                initialization='lecun_normal',\n",
    "                batch_normalization=True,\n",
    "                shared_weights=True)\n",
    "\n",
    "# inputs: S, Y, X, insample_mask\n",
    "# S.shape (n_batch,n_s)\n",
    "# Y.shape (n_batch,n_time_in+n_time_out) \n",
    "# X.shape (n_batch,n_x,n_time_in+n_time_out)\n",
    "# insample_mask.shape (n_batch,n_time_in+n_time_out)\n",
    "# summary(model, input_size=[(256, 1), (256, 168+24), (256, 10, 168+24), (256, 168+24)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-BEATS model wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import time\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch import optim\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from nixtlats.losses.pytorch import (\n",
    "    MAPELoss, MASELoss, SMAPELoss, \n",
    "    MSELoss, MAELoss, PinballLoss\n",
    ")\n",
    "from nixtlats.losses.numpy import (\n",
    "    mae, mse, mape, \n",
    "    smape, rmse, pinball_loss\n",
    ")\n",
    "\n",
    "from nixtlats.data.tsdataset import WindowsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NBEATS(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 n_time_in,\n",
    "                 n_time_out,\n",
    "                 n_x,\n",
    "                 n_x_hidden,\n",
    "                 n_s,\n",
    "                 n_s_hidden,\n",
    "                 shared_weights,\n",
    "                 activation,\n",
    "                 initialization,\n",
    "                 stack_types,\n",
    "                 n_blocks,\n",
    "                 n_layers,\n",
    "                 n_harmonics,\n",
    "                 n_polynomials,\n",
    "                 n_theta_hidden,\n",
    "                 batch_normalization,\n",
    "                 dropout_prob_theta,\n",
    "                 learning_rate,\n",
    "                 lr_decay,\n",
    "                 lr_decay_step_size,\n",
    "                 weight_decay,\n",
    "                 loss_train,\n",
    "                 loss_hypar,\n",
    "                 loss_valid,\n",
    "                 frequency,\n",
    "                 random_seed,\n",
    "                 seasonality):\n",
    "        super(NBEATS, self).__init__()\n",
    "        \"\"\"\n",
    "        N-BEATS model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        # TODO: Fix parameters' documentation.\n",
    "        # TODO: Remove useless parameters (dropout_prob_exogenous).\n",
    "        n_time_in: int\n",
    "            Multiplier to get insample size.\n",
    "            Insample size = n_time_in * output_size\n",
    "        n_time_out: int\n",
    "            Forecast horizon.\n",
    "        shared_weights: bool\n",
    "            If True, repeats first block.\n",
    "        activation: str\n",
    "            Activation function.\n",
    "            An item from ['relu', 'softplus', 'tanh', 'selu', 'lrelu', 'prelu', 'sigmoid'].\n",
    "        initialization: str\n",
    "            Initialization function.\n",
    "            An item from ['orthogonal', 'he_uniform', 'glorot_uniform', 'glorot_normal', 'lecun_normal'].\n",
    "        stack_types: List[str]\n",
    "            List of stack types.\n",
    "            Subset from ['seasonality', 'trend', 'identity', 'exogenous', 'exogenous_tcn', 'exogenous_wavenet'].\n",
    "        n_blocks: List[int]\n",
    "            Number of blocks for each stack type.\n",
    "            Note that len(n_blocks) = len(stack_types).\n",
    "        n_layers: List[int]\n",
    "            Number of layers for each stack type.\n",
    "            Note that len(n_layers) = len(stack_types).\n",
    "        n_hidden: List[List[int]]\n",
    "            Structure of hidden layers for each stack type.\n",
    "            Each internal list should contain the number of units of each hidden layer.\n",
    "            Note that len(n_hidden) = len(stack_types).\n",
    "        n_harmonics: List[int]\n",
    "            Number of harmonic terms for each stack type.\n",
    "            Note that len(n_harmonics) = len(stack_types).\n",
    "        n_polynomials: List[int]\n",
    "            Number of polynomial terms for each stack type.\n",
    "            Note that len(n_polynomials) = len(stack_types).\n",
    "        exogenous_n_channels:\n",
    "            Exogenous channels for non-interpretable exogenous basis.\n",
    "        batch_normalization: bool\n",
    "            Whether perform batch normalization. \n",
    "        dropout_prob_theta: float\n",
    "            Float between (0, 1).\n",
    "            Dropout for Nbeats basis.\n",
    "        dropout_prob_exogenous: float\n",
    "            Float between (0, 1).\n",
    "            Dropout for exogenous basis.\n",
    "        x_s_n_hidden: int\n",
    "            Number of encoded static features to calculate.\n",
    "        learning_rate: float\n",
    "            Learning rate between (0, 1).\n",
    "        lr_decay: float\n",
    "            Decreasing multiplier for the learning rate.\n",
    "        lr_decay_step_size: int\n",
    "            Steps between each lerning rate decay.\n",
    "        weight_decay: float\n",
    "            L2 penalty for optimizer.\n",
    "        loss_train: str\n",
    "            Loss to optimize.\n",
    "            An item from ['MAPE', 'MASE', 'SMAPE', 'MSE', 'MAE', 'PINBALL', 'PINBALL2'].\n",
    "        loss_hypar:\n",
    "            Hyperparameter for chosen loss.\n",
    "        loss_valid:\n",
    "            Validation loss.\n",
    "            An item from ['MAPE', 'MASE', 'SMAPE', 'RMSE', 'MAE', 'PINBALL'].\n",
    "        frequency: str\n",
    "            Time series frequency.\n",
    "        random_seed: int\n",
    "            random_seed for pseudo random pytorch initializer and\n",
    "            numpy random generator.\n",
    "        seasonality: int\n",
    "            Time series seasonality.\n",
    "            Usually 7 for daily data, 12 for monthly data and 4 for weekly data.\n",
    "        \"\"\"\n",
    "\n",
    "        if activation == 'SELU': initialization = 'lecun_normal'\n",
    "\n",
    "        #------------------------ Model Attributes ------------------------#\n",
    "        # Architecture parameters\n",
    "        self.n_time_in = n_time_in\n",
    "        self.n_time_out = n_time_out\n",
    "        self.n_x = n_x\n",
    "        self.n_x_hidden = n_x_hidden\n",
    "        self.n_s = n_s\n",
    "        self.n_s_hidden = n_s_hidden\n",
    "        self.shared_weights = shared_weights\n",
    "        self.activation = activation\n",
    "        self.initialization = initialization\n",
    "        self.stack_types = stack_types\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_layers = n_layers\n",
    "        self.n_harmonics = n_harmonics\n",
    "        self.n_polynomials = n_polynomials\n",
    "        self.n_theta_hidden = n_theta_hidden\n",
    "\n",
    "        # Loss functions\n",
    "        self.loss_train = loss_train\n",
    "        self.loss_hypar = loss_hypar\n",
    "        self.loss_valid = loss_valid\n",
    "        self.loss_fn_train = self.__loss_fn(self.loss_train)\n",
    "        self.loss_fn_valid = self.__val_loss_fn(self.loss_valid) #Uses numpy losses\n",
    "        \n",
    "        # Regularization and optimization parameters\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.dropout_prob_theta = dropout_prob_theta        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.lr_decay = lr_decay\n",
    "        self.weight_decay = weight_decay\n",
    "        self.lr_decay_step_size = lr_decay_step_size\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        # Data parameters\n",
    "        self.frequency = frequency\n",
    "        self.seasonality = seasonality\n",
    "        self.return_decomposition = False\n",
    "\n",
    "        self.model = _NBEATS(n_time_in=self.n_time_in,\n",
    "                             n_time_out=self.n_time_out,\n",
    "                             n_s=self.n_s,\n",
    "                             n_x=self.n_x,\n",
    "                             n_s_hidden=self.n_s_hidden,\n",
    "                             n_x_hidden=self.n_x_hidden,\n",
    "                             n_polynomials=self.n_polynomials,\n",
    "                             n_harmonics=self.n_harmonics,\n",
    "                             stack_types=self.stack_types,\n",
    "                             n_blocks=self.n_blocks,\n",
    "                             n_layers=self.n_layers,\n",
    "                             n_theta_hidden=self.n_theta_hidden,\n",
    "                             dropout_prob_theta=self.dropout_prob_theta,\n",
    "                             activation=self.activation,\n",
    "                             initialization=self.initialization,\n",
    "                             batch_normalization=self.batch_normalization,\n",
    "                             shared_weights=self.shared_weights)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        S = batch['S']\n",
    "        Y = batch['Y']\n",
    "        X = batch['X']\n",
    "        available_mask = batch['available_mask']\n",
    "\n",
    "        outsample_y, forecast, outsample_mask = self.model(S=S, Y=Y, X=X,\n",
    "                                                           insample_mask=available_mask,\n",
    "                                                           return_decomposition=False)\n",
    "\n",
    "        loss = self.loss_fn_train(x=Y, # TODO: eliminate only useful for MASE \n",
    "                                  loss_hypar=self.loss_hypar, \n",
    "                                  forecast=forecast,\n",
    "                                  target=outsample_y, \n",
    "                                  mask=outsample_mask)\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, idx):\n",
    "        S = batch['S']\n",
    "        Y = batch['Y']\n",
    "        X = batch['X']\n",
    "        available_mask = batch['available_mask']\n",
    "\n",
    "        outsample_y, forecast, outsample_mask = self.model(S=S, Y=Y, X=X,\n",
    "                                                           insample_mask=available_mask,\n",
    "                                                           return_decomposition=False)\n",
    "\n",
    "        loss = self.loss_fn_valid(forecast=forecast,\n",
    "                                  target=outsample_y,\n",
    "                                  weights=outsample_mask)\n",
    "\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def on_fit_start(self):\n",
    "        t.manual_seed(self.random_seed)\n",
    "        np.random.seed(self.random_seed)\n",
    "        random.seed(self.random_seed) #TODO: interaccion rara con window_sampling de validacion\n",
    "\n",
    "    def forward(self, batch):\n",
    "        S = batch['S']\n",
    "        Y = batch['Y']\n",
    "        X = batch['X']\n",
    "        available_mask = batch['available_mask']\n",
    "        outsample_mask = batch['sample_mask'][:, -self.n_time_out:]\n",
    "\n",
    "        if self.return_decomposition:\n",
    "            outsample_y, forecast, block_forecast, outsample_mask = self.model(S=S, Y=Y, X=X,\n",
    "                                                                     insample_mask=available_mask,\n",
    "                                                                     return_decomposition=True)\n",
    "            return outsample_y, forecast, block_forecast, outsample_mask\n",
    "\n",
    "        outsample_y, forecast, outsample_mask = self.model(S=S, Y=Y, X=X,\n",
    "                                                           insample_mask=available_mask,\n",
    "                                                           return_decomposition=False)\n",
    "        return outsample_y, forecast, outsample_mask\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.model.parameters(),\n",
    "                               lr=self.learning_rate, \n",
    "                               weight_decay=self.weight_decay)\n",
    "        \n",
    "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                                 step_size=self.lr_decay_step_size, \n",
    "                                                 gamma=self.lr_decay)\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': lr_scheduler}\n",
    "\n",
    "    def __loss_fn(self, loss_name: str):\n",
    "        def loss(x, loss_hypar, forecast, target, mask):\n",
    "            if loss_name == 'MAPE':\n",
    "                return MAPELoss(y=target, y_hat=forecast, mask=mask)\n",
    "            elif loss_name == 'MASE':\n",
    "                return MASELoss(y=target, y_hat=forecast, y_insample=x, \n",
    "                                seasonality=loss_hypar, mask=mask)\n",
    "            elif loss_name == 'SMAPE':\n",
    "                return SMAPELoss(y=target, y_hat=forecast, mask=mask)\n",
    "            elif loss_name == 'MSE':\n",
    "                return MSELoss(y=target, y_hat=forecast, mask=mask)\n",
    "            elif loss_name == 'MAE':\n",
    "                return MAELoss(y=target, y_hat=forecast, mask=mask)\n",
    "            elif loss_name == 'PINBALL':\n",
    "                return PinballLoss(y=target, y_hat=forecast, mask=mask, tau=loss_hypar)\n",
    "            else:\n",
    "                raise Exception(f'Unknown loss function: {loss_name}')\n",
    "        return loss\n",
    "\n",
    "    def __val_loss_fn(self, loss_name: str):\n",
    "        #TODO: mase not implemented\n",
    "        def loss(forecast, target, weights):\n",
    "            forecast = forecast.detach().numpy()\n",
    "            target = target.detach().numpy()\n",
    "            weights = weights.detach().numpy()\n",
    "\n",
    "            if loss_name == 'MAPE':\n",
    "                return mape(y=target, y_hat=forecast, weights=weights)\n",
    "            elif loss_name == 'SMAPE':\n",
    "                return smape(y=target, y_hat=forecast, weights=weights)\n",
    "            elif loss_name == 'MSE':\n",
    "                return mse(y=target, y_hat=forecast, weights=weights)\n",
    "            elif loss_name == 'RMSE':\n",
    "                return rmse(y=target, y_hat=forecast, weights=weights)\n",
    "            elif loss_name == 'MAE':\n",
    "                return mae(y=target, y_hat=forecast, weights=weights)\n",
    "            elif loss_name == 'PINBALL':\n",
    "                return pinball_loss(y=target, y_hat=forecast, weights=weights, tau=0.5)\n",
    "            else:\n",
    "                raise Exception(f'Unknown loss function: {loss_name}')\n",
    "        return loss\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-BEATS Usage Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "import pandas as pd\n",
    "from nixtlats.data.datasets.epf import EPF#, EPFInfo\n",
    "from nixtlats.data.tsloader import TimeSeriesLoader\n",
    "\n",
    "import pylab as plt\n",
    "from pylab import rcParams\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "FONTSIZE = 19\n",
    "\n",
    "# Load and plot data\n",
    "Y_df, X_df, S_df = EPF.load_groups(directory='./data', groups=['NP'])\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "plt.plot(Y_df.ds, Y_df.y.values, color='#628793', linewidth=0.4)\n",
    "plt.ylabel('Price [EUR/MWh]', fontsize=19)\n",
    "plt.xlabel('Date', fontsize=15)\n",
    "# plt.savefig('./results/NP.png', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare Model and Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "model                                                      nbeats\n",
      "mode                                                       simple\n",
      "activation                                                   SELU\n",
      "n_time_in                                                     168\n",
      "n_time_out                                                    168\n",
      "n_x_hidden                                                      8\n",
      "n_s_hidden                                                      0\n",
      "stack_types               [trend, seasonality, exogenous_wavenet]\n",
      "n_blocks                                                [1, 1, 1]\n",
      "n_layers                                                [2, 2, 2]\n",
      "n_hidden                                                      128\n",
      "shared_weights                                              False\n",
      "n_harmonics                                                     2\n",
      "n_polynomials                                                   4\n",
      "initialization                                       lecun_normal\n",
      "learning_rate                                              0.0005\n",
      "batch_size                                                    256\n",
      "lr_decay                                                      0.5\n",
      "lr_decay_step_size                                              2\n",
      "max_epochs                                                      1\n",
      "max_steps                                                      20\n",
      "early_stop_patience                                            20\n",
      "eval_freq                                                     500\n",
      "batch_normalization                                         False\n",
      "dropout_prob_theta                                              0\n",
      "dropout_prob_exogenous                                          0\n",
      "l1_theta                                                        0\n",
      "weight_decay                                              0.00006\n",
      "loss_train                                                    MAE\n",
      "loss_hypar                                                    0.5\n",
      "loss_valid                                                    MAE\n",
      "random_seed                                                     1\n",
      "len_sample_chunks                                            None\n",
      "idx_to_sample_freq                                              1\n",
      "val_idx_to_sample_freq                                        168\n",
      "n_val_weeks                                                    52\n",
      "window_sampling_limit                                      500000\n",
      "normalizer_y                                                 None\n",
      "normalizer_x                                               median\n",
      "complete_inputs                                             False\n",
      "frequency                                                       H\n",
      "seasonality                                                    24\n",
      "dtype: object\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Architecture parameters\n",
    "mc = {}\n",
    "mc['model'] = 'nbeats'\n",
    "mc['mode'] = 'simple'\n",
    "mc['activation'] = 'SELU'\n",
    "\n",
    "mc['n_time_in'] = 24*7\n",
    "mc['n_time_out'] = 24*7\n",
    "mc['n_x_hidden'] = 8\n",
    "mc['n_s_hidden'] = 0\n",
    "\n",
    "# mc['input_size_multiplier'] = 7\n",
    "# mc['output_size'] = 24\n",
    "\n",
    "mc['stack_types'] = ['trend', 'seasonality', 'exogenous_wavenet']\n",
    "mc['n_blocks'] = [1, 1, 1]\n",
    "mc['n_layers'] = [2, 2, 2]\n",
    "# mc['stack_types'] = ['trend', 'seasonality']\n",
    "# mc['n_blocks'] = [1, 1]\n",
    "# mc['n_layers'] = [2, 2]\n",
    "\n",
    "mc['n_hidden'] = 128\n",
    "mc['shared_weights'] = False\n",
    "mc['n_harmonics'] = 4\n",
    "mc['n_polynomials'] = 2\n",
    "\n",
    "# Optimization and regularization parameters\n",
    "mc['initialization'] = 'lecun_normal'\n",
    "mc['learning_rate'] = 0.0007\n",
    "mc['batch_size'] = 128\n",
    "mc['lr_decay'] = 0.5\n",
    "mc['lr_decay_step_size'] = 2\n",
    "mc['max_epochs'] = 1#_000\n",
    "mc['max_steps'] = 20#_000\n",
    "mc['early_stop_patience'] = 20\n",
    "mc['eval_freq'] = 500\n",
    "mc['batch_normalization'] = False\n",
    "mc['dropout_prob_theta'] = 0.51\n",
    "mc['dropout_prob_exogenous'] = 0.44\n",
    "mc['l1_theta'] = 0\n",
    "mc['weight_decay'] = 0\n",
    "mc['loss_train'] = 'MAE'\n",
    "mc['loss_hypar'] = 0.5\n",
    "mc['loss_valid'] = mc['loss_train']\n",
    "mc['random_seed'] = 1\n",
    "\n",
    "# Data Parameters\n",
    "mc['len_sample_chunks'] = None\n",
    "mc['idx_to_sample_freq'] = 1\n",
    "mc['val_idx_to_sample_freq'] = 24 * 7\n",
    "mc['n_val_weeks'] = 52\n",
    "mc['window_sampling_limit'] = 500_000\n",
    "mc['normalizer_y'] = None\n",
    "mc['normalizer_x'] = 'median'\n",
    "mc['complete_inputs'] = False\n",
    "mc['frequency'] = 'H'\n",
    "mc['seasonality'] = 24\n",
    "\n",
    "# # Within decomposition\n",
    "mc['learning_rate'] = 0.0005\n",
    "mc['batch_size'] = 256\n",
    "mc['weight_decay'] = 0.00006\n",
    "mc['n_harmonics'] = 2\n",
    "mc['n_polynomials'] = 4\n",
    "mc['dropout_prob_theta'] = 0\n",
    "mc['dropout_prob_exogenous'] = 0\n",
    "\n",
    "print(65*'=')\n",
    "print(pd.Series(mc))\n",
    "print(65*'=')\n",
    "\n",
    "mc['n_theta_hidden'] = len(mc['stack_types']) * [ [int(mc['n_hidden']), int(mc['n_hidden'])] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Loaders and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Validation splits\n",
      "\n",
      "INFO:root:                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0           2016-03-08 2018-12-24 23:00:00\n",
      "          1           2013-01-01 2016-03-07 23:00:00\n",
      "INFO:root:\n",
      "Total data \t\t\t52416 time stamps \n",
      "Available percentage=100.0, \t52416 time stamps \n",
      "Insample  percentage=53.21, \t27888 time stamps \n",
      "Outsample percentage=46.79, \t24528 time stamps \n",
      "\n",
      "INFO:root:Train Validation splits\n",
      "\n",
      "INFO:root:                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0           2013-01-01 2018-12-24 23:00:00\n",
      "          1           2016-03-08 2016-12-26 23:00:00\n",
      "INFO:root:\n",
      "Total data \t\t\t52416 time stamps \n",
      "Available percentage=100.0, \t52416 time stamps \n",
      "Insample  percentage=13.46, \t7056 time stamps \n",
      "Outsample percentage=86.54, \t45360 time stamps \n",
      "\n",
      "INFO:root:Train Validation splits\n",
      "\n",
      "INFO:root:                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0           2013-01-01 2016-12-26 23:00:00\n",
      "          1           2016-12-27 2018-12-24 23:00:00\n",
      "INFO:root:\n",
      "Total data \t\t\t52416 time stamps \n",
      "Available percentage=100.0, \t52416 time stamps \n",
      "Insample  percentage=33.33, \t17472 time stamps \n",
      "Outsample percentage=66.67, \t34944 time stamps \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nixtlats.experiments.utils import create_datasets\n",
    "\n",
    "train_dataset, val_dataset, test_dataset, scaler_y = create_datasets(mc=mc,\n",
    "                                                                     S_df=S_df, Y_df=Y_df, X_df=X_df,\n",
    "                                                                     f_cols=['Exogenous1', 'Exogenous2'],\n",
    "                                                                     ds_in_val=294*24,\n",
    "                                                                     ds_in_test=728*24,\n",
    "                                                                     n_uids=None, n_val_windows=None,freq=None, \n",
    "                                                                     is_val_random=False)\n",
    "\n",
    "train_loader = TimeSeriesLoader(dataset=train_dataset,\n",
    "                                batch_size=int(mc['batch_size']),\n",
    "                                #num_workers=int(min(multiprocessing.cpu_count(), 3)),\n",
    "                                shuffle=True)\n",
    "\n",
    "val_loader = TimeSeriesLoader(dataset=val_dataset,\n",
    "                              batch_size=int(mc['batch_size']),\n",
    "                              #num_workers=int(min(multiprocessing.cpu_count(), 3)),\n",
    "                              shuffle=False)\n",
    "\n",
    "test_loader = TimeSeriesLoader(dataset=test_dataset,\n",
    "                               batch_size=int(mc['batch_size']),\n",
    "                               #num_workers=int(min(multiprocessing.cpu_count(), 3)),\n",
    "                               shuffle=False)\n",
    "\n",
    "mc['n_x'], mc['n_s'] = train_dataset.get_n_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NBEATS(n_time_in=int(mc['n_time_in']),\n",
    "               n_time_out=int(mc['n_time_out']),\n",
    "               n_x=mc['n_x'],\n",
    "               n_s=mc['n_s'],\n",
    "               n_s_hidden=int(mc['n_s_hidden']),\n",
    "               n_x_hidden=int(mc['n_x_hidden']),\n",
    "               shared_weights=mc['shared_weights'],\n",
    "               initialization=mc['initialization'],\n",
    "               activation=mc['activation'],\n",
    "               stack_types=mc['stack_types'],\n",
    "               n_blocks=mc['n_blocks'],\n",
    "               n_layers=mc['n_layers'],\n",
    "               n_theta_hidden=mc['n_theta_hidden'],\n",
    "               n_harmonics=int(mc['n_harmonics']),\n",
    "               n_polynomials=int(mc['n_polynomials']),\n",
    "               batch_normalization = mc['batch_normalization'],\n",
    "               dropout_prob_theta=mc['dropout_prob_theta'],\n",
    "               learning_rate=float(mc['learning_rate']),\n",
    "               lr_decay=float(mc['lr_decay']),\n",
    "               lr_decay_step_size=float(mc['lr_decay_step_size']),\n",
    "               weight_decay=mc['weight_decay'],\n",
    "               loss_train=mc['loss_train'],\n",
    "               loss_hypar=float(mc['loss_hypar']),\n",
    "               loss_valid=mc['loss_valid'],\n",
    "               frequency=mc['frequency'],\n",
    "               seasonality=int(mc['seasonality']),\n",
    "               random_seed=int(mc['random_seed']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/ubuntu/anaconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | _NBEATS | 1.6 M \n",
      "----------------------------------\n",
      "1.5 M     Trainable params\n",
      "113 K     Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.436     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56048764eebc49c8982f39084304548b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ubuntu/anaconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cf1813fd0844ca931e84e0cea2cf43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6346ee6a7245d58421d3d28fca89f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", \n",
    "                               min_delta=1e-4, \n",
    "                               patience=mc['early_stop_patience'],\n",
    "                               verbose=False,\n",
    "                               mode=\"min\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=mc['max_epochs'], \n",
    "                     max_steps=mc['max_steps'],\n",
    "                     gradient_clip_val=1.0,\n",
    "                     progress_bar_refresh_rate=10, \n",
    "                     log_every_n_steps=500, \n",
    "                     check_val_every_n_epoch=1,\n",
    "                     callbacks=[early_stopping])\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, predict dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "629f2fc8b3eb4b8597da090c87bd1766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs[0][0].shape torch.Size([42, 168])\n",
      "outputs[0][1].shape torch.Size([42, 168])\n",
      "outputs[0][2].shape torch.Size([42, 4, 168])\n"
     ]
    }
   ],
   "source": [
    "model.return_decomposition = True\n",
    "outputs = trainer.predict(model, val_loader)\n",
    "\n",
    "print(\"outputs[0][0].shape\", outputs[0][0].shape)\n",
    "print(\"outputs[0][1].shape\", outputs[0][1].shape)\n",
    "print(\"outputs[0][2].shape\", outputs[0][2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nixtla] *",
   "language": "python",
   "name": "conda-env-nixtla-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
