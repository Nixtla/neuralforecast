{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.deepar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepAR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DeepAR model produces probabilistic forecasts based on an autoregressive recurrent neural network optimized on panel data using cross-learning. DeepAR obtains its forecast distribution uses a Markov Chain Monte Carlo sampler with the following conditional probability:\n",
    "$$\\mathbb{P}(\\mathbf{y}_{[t+1:t+H]}|\\;\\mathbf{y}_{[:t]},\\; \\mathbf{x}^{(f)}_{[:t+H]},\\; \\mathbf{x}^{(s)})$$\n",
    "\n",
    "where $\\mathbf{x}^{(s)}$ are static exogenous inputs, $\\mathbf{x}^{(f)}_{[:t+H]}$ are future exogenous available at the time of the prediction.\n",
    "The predictions are obtained by transforming the hidden states $\\mathbf{h}_{t}$ into predictive distribution parameters $\\theta_{t}$, and then generating samples $\\mathbf{\\hat{y}}_{[t+1:t+H]}$ through Monte Carlo sampling trajectories.\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{h}_{t} &= \\textrm{RNN}([\\mathbf{y}_{t},\\mathbf{x}^{(f)}_{t},\\mathbf{x}^{(s)}], \\mathbf{h}_{t-1})\\\\\n",
    "\\mathbf{\\theta}_{t}&=\\textrm{Linear}(\\mathbf{h}_{t}) \\\\\n",
    "\\hat{y}_{t+1}&=\\textrm{sample}(\\;\\mathrm{P}(y_{t+1}\\;|\\;\\mathbf{\\theta}_{t})\\;)\n",
    "\\end{align}\n",
    "\n",
    "**References**<br>\n",
    "- [David Salinas, Valentin Flunkert, Jan Gasthaus, Tim Januschowski (2020). \"DeepAR: Probabilistic forecasting with autoregressive recurrent networks\". International Journal of Forecasting.](https://www.sciencedirect.com/science/article/pii/S0169207019301888)<br>\n",
    "- [Alexander Alexandrov et. al (2020). \"GluonTS: Probabilistic and Neural Time Series Modeling in Python\". Journal of Machine Learning Research.](https://www.jmlr.org/papers/v21/19-820.html)<br>\n",
    "\n",
    "\n",
    ":::{.callout-warning collapse=\"false\"}\n",
    "#### Exogenous Variables, Losses, and Parameters Availability\n",
    "\n",
    "Given the sampling procedure during inference, DeepAR only supports `DistributionLoss` as training loss.\n",
    "\n",
    "Note that DeepAR generates a non-parametric forecast distribution using Monte Carlo. We use this sampling procedure also during validation to make it closer to the inference procedure. Therefore, only the `MQLoss` is available for validation.\n",
    "\n",
    "Aditionally, Monte Carlo implies that historic exogenous variables are not available for the model.\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 1. DeepAR model, during training the optimization signal comes from likelihood of observations, during inference a recurrent multi-step strategy is used to generate predictive distributions.](imgs_models/deepar.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from neuralforecast.common._base_windows import BaseWindows\n",
    "from neuralforecast.losses.pytorch import DistributionLoss, MQLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import logging\n",
    "import warnings\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"Multi-Layer Perceptron Decoder\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `in_features`: int, dimension of input.<br>\n",
    "    `out_features`: int, dimension of output.<br>\n",
    "    `hidden_size`: int, dimension of hidden layers.<br>\n",
    "    `num_layers`: int, number of hidden layers.<br>\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, hidden_size, hidden_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        if hidden_layers == 0:\n",
    "            # Input layer\n",
    "            layers = [nn.Linear(in_features=in_features, out_features=out_features)]\n",
    "        else:\n",
    "            # Input layer\n",
    "            layers = [nn.Linear(in_features=in_features, out_features=hidden_size), nn.ReLU()]\n",
    "            # Hidden layers\n",
    "            for i in range(hidden_layers - 2):\n",
    "                layers += [nn.Linear(in_features=hidden_size, out_features=hidden_size), nn.ReLU()]\n",
    "            # Output layer\n",
    "            layers += [nn.Linear(in_features=hidden_size, out_features=out_features)]\n",
    "\n",
    "        # Store in layers as ModuleList\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DeepAR(BaseWindows):\n",
    "    \"\"\" DeepAR\n",
    "\n",
    "    The DeepAR model produces probabilistic forecasts based on an autoregressive recurrent neural network optimized on panel data using cross-learning. DeepAR obtains its forecast distribution uses a Markov Chain Monte Carlo sampler with the following conditional probability:\n",
    "    $$\\mathbb{P}(\\mathbf{y}_{[t+1:t+H]}|\\;\\mathbf{y}_{[:t]},\\; \\mathbf{x}^{(f)}_{[:t+H]},\\; \\mathbf{x}^{(s)})$$\n",
    "\n",
    "    where $\\mathbf{x}^{(s)}$ are static exogenous inputs, $\\mathbf{x}^{(f)}_{[:t+H]}$ are future exogenous available at the time of the prediction.\n",
    "    The predictions are obtained by transforming the hidden states $\\mathbf{h}_{t}$ into predictive distribution parameters $\\theta_{t}$, and then generating samples $\\mathbf{\\hat{y}}_{[t+1:t+H]}$ through Monte Carlo sampling trajectories.\n",
    "\n",
    "    \\begin{align}\n",
    "    \\mathbf{h}_{t} &= \\textrm{RNN}([\\mathbf{y}_{t},\\mathbf{x}^{(f)}_{t},\\mathbf{x}^{(s)}], \\mathbf{h}_{t-1})\\\\\n",
    "    \\mathbf{\\theta}_{t}&=\\textrm{Linear}(\\mathbf{h}_{t}) \\\\\n",
    "    \\hat{y}_{t+1}&=\\textrm{sample}(\\;\\mathrm{P}(y_{t+1}\\;|\\;\\mathbf{\\theta}_{t})\\;)\n",
    "    \\end{align}\n",
    "\n",
    "    **References**<br>\n",
    "    - [David Salinas, Valentin Flunkert, Jan Gasthaus, Tim Januschowski (2020). \"DeepAR: Probabilistic forecasting with autoregressive recurrent networks\". International Journal of Forecasting.](https://www.sciencedirect.com/science/article/pii/S0169207019301888)<br>\n",
    "    - [Alexander Alexandrov et. al (2020). \"GluonTS: Probabilistic and Neural Time Series Modeling in Python\". Journal of Machine Learning Research.](https://www.jmlr.org/papers/v21/19-820.html)<br>\n",
    "\n",
    "    \"\"\"\n",
    "    # Class attributes\n",
    "    SAMPLING_TYPE = 'windows'\n",
    "    \n",
    "    def __init__(self,\n",
    "                 h,\n",
    "                 input_size: int = -1,\n",
    "                 lstm_n_layers: int=2,\n",
    "                 lstm_hidden_size: int = 128,\n",
    "                 lstm_dropout: float = 0.1,\n",
    "                 decoder_hidden_layers: int = 0,\n",
    "                 decoder_hidden_size: int = 0,\n",
    "                 trajectory_samples: int = 100,\n",
    "                 futr_exog_list = None,\n",
    "                 hist_exog_list = None,\n",
    "                 stat_exog_list = None,\n",
    "                 exclude_insample_y = False,\n",
    "                 loss = DistributionLoss(distribution='StudentT', level=[80, 90], return_params=False),\n",
    "                 valid_loss = MQLoss(level=[80, 90]),\n",
    "                 max_steps: int = 1000,\n",
    "                 learning_rate: float = 1e-3,\n",
    "                 num_lr_decays: int = 3,\n",
    "                 early_stop_patience_steps: int =-1,\n",
    "                 val_check_steps: int = 100,\n",
    "                 batch_size: int = 32,\n",
    "                 valid_batch_size: Optional[int] = None,\n",
    "                 windows_batch_size: int = 1024,\n",
    "                 inference_windows_batch_size: int = -1,\n",
    "                 step_size: int = 1,\n",
    "                 scaler_type: str = 'identity',\n",
    "                 random_seed: int = 1,\n",
    "                 num_workers_loader = 0,\n",
    "                 drop_last_loader = False,\n",
    "                 **trainer_kwargs):\n",
    "\n",
    "        # DeepAR does not support historic exogenous variables\n",
    "        if hist_exog_list is not None:\n",
    "            raise Exception('DeepAR does not support historic exogenous variables.')\n",
    "\n",
    "        if exclude_insample_y:\n",
    "            raise Exception('DeepAR has no possibility for excluding y.')\n",
    "        \n",
    "        if not loss.is_distribution_output:\n",
    "            raise Exception('DeepAR only supports distributional outputs.')\n",
    "        \n",
    "        if str(type(valid_loss)) not in [\"<class 'neuralforecast.losses.pytorch.MQLoss'>\"]:\n",
    "            raise Exception('DeepAR only supports MQLoss as validation loss.')\n",
    "\n",
    "        if loss.return_params:\n",
    "            raise Exception('DeepAR does not return distribution parameters due to Monte Carlo sampling.')\n",
    "    \n",
    "        # Inherit BaseWindows class\n",
    "        super(DeepAR, self).__init__(h=h,\n",
    "                                    input_size=input_size,\n",
    "                                    futr_exog_list=futr_exog_list,\n",
    "                                    hist_exog_list=hist_exog_list,\n",
    "                                    stat_exog_list=stat_exog_list,\n",
    "                                    exclude_insample_y = exclude_insample_y,\n",
    "                                    loss=loss,\n",
    "                                    valid_loss=valid_loss,\n",
    "                                    max_steps=max_steps,\n",
    "                                    learning_rate=learning_rate,\n",
    "                                    num_lr_decays=num_lr_decays,\n",
    "                                    early_stop_patience_steps=early_stop_patience_steps,\n",
    "                                    val_check_steps=val_check_steps,\n",
    "                                    batch_size=batch_size,\n",
    "                                    windows_batch_size=windows_batch_size,\n",
    "                                    valid_batch_size=valid_batch_size,\n",
    "                                    inference_windows_batch_size=inference_windows_batch_size,\n",
    "                                    step_size=step_size,\n",
    "                                    scaler_type=scaler_type,\n",
    "                                    num_workers_loader=num_workers_loader,\n",
    "                                    drop_last_loader=drop_last_loader,\n",
    "                                    random_seed=random_seed,\n",
    "                                    **trainer_kwargs)\n",
    "\n",
    "        self.horizon_backup = self.h # Used because h=0 during training\n",
    "        self.trajectory_samples = trajectory_samples\n",
    "\n",
    "        # LSTM\n",
    "        self.encoder_n_layers = lstm_n_layers\n",
    "        self.encoder_hidden_size = lstm_hidden_size\n",
    "        self.encoder_dropout = lstm_dropout\n",
    "\n",
    "        self.futr_exog_size = len(self.futr_exog_list)\n",
    "        self.hist_exog_size = 0\n",
    "        self.stat_exog_size = len(self.stat_exog_list)\n",
    "        \n",
    "        # LSTM input size (1 for target variable y)\n",
    "        input_encoder = 1 + self.futr_exog_size + self.stat_exog_size\n",
    "\n",
    "        # Instantiate model\n",
    "        self.hist_encoder = nn.LSTM(input_size=input_encoder,\n",
    "                                    hidden_size=self.encoder_hidden_size,\n",
    "                                    num_layers=self.encoder_n_layers,\n",
    "                                    dropout=self.encoder_dropout,\n",
    "                                    batch_first=True)\n",
    "\n",
    "        # Decoder MLP\n",
    "        self.decoder = Decoder(in_features=lstm_hidden_size,\n",
    "                               out_features=self.loss.outputsize_multiplier,\n",
    "                               hidden_size=decoder_hidden_size,\n",
    "                               hidden_layers=decoder_hidden_layers)\n",
    "\n",
    "    # Override BaseWindows method\n",
    "    def training_step(self, batch, batch_idx):\n",
    "\n",
    "        # During training h=0  \n",
    "        self.h = 0\n",
    "\n",
    "        # Create and normalize windows [Ws, L, C]\n",
    "        windows = self._create_windows(batch, step='train')\n",
    "        original_insample_y = windows['temporal'][:, :, 0].clone() # windows: [B, L, Feature] -> [B, L]\n",
    "        original_insample_y = original_insample_y[:,1:] # Remove first (shift in DeepAr, cell at t outputs t+1)\n",
    "        windows = self._normalization(windows=windows)\n",
    "\n",
    "        # Parse windows\n",
    "        insample_y, insample_mask, _, _, _, futr_exog, stat_exog = self._parse_windows(batch, windows)\n",
    "\n",
    "        windows_batch = dict(insample_y=insample_y, # [Ws, L]\n",
    "                             insample_mask=insample_mask, # [Ws, L]\n",
    "                             futr_exog=futr_exog, # [Ws, L+H]\n",
    "                             hist_exog=None, # None\n",
    "                             stat_exog=stat_exog) # [Ws, 1]\n",
    "\n",
    "        # Model Predictions\n",
    "        output = self.train_forward(windows_batch)\n",
    "\n",
    "        if self.loss.is_distribution_output:\n",
    "            _, y_loc, y_scale = self._inv_normalization(y_hat=original_insample_y,\n",
    "                                            temporal_cols=batch['temporal_cols'])\n",
    "            outsample_y = original_insample_y\n",
    "            distr_args = self.loss.scale_decouple(output=output, loc=y_loc, scale=y_scale)\n",
    "            mask = insample_mask[:,1:].clone() # Remove first (shift in DeepAr, cell at t outputs t+1)\n",
    "            loss = self.loss(y=outsample_y, distr_args=distr_args, mask=mask)\n",
    "        else:\n",
    "            raise Exception('DeepAR only supports distributional outputs.')\n",
    "\n",
    "        if torch.isnan(loss):\n",
    "            print('Model Parameters', self.hparams)\n",
    "            print('insample_y', torch.isnan(insample_y).sum())\n",
    "            print('outsample_y', torch.isnan(outsample_y).sum())\n",
    "            print('output', torch.isnan(output).sum())\n",
    "            raise Exception('Loss is NaN, training stopped.')\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_epoch=True)\n",
    "        self.train_trajectories.append((self.global_step, float(loss)))\n",
    "\n",
    "        self.h = self.horizon_backup # Restore horizon\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "\n",
    "        self.h == self.horizon_backup\n",
    "\n",
    "        if self.val_size == 0:\n",
    "            return np.nan\n",
    "\n",
    "        # TODO: Hack to compute number of windows\n",
    "        windows = self._create_windows(batch, step='val')\n",
    "        n_windows = len(windows['temporal'])\n",
    "\n",
    "        # Number of windows in batch\n",
    "        windows_batch_size = self.inference_windows_batch_size\n",
    "        if windows_batch_size < 0:\n",
    "            windows_batch_size = n_windows\n",
    "        n_batches = int(np.ceil(n_windows/windows_batch_size))\n",
    "\n",
    "        valid_losses = []\n",
    "        batch_sizes = []\n",
    "        for i in range(n_batches):\n",
    "            # Create and normalize windows [Ws, L+H, C]\n",
    "            w_idxs = np.arange(i*windows_batch_size, \n",
    "                               min((i+1)*windows_batch_size, n_windows))\n",
    "            windows = self._create_windows(batch, step='val', w_idxs=w_idxs)\n",
    "            original_outsample_y = torch.clone(windows['temporal'][:,-self.h:,0])\n",
    "            windows = self._normalization(windows=windows)\n",
    "\n",
    "            # Parse windows\n",
    "            insample_y, insample_mask, _, outsample_mask, \\\n",
    "                _, futr_exog, stat_exog = self._parse_windows(batch, windows)\n",
    "            windows_batch = dict(insample_y=insample_y,\n",
    "                        insample_mask=insample_mask,\n",
    "                        futr_exog=futr_exog,\n",
    "                        hist_exog=None,\n",
    "                        stat_exog=stat_exog,\n",
    "                        temporal_cols=batch['temporal_cols']) \n",
    "            \n",
    "            # Model Predictions\n",
    "            output_batch = self(windows_batch)\n",
    "            # Monte Carlo already returns y_hat with mean and quantiles\n",
    "            output_batch = output_batch[:,:, 1:] # Remove mean\n",
    "            valid_loss_batch = self.valid_loss(y=original_outsample_y, y_hat=output_batch, mask=outsample_mask)\n",
    "            valid_losses.append(valid_loss_batch)\n",
    "            batch_sizes.append(len(output_batch))\n",
    "\n",
    "        valid_loss = torch.stack(valid_losses)\n",
    "        batch_sizes = torch.tensor(batch_sizes).to(valid_loss.device)\n",
    "        valid_loss = torch.sum(valid_loss * batch_sizes) \\\n",
    "                        / torch.sum(batch_sizes)\n",
    "\n",
    "        if torch.isnan(valid_loss):\n",
    "            raise Exception('Loss is NaN, training stopped.')\n",
    "\n",
    "        self.log('valid_loss', valid_loss, prog_bar=True, on_epoch=True)\n",
    "        self.validation_step_outputs.append(valid_loss)\n",
    "        return valid_loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "\n",
    "        self.h == self.horizon_backup\n",
    "\n",
    "        # TODO: Hack to compute number of windows\n",
    "        windows = self._create_windows(batch, step='predict')\n",
    "        n_windows = len(windows['temporal'])\n",
    "\n",
    "        # Number of windows in batch\n",
    "        windows_batch_size = self.inference_windows_batch_size\n",
    "        if windows_batch_size < 0:\n",
    "            windows_batch_size = n_windows\n",
    "        n_batches = int(np.ceil(n_windows/windows_batch_size))\n",
    "\n",
    "        y_hats = []\n",
    "        for i in range(n_batches):\n",
    "            # Create and normalize windows [Ws, L+H, C]\n",
    "            w_idxs = np.arange(i*windows_batch_size, \n",
    "                    min((i+1)*windows_batch_size, n_windows))\n",
    "            windows = self._create_windows(batch, step='predict', w_idxs=w_idxs)\n",
    "            windows = self._normalization(windows=windows)\n",
    "\n",
    "            # Parse windows\n",
    "            insample_y, insample_mask, _, _, _, futr_exog, stat_exog = self._parse_windows(batch, windows)\n",
    "            windows_batch = dict(insample_y=insample_y, # [Ws, L]\n",
    "                                insample_mask=insample_mask, # [Ws, L]\n",
    "                                futr_exog=futr_exog, # [Ws, L+H]\n",
    "                                stat_exog=stat_exog,\n",
    "                                temporal_cols=batch['temporal_cols']) \n",
    "            \n",
    "            # Model Predictions\n",
    "            y_hat = self(windows_batch)\n",
    "            # Monte Carlo already returns y_hat with mean and quantiles\n",
    "            y_hats.append(y_hat)\n",
    "        y_hat = torch.cat(y_hats, dim=0)\n",
    "        return y_hat\n",
    "\n",
    "    def train_forward(self, windows_batch):\n",
    "\n",
    "        # Parse windows_batch\n",
    "        encoder_input = windows_batch['insample_y'][:,:, None] # <- [B,T,1]\n",
    "        futr_exog  = windows_batch['futr_exog']\n",
    "        stat_exog  = windows_batch['stat_exog']\n",
    "\n",
    "        #[B, seq_len, X]\n",
    "        _, input_size = encoder_input.shape[:2]\n",
    "        if self.futr_exog_size > 0:\n",
    "            # Remove last and shift futr_exog (t predicts t+1, last output is outside insample_y)\n",
    "            encoder_input = torch.cat((encoder_input[:,:-1,:], futr_exog[:,1:,:]), dim=2)\n",
    "        if self.stat_exog_size > 0:\n",
    "            stat_exog = stat_exog.unsqueeze(1).repeat(1, input_size-1, 1) # [B, S] -> [B, input_size-1, S]\n",
    "            encoder_input = torch.cat((encoder_input, stat_exog), dim=2)\n",
    "\n",
    "        # RNN forward\n",
    "        hidden_state, _ = self.hist_encoder(encoder_input) # [B, input_size-1, rnn_hidden_state]\n",
    "\n",
    "        # Decoder forward\n",
    "        output = self.decoder(hidden_state) # [B, input_size-1, output_size]\n",
    "        output = self.loss.domain_map(output)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, windows_batch):\n",
    "\n",
    "        # Parse windows_batch\n",
    "        encoder_input = windows_batch['insample_y'][:,:, None] # <- [B,L,1]\n",
    "        futr_exog  = windows_batch['futr_exog'] # <- [B,L+H, n_f]\n",
    "        stat_exog  = windows_batch['stat_exog']\n",
    "        temporal_cols = windows_batch['temporal_cols']\n",
    "\n",
    "        #[B, seq_len, X]\n",
    "        batch_size, input_size = encoder_input.shape[:2]\n",
    "        if self.futr_exog_size > 0:\n",
    "            futr_exog_input_window = futr_exog[:,1:input_size+1,:] # Align y_t with futr_exog_t+1\n",
    "            encoder_input = torch.cat((encoder_input, futr_exog_input_window), dim=2)\n",
    "        if self.stat_exog_size > 0:\n",
    "            stat_exog_input_window = stat_exog.unsqueeze(1).repeat(1, input_size, 1) # [B, S] -> [B, input_size, S]\n",
    "            encoder_input = torch.cat((encoder_input, stat_exog_input_window), dim=2)\n",
    "\n",
    "        # Use input_size history to predict first h of the forecasting window\n",
    "        _, h_c_tuple = self.hist_encoder(encoder_input)\n",
    "        h_n = h_c_tuple[0] # [n_layers, B, lstm_hidden_state]\n",
    "        c_n = h_c_tuple[1] # [n_layers, B, lstm_hidden_state]\n",
    "\n",
    "        # Vectorizes trajectory samples in batch dimension [1]\n",
    "        h_n = torch.repeat_interleave(h_n, self.trajectory_samples, 1) # [n_layers, B*trajectory_samples, rnn_hidden_state]\n",
    "        c_n = torch.repeat_interleave(c_n, self.trajectory_samples, 1) # [n_layers, B*trajectory_samples, rnn_hidden_state]\n",
    "\n",
    "        # Scales for inverse normalization\n",
    "        y_scale = self.scaler.x_scale[:,0,temporal_cols.get_indexer(['y'])].squeeze(-1)\n",
    "        y_loc = self.scaler.x_shift[:,0,temporal_cols.get_indexer(['y'])].squeeze(-1)\n",
    "        y_scale = torch.repeat_interleave(y_scale, self.trajectory_samples, 0)\n",
    "        y_loc = torch.repeat_interleave(y_loc, self.trajectory_samples, 0)\n",
    "\n",
    "        # Recursive strategy prediction\n",
    "        quantiles = self.loss.quantiles.to(encoder_input.device)\n",
    "        y_hat = torch.zeros(batch_size, self.h, len(quantiles)+1)\n",
    "        for tau in range(self.h):\n",
    "            # Decoder forward\n",
    "            last_layer_h = h_n[-1] # [B*trajectory_samples, lstm_hidden_state]\n",
    "            output = self.decoder(last_layer_h) \n",
    "            output = self.loss.domain_map(output)\n",
    "\n",
    "            # Inverse normalization\n",
    "            distr_args = self.loss.scale_decouple(output=output, loc=y_loc, scale=y_scale)\n",
    "            # Add horizon (1) dimension\n",
    "            distr_args = list(distr_args)\n",
    "            for i in range(len(distr_args)):\n",
    "                distr_args[i] = distr_args[i].unsqueeze(-1)\n",
    "            distr_args = tuple(distr_args)\n",
    "            samples_tau, _, _ = self.loss.sample(distr_args=distr_args, num_samples=1)\n",
    "            samples_tau = samples_tau.reshape(batch_size, self.trajectory_samples)\n",
    "            sample_mean = torch.mean(samples_tau, dim=-1)\n",
    "            quants = torch.quantile(input=samples_tau, \n",
    "                                    q=quantiles, dim=-1)\n",
    "            y_hat[:,tau,0] = sample_mean\n",
    "            y_hat[:,tau,1:] = quants.permute((1,0)) # [Q, B] -> [B, Q]\n",
    "            \n",
    "            # Stop if already in the last step (no need to predict next step)\n",
    "            if tau+1 == self.h:\n",
    "                continue\n",
    "            # Normalize to use as input\n",
    "            encoder_input = self.scaler.scaler(samples_tau.flatten(), y_loc, y_scale) # [B*n_samples]\n",
    "            encoder_input = encoder_input[:, None, None] # [B*n_samples, 1, 1]\n",
    "\n",
    "            # Update input\n",
    "            if self.futr_exog_size > 0:\n",
    "                futr_exog_tau = futr_exog[:,[input_size+tau+1],:] # [B, 1, n_f]\n",
    "                futr_exog_tau = torch.repeat_interleave(futr_exog_tau, self.trajectory_samples, 0) # [B*n_samples, 1, n_f]\n",
    "                encoder_input = torch.cat((encoder_input, futr_exog_tau), dim=2) # [B*n_samples, 1, 1+n_f]\n",
    "            if self.stat_exog_size > 0:\n",
    "                stat_exog_tau = torch.repeat_interleave(stat_exog, self.trajectory_samples, 0) # [B*n_samples, n_s]\n",
    "                encoder_input = torch.cat((encoder_input, stat_exog_tau[:,None,:]), dim=2) # [B*n_samples, 1, 1+n_f+n_s]\n",
    "            \n",
    "            _, h_c_tuple = self.hist_encoder(encoder_input, (h_n, c_n))\n",
    "            h_n = h_c_tuple[0] # [n_layers, B, rnn_hidden_state]\n",
    "            c_n = h_c_tuple[1] # [n_layers, B, rnn_hidden_state]\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/models/deepar.py#L62){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DeepAR\n",
       "\n",
       ">      DeepAR (h, input_size:int=-1, lstm_n_layers:int=2,\n",
       ">              lstm_hidden_size:int=128, lstm_dropout:float=0.1,\n",
       ">              decoder_hidden_layers:int=0, decoder_hidden_size:int=0,\n",
       ">              trajectory_samples:int=100, futr_exog_list=None,\n",
       ">              hist_exog_list=None, stat_exog_list=None,\n",
       ">              exclude_insample_y=False, loss=DistributionLoss(),\n",
       ">              valid_loss=MQLoss(), max_steps:int=1000,\n",
       ">              learning_rate:float=0.001, num_lr_decays:int=3,\n",
       ">              early_stop_patience_steps:int=-1, val_check_steps:int=100,\n",
       ">              batch_size:int=32, valid_batch_size:Optional[int]=None,\n",
       ">              windows_batch_size:int=1024, inference_windows_batch_size:int=-1,\n",
       ">              step_size:int=1, scaler_type:str='identity', random_seed:int=1,\n",
       ">              num_workers_loader=0, drop_last_loader=False, **trainer_kwargs)\n",
       "\n",
       "DeepAR\n",
       "\n",
       "The DeepAR model produces probabilistic forecasts based on an autoregressive recurrent neural network optimized on panel data using cross-learning. DeepAR obtains its forecast distribution uses a Markov Chain Monte Carlo sampler with the following conditional probability:\n",
       "$$\\mathbb{P}(\\mathbf{y}_{[t+1:t+H]}|\\;\\mathbf{y}_{[:t]},\\; \\mathbf{x}^{(f)}_{[:t+H]},\\; \\mathbf{x}^{(s)})$$\n",
       "\n",
       "where $\\mathbf{x}^{(s)}$ are static exogenous inputs, $\\mathbf{x}^{(f)}_{[:t+H]}$ are future exogenous available at the time of the prediction.\n",
       "The predictions are obtained by transforming the hidden states $\\mathbf{h}_{t}$ into predictive distribution parameters $   heta_{t}$, and then generating samples $\\mathbf{\\hat{y}}_{[t+1:t+H]}$ through Monte Carlo sampling trajectories.\n",
       "\n",
       "\begin{align}\n",
       "\\mathbf{h}_{t} &=   extrm{RNN}([\\mathbf{y}_{t},\\mathbf{x}^{(f)}_{t},\\mathbf{x}^{(s)}], \\mathbf{h}_{t-1})\\\n",
       "\\mathbf{    heta}_{t}&=     extrm{Linear}(\\mathbf{h}_{t}) \\\n",
       "\\hat{y}_{t+1}&=     extrm{sample}(\\;\\mathrm{P}(y_{t+1}\\;|\\;\\mathbf{ heta}_{t})\\;)\n",
       "\\end{align}\n",
       "\n",
       "**References**<br>\n",
       "- [David Salinas, Valentin Flunkert, Jan Gasthaus, Tim Januschowski (2020). \"DeepAR: Probabilistic forecasting with autoregressive recurrent networks\". International Journal of Forecasting.](https://www.sciencedirect.com/science/article/pii/S0169207019301888)<br>\n",
       "- [Alexander Alexandrov et. al (2020). \"GluonTS: Probabilistic and Neural Time Series Modeling in Python\". Journal of Machine Learning Research.](https://www.jmlr.org/papers/v21/19-820.html)<br>"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/models/deepar.py#L62){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DeepAR\n",
       "\n",
       ">      DeepAR (h, input_size:int=-1, lstm_n_layers:int=2,\n",
       ">              lstm_hidden_size:int=128, lstm_dropout:float=0.1,\n",
       ">              decoder_hidden_layers:int=0, decoder_hidden_size:int=0,\n",
       ">              trajectory_samples:int=100, futr_exog_list=None,\n",
       ">              hist_exog_list=None, stat_exog_list=None,\n",
       ">              exclude_insample_y=False, loss=DistributionLoss(),\n",
       ">              valid_loss=MQLoss(), max_steps:int=1000,\n",
       ">              learning_rate:float=0.001, num_lr_decays:int=3,\n",
       ">              early_stop_patience_steps:int=-1, val_check_steps:int=100,\n",
       ">              batch_size:int=32, valid_batch_size:Optional[int]=None,\n",
       ">              windows_batch_size:int=1024, inference_windows_batch_size:int=-1,\n",
       ">              step_size:int=1, scaler_type:str='identity', random_seed:int=1,\n",
       ">              num_workers_loader=0, drop_last_loader=False, **trainer_kwargs)\n",
       "\n",
       "DeepAR\n",
       "\n",
       "The DeepAR model produces probabilistic forecasts based on an autoregressive recurrent neural network optimized on panel data using cross-learning. DeepAR obtains its forecast distribution uses a Markov Chain Monte Carlo sampler with the following conditional probability:\n",
       "$$\\mathbb{P}(\\mathbf{y}_{[t+1:t+H]}|\\;\\mathbf{y}_{[:t]},\\; \\mathbf{x}^{(f)}_{[:t+H]},\\; \\mathbf{x}^{(s)})$$\n",
       "\n",
       "where $\\mathbf{x}^{(s)}$ are static exogenous inputs, $\\mathbf{x}^{(f)}_{[:t+H]}$ are future exogenous available at the time of the prediction.\n",
       "The predictions are obtained by transforming the hidden states $\\mathbf{h}_{t}$ into predictive distribution parameters $   heta_{t}$, and then generating samples $\\mathbf{\\hat{y}}_{[t+1:t+H]}$ through Monte Carlo sampling trajectories.\n",
       "\n",
       "\begin{align}\n",
       "\\mathbf{h}_{t} &=   extrm{RNN}([\\mathbf{y}_{t},\\mathbf{x}^{(f)}_{t},\\mathbf{x}^{(s)}], \\mathbf{h}_{t-1})\\\n",
       "\\mathbf{    heta}_{t}&=     extrm{Linear}(\\mathbf{h}_{t}) \\\n",
       "\\hat{y}_{t+1}&=     extrm{sample}(\\;\\mathrm{P}(y_{t+1}\\;|\\;\\mathbf{ heta}_{t})\\;)\n",
       "\\end{align}\n",
       "\n",
       "**References**<br>\n",
       "- [David Salinas, Valentin Flunkert, Jan Gasthaus, Tim Januschowski (2020). \"DeepAR: Probabilistic forecasting with autoregressive recurrent networks\". International Journal of Forecasting.](https://www.sciencedirect.com/science/article/pii/S0169207019301888)<br>\n",
       "- [Alexander Alexandrov et. al (2020). \"GluonTS: Probabilistic and Neural Time Series Modeling in Python\". Journal of Machine Learning Research.](https://www.jmlr.org/papers/v21/19-820.html)<br>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DeepAR, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### DeepAR.fit\n",
       "\n",
       ">      DeepAR.fit (dataset, val_size=0, test_size=0, random_seed=None)\n",
       "\n",
       "Fit.\n",
       "\n",
       "The `fit` method, optimizes the neural network's weights using the\n",
       "initialization parameters (`learning_rate`, `windows_batch_size`, ...)\n",
       "and the `loss` function as defined during the initialization.\n",
       "Within `fit` we use a PyTorch Lightning `Trainer` that\n",
       "inherits the initialization's `self.trainer_kwargs`, to customize\n",
       "its inputs, see [PL's trainer arguments](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).\n",
       "\n",
       "The method is designed to be compatible with SKLearn-like classes\n",
       "and in particular to be compatible with the StatsForecast library.\n",
       "\n",
       "By default the `model` is not saving training checkpoints to protect\n",
       "disk memory, to get them change `enable_checkpointing=True` in `__init__`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`val_size`: int, validation size for temporal cross-validation.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`test_size`: int, test size for temporal cross-validation.<br>"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### DeepAR.fit\n",
       "\n",
       ">      DeepAR.fit (dataset, val_size=0, test_size=0, random_seed=None)\n",
       "\n",
       "Fit.\n",
       "\n",
       "The `fit` method, optimizes the neural network's weights using the\n",
       "initialization parameters (`learning_rate`, `windows_batch_size`, ...)\n",
       "and the `loss` function as defined during the initialization.\n",
       "Within `fit` we use a PyTorch Lightning `Trainer` that\n",
       "inherits the initialization's `self.trainer_kwargs`, to customize\n",
       "its inputs, see [PL's trainer arguments](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).\n",
       "\n",
       "The method is designed to be compatible with SKLearn-like classes\n",
       "and in particular to be compatible with the StatsForecast library.\n",
       "\n",
       "By default the `model` is not saving training checkpoints to protect\n",
       "disk memory, to get them change `enable_checkpointing=True` in `__init__`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`val_size`: int, validation size for temporal cross-validation.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`test_size`: int, test size for temporal cross-validation.<br>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DeepAR.fit, name='DeepAR.fit', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### DeepAR.predict\n",
       "\n",
       ">      DeepAR.predict (dataset, test_size=None, step_size=1, random_seed=None,\n",
       ">                      **data_module_kwargs)\n",
       "\n",
       "Predict.\n",
       "\n",
       "Neural network prediction with PL's `Trainer` execution of `predict_step`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`test_size`: int=None, test size for temporal cross-validation.<br>\n",
       "`step_size`: int=1, Step size between each window.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`**data_module_kwargs`: PL's TimeSeriesDataModule args, see [documentation](https://pytorch-lightning.readthedocs.io/en/1.6.1/extensions/datamodules.html#using-a-datamodule)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### DeepAR.predict\n",
       "\n",
       ">      DeepAR.predict (dataset, test_size=None, step_size=1, random_seed=None,\n",
       ">                      **data_module_kwargs)\n",
       "\n",
       "Predict.\n",
       "\n",
       "Neural network prediction with PL's `Trainer` execution of `predict_step`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`test_size`: int=None, test size for temporal cross-validation.<br>\n",
       "`step_size`: int=1, Step size between each window.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`**data_module_kwargs`: PL's TimeSeriesDataModule args, see [documentation](https://pytorch-lightning.readthedocs.io/en/1.6.1/extensions/datamodules.html#using-a-datamodule)."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DeepAR.predict, name='DeepAR.predict', title_level=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.losses.pytorch import MQLoss, DistributionLoss, GMM, PMM\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset\n",
    "from neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s, v_num=108, train_loss_step=4.010, train_loss_epoch=4.010, valid_loss=4.530]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "#from neuralforecast.models import DeepAR\n",
    "from neuralforecast.losses.pytorch import DistributionLoss, HuberMQLoss\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset\n",
    "from neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic\n",
    "\n",
    "#AirPassengersPanel['y'] = AirPassengersPanel['y'] + 10\n",
    "Y_train_df = AirPassengersPanel[AirPassengersPanel.ds<AirPassengersPanel['ds'].values[-12]] # 132 train\n",
    "Y_test_df = AirPassengersPanel[AirPassengersPanel.ds>=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n",
    "\n",
    "nf = NeuralForecast(\n",
    "    models=[DeepAR(h=12,\n",
    "                   input_size=48,\n",
    "                   lstm_n_layers=3,\n",
    "                   trajectory_samples=100,\n",
    "                   loss=DistributionLoss(distribution='Normal', level=[80, 90], return_params=False),\n",
    "                   learning_rate=0.005,\n",
    "                   stat_exog_list=['airline1'],\n",
    "                   futr_exog_list=['trend'],\n",
    "                   max_steps=100,\n",
    "                   val_check_steps=10,\n",
    "                   early_stop_patience_steps=-1,\n",
    "                   scaler_type='standard',\n",
    "                   enable_progress_bar=True),\n",
    "    ],\n",
    "    freq='M'\n",
    ")\n",
    "nf.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\n",
    "Y_hat_df = nf.predict(futr_df=Y_test_df)\n",
    "\n",
    "# Plot quantile predictions\n",
    "Y_hat_df = Y_hat_df.reset_index(drop=False).drop(columns=['unique_id','ds'])\n",
    "plot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\n",
    "plot_df = pd.concat([Y_train_df, plot_df])\n",
    "\n",
    "plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n",
    "plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n",
    "#plt.plot(plot_df['ds'], plot_df['DeepAR'], c='purple', label='mean')\n",
    "plt.plot(plot_df['ds'], plot_df['DeepAR-median'], c='blue', label='median')\n",
    "plt.fill_between(x=plot_df['ds'][-12:], \n",
    "                 y1=plot_df['DeepAR-lo-90'][-12:].values, \n",
    "                 y2=plot_df['DeepAR-hi-90'][-12:].values,\n",
    "                 alpha=0.4, label='level 90')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
