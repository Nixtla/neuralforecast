{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.datasets.ett"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electricity Transformer (ETT) dataset\n",
    "\n",
    "> Download the ETT dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nixtlats.data.datasets.utils import download_file, Info, time_features_from_frequency_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETT meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class ETTh1:\n",
    "    freq: str = 'H'\n",
    "    name: str = 'ETTh1'\n",
    "    n_ts: int = 7\n",
    "\n",
    "@dataclass\n",
    "class ETTh2:\n",
    "    freq: str = 'H'\n",
    "    name: str = 'ETTh2'\n",
    "    n_ts: int = 7\n",
    "\n",
    "@dataclass\n",
    "class ETTm1:\n",
    "    freq: str = '15T'\n",
    "    name: str = 'ETTm1'\n",
    "    n_ts: int = 7\n",
    "\n",
    "@dataclass\n",
    "class ETTm2:\n",
    "    freq: str = '15T'\n",
    "    name: str = 'ETTm2'\n",
    "    n_ts: int = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "ETTInfo = Info(groups=('ETTh1', 'ETTh2', 'ETTm1', 'ETTm2'),\n",
    "               class_groups=(ETTh1, ETTh2, ETTm1, ETTm2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class ETT:\n",
    "    \n",
    "    source_url: str = 'https://raw.githubusercontent.com/zhouhaoyi/ETDataset/main/ETT-small/'\n",
    "\n",
    "    @staticmethod\n",
    "    def load(directory: str,\n",
    "             group: str,\n",
    "             cache: bool = True) -> Tuple[pd.DataFrame, \n",
    "                                          Optional[pd.DataFrame], \n",
    "                                          Optional[pd.DataFrame]]:\n",
    "        \"\"\"Downloads and loads ETT data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'ETTh1', 'ETTh2', \n",
    "                            'ETTm1', 'ETTm2'.\n",
    "        cache: bool\n",
    "            If `True` saves and loads \n",
    "            \n",
    "        Notes\n",
    "        -----\n",
    "        [1] Returns train+val+test sets.\n",
    "        \"\"\"\n",
    "        path = f'{directory}/ett/datasets'\n",
    "        file_cache = f'{path}/{group}.p'\n",
    "        \n",
    "        if os.path.exists(file_cache) and cache:\n",
    "            df, X_df, S_df = pd.read_pickle(file_cache)\n",
    "            \n",
    "            return df, X_df, S_df\n",
    "        \n",
    "        \n",
    "        ETT.download(directory)\n",
    "        path = f'{directory}/ett/datasets'\n",
    "        class_group = ETTInfo[group]\n",
    "        \n",
    "        y_df = pd.read_csv(f'{path}/{group}.csv')\n",
    "        y_df['date'] = pd.to_datetime(y_df['date'])\n",
    "        y_df.rename(columns={'date': 'ds'}, inplace=True)\n",
    "        u_ids = y_df.columns.to_list()\n",
    "        u_ids.remove('ds')\n",
    "        \n",
    "        time_cls = time_features_from_frequency_str('h')\n",
    "        for cls_ in time_cls:\n",
    "            cls_name = cls_.__class__.__name__\n",
    "            y_df[cls_name] = cls_(y_df['ds'].dt)\n",
    "\n",
    "        X_df = y_df.drop(u_ids, axis=1)\n",
    "        y_df = y_df.filter(items=['ds'] + u_ids)\n",
    "        y_df = y_df.set_index('ds').stack()\n",
    "        y_df = y_df.rename('y').rename_axis(['ds', 'unique_id']).reset_index()\n",
    "        y_df['unique_id'] = pd.Categorical(y_df['unique_id'], u_ids)\n",
    "        y_df = y_df[['unique_id', 'ds', 'y']].sort_values(['unique_id', 'ds'])\n",
    "        \n",
    "        X_df = y_df[['unique_id', 'ds']].merge(X_df, how='left', on=['ds'])\n",
    "       \n",
    "        S_df = None\n",
    "        if cache:\n",
    "            pd.to_pickle((y_df, X_df, S_df), file_cache)\n",
    "            \n",
    "        return y_df, X_df, S_df\n",
    "\n",
    "    @staticmethod\n",
    "    def download(directory: str) -> None:\n",
    "        \"\"\"Download ETT Dataset.\"\"\"\n",
    "        path = f'{directory}/ett/datasets/'\n",
    "        if not os.path.exists(path):\n",
    "            for group in ETTInfo.groups:\n",
    "                download_file(path, f'{ETT.source_url}/{group}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: ETTh1 n_series: 7 ex_vars: HourOfDay, DayOfWeek, DayOfMonth, DayOfYear\n",
      "Group: ETTh2 n_series: 7 ex_vars: HourOfDay, DayOfWeek, DayOfMonth, DayOfYear\n",
      "Group: ETTm1 n_series: 7 ex_vars: HourOfDay, DayOfWeek, DayOfMonth, DayOfYear\n",
      "Group: ETTm2 n_series: 7 ex_vars: HourOfDay, DayOfWeek, DayOfMonth, DayOfYear\n"
     ]
    }
   ],
   "source": [
    "for group, meta in ETTInfo:\n",
    "    y_df, x_df, s_df = ETT.load(directory='data', group=group, cache=False)\n",
    "    n_series = len(np.unique(y_df.unique_id.values))\n",
    "    ex_vars = x_df.columns.to_list()\n",
    "    ex_vars.remove('unique_id')\n",
    "    ex_vars.remove('ds')\n",
    "\n",
    "    display_str  = f'Group: {group} '\n",
    "    display_str += f'n_series: {n_series} '\n",
    "    display_str += f'ex_vars: {\", \".join(ex_vars)}'\n",
    "\n",
    "    print(display_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_group(group: str, expected_first_ds_y: np.ndarray,\n",
    "               expected_first_ds_x: np.ndarray) -> None:\n",
    "    y_df, x_df, _ = ETT.load(directory='data', group=group, cache=False)\n",
    "    first_ds_y = y_df.groupby('unique_id').head(1)['y'].values\n",
    "    first_ds_x = x_df.groupby('unique_id').head(1).drop(['unique_id', 'ds'], axis=1).values\n",
    "    expected_x = np.repeat(expected_first_ds_x.reshape(1, -1), first_ds_x.shape[0], axis=0)\n",
    "    \n",
    "    np.testing.assert_array_almost_equal(first_ds_y, expected_first_ds_y)\n",
    "    np.testing.assert_array_almost_equal(first_ds_x, expected_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_group(group='ETTh1', \n",
    "           expected_first_ds_y=np.array([ 5.82700014,  2.00900006,  1.59899998,  0.46200001,  4.20300007, 1.34000003, 30.53100014]),\n",
    "           expected_first_ds_x=np.array([-0.5       ,  0.16666667, -0.5       , -0.00136986]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_group(group='ETTh2', \n",
    "           expected_first_ds_y=np.array([41.13000107, 12.48099995, 36.5359993 ,  9.35499954,  4.42399979, 1.31099999, 38.66199875]),\n",
    "           expected_first_ds_x=np.array([-0.5       ,  0.16666667, -0.5       , -0.00136986]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_group(group='ETTm1', \n",
    "           expected_first_ds_y=np.array([ 5.82700014,  2.00900006,  1.59899998,  0.46200001,  4.20300007, 1.34000003, 30.53100014]),\n",
    "           expected_first_ds_x=np.array([-0.5       ,  0.16666667, -0.5       , -0.00136986]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_group(group='ETTm2', \n",
    "           expected_first_ds_y=np.array([41.13000107, 12.48099995, 36.5359993 ,  9.35499954,  4.42399979, 1.31099999, 38.66199875]),\n",
    "           expected_first_ds_x=np.array([-0.5       ,  0.16666667, -0.5       , -0.00136986]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
