{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.patchtst"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PatchTST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PatchTST ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**<br>\n",
    "- [Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, Wancai Zhang. \"Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting\"](https://arxiv.org/abs/2012.07436)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cchallu/opt/anaconda3/envs/neuralforecast/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import math\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from neuralforecast.common._base_windows import BaseWindows\n",
    "\n",
    "from neuralforecast.losses.pytorch import MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Backbone"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transpose(nn.Module):\n",
    "    def __init__(self, *dims, contiguous=False): \n",
    "        super().__init__()\n",
    "        self.dims, self.contiguous = dims, contiguous\n",
    "    def forward(self, x):\n",
    "        if self.contiguous: return x.transpose(*self.dims).contiguous()\n",
    "        else: return x.transpose(*self.dims)\n",
    "\n",
    "def get_activation_fn(activation):\n",
    "    if callable(activation): return activation()\n",
    "    elif activation.lower() == \"relu\": return nn.ReLU()\n",
    "    elif activation.lower() == \"gelu\": return nn.GELU()\n",
    "    raise ValueError(f'{activation} is not available. You can use \"relu\", \"gelu\", or a callable') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def PositionalEncoding(q_len, d_model, normalize=True):\n",
    "    pe = torch.zeros(q_len, d_model)\n",
    "    position = torch.arange(0, q_len).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    if normalize:\n",
    "        pe = pe - pe.mean()\n",
    "        pe = pe / (pe.std() * 10)\n",
    "    return pe\n",
    "\n",
    "SinCosPosEncoding = PositionalEncoding\n",
    "\n",
    "def Coord2dPosEncoding(q_len, d_model, exponential=False, normalize=True, eps=1e-3):\n",
    "    x = .5 if exponential else 1\n",
    "    i = 0\n",
    "    for i in range(100):\n",
    "        cpe = 2 * (torch.linspace(0, 1, q_len).reshape(-1, 1) ** x) * (torch.linspace(0, 1, d_model).reshape(1, -1) ** x) - 1\n",
    "        if abs(cpe.mean()) <= eps: break\n",
    "        elif cpe.mean() > eps: x += .001\n",
    "        else: x -= .001\n",
    "        i += 1\n",
    "    if normalize:\n",
    "        cpe = cpe - cpe.mean()\n",
    "        cpe = cpe / (cpe.std() * 10)\n",
    "    return cpe\n",
    "\n",
    "def Coord1dPosEncoding(q_len, exponential=False, normalize=True):\n",
    "    cpe = (2 * (torch.linspace(0, 1, q_len).reshape(-1, 1)**(.5 if exponential else 1)) - 1)\n",
    "    if normalize:\n",
    "        cpe = cpe - cpe.mean()\n",
    "        cpe = cpe / (cpe.std() * 10)\n",
    "    return cpe\n",
    "\n",
    "def positional_encoding(pe, learn_pe, q_len, d_model):\n",
    "    # Positional encoding\n",
    "    if pe == None:\n",
    "        W_pos = torch.empty((q_len, d_model)) # pe = None and learn_pe = False can be used to measure impact of pe\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "        learn_pe = False\n",
    "    elif pe == 'zero':\n",
    "        W_pos = torch.empty((q_len, 1))\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "    elif pe == 'zeros':\n",
    "        W_pos = torch.empty((q_len, d_model))\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "    elif pe == 'normal' or pe == 'gauss':\n",
    "        W_pos = torch.zeros((q_len, 1))\n",
    "        torch.nn.init.normal_(W_pos, mean=0.0, std=0.1)\n",
    "    elif pe == 'uniform':\n",
    "        W_pos = torch.zeros((q_len, 1))\n",
    "        nn.init.uniform_(W_pos, a=0.0, b=0.1)\n",
    "    elif pe == 'lin1d': W_pos = Coord1dPosEncoding(q_len, exponential=False, normalize=True)\n",
    "    elif pe == 'exp1d': W_pos = Coord1dPosEncoding(q_len, exponential=True, normalize=True)\n",
    "    elif pe == 'lin2d': W_pos = Coord2dPosEncoding(q_len, d_model, exponential=False, normalize=True)\n",
    "    elif pe == 'exp2d': W_pos = Coord2dPosEncoding(q_len, d_model, exponential=True, normalize=True)\n",
    "    elif pe == 'sincos': W_pos = PositionalEncoding(q_len, d_model, normalize=True)\n",
    "    else: raise ValueError(f\"{pe} is not a valid pe (positional encoder. Available types: 'gauss'=='normal', \\\n",
    "        'zeros', 'zero', uniform', 'lin1d', 'exp1d', 'lin2d', 'exp2d', 'sincos', None.)\")\n",
    "    return nn.Parameter(W_pos, requires_grad=learn_pe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RevIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RevIN(nn.Module):\n",
    "    def __init__(self, num_features: int, eps=1e-5, affine=True, subtract_last=False):\n",
    "        \"\"\"\n",
    "        :param num_features: the number of features or channels\n",
    "        :param eps: a value added for numerical stability\n",
    "        :param affine: if True, RevIN has learnable affine parameters\n",
    "        \"\"\"\n",
    "        super(RevIN, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        self.subtract_last = subtract_last\n",
    "        if self.affine:\n",
    "            self._init_params()\n",
    "\n",
    "    def forward(self, x, mode:str):\n",
    "        if mode == 'norm':\n",
    "            self._get_statistics(x)\n",
    "            x = self._normalize(x)\n",
    "        elif mode == 'denorm':\n",
    "            x = self._denormalize(x)\n",
    "        else: raise NotImplementedError\n",
    "        return x\n",
    "\n",
    "    def _init_params(self):\n",
    "        # initialize RevIN params: (C,)\n",
    "        self.affine_weight = nn.Parameter(torch.ones(self.num_features))\n",
    "        self.affine_bias = nn.Parameter(torch.zeros(self.num_features))\n",
    "\n",
    "    def _get_statistics(self, x):\n",
    "        dim2reduce = tuple(range(1, x.ndim-1))\n",
    "        if self.subtract_last:\n",
    "            self.last = x[:,-1,:].unsqueeze(1)\n",
    "        else:\n",
    "            self.mean = torch.mean(x, dim=dim2reduce, keepdim=True).detach()\n",
    "        self.stdev = torch.sqrt(torch.var(x, dim=dim2reduce, keepdim=True, unbiased=False) + self.eps).detach()\n",
    "\n",
    "    def _normalize(self, x):\n",
    "        if self.subtract_last:\n",
    "            x = x - self.last\n",
    "        else:\n",
    "            x = x - self.mean\n",
    "        x = x / self.stdev\n",
    "        if self.affine:\n",
    "            x = x * self.affine_weight\n",
    "            x = x + self.affine_bias\n",
    "        return x\n",
    "\n",
    "    def _denormalize(self, x):\n",
    "        if self.affine:\n",
    "            x = x - self.affine_bias\n",
    "            x = x / (self.affine_weight + self.eps*self.eps)\n",
    "        x = x * self.stdev\n",
    "        if self.subtract_last:\n",
    "            x = x + self.last\n",
    "        else:\n",
    "            x = x + self.mean\n",
    "        return "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PatchTST_backbone(nn.Module):\n",
    "    def __init__(self, c_in:int, context_window:int, target_window:int, patch_len:int, stride:int, max_seq_len:Optional[int]=1024, \n",
    "                 n_layers:int=3, d_model=128, n_heads=16, d_k:Optional[int]=None, d_v:Optional[int]=None,\n",
    "                 d_ff:int=256, norm:str='BatchNorm', attn_dropout:float=0., dropout:float=0., act:str=\"gelu\", key_padding_mask:bool='auto',\n",
    "                 padding_var:Optional[int]=None, attn_mask:Optional[torch.Tensor]=None, res_attention:bool=True, pre_norm:bool=False, store_attn:bool=False,\n",
    "                 pe:str='zeros', learn_pe:bool=True, fc_dropout:float=0., head_dropout = 0, padding_patch = None,\n",
    "                 pretrain_head:bool=False, head_type = 'flatten', individual = False, revin = True, affine = True, subtract_last = False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # RevIn\n",
    "        self.revin = revin\n",
    "        if self.revin: self.revin_layer = RevIN(c_in, affine=affine, subtract_last=subtract_last)\n",
    "        \n",
    "        # Patching\n",
    "        self.patch_len = patch_len\n",
    "        self.stride = stride\n",
    "        self.padding_patch = padding_patch\n",
    "        patch_num = int((context_window - patch_len)/stride + 1)\n",
    "        if padding_patch == 'end': # can be modified to general case\n",
    "            self.padding_patch_layer = nn.ReplicationPad1d((0, stride)) \n",
    "            patch_num += 1\n",
    "        \n",
    "        # Backbone \n",
    "        self.backbone = TSTiEncoder(c_in, patch_num=patch_num, patch_len=patch_len, max_seq_len=max_seq_len,\n",
    "                                n_layers=n_layers, d_model=d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff,\n",
    "                                attn_dropout=attn_dropout, dropout=dropout, act=act, key_padding_mask=key_padding_mask, padding_var=padding_var,\n",
    "                                attn_mask=attn_mask, res_attention=res_attention, pre_norm=pre_norm, store_attn=store_attn,\n",
    "                                pe=pe, learn_pe=learn_pe)\n",
    "\n",
    "        # Head\n",
    "        self.head_nf = d_model * patch_num\n",
    "        self.n_vars = c_in\n",
    "        self.pretrain_head = pretrain_head\n",
    "        self.head_type = head_type\n",
    "        self.individual = individual\n",
    "\n",
    "        if self.pretrain_head: \n",
    "            self.head = self.create_pretrain_head(self.head_nf, c_in, fc_dropout) # custom head passed as a partial func with all its kwargs\n",
    "        elif head_type == 'flatten': \n",
    "            self.head = Flatten_Head(self.individual, self.n_vars, self.head_nf, target_window, head_dropout=head_dropout)\n",
    "\n",
    "    def forward(self, z):                                                                   # z: [bs x nvars x seq_len]\n",
    "        # norm\n",
    "        if self.revin: \n",
    "            z = z.permute(0,2,1)\n",
    "            z = self.revin_layer(z, 'norm')\n",
    "            z = z.permute(0,2,1)\n",
    "\n",
    "        # do patching\n",
    "        if self.padding_patch == 'end':\n",
    "            z = self.padding_patch_layer(z)\n",
    "        z = z.unfold(dimension=-1, size=self.patch_len, step=self.stride)                   # z: [bs x nvars x patch_num x patch_len]\n",
    "        z = z.permute(0,1,3,2)                                                              # z: [bs x nvars x patch_len x patch_num]\n",
    "\n",
    "        # model\n",
    "        z = self.backbone(z)                                                                # z: [bs x nvars x d_model x patch_num]\n",
    "        z = self.head(z)                                                                    # z: [bs x nvars x target_window] \n",
    "\n",
    "        # denorm\n",
    "        if self.revin: \n",
    "            z = z.permute(0,2,1)\n",
    "            z = self.revin_layer(z, 'denorm')\n",
    "            z = z.permute(0,2,1)\n",
    "        return z\n",
    "    \n",
    "    def create_pretrain_head(self, head_nf, vars, dropout):\n",
    "        return nn.Sequential(nn.Dropout(dropout),\n",
    "                    nn.Conv1d(head_nf, vars, 1)\n",
    "                    )\n",
    "\n",
    "\n",
    "class Flatten_Head(nn.Module):\n",
    "    def __init__(self, individual, n_vars, nf, target_window, head_dropout=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.individual = individual\n",
    "        self.n_vars = n_vars\n",
    "        \n",
    "        if self.individual:\n",
    "            self.linears = nn.ModuleList()\n",
    "            self.dropouts = nn.ModuleList()\n",
    "            self.flattens = nn.ModuleList()\n",
    "            for i in range(self.n_vars):\n",
    "                self.flattens.append(nn.Flatten(start_dim=-2))\n",
    "                self.linears.append(nn.Linear(nf, target_window))\n",
    "                self.dropouts.append(nn.Dropout(head_dropout))\n",
    "        else:\n",
    "            self.flatten = nn.Flatten(start_dim=-2)\n",
    "            self.linear = nn.Linear(nf, target_window)\n",
    "            self.dropout = nn.Dropout(head_dropout)\n",
    "            \n",
    "    def forward(self, x):                                 # x: [bs x nvars x d_model x patch_num]\n",
    "        if self.individual:\n",
    "            x_out = []\n",
    "            for i in range(self.n_vars):\n",
    "                z = self.flattens[i](x[:,i,:,:])          # z: [bs x d_model * patch_num]\n",
    "                z = self.linears[i](z)                    # z: [bs x target_window]\n",
    "                z = self.dropouts[i](z)\n",
    "                x_out.append(z)\n",
    "            x = torch.stack(x_out, dim=1)                 # x: [bs x nvars x target_window]\n",
    "        else:\n",
    "            x = self.flatten(x)\n",
    "            x = self.linear(x)\n",
    "            x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TSTiEncoder(nn.Module):  #i means channel-independent\n",
    "    def __init__(self, c_in, patch_num, patch_len, max_seq_len=1024,\n",
    "                 n_layers=3, d_model=128, n_heads=16, d_k=None, d_v=None,\n",
    "                 d_ff=256, norm='BatchNorm', attn_dropout=0., dropout=0., act=\"gelu\", store_attn=False,\n",
    "                 key_padding_mask='auto', padding_var=None, attn_mask=None, res_attention=True, pre_norm=False,\n",
    "                 pe='zeros', learn_pe=True):\n",
    "        \n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.patch_num = patch_num\n",
    "        self.patch_len = patch_len\n",
    "        \n",
    "        # Input encoding\n",
    "        q_len = patch_num\n",
    "        self.W_P = nn.Linear(patch_len, d_model)        # Eq 1: projection of feature vectors onto a d-dim vector space\n",
    "        self.seq_len = q_len\n",
    "\n",
    "        # Positional encoding\n",
    "        self.W_pos = positional_encoding(pe, learn_pe, q_len, d_model)\n",
    "\n",
    "        # Residual dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = TSTEncoder(q_len, d_model, n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, norm=norm, attn_dropout=attn_dropout, dropout=dropout,\n",
    "                                   pre_norm=pre_norm, activation=act, res_attention=res_attention, n_layers=n_layers, store_attn=store_attn)\n",
    "        \n",
    "    def forward(self, x) -> torch.Tensor:                                        # x: [bs x nvars x patch_len x patch_num]\n",
    "        \n",
    "        n_vars = x.shape[1]\n",
    "        # Input encoding\n",
    "        x = x.permute(0,1,3,2)                                                   # x: [bs x nvars x patch_num x patch_len]\n",
    "        x = self.W_P(x)                                                          # x: [bs x nvars x patch_num x d_model]\n",
    "\n",
    "        u = torch.reshape(x, (x.shape[0]*x.shape[1],x.shape[2],x.shape[3]))      # u: [bs * nvars x patch_num x d_model]\n",
    "        u = self.dropout(u + self.W_pos)                                         # u: [bs * nvars x patch_num x d_model]\n",
    "\n",
    "        # Encoder\n",
    "        z = self.encoder(u)                                                      # z: [bs * nvars x patch_num x d_model]\n",
    "        z = torch.reshape(z, (-1,n_vars,z.shape[-2],z.shape[-1]))                # z: [bs x nvars x patch_num x d_model]\n",
    "        z = z.permute(0,1,3,2)                                                   # z: [bs x nvars x d_model x patch_num]\n",
    "        \n",
    "        return z    \n",
    "            \n",
    "\n",
    "class TSTEncoder(nn.Module):\n",
    "    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=None, \n",
    "                        norm='BatchNorm', attn_dropout=0., dropout=0., activation='gelu',\n",
    "                        res_attention=False, n_layers=1, pre_norm=False, store_attn=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList([TSTEncoderLayer(q_len, d_model, n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=d_ff, norm=norm,\n",
    "                                                      attn_dropout=attn_dropout, dropout=dropout,\n",
    "                                                      activation=activation, res_attention=res_attention,\n",
    "                                                      pre_norm=pre_norm, store_attn=store_attn) for i in range(n_layers)])\n",
    "        self.res_attention = res_attention\n",
    "\n",
    "    def forward(self, src:torch.Tensor, key_padding_mask:Optional[torch.Tensor]=None, attn_mask:Optional[torch.Tensor]=None):\n",
    "        output = src\n",
    "        scores = None\n",
    "        if self.res_attention:\n",
    "            for mod in self.layers: output, scores = mod(output, prev=scores, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "            return output\n",
    "        else:\n",
    "            for mod in self.layers: output = mod(output, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "            return output\n",
    "\n",
    "\n",
    "class TSTEncoderLayer(nn.Module):\n",
    "    def __init__(self, q_len, d_model, n_heads, d_k=None, d_v=None, d_ff=256, store_attn=False,\n",
    "                 norm='BatchNorm', attn_dropout=0, dropout=0., bias=True, activation=\"gelu\", res_attention=False, pre_norm=False):\n",
    "        super().__init__()\n",
    "        assert not d_model%n_heads, f\"d_model ({d_model}) must be divisible by n_heads ({n_heads})\"\n",
    "        d_k = d_model // n_heads if d_k is None else d_k\n",
    "        d_v = d_model // n_heads if d_v is None else d_v\n",
    "\n",
    "        # Multi-Head attention\n",
    "        self.res_attention = res_attention\n",
    "        self.self_attn = _MultiheadAttention(d_model, n_heads, d_k, d_v, attn_dropout=attn_dropout,\n",
    "                                             proj_dropout=dropout, res_attention=res_attention)\n",
    "\n",
    "        # Add & Norm\n",
    "        self.dropout_attn = nn.Dropout(dropout)\n",
    "        if \"batch\" in norm.lower():\n",
    "            self.norm_attn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(d_model), Transpose(1,2))\n",
    "        else:\n",
    "            self.norm_attn = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Position-wise Feed-Forward\n",
    "        self.ff = nn.Sequential(nn.Linear(d_model, d_ff, bias=bias),\n",
    "                                get_activation_fn(activation),\n",
    "                                nn.Dropout(dropout),\n",
    "                                nn.Linear(d_ff, d_model, bias=bias))\n",
    "\n",
    "        # Add & Norm\n",
    "        self.dropout_ffn = nn.Dropout(dropout)\n",
    "        if \"batch\" in norm.lower():\n",
    "            self.norm_ffn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(d_model), Transpose(1,2))\n",
    "        else:\n",
    "            self.norm_ffn = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.pre_norm = pre_norm\n",
    "        self.store_attn = store_attn\n",
    "\n",
    "    def forward(self, src:torch.Tensor, prev:Optional[torch.Tensor]=None,\n",
    "                key_padding_mask:Optional[torch.Tensor]=None,\n",
    "                attn_mask:Optional[torch.Tensor]=None) -> torch.Tensor:\n",
    "\n",
    "        # Multi-Head attention sublayer\n",
    "        if self.pre_norm:\n",
    "            src = self.norm_attn(src)\n",
    "        ## Multi-Head attention\n",
    "        if self.res_attention:\n",
    "            src2, attn, scores = self.self_attn(src, src, src, prev,\n",
    "                                                key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        else:\n",
    "            src2, attn = self.self_attn(src, src, src, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        if self.store_attn:\n",
    "            self.attn = attn\n",
    "        ## Add & Norm\n",
    "        src = src + self.dropout_attn(src2) # Add: residual connection with residual dropout\n",
    "        if not self.pre_norm:\n",
    "            src = self.norm_attn(src)\n",
    "\n",
    "        # Feed-forward sublayer\n",
    "        if self.pre_norm:\n",
    "            src = self.norm_ffn(src)\n",
    "        ## Position-wise Feed-Forward\n",
    "        src2 = self.ff(src)\n",
    "        ## Add & Norm\n",
    "        src = src + self.dropout_ffn(src2) # Add: residual connection with residual dropout\n",
    "        if not self.pre_norm:\n",
    "            src = self.norm_ffn(src)\n",
    "\n",
    "        if self.res_attention:\n",
    "            return src, scores\n",
    "        else:\n",
    "            return src\n",
    "\n",
    "\n",
    "class _MultiheadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k=None, d_v=None,\n",
    "                 res_attention=False, attn_dropout=0., proj_dropout=0., qkv_bias=True, lsa=False):\n",
    "        \"\"\"Multi Head Attention Layer\n",
    "        Input shape:\n",
    "            Q:       [batch_size (bs) x max_q_len x d_model]\n",
    "            K, V:    [batch_size (bs) x q_len x d_model]\n",
    "            mask:    [q_len x q_len]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        d_k = d_model // n_heads if d_k is None else d_k\n",
    "        d_v = d_model // n_heads if d_v is None else d_v\n",
    "\n",
    "        self.n_heads, self.d_k, self.d_v = n_heads, d_k, d_v\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=qkv_bias)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=qkv_bias)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=qkv_bias)\n",
    "\n",
    "        # Scaled Dot-Product Attention (multiple heads)\n",
    "        self.res_attention = res_attention\n",
    "        self.sdp_attn = _ScaledDotProductAttention(d_model, n_heads, attn_dropout=attn_dropout,\n",
    "                                                   res_attention=self.res_attention, lsa=lsa)\n",
    "\n",
    "        # Poject output\n",
    "        self.to_out = nn.Sequential(nn.Linear(n_heads * d_v, d_model), nn.Dropout(proj_dropout))\n",
    "\n",
    "    def forward(self, Q:torch.Tensor, K:Optional[torch.Tensor]=None, V:Optional[torch.Tensor]=None, prev:Optional[torch.Tensor]=None,\n",
    "                key_padding_mask:Optional[torch.Tensor]=None, attn_mask:Optional[torch.Tensor]=None):\n",
    "\n",
    "        bs = Q.size(0)\n",
    "        if K is None: K = Q\n",
    "        if V is None: V = Q\n",
    "\n",
    "        # Linear (+ split in multiple heads)\n",
    "        q_s = self.W_Q(Q).view(bs, -1, self.n_heads, self.d_k).transpose(1,2)       # q_s    : [bs x n_heads x max_q_len x d_k]\n",
    "        k_s = self.W_K(K).view(bs, -1, self.n_heads, self.d_k).permute(0,2,3,1)     # k_s    : [bs x n_heads x d_k x q_len] - transpose(1,2) + transpose(2,3)\n",
    "        v_s = self.W_V(V).view(bs, -1, self.n_heads, self.d_v).transpose(1,2)       # v_s    : [bs x n_heads x q_len x d_v]\n",
    "\n",
    "        # Apply Scaled Dot-Product Attention (multiple heads)\n",
    "        if self.res_attention:\n",
    "            output, attn_weights, attn_scores = self.sdp_attn(q_s, k_s, v_s,\n",
    "                                                    prev=prev, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        else:\n",
    "            output, attn_weights = self.sdp_attn(q_s, k_s, v_s, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        # output: [bs x n_heads x q_len x d_v], attn: [bs x n_heads x q_len x q_len], scores: [bs x n_heads x max_q_len x q_len]\n",
    "\n",
    "        # back to the original inputs dimensions\n",
    "        output = output.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * self.d_v) # output: [bs x q_len x n_heads * d_v]\n",
    "        output = self.to_out(output)\n",
    "\n",
    "        if self.res_attention: return output, attn_weights, attn_scores\n",
    "        else: return output, attn_weights\n",
    "\n",
    "\n",
    "class _ScaledDotProductAttention(nn.Module):\n",
    "    r\"\"\"Scaled Dot-Product Attention module (Attention is all you need by Vaswani et al., 2017) with optional residual attention from previous layer\n",
    "    (Realformer: Transformer likes residual attention by He et al, 2020) and locality self sttention (Vision Transformer for Small-Size Datasets\n",
    "    by Lee et al, 2021)\"\"\"\n",
    "\n",
    "    def __init__(self, d_model, n_heads, attn_dropout=0., res_attention=False, lsa=False):\n",
    "        super().__init__()\n",
    "        self.attn_dropout = nn.Dropout(attn_dropout)\n",
    "        self.res_attention = res_attention\n",
    "        head_dim = d_model // n_heads\n",
    "        self.scale = nn.Parameter(torch.tensor(head_dim ** -0.5), requires_grad=lsa)\n",
    "        self.lsa = lsa\n",
    "\n",
    "    def forward(self, q:torch.Tensor, k:torch.Tensor, v:torch.Tensor,\n",
    "                prev:Optional[torch.Tensor]=None, key_padding_mask:Optional[torch.Tensor]=None,\n",
    "                attn_mask:Optional[torch.Tensor]=None):\n",
    "        '''\n",
    "        Input shape:\n",
    "            q               : [bs x n_heads x max_q_len x d_k]\n",
    "            k               : [bs x n_heads x d_k x seq_len]\n",
    "            v               : [bs x n_heads x seq_len x d_v]\n",
    "            prev            : [bs x n_heads x q_len x seq_len]\n",
    "            key_padding_mask: [bs x seq_len]\n",
    "            attn_mask       : [1 x seq_len x seq_len]\n",
    "        Output shape:\n",
    "            output:  [bs x n_heads x q_len x d_v]\n",
    "            attn   : [bs x n_heads x q_len x seq_len]\n",
    "            scores : [bs x n_heads x q_len x seq_len]\n",
    "        '''\n",
    "\n",
    "        # Scaled MatMul (q, k) - similarity scores for all pairs of positions in an input sequence\n",
    "        attn_scores = torch.matmul(q, k) * self.scale      # attn_scores : [bs x n_heads x max_q_len x q_len]\n",
    "\n",
    "        # Add pre-softmax attention scores from the previous layer (optional)\n",
    "        if prev is not None: attn_scores = attn_scores + prev\n",
    "\n",
    "        # Attention mask (optional)\n",
    "        if attn_mask is not None:                                     # attn_mask with shape [q_len x seq_len] - only used when q_len == seq_len\n",
    "            if attn_mask.dtype == torch.bool:\n",
    "                attn_scores.masked_fill_(attn_mask, -np.inf)\n",
    "            else:\n",
    "                attn_scores += attn_mask\n",
    "\n",
    "        # Key padding mask (optional)\n",
    "        if key_padding_mask is not None:                              # mask with shape [bs x q_len] (only when max_w_len == q_len)\n",
    "            attn_scores.masked_fill_(key_padding_mask.unsqueeze(1).unsqueeze(2), -np.inf)\n",
    "\n",
    "        # normalize the attention weights\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)                 # attn_weights   : [bs x n_heads x max_q_len x q_len]\n",
    "        attn_weights = self.attn_dropout(attn_weights)\n",
    "\n",
    "        # compute the new values given the attention weights\n",
    "        output = torch.matmul(attn_weights, v)                        # output: [bs x n_heads x max_q_len x d_v]\n",
    "\n",
    "        if self.res_attention: return output, attn_weights, attn_scores\n",
    "        else: return output, attn_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PatchTST(BaseWindows):\n",
    "    def __init__(self,\n",
    "                 h,\n",
    "                 input_size, # 336\n",
    "                 stat_exog_list = None,\n",
    "                 hist_exog_list = None,\n",
    "                 futr_exog_list = None,\n",
    "                 # Architecture\n",
    "                 encoder_layers: int = 3,\n",
    "                 n_heads: int = 16,\n",
    "                 hidden_size: int = 128,\n",
    "                 linear_hidden_size: int = 256,\n",
    "                 dropout: float = 0.2,\n",
    "                 fc_dropout: float = 0.2,\n",
    "                 head_dropout: float = 0.0,\n",
    "                 patch_len: int = 16,\n",
    "                 stride: int = 8,\n",
    "                 padding_patch: str = 'end',\n",
    "                 revin: bool = True,\n",
    "                 revin_affine: bool = False,\n",
    "                 revin_subtract_last:bool = True,\n",
    "                 activation: str = \"gelu\",\n",
    "                 attn_dropout: float =0.,\n",
    "                 res_attention: bool = True, \n",
    "                 batch_normalization: bool = False,\n",
    "                 learn_pos_embed: bool = True,\n",
    "                 # Neuralforecast\n",
    "                 loss = MAE(),\n",
    "                 valid_loss = None,\n",
    "                 max_steps: int = 5000,\n",
    "                 learning_rate: float = 1e-4,\n",
    "                 num_lr_decays: int = -1,\n",
    "                 early_stop_patience_steps: int =-1,\n",
    "                 val_check_steps: int = 100,\n",
    "                 batch_size: int = 32,\n",
    "                 valid_batch_size: Optional[int] = None,\n",
    "                 windows_batch_size = 1024,\n",
    "                 step_size: int = 1,\n",
    "                 scaler_type: str = 'identity',\n",
    "                 random_seed: int = 1,\n",
    "                 num_workers_loader: int = 0,\n",
    "                 drop_last_loader: bool = False,\n",
    "                 **trainer_kwargs):\n",
    "        super(PatchTST, self).__init__(h=h,\n",
    "                                       input_size=input_size,\n",
    "                                       hist_exog_list=hist_exog_list,\n",
    "                                       stat_exog_list=stat_exog_list,\n",
    "                                       futr_exog_list = futr_exog_list,\n",
    "                                       loss=loss,\n",
    "                                       valid_loss=valid_loss,\n",
    "                                       max_steps=max_steps,\n",
    "                                       learning_rate=learning_rate,\n",
    "                                       num_lr_decays=num_lr_decays,\n",
    "                                       early_stop_patience_steps=early_stop_patience_steps,\n",
    "                                       val_check_steps=val_check_steps,\n",
    "                                       batch_size=batch_size,\n",
    "                                       windows_batch_size=windows_batch_size,\n",
    "                                       valid_batch_size=valid_batch_size,\n",
    "                                       step_size=step_size,\n",
    "                                       scaler_type=scaler_type,\n",
    "                                       num_workers_loader=num_workers_loader,\n",
    "                                       drop_last_loader=drop_last_loader,\n",
    "                                       random_seed=random_seed,\n",
    "                                       **trainer_kwargs)        \n",
    "        # Fixed hyperparameters\n",
    "        c_in = 1                  # Always univariate\n",
    "        pretrain_head = False     # No pretrained head\n",
    "        norm = 'BatchNorm'        # Use BatchNorm (if batch_normalization is True)\n",
    "        pe = 'zeros'              # Initial zeros for positional encoding \n",
    "        d_k = None                # Key dimension\n",
    "        d_v = None                # Value dimension\n",
    "        store_attn = False        # Store attention weights\n",
    "        head_type = 'flatten'     # Head type\n",
    "        individual = False        # Separate heads for each time series\n",
    "        max_seq_len = 1024        # Not used\n",
    "        key_padding_mask = 'auto' # Not used\n",
    "        padding_var = None        # Not used\n",
    "        attn_mask = None          # Not used\n",
    "\n",
    "        self.model = PatchTST_backbone(c_in=c_in, context_window=input_size, target_window=h, patch_len=patch_len, stride=stride, \n",
    "                                max_seq_len=max_seq_len, n_layers=encoder_layers, d_model=hidden_size,\n",
    "                                n_heads=n_heads, d_k=d_k, d_v=d_v, d_ff=linear_hidden_size, norm=norm, attn_dropout=attn_dropout,\n",
    "                                dropout=dropout, act=activation, key_padding_mask=key_padding_mask, padding_var=padding_var, \n",
    "                                attn_mask=attn_mask, res_attention=res_attention, pre_norm=batch_normalization, store_attn=store_attn,\n",
    "                                pe=pe, learn_pe=learn_pos_embed, fc_dropout=fc_dropout, head_dropout=head_dropout, padding_patch = padding_patch,\n",
    "                                pretrain_head=pretrain_head, head_type=head_type, individual=individual, revin=revin, affine=revin_affine,\n",
    "                                subtract_last=revin_subtract_last)\n",
    "    \n",
    "    \n",
    "    def forward(self, windows_batch):           # x: [Batch, Input length, Channel]\n",
    "\n",
    "        # Parse windows_batch\n",
    "        insample_y    = windows_batch['insample_y']\n",
    "        #insample_mask = windows_batch['insample_mask']\n",
    "        #hist_exog     = windows_batch['hist_exog']\n",
    "        #stat_exog     = windows_batch['stat_exog']\n",
    "        #futr_exog     = windows_batch['futr_exog']\n",
    "\n",
    "        # Add dimension for channel\n",
    "        x = insample_y.unsqueeze(-1) # [Ws,L,1]\n",
    "\n",
    "        x = x.permute(0,2,1)    # x: [Batch, Channel, Input length]\n",
    "        x = self.model(x)\n",
    "        x = x.permute(0,2,1)    # x: [Batch, Input length, Channel]\n",
    "\n",
    "        forecast = self.loss.domain_map(x[:, -self.h:])\n",
    "        \n",
    "        return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### PatchTST\n",
       "\n",
       ">      PatchTST (h, input_size, stat_exog_list=None, hist_exog_list=None,\n",
       ">                futr_exog_list=None, encoder_layers:int=3, n_heads:int=16,\n",
       ">                hidden_size:int=128, linear_hidden_size:int=256,\n",
       ">                dropout:float=0.2, fc_dropout:float=0.2,\n",
       ">                head_dropout:float=0.0, patch_len:int=16, stride:int=8,\n",
       ">                padding_patch:str='end', revin:bool=True,\n",
       ">                revin_affine:bool=False, revin_subtract_last:bool=True,\n",
       ">                activation:str='gelu', attn_dropout:float=0.0,\n",
       ">                res_attention:bool=True, batch_normalization:bool=False,\n",
       ">                learn_pos_embed:bool=True, loss=MAE(), valid_loss=None,\n",
       ">                max_steps:int=5000, learning_rate:float=0.0001,\n",
       ">                num_lr_decays:int=-1, early_stop_patience_steps:int=-1,\n",
       ">                val_check_steps:int=100, batch_size:int=32,\n",
       ">                valid_batch_size:Optional[int]=None, windows_batch_size=1024,\n",
       ">                step_size:int=1, scaler_type:str='identity', random_seed:int=1,\n",
       ">                num_workers_loader:int=0, drop_last_loader:bool=False,\n",
       ">                **trainer_kwargs)\n",
       "\n",
       "Hooks to be used in LightningModule.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| h |  |  |  |\n",
       "| input_size |  |  | 336 |\n",
       "| stat_exog_list | NoneType | None |  |\n",
       "| hist_exog_list | NoneType | None |  |\n",
       "| futr_exog_list | NoneType | None |  |\n",
       "| encoder_layers | int | 3 | Architecture |\n",
       "| n_heads | int | 16 |  |\n",
       "| hidden_size | int | 128 |  |\n",
       "| linear_hidden_size | int | 256 |  |\n",
       "| dropout | float | 0.2 |  |\n",
       "| fc_dropout | float | 0.2 |  |\n",
       "| head_dropout | float | 0.0 |  |\n",
       "| patch_len | int | 16 |  |\n",
       "| stride | int | 8 |  |\n",
       "| padding_patch | str | end |  |\n",
       "| revin | bool | True |  |\n",
       "| revin_affine | bool | False |  |\n",
       "| revin_subtract_last | bool | True |  |\n",
       "| activation | str | gelu |  |\n",
       "| attn_dropout | float | 0.0 |  |\n",
       "| res_attention | bool | True |  |\n",
       "| batch_normalization | bool | False |  |\n",
       "| learn_pos_embed | bool | True |  |\n",
       "| loss | MAE | MAE() | Neuralforecast |\n",
       "| valid_loss | NoneType | None |  |\n",
       "| max_steps | int | 5000 |  |\n",
       "| learning_rate | float | 0.0001 |  |\n",
       "| num_lr_decays | int | -1 |  |\n",
       "| early_stop_patience_steps | int | -1 |  |\n",
       "| val_check_steps | int | 100 |  |\n",
       "| batch_size | int | 32 |  |\n",
       "| valid_batch_size | Optional | None |  |\n",
       "| windows_batch_size | int | 1024 |  |\n",
       "| step_size | int | 1 |  |\n",
       "| scaler_type | str | identity |  |\n",
       "| random_seed | int | 1 |  |\n",
       "| num_workers_loader | int | 0 |  |\n",
       "| drop_last_loader | bool | False |  |\n",
       "| trainer_kwargs |  |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### PatchTST\n",
       "\n",
       ">      PatchTST (h, input_size, stat_exog_list=None, hist_exog_list=None,\n",
       ">                futr_exog_list=None, encoder_layers:int=3, n_heads:int=16,\n",
       ">                hidden_size:int=128, linear_hidden_size:int=256,\n",
       ">                dropout:float=0.2, fc_dropout:float=0.2,\n",
       ">                head_dropout:float=0.0, patch_len:int=16, stride:int=8,\n",
       ">                padding_patch:str='end', revin:bool=True,\n",
       ">                revin_affine:bool=False, revin_subtract_last:bool=True,\n",
       ">                activation:str='gelu', attn_dropout:float=0.0,\n",
       ">                res_attention:bool=True, batch_normalization:bool=False,\n",
       ">                learn_pos_embed:bool=True, loss=MAE(), valid_loss=None,\n",
       ">                max_steps:int=5000, learning_rate:float=0.0001,\n",
       ">                num_lr_decays:int=-1, early_stop_patience_steps:int=-1,\n",
       ">                val_check_steps:int=100, batch_size:int=32,\n",
       ">                valid_batch_size:Optional[int]=None, windows_batch_size=1024,\n",
       ">                step_size:int=1, scaler_type:str='identity', random_seed:int=1,\n",
       ">                num_workers_loader:int=0, drop_last_loader:bool=False,\n",
       ">                **trainer_kwargs)\n",
       "\n",
       "Hooks to be used in LightningModule.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| h |  |  |  |\n",
       "| input_size |  |  | 336 |\n",
       "| stat_exog_list | NoneType | None |  |\n",
       "| hist_exog_list | NoneType | None |  |\n",
       "| futr_exog_list | NoneType | None |  |\n",
       "| encoder_layers | int | 3 | Architecture |\n",
       "| n_heads | int | 16 |  |\n",
       "| hidden_size | int | 128 |  |\n",
       "| linear_hidden_size | int | 256 |  |\n",
       "| dropout | float | 0.2 |  |\n",
       "| fc_dropout | float | 0.2 |  |\n",
       "| head_dropout | float | 0.0 |  |\n",
       "| patch_len | int | 16 |  |\n",
       "| stride | int | 8 |  |\n",
       "| padding_patch | str | end |  |\n",
       "| revin | bool | True |  |\n",
       "| revin_affine | bool | False |  |\n",
       "| revin_subtract_last | bool | True |  |\n",
       "| activation | str | gelu |  |\n",
       "| attn_dropout | float | 0.0 |  |\n",
       "| res_attention | bool | True |  |\n",
       "| batch_normalization | bool | False |  |\n",
       "| learn_pos_embed | bool | True |  |\n",
       "| loss | MAE | MAE() | Neuralforecast |\n",
       "| valid_loss | NoneType | None |  |\n",
       "| max_steps | int | 5000 |  |\n",
       "| learning_rate | float | 0.0001 |  |\n",
       "| num_lr_decays | int | -1 |  |\n",
       "| early_stop_patience_steps | int | -1 |  |\n",
       "| val_check_steps | int | 100 |  |\n",
       "| batch_size | int | 32 |  |\n",
       "| valid_batch_size | Optional | None |  |\n",
       "| windows_batch_size | int | 1024 |  |\n",
       "| step_size | int | 1 |  |\n",
       "| scaler_type | str | identity |  |\n",
       "| random_seed | int | 1 |  |\n",
       "| num_workers_loader | int | 0 |  |\n",
       "| drop_last_loader | bool | False |  |\n",
       "| trainer_kwargs |  |  |  |"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(PatchTST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### PatchTST.fit\n",
       "\n",
       ">      PatchTST.fit (dataset, val_size=0, test_size=0, random_seed=None)\n",
       "\n",
       "Fit.\n",
       "\n",
       "The `fit` method, optimizes the neural network's weights using the\n",
       "initialization parameters (`learning_rate`, `windows_batch_size`, ...)\n",
       "and the `loss` function as defined during the initialization.\n",
       "Within `fit` we use a PyTorch Lightning `Trainer` that\n",
       "inherits the initialization's `self.trainer_kwargs`, to customize\n",
       "its inputs, see [PL's trainer arguments](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).\n",
       "\n",
       "The method is designed to be compatible with SKLearn-like classes\n",
       "and in particular to be compatible with the StatsForecast library.\n",
       "\n",
       "By default the `model` is not saving training checkpoints to protect\n",
       "disk memory, to get them change `enable_checkpointing=True` in `__init__`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`val_size`: int, validation size for temporal cross-validation.<br>\n",
       "`test_size`: int, test size for temporal cross-validation.<br>"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### PatchTST.fit\n",
       "\n",
       ">      PatchTST.fit (dataset, val_size=0, test_size=0, random_seed=None)\n",
       "\n",
       "Fit.\n",
       "\n",
       "The `fit` method, optimizes the neural network's weights using the\n",
       "initialization parameters (`learning_rate`, `windows_batch_size`, ...)\n",
       "and the `loss` function as defined during the initialization.\n",
       "Within `fit` we use a PyTorch Lightning `Trainer` that\n",
       "inherits the initialization's `self.trainer_kwargs`, to customize\n",
       "its inputs, see [PL's trainer arguments](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).\n",
       "\n",
       "The method is designed to be compatible with SKLearn-like classes\n",
       "and in particular to be compatible with the StatsForecast library.\n",
       "\n",
       "By default the `model` is not saving training checkpoints to protect\n",
       "disk memory, to get them change `enable_checkpointing=True` in `__init__`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`val_size`: int, validation size for temporal cross-validation.<br>\n",
       "`test_size`: int, test size for temporal cross-validation.<br>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(PatchTST.fit, name='PatchTST.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### PatchTST.predict\n",
       "\n",
       ">      PatchTST.predict (dataset, test_size=None, step_size=1, random_seed=None,\n",
       ">                        **data_module_kwargs)\n",
       "\n",
       "Predict.\n",
       "\n",
       "Neural network prediction with PL's `Trainer` execution of `predict_step`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`test_size`: int=None, test size for temporal cross-validation.<br>\n",
       "`step_size`: int=1, Step size between each window.<br>\n",
       "`**data_module_kwargs`: PL's TimeSeriesDataModule args, see [documentation](https://pytorch-lightning.readthedocs.io/en/1.6.1/extensions/datamodules.html#using-a-datamodule)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### PatchTST.predict\n",
       "\n",
       ">      PatchTST.predict (dataset, test_size=None, step_size=1, random_seed=None,\n",
       ">                        **data_module_kwargs)\n",
       "\n",
       "Predict.\n",
       "\n",
       "Neural network prediction with PL's `Trainer` execution of `predict_step`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`test_size`: int=None, test size for temporal cross-validation.<br>\n",
       "`step_size`: int=1, Step size between each window.<br>\n",
       "`**data_module_kwargs`: PL's TimeSeriesDataModule args, see [documentation](https://pytorch-lightning.readthedocs.io/en/1.6.1/extensions/datamodules.html#using-a-datamodule)."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(PatchTST.predict, name='PatchTST.predict')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149: 100%|| 2/2 [00:00<00:00,  3.44it/s, loss=0.0885, v_num=105, train_loss_step=0.0864, train_loss_epoch=0.0864, valid_loss=0.681]\n",
      "Predicting DataLoader 0: 100%|| 1/1 [00:00<00:00, 96.04it/s] \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import MLP\n",
    "from neuralforecast.losses.pytorch import MQLoss, DistributionLoss\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset\n",
    "from neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic, augment_calendar_df\n",
    "\n",
    "AirPassengersPanel, calendar_cols = augment_calendar_df(df=AirPassengersPanel, freq='M')\n",
    "\n",
    "Y_train_df = AirPassengersPanel[AirPassengersPanel.ds<AirPassengersPanel['ds'].values[-12]] # 132 train\n",
    "Y_test_df = AirPassengersPanel[AirPassengersPanel.ds>=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n",
    "\n",
    "model = PatchTST(h=12,\n",
    "                 input_size=104,\n",
    "                 patch_len=24,\n",
    "                 stride=2,\n",
    "                 revin=False,\n",
    "                 hidden_size=16,\n",
    "                 n_heads=4,\n",
    "                 scaler_type='robust',\n",
    "                 #loss=DistributionLoss(distribution='StudentT', level=[80, 90]),\n",
    "                 loss=MAE(),\n",
    "                 learning_rate=1e-3,\n",
    "                 max_steps=500,\n",
    "                 val_check_steps=50,\n",
    "                 early_stop_patience_steps=2)\n",
    "\n",
    "nf = NeuralForecast(\n",
    "    models=[model],\n",
    "    freq='M'\n",
    ")\n",
    "nf.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\n",
    "forecasts = nf.predict(futr_df=Y_test_df)\n",
    "\n",
    "Y_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\n",
    "plot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\n",
    "plot_df = pd.concat([Y_train_df, plot_df])\n",
    "\n",
    "if model.loss.is_distribution_output:\n",
    "    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n",
    "    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n",
    "    plt.plot(plot_df['ds'], plot_df['PatchTST-median'], c='blue', label='median')\n",
    "    plt.fill_between(x=plot_df['ds'][-12:], \n",
    "                    y1=plot_df['PatchTST-lo-90'][-12:].values, \n",
    "                    y2=plot_df['PatchTST-hi-90'][-12:].values,\n",
    "                    alpha=0.4, label='level 90')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.plot()\n",
    "else:\n",
    "    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n",
    "    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n",
    "    plt.plot(plot_df['ds'], plot_df['PatchTST'], c='blue', label='Forecast')\n",
    "    plt.legend()\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralforecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
