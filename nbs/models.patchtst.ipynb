{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.patchtst"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PatchTST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PatchTST model is an efficient Transformer-based model for multivariate time series forecasting.\n",
    "\n",
    "It is based on two key components:\n",
    "- segmentation of time series into windows (patches) which are served as input tokens to Transformer\n",
    "- channel-independence. where each channel contains a single univariate time series."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**<br>\n",
    "- [Nie, Y., Nguyen, N. H., Sinthong, P., & Kalagnanam, J. (2022). \"A Time Series is Worth 64 Words: Long-term Forecasting with Transformers\"](https://arxiv.org/pdf/2211.14730.pdf)<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 1. PatchTST.](imgs_models/patchtst.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ospra\\miniconda3\\envs\\neuralforecast\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-01-28 16:04:37,055\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-01-28 16:04:37,164\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import math\n",
    "import numpy as np\n",
    "from typing import Optional #, Any, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from neuralforecast.common._base_windows import BaseWindows\n",
    "from neuralforecast.common._modules import RevIN\n",
    "\n",
    "from neuralforecast.losses.pytorch import MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Backbone"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Transpose(nn.Module):\n",
    "    \"\"\"\n",
    "    Transpose\n",
    "    \"\"\"\n",
    "    def __init__(self, *dims, contiguous=False): \n",
    "        super().__init__()\n",
    "        self.dims, self.contiguous = dims, contiguous\n",
    "    def forward(self, x):\n",
    "        if self.contiguous: return x.transpose(*self.dims).contiguous()\n",
    "        else: return x.transpose(*self.dims)\n",
    "\n",
    "def get_activation_fn(activation):\n",
    "    if callable(activation): return activation()\n",
    "    elif activation.lower() == \"relu\": return nn.ReLU()\n",
    "    elif activation.lower() == \"gelu\": return nn.GELU()\n",
    "    raise ValueError(f'{activation} is not available. You can use \"relu\", \"gelu\", or a callable') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def PositionalEncoding(q_len, hidden_size, normalize=True):\n",
    "    pe = torch.zeros(q_len, hidden_size)\n",
    "    position = torch.arange(0, q_len).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, hidden_size, 2) * -(math.log(10000.0) / hidden_size))\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    if normalize:\n",
    "        pe = pe - pe.mean()\n",
    "        pe = pe / (pe.std() * 10)\n",
    "    return pe\n",
    "\n",
    "SinCosPosEncoding = PositionalEncoding\n",
    "\n",
    "def Coord2dPosEncoding(q_len, hidden_size, exponential=False, normalize=True, eps=1e-3):\n",
    "    x = .5 if exponential else 1\n",
    "    i = 0\n",
    "    for i in range(100):\n",
    "        cpe = 2 * (torch.linspace(0, 1, q_len).reshape(-1, 1) ** x) * (torch.linspace(0, 1, hidden_size).reshape(1, -1) ** x) - 1\n",
    "        if abs(cpe.mean()) <= eps: break\n",
    "        elif cpe.mean() > eps: x += .001\n",
    "        else: x -= .001\n",
    "        i += 1\n",
    "    if normalize:\n",
    "        cpe = cpe - cpe.mean()\n",
    "        cpe = cpe / (cpe.std() * 10)\n",
    "    return cpe\n",
    "\n",
    "def Coord1dPosEncoding(q_len, exponential=False, normalize=True):\n",
    "    cpe = (2 * (torch.linspace(0, 1, q_len).reshape(-1, 1)**(.5 if exponential else 1)) - 1)\n",
    "    if normalize:\n",
    "        cpe = cpe - cpe.mean()\n",
    "        cpe = cpe / (cpe.std() * 10)\n",
    "    return cpe\n",
    "\n",
    "def positional_encoding(pe, learn_pe, q_len, hidden_size):\n",
    "    # Positional encoding\n",
    "    if pe == None:\n",
    "        W_pos = torch.empty((q_len, hidden_size)) # pe = None and learn_pe = False can be used to measure impact of pe\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "        learn_pe = False\n",
    "    elif pe == 'zero':\n",
    "        W_pos = torch.empty((q_len, 1))\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "    elif pe == 'zeros':\n",
    "        W_pos = torch.empty((q_len, hidden_size))\n",
    "        nn.init.uniform_(W_pos, -0.02, 0.02)\n",
    "    elif pe == 'normal' or pe == 'gauss':\n",
    "        W_pos = torch.zeros((q_len, 1))\n",
    "        torch.nn.init.normal_(W_pos, mean=0.0, std=0.1)\n",
    "    elif pe == 'uniform':\n",
    "        W_pos = torch.zeros((q_len, 1))\n",
    "        nn.init.uniform_(W_pos, a=0.0, b=0.1)\n",
    "    elif pe == 'lin1d': W_pos = Coord1dPosEncoding(q_len, exponential=False, normalize=True)\n",
    "    elif pe == 'exp1d': W_pos = Coord1dPosEncoding(q_len, exponential=True, normalize=True)\n",
    "    elif pe == 'lin2d': W_pos = Coord2dPosEncoding(q_len, hidden_size, exponential=False, normalize=True)\n",
    "    elif pe == 'exp2d': W_pos = Coord2dPosEncoding(q_len, hidden_size, exponential=True, normalize=True)\n",
    "    elif pe == 'sincos': W_pos = PositionalEncoding(q_len, hidden_size, normalize=True)\n",
    "    else: raise ValueError(f\"{pe} is not a valid pe (positional encoder. Available types: 'gauss'=='normal', \\\n",
    "        'zeros', 'zero', uniform', 'lin1d', 'exp1d', 'lin2d', 'exp2d', 'sincos', None.)\")\n",
    "    return nn.Parameter(W_pos, requires_grad=learn_pe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PatchTST_backbone(nn.Module):\n",
    "    \"\"\"\n",
    "    PatchTST_backbone\n",
    "    \"\"\"      \n",
    "    def __init__(self, c_in:int, c_out:int, input_size:int, h:int, patch_len:int, stride:int, max_seq_len:Optional[int]=1024, \n",
    "                 n_layers:int=3, hidden_size=128, n_heads=16, d_k:Optional[int]=None, d_v:Optional[int]=None,\n",
    "                 linear_hidden_size:int=256, norm:str='BatchNorm', attn_dropout:float=0., dropout:float=0., act:str=\"gelu\", key_padding_mask:str='auto',\n",
    "                 padding_var:Optional[int]=None, attn_mask:Optional[torch.Tensor]=None, res_attention:bool=True, pre_norm:bool=False, store_attn:bool=False,\n",
    "                 pe:str='zeros', learn_pe:bool=True, fc_dropout:float=0., head_dropout = 0, padding_patch = None,\n",
    "                 pretrain_head:bool=False, head_type = 'flatten', individual = False, revin = True, affine = True, subtract_last = False):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        # RevIn\n",
    "        self.revin = revin\n",
    "        if self.revin: self.revin_layer = RevIN(c_in, affine=affine, subtract_last=subtract_last)\n",
    "\n",
    "        # Patching\n",
    "        self.patch_len = patch_len\n",
    "        self.stride = stride\n",
    "        self.padding_patch = padding_patch\n",
    "        patch_num = int((input_size - patch_len)/stride + 1)\n",
    "        if padding_patch == 'end': # can be modified to general case\n",
    "            self.padding_patch_layer = nn.ReplicationPad1d((0, stride)) \n",
    "            patch_num += 1\n",
    "\n",
    "        # Backbone \n",
    "        self.backbone = TSTiEncoder(c_in, patch_num=patch_num, patch_len=patch_len, max_seq_len=max_seq_len,\n",
    "                                n_layers=n_layers, hidden_size=hidden_size, n_heads=n_heads, d_k=d_k, d_v=d_v, linear_hidden_size=linear_hidden_size,\n",
    "                                attn_dropout=attn_dropout, dropout=dropout, act=act, key_padding_mask=key_padding_mask, padding_var=padding_var,\n",
    "                                attn_mask=attn_mask, res_attention=res_attention, pre_norm=pre_norm, store_attn=store_attn,\n",
    "                                pe=pe, learn_pe=learn_pe)\n",
    "\n",
    "        # Head\n",
    "        self.head_nf = hidden_size * patch_num\n",
    "        self.n_vars = c_in\n",
    "        self.c_out = c_out\n",
    "        self.pretrain_head = pretrain_head\n",
    "        self.head_type = head_type\n",
    "        self.individual = individual\n",
    "\n",
    "        if self.pretrain_head: \n",
    "            self.head = self.create_pretrain_head(self.head_nf, c_in, fc_dropout) # custom head passed as a partial func with all its kwargs\n",
    "        elif head_type == 'flatten': \n",
    "            self.head = Flatten_Head(self.individual, self.n_vars, self.head_nf, h, c_out, head_dropout=head_dropout)\n",
    "\n",
    "    def forward(self, z):                                                                   # z: [bs x nvars x seq_len]\n",
    "        # norm\n",
    "        if self.revin: \n",
    "            z = z.permute(0,2,1)\n",
    "            z = self.revin_layer(z, 'norm')\n",
    "            z = z.permute(0,2,1)\n",
    "\n",
    "        # do patching\n",
    "        if self.padding_patch == 'end':\n",
    "            z = self.padding_patch_layer(z)\n",
    "        z = z.unfold(dimension=-1, size=self.patch_len, step=self.stride)                   # z: [bs x nvars x patch_num x patch_len]\n",
    "        z = z.permute(0,1,3,2)                                                              # z: [bs x nvars x patch_len x patch_num]\n",
    "\n",
    "        # model\n",
    "        z = self.backbone(z)                                                                # z: [bs x nvars x hidden_size x patch_num]\n",
    "        z = self.head(z)                                                                    # z: [bs x nvars x h] \n",
    "\n",
    "        # denorm\n",
    "        if self.revin:\n",
    "            z = z.permute(0,2,1)\n",
    "            z = self.revin_layer(z, 'denorm')\n",
    "            z = z.permute(0,2,1)\n",
    "        return z\n",
    "    \n",
    "    def create_pretrain_head(self, head_nf, vars, dropout):\n",
    "        return nn.Sequential(nn.Dropout(dropout),\n",
    "                    nn.Conv1d(head_nf, vars, 1)\n",
    "                    )\n",
    "\n",
    "\n",
    "class Flatten_Head(nn.Module):\n",
    "    \"\"\"\n",
    "    Flatten_Head\n",
    "    \"\"\"        \n",
    "    def __init__(self, individual, n_vars, nf, h, c_out, head_dropout=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.individual = individual\n",
    "        self.n_vars = n_vars\n",
    "        self.c_out = c_out\n",
    "        \n",
    "        if self.individual:\n",
    "            self.linears = nn.ModuleList()\n",
    "            self.dropouts = nn.ModuleList()\n",
    "            self.flattens = nn.ModuleList()\n",
    "            for i in range(self.n_vars):\n",
    "                self.flattens.append(nn.Flatten(start_dim=-2))\n",
    "                self.linears.append(nn.Linear(nf, h*c_out))\n",
    "                self.dropouts.append(nn.Dropout(head_dropout))\n",
    "        else:\n",
    "            self.flatten = nn.Flatten(start_dim=-2)\n",
    "            self.linear = nn.Linear(nf, h*c_out)\n",
    "            self.dropout = nn.Dropout(head_dropout)\n",
    "            \n",
    "    def forward(self, x):                                 # x: [bs x nvars x hidden_size x patch_num]\n",
    "        if self.individual:\n",
    "            x_out = []\n",
    "            for i in range(self.n_vars):\n",
    "                z = self.flattens[i](x[:,i,:,:])          # z: [bs x hidden_size * patch_num]\n",
    "                z = self.linears[i](z)                    # z: [bs x h]\n",
    "                z = self.dropouts[i](z)\n",
    "                x_out.append(z)\n",
    "            x = torch.stack(x_out, dim=1)                 # x: [bs x nvars x h]\n",
    "        else:\n",
    "            x = self.flatten(x)\n",
    "            x = self.linear(x)\n",
    "            x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TSTiEncoder(nn.Module):  #i means channel-independent\n",
    "    \"\"\"\n",
    "    TSTiEncoder\n",
    "    \"\"\"      \n",
    "    def __init__(self, c_in, patch_num, patch_len, max_seq_len=1024,\n",
    "                 n_layers=3, hidden_size=128, n_heads=16, d_k=None, d_v=None,\n",
    "                 linear_hidden_size=256, norm='BatchNorm', attn_dropout=0., dropout=0., act=\"gelu\", store_attn=False,\n",
    "                 key_padding_mask='auto', padding_var=None, attn_mask=None, res_attention=True, pre_norm=False,\n",
    "                 pe='zeros', learn_pe=True):\n",
    "        \n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.patch_num = patch_num\n",
    "        self.patch_len = patch_len\n",
    "        \n",
    "        # Input encoding\n",
    "        q_len = patch_num\n",
    "        self.W_P = nn.Linear(patch_len, hidden_size)        # Eq 1: projection of feature vectors onto a d-dim vector space\n",
    "        self.seq_len = q_len\n",
    "\n",
    "        # Positional encoding\n",
    "        self.W_pos = positional_encoding(pe, learn_pe, q_len, hidden_size)\n",
    "\n",
    "        # Residual dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = TSTEncoder(q_len, hidden_size, n_heads, d_k=d_k, d_v=d_v, linear_hidden_size=linear_hidden_size, norm=norm, attn_dropout=attn_dropout, dropout=dropout,\n",
    "                                   pre_norm=pre_norm, activation=act, res_attention=res_attention, n_layers=n_layers, store_attn=store_attn)\n",
    "        \n",
    "    def forward(self, x) -> torch.Tensor:                                        # x: [bs x nvars x patch_len x patch_num]\n",
    "        \n",
    "        n_vars = x.shape[1]\n",
    "        # Input encoding\n",
    "        x = x.permute(0,1,3,2)                                                   # x: [bs x nvars x patch_num x patch_len]\n",
    "        x = self.W_P(x)                                                          # x: [bs x nvars x patch_num x hidden_size]\n",
    "\n",
    "        u = torch.reshape(x, (x.shape[0]*x.shape[1],x.shape[2],x.shape[3]))      # u: [bs * nvars x patch_num x hidden_size]\n",
    "        u = self.dropout(u + self.W_pos)                                         # u: [bs * nvars x patch_num x hidden_size]\n",
    "\n",
    "        # Encoder\n",
    "        z = self.encoder(u)                                                      # z: [bs * nvars x patch_num x hidden_size]\n",
    "        z = torch.reshape(z, (-1,n_vars,z.shape[-2],z.shape[-1]))                # z: [bs x nvars x patch_num x hidden_size]\n",
    "        z = z.permute(0,1,3,2)                                                   # z: [bs x nvars x hidden_size x patch_num]\n",
    "        \n",
    "        return z    \n",
    "            \n",
    "\n",
    "class TSTEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    TSTEncoder\n",
    "    \"\"\"     \n",
    "    def __init__(self, q_len, hidden_size, n_heads, d_k=None, d_v=None, linear_hidden_size=None, \n",
    "                        norm='BatchNorm', attn_dropout=0., dropout=0., activation='gelu',\n",
    "                        res_attention=False, n_layers=1, pre_norm=False, store_attn=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList([TSTEncoderLayer(q_len, hidden_size, n_heads=n_heads, d_k=d_k, d_v=d_v, linear_hidden_size=linear_hidden_size, norm=norm,\n",
    "                                                      attn_dropout=attn_dropout, dropout=dropout,\n",
    "                                                      activation=activation, res_attention=res_attention,\n",
    "                                                      pre_norm=pre_norm, store_attn=store_attn) for i in range(n_layers)])\n",
    "        self.res_attention = res_attention\n",
    "\n",
    "    def forward(self, src:torch.Tensor, key_padding_mask:Optional[torch.Tensor]=None, attn_mask:Optional[torch.Tensor]=None):\n",
    "        output = src\n",
    "        scores = None\n",
    "        if self.res_attention:\n",
    "            for mod in self.layers: output, scores = mod(output, prev=scores, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "            return output\n",
    "        else:\n",
    "            for mod in self.layers: output = mod(output, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "            return output\n",
    "\n",
    "\n",
    "class TSTEncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    TSTEncoderLayer\n",
    "    \"\"\"      \n",
    "    def __init__(self, q_len, hidden_size, n_heads, d_k=None, d_v=None, linear_hidden_size=256, store_attn=False,\n",
    "                 norm='BatchNorm', attn_dropout=0, dropout=0., bias=True, activation=\"gelu\", res_attention=False, pre_norm=False):\n",
    "        super().__init__()\n",
    "        assert not hidden_size%n_heads, f\"hidden_size ({hidden_size}) must be divisible by n_heads ({n_heads})\"\n",
    "        d_k = hidden_size // n_heads if d_k is None else d_k\n",
    "        d_v = hidden_size // n_heads if d_v is None else d_v\n",
    "\n",
    "        # Multi-Head attention\n",
    "        self.res_attention = res_attention\n",
    "        self.self_attn = _MultiheadAttention(hidden_size, n_heads, d_k, d_v, attn_dropout=attn_dropout,\n",
    "                                             proj_dropout=dropout, res_attention=res_attention)\n",
    "\n",
    "        # Add & Norm\n",
    "        self.dropout_attn = nn.Dropout(dropout)\n",
    "        if \"batch\" in norm.lower():\n",
    "            self.norm_attn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(hidden_size), Transpose(1,2))\n",
    "        else:\n",
    "            self.norm_attn = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        # Position-wise Feed-Forward\n",
    "        self.ff = nn.Sequential(nn.Linear(hidden_size, linear_hidden_size, bias=bias),\n",
    "                                get_activation_fn(activation),\n",
    "                                nn.Dropout(dropout),\n",
    "                                nn.Linear(linear_hidden_size, hidden_size, bias=bias))\n",
    "\n",
    "        # Add & Norm\n",
    "        self.dropout_ffn = nn.Dropout(dropout)\n",
    "        if \"batch\" in norm.lower():\n",
    "            self.norm_ffn = nn.Sequential(Transpose(1,2), nn.BatchNorm1d(hidden_size), Transpose(1,2))\n",
    "        else:\n",
    "            self.norm_ffn = nn.LayerNorm(hidden_size)\n",
    "\n",
    "        self.pre_norm = pre_norm\n",
    "        self.store_attn = store_attn\n",
    "\n",
    "    def forward(self, src:torch.Tensor, prev:Optional[torch.Tensor]=None,\n",
    "                key_padding_mask:Optional[torch.Tensor]=None,\n",
    "                attn_mask:Optional[torch.Tensor]=None): # -> Tuple[torch.Tensor, Any]:\n",
    "\n",
    "        # Multi-Head attention sublayer\n",
    "        if self.pre_norm:\n",
    "            src = self.norm_attn(src)\n",
    "        ## Multi-Head attention\n",
    "        if self.res_attention:\n",
    "            src2, attn, scores = self.self_attn(src, src, src, prev,\n",
    "                                                key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        else:\n",
    "            src2, attn = self.self_attn(src, src, src, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        if self.store_attn:\n",
    "            self.attn = attn\n",
    "        ## Add & Norm\n",
    "        src = src + self.dropout_attn(src2) # Add: residual connection with residual dropout\n",
    "        if not self.pre_norm:\n",
    "            src = self.norm_attn(src)\n",
    "\n",
    "        # Feed-forward sublayer\n",
    "        if self.pre_norm:\n",
    "            src = self.norm_ffn(src)\n",
    "        ## Position-wise Feed-Forward\n",
    "        src2 = self.ff(src)\n",
    "        ## Add & Norm\n",
    "        src = src + self.dropout_ffn(src2) # Add: residual connection with residual dropout\n",
    "        if not self.pre_norm:\n",
    "            src = self.norm_ffn(src)\n",
    "\n",
    "        if self.res_attention:\n",
    "            return src, scores\n",
    "        else:\n",
    "            return src\n",
    "\n",
    "\n",
    "class _MultiheadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    _MultiheadAttention\n",
    "    \"\"\"       \n",
    "    def __init__(self, hidden_size, n_heads, d_k=None, d_v=None,\n",
    "                 res_attention=False, attn_dropout=0., proj_dropout=0., qkv_bias=True, lsa=False):\n",
    "        \"\"\"\n",
    "        Multi Head Attention Layer\n",
    "        Input shape:\n",
    "            Q:       [batch_size (bs) x max_q_len x hidden_size]\n",
    "            K, V:    [batch_size (bs) x q_len x hidden_size]\n",
    "            mask:    [q_len x q_len]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        d_k = hidden_size // n_heads if d_k is None else d_k\n",
    "        d_v = hidden_size // n_heads if d_v is None else d_v\n",
    "\n",
    "        self.n_heads, self.d_k, self.d_v = n_heads, d_k, d_v\n",
    "\n",
    "        self.W_Q = nn.Linear(hidden_size, d_k * n_heads, bias=qkv_bias)\n",
    "        self.W_K = nn.Linear(hidden_size, d_k * n_heads, bias=qkv_bias)\n",
    "        self.W_V = nn.Linear(hidden_size, d_v * n_heads, bias=qkv_bias)\n",
    "\n",
    "        # Scaled Dot-Product Attention (multiple heads)\n",
    "        self.res_attention = res_attention\n",
    "        self.sdp_attn = _ScaledDotProductAttention(hidden_size, n_heads, attn_dropout=attn_dropout,\n",
    "                                                   res_attention=self.res_attention, lsa=lsa)\n",
    "\n",
    "        # Poject output\n",
    "        self.to_out = nn.Sequential(nn.Linear(n_heads * d_v, hidden_size), nn.Dropout(proj_dropout))\n",
    "\n",
    "    def forward(self, Q:torch.Tensor, K:Optional[torch.Tensor]=None, V:Optional[torch.Tensor]=None, prev:Optional[torch.Tensor]=None,\n",
    "                key_padding_mask:Optional[torch.Tensor]=None, attn_mask:Optional[torch.Tensor]=None):\n",
    "\n",
    "        bs = Q.size(0)\n",
    "        if K is None: K = Q\n",
    "        if V is None: V = Q\n",
    "\n",
    "        # Linear (+ split in multiple heads)\n",
    "        q_s = self.W_Q(Q).view(bs, -1, self.n_heads, self.d_k).transpose(1,2)       # q_s    : [bs x n_heads x max_q_len x d_k]\n",
    "        k_s = self.W_K(K).view(bs, -1, self.n_heads, self.d_k).permute(0,2,3,1)     # k_s    : [bs x n_heads x d_k x q_len] - transpose(1,2) + transpose(2,3)\n",
    "        v_s = self.W_V(V).view(bs, -1, self.n_heads, self.d_v).transpose(1,2)       # v_s    : [bs x n_heads x q_len x d_v]\n",
    "\n",
    "        # Apply Scaled Dot-Product Attention (multiple heads)\n",
    "        if self.res_attention:\n",
    "            output, attn_weights, attn_scores = self.sdp_attn(q_s, k_s, v_s,\n",
    "                                                    prev=prev, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        else:\n",
    "            output, attn_weights = self.sdp_attn(q_s, k_s, v_s, key_padding_mask=key_padding_mask, attn_mask=attn_mask)\n",
    "        # output: [bs x n_heads x q_len x d_v], attn: [bs x n_heads x q_len x q_len], scores: [bs x n_heads x max_q_len x q_len]\n",
    "\n",
    "        # back to the original inputs dimensions\n",
    "        output = output.transpose(1, 2).contiguous().view(bs, -1, self.n_heads * self.d_v) # output: [bs x q_len x n_heads * d_v]\n",
    "        output = self.to_out(output)\n",
    "\n",
    "        if self.res_attention: return output, attn_weights, attn_scores\n",
    "        else: return output, attn_weights\n",
    "\n",
    "\n",
    "class _ScaledDotProductAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Scaled Dot-Product Attention module (Attention is all you need by Vaswani et al., 2017) with optional residual attention from previous layer\n",
    "    (Realformer: Transformer likes residual attention by He et al, 2020) and locality self sttention (Vision Transformer for Small-Size Datasets\n",
    "    by Lee et al, 2021)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, n_heads, attn_dropout=0., res_attention=False, lsa=False):\n",
    "        super().__init__()\n",
    "        self.attn_dropout = nn.Dropout(attn_dropout)\n",
    "        self.res_attention = res_attention\n",
    "        head_dim = hidden_size // n_heads\n",
    "        self.scale = nn.Parameter(torch.tensor(head_dim ** -0.5), requires_grad=lsa)\n",
    "        self.lsa = lsa\n",
    "\n",
    "    def forward(self, q:torch.Tensor, k:torch.Tensor, v:torch.Tensor,\n",
    "                prev:Optional[torch.Tensor]=None, key_padding_mask:Optional[torch.Tensor]=None,\n",
    "                attn_mask:Optional[torch.Tensor]=None):\n",
    "        '''\n",
    "        Input shape:\n",
    "            q               : [bs x n_heads x max_q_len x d_k]\n",
    "            k               : [bs x n_heads x d_k x seq_len]\n",
    "            v               : [bs x n_heads x seq_len x d_v]\n",
    "            prev            : [bs x n_heads x q_len x seq_len]\n",
    "            key_padding_mask: [bs x seq_len]\n",
    "            attn_mask       : [1 x seq_len x seq_len]\n",
    "        Output shape:\n",
    "            output:  [bs x n_heads x q_len x d_v]\n",
    "            attn   : [bs x n_heads x q_len x seq_len]\n",
    "            scores : [bs x n_heads x q_len x seq_len]\n",
    "        '''\n",
    "\n",
    "        # Scaled MatMul (q, k) - similarity scores for all pairs of positions in an input sequence\n",
    "        attn_scores = torch.matmul(q, k) * self.scale      # attn_scores : [bs x n_heads x max_q_len x q_len]\n",
    "\n",
    "        # Add pre-softmax attention scores from the previous layer (optional)\n",
    "        if prev is not None: attn_scores = attn_scores + prev\n",
    "\n",
    "        # Attention mask (optional)\n",
    "        if attn_mask is not None:                                     # attn_mask with shape [q_len x seq_len] - only used when q_len == seq_len\n",
    "            if attn_mask.dtype == torch.bool:\n",
    "                attn_scores.masked_fill_(attn_mask, -np.inf)\n",
    "            else:\n",
    "                attn_scores += attn_mask\n",
    "\n",
    "        # Key padding mask (optional)\n",
    "        if key_padding_mask is not None:                              # mask with shape [bs x q_len] (only when max_w_len == q_len)\n",
    "            attn_scores.masked_fill_(key_padding_mask.unsqueeze(1).unsqueeze(2), -np.inf)\n",
    "\n",
    "        # normalize the attention weights\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)                 # attn_weights   : [bs x n_heads x max_q_len x q_len]\n",
    "        attn_weights = self.attn_dropout(attn_weights)\n",
    "\n",
    "        # compute the new values given the attention weights\n",
    "        output = torch.matmul(attn_weights, v)                        # output: [bs x n_heads x max_q_len x d_v]\n",
    "\n",
    "        if self.res_attention: return output, attn_weights, attn_scores\n",
    "        else: return output, attn_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PatchTST(BaseWindows):\n",
    "    \"\"\" PatchTST\n",
    "\n",
    "    The PatchTST model is an efficient Transformer-based model for multivariate time series forecasting.\n",
    "\n",
    "    It is based on two key components:\n",
    "    - segmentation of time series into windows (patches) which are served as input tokens to Transformer\n",
    "    - channel-independence, where each channel contains a single univariate time series.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `h`: int, Forecast horizon. <br>\n",
    "    `input_size`: int, autorregresive inputs size, y=[1,2,3,4] input_size=2 -> y_[t-2:t]=[1,2].<br>\n",
    "    `stat_exog_list`: str list, static exogenous columns.<br>\n",
    "    `hist_exog_list`: str list, historic exogenous columns.<br>\n",
    "    `futr_exog_list`: str list, future exogenous columns.<br>\n",
    "    `exclude_insample_y`: bool=False, the model skips the autoregressive features y[t-input_size:t] if True.<br>\n",
    "    `encoder_layers`: int, number of layers for encoder.<br>\n",
    "    `n_heads`: int=16, number of multi-head's attention.<br>\n",
    "    `hidden_size`: int=128, units of embeddings and encoders.<br>\n",
    "    `linear_hidden_size`: int=256, units of linear layer.<br>\n",
    "    `dropout`: float=0.1, dropout rate for residual connection.<br>\n",
    "    `fc_dropout`: float=0.1, dropout rate for linear layer.<br>\n",
    "    `head_dropout`: float=0.1, dropout rate for Flatten head layer.<br>\n",
    "    `attn_dropout`: float=0.1, dropout rate for attention layer.<br>\n",
    "    `patch_len`: int=32, length of patch. Note: patch_len = min(patch_len, input_size + stride).<br>\n",
    "    `stride`: int=16, stride of patch.<br>\n",
    "    `revin`: bool=True, bool to use RevIn.<br>\n",
    "    `revin_affine`: bool=False, bool to use affine in RevIn.<br>\n",
    "    `revin_substract_last`: bool=False, bool to use substract last in RevIn.<br>\n",
    "    `activation`: str='ReLU', activation from ['gelu','relu'].<br>\n",
    "    `res_attention`: bool=False, bool to use residual attention.<br>\n",
    "    `batch_normalization`: bool=False, bool to use batch normalization.<br>\n",
    "    `learn_pos_embedding`: bool=True, bool to learn positional embedding.<br>\n",
    "    `loss`: PyTorch module, instantiated train loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
    "    `valid_loss`: PyTorch module=`loss`, instantiated valid loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
    "    `max_steps`: int=1000, maximum number of training steps.<br>\n",
    "    `learning_rate`: float=1e-3, Learning rate between (0, 1).<br>\n",
    "    `num_lr_decays`: int=-1, Number of learning rate decays, evenly distributed across max_steps.<br>\n",
    "    `early_stop_patience_steps`: int=-1, Number of validation iterations before early stopping.<br>\n",
    "    `val_check_steps`: int=100, Number of training steps between every validation loss check.<br>\n",
    "    `batch_size`: int=32, number of different series in each batch.<br>\n",
    "    `valid_batch_size`: int=None, number of different series in each validation and test batch, if None uses batch_size.<br>\n",
    "    `windows_batch_size`: int=1024, number of windows to sample in each training batch, default uses all.<br>\n",
    "    `inference_windows_batch_size`: int=1024, number of windows to sample in each inference batch.<br>\n",
    "    `start_padding_enabled`: bool=False, if True, the model will pad the time series with zeros at the beginning, by input size.<br>\n",
    "    `step_size`: int=1, step size between each window of temporal data.<br>\n",
    "    `scaler_type`: str='identity', type of scaler for temporal inputs normalization see [temporal scalers](https://nixtla.github.io/neuralforecast/common.scalers.html).<br>\n",
    "    `random_seed`: int, random_seed for pytorch initializer and numpy generators.<br>\n",
    "    `drop_last_loader`: bool=False, if True `TimeSeriesDataLoader` drops last non-full batch.<br>\n",
    "    `alias`: str, optional,  Custom name of the model.<br>\n",
    "    `optimizer`: Subclass of 'torch.optim.Optimizer', optional, user specified optimizer instead of the default choice (Adam).<br>\n",
    "    `optimizer_kwargs`: dict, optional, list of parameters used by the user specified `optimizer`.<br>\n",
    "    `lr_scheduler`: Subclass of 'torch.optim.lr_scheduler.LRScheduler', optional, user specified lr_scheduler instead of the default choice (StepLR).<br>\n",
    "    `lr_scheduler_kwargs`: dict, optional, list of parameters used by the user specified `lr_scheduler`.<br>    \n",
    "    `dataloader_kwargs`: dict, optional, list of parameters passed into the PyTorch Lightning dataloader by the `TimeSeriesDataLoader`. <br>\n",
    "    `**trainer_kwargs`: int,  keyword trainer arguments inherited from [PyTorch Lighning's trainer](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).<br>    \n",
    "\n",
    "    **References:**<br>\n",
    "    -[Nie, Y., Nguyen, N. H., Sinthong, P., & Kalagnanam, J. (2022). \"A Time Series is Worth 64 Words: Long-term Forecasting with Transformers\"](https://arxiv.org/pdf/2211.14730.pdf)\n",
    "    \"\"\"\n",
    "    # Class attributes\n",
    "    SAMPLING_TYPE = 'windows'\n",
    "    EXOGENOUS_FUTR = False\n",
    "    EXOGENOUS_HIST = False\n",
    "    EXOGENOUS_STAT = False\n",
    "\n",
    "    def __init__(self,\n",
    "                 h,\n",
    "                 input_size,\n",
    "                 stat_exog_list = None,\n",
    "                 hist_exog_list = None,\n",
    "                 futr_exog_list = None,\n",
    "                 exclude_insample_y = False,\n",
    "                 encoder_layers: int = 3,\n",
    "                 n_heads: int = 16,\n",
    "                 hidden_size: int = 128,\n",
    "                 linear_hidden_size: int = 256,\n",
    "                 dropout: float = 0.2,\n",
    "                 fc_dropout: float = 0.2,\n",
    "                 head_dropout: float = 0.0,\n",
    "                 attn_dropout: float = 0.,\n",
    "                 patch_len: int = 16,\n",
    "                 stride: int = 8,\n",
    "                 revin: bool = True,\n",
    "                 revin_affine: bool = False,\n",
    "                 revin_subtract_last: bool = True,\n",
    "                 activation: str = \"gelu\",\n",
    "                 res_attention: bool = True, \n",
    "                 batch_normalization: bool = False,\n",
    "                 learn_pos_embed: bool = True,\n",
    "                 loss = MAE(),\n",
    "                 valid_loss = None,\n",
    "                 max_steps: int = 5000,\n",
    "                 learning_rate: float = 1e-4,\n",
    "                 num_lr_decays: int = -1,\n",
    "                 early_stop_patience_steps: int =-1,\n",
    "                 val_check_steps: int = 100,\n",
    "                 batch_size: int = 32,\n",
    "                 valid_batch_size: Optional[int] = None,\n",
    "                 windows_batch_size = 1024,\n",
    "                 inference_windows_batch_size: int = 1024,\n",
    "                 start_padding_enabled = False,\n",
    "                 step_size: int = 1,\n",
    "                 scaler_type: str = 'identity',\n",
    "                 random_seed: int = 1,\n",
    "                 drop_last_loader: bool = False,\n",
    "                 optimizer = None,\n",
    "                 optimizer_kwargs = None,\n",
    "                 lr_scheduler = None,\n",
    "                 lr_scheduler_kwargs = None,\n",
    "                 dataloader_kwargs = None,\n",
    "                 **trainer_kwargs):\n",
    "        super(PatchTST, self).__init__(h=h,\n",
    "                                       input_size=input_size,\n",
    "                                       hist_exog_list=hist_exog_list,\n",
    "                                       stat_exog_list=stat_exog_list,\n",
    "                                       futr_exog_list = futr_exog_list,\n",
    "                                       exclude_insample_y = exclude_insample_y,\n",
    "                                       loss=loss,\n",
    "                                       valid_loss=valid_loss,\n",
    "                                       max_steps=max_steps,\n",
    "                                       learning_rate=learning_rate,\n",
    "                                       num_lr_decays=num_lr_decays,\n",
    "                                       early_stop_patience_steps=early_stop_patience_steps,\n",
    "                                       val_check_steps=val_check_steps,\n",
    "                                       batch_size=batch_size,\n",
    "                                       valid_batch_size=valid_batch_size,\n",
    "                                       windows_batch_size=windows_batch_size,\n",
    "                                       inference_windows_batch_size=inference_windows_batch_size,\n",
    "                                       start_padding_enabled=start_padding_enabled,\n",
    "                                       step_size=step_size,\n",
    "                                       scaler_type=scaler_type,\n",
    "                                       drop_last_loader=drop_last_loader,\n",
    "                                       random_seed=random_seed,\n",
    "                                       optimizer=optimizer,\n",
    "                                       optimizer_kwargs=optimizer_kwargs,\n",
    "                                       lr_scheduler=lr_scheduler,\n",
    "                                       lr_scheduler_kwargs=lr_scheduler_kwargs,\n",
    "                                       dataloader_kwargs=dataloader_kwargs,\n",
    "                                       **trainer_kwargs) \n",
    "\n",
    "        # Enforce correct patch_len, regardless of user input\n",
    "        patch_len = min(input_size + stride, patch_len)\n",
    "\n",
    "        c_out = self.loss.outputsize_multiplier\n",
    "\n",
    "        # Fixed hyperparameters\n",
    "        c_in = 1                  # Always univariate\n",
    "        padding_patch='end'       # Padding at the end\n",
    "        pretrain_head = False     # No pretrained head\n",
    "        norm = 'BatchNorm'        # Use BatchNorm (if batch_normalization is True)\n",
    "        pe = 'zeros'              # Initial zeros for positional encoding \n",
    "        d_k = None                # Key dimension\n",
    "        d_v = None                # Value dimension\n",
    "        store_attn = False        # Store attention weights\n",
    "        head_type = 'flatten'     # Head type\n",
    "        individual = False        # Separate heads for each time series\n",
    "        max_seq_len = 1024        # Not used\n",
    "        key_padding_mask = 'auto' # Not used\n",
    "        padding_var = None        # Not used\n",
    "        attn_mask = None          # Not used\n",
    "\n",
    "        self.model = PatchTST_backbone(c_in=c_in, c_out=c_out, input_size=input_size, h=h, patch_len=patch_len, stride=stride, \n",
    "                                max_seq_len=max_seq_len, n_layers=encoder_layers, hidden_size=hidden_size,\n",
    "                                n_heads=n_heads, d_k=d_k, d_v=d_v, linear_hidden_size=linear_hidden_size, norm=norm, attn_dropout=attn_dropout,\n",
    "                                dropout=dropout, act=activation, key_padding_mask=key_padding_mask, padding_var=padding_var, \n",
    "                                attn_mask=attn_mask, res_attention=res_attention, pre_norm=batch_normalization, store_attn=store_attn,\n",
    "                                pe=pe, learn_pe=learn_pos_embed, fc_dropout=fc_dropout, head_dropout=head_dropout, padding_patch = padding_patch,\n",
    "                                pretrain_head=pretrain_head, head_type=head_type, individual=individual, revin=revin, affine=revin_affine,\n",
    "                                subtract_last=revin_subtract_last)\n",
    "    \n",
    "    \n",
    "    def forward(self, windows_batch):  # x: [batch, input_size]\n",
    "\n",
    "        # Parse windows_batch\n",
    "        insample_y    = windows_batch['insample_y']\n",
    "        #insample_mask = windows_batch['insample_mask']\n",
    "        #hist_exog     = windows_batch['hist_exog']\n",
    "        #stat_exog     = windows_batch['stat_exog']\n",
    "        #futr_exog     = windows_batch['futr_exog']\n",
    "\n",
    "        # Add dimension for channel\n",
    "        x = insample_y.unsqueeze(-1) # [Ws,L,1]\n",
    "\n",
    "        x = x.permute(0,2,1)    # x: [Batch, 1, input_size]\n",
    "        x = self.model(x)\n",
    "        x = x.reshape(x.shape[0], self.h, -1) # x: [Batch, h, c_out]\n",
    "\n",
    "        # Domain map\n",
    "        forecast = self.loss.domain_map(x)\n",
    "        \n",
    "        return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/models/patchtst.py#L788){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PatchTST\n",
       "\n",
       ">      PatchTST (h, input_size, stat_exog_list=None, hist_exog_list=None,\n",
       ">                futr_exog_list=None, exclude_insample_y=False,\n",
       ">                encoder_layers:int=3, n_heads:int=16, hidden_size:int=128,\n",
       ">                linear_hidden_size:int=256, dropout:float=0.2,\n",
       ">                fc_dropout:float=0.2, head_dropout:float=0.0,\n",
       ">                attn_dropout:float=0.0, patch_len:int=16, stride:int=8,\n",
       ">                revin:bool=True, revin_affine:bool=False,\n",
       ">                revin_subtract_last:bool=True, activation:str='gelu',\n",
       ">                res_attention:bool=True, batch_normalization:bool=False,\n",
       ">                learn_pos_embed:bool=True, loss=MAE(), valid_loss=None,\n",
       ">                max_steps:int=5000, learning_rate:float=0.0001,\n",
       ">                num_lr_decays:int=-1, early_stop_patience_steps:int=-1,\n",
       ">                val_check_steps:int=100, batch_size:int=32,\n",
       ">                valid_batch_size:Optional[int]=None, windows_batch_size=1024,\n",
       ">                inference_windows_batch_size:int=1024,\n",
       ">                start_padding_enabled=False, step_size:int=1,\n",
       ">                scaler_type:str='identity', random_seed:int=1,\n",
       ">                drop_last_loader:bool=False, optimizer=None,\n",
       ">                optimizer_kwargs=None, lr_scheduler=None,\n",
       ">                lr_scheduler_kwargs=None, dataloader_kwargs=None,\n",
       ">                **trainer_kwargs)\n",
       "\n",
       "*PatchTST\n",
       "\n",
       "The PatchTST model is an efficient Transformer-based model for multivariate time series forecasting.\n",
       "\n",
       "It is based on two key components:\n",
       "- segmentation of time series into windows (patches) which are served as input tokens to Transformer\n",
       "- channel-independence, where each channel contains a single univariate time series.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`h`: int, Forecast horizon. <br>\n",
       "`input_size`: int, autorregresive inputs size, y=[1,2,3,4] input_size=2 -> y_[t-2:t]=[1,2].<br>\n",
       "`stat_exog_list`: str list, static exogenous columns.<br>\n",
       "`hist_exog_list`: str list, historic exogenous columns.<br>\n",
       "`futr_exog_list`: str list, future exogenous columns.<br>\n",
       "`exclude_insample_y`: bool=False, the model skips the autoregressive features y[t-input_size:t] if True.<br>\n",
       "`encoder_layers`: int, number of layers for encoder.<br>\n",
       "`n_heads`: int=16, number of multi-head's attention.<br>\n",
       "`hidden_size`: int=128, units of embeddings and encoders.<br>\n",
       "`linear_hidden_size`: int=256, units of linear layer.<br>\n",
       "`dropout`: float=0.1, dropout rate for residual connection.<br>\n",
       "`fc_dropout`: float=0.1, dropout rate for linear layer.<br>\n",
       "`head_dropout`: float=0.1, dropout rate for Flatten head layer.<br>\n",
       "`attn_dropout`: float=0.1, dropout rate for attention layer.<br>\n",
       "`patch_len`: int=32, length of patch. Note: patch_len = min(patch_len, input_size + stride).<br>\n",
       "`stride`: int=16, stride of patch.<br>\n",
       "`revin`: bool=True, bool to use RevIn.<br>\n",
       "`revin_affine`: bool=False, bool to use affine in RevIn.<br>\n",
       "`revin_substract_last`: bool=False, bool to use substract last in RevIn.<br>\n",
       "`activation`: str='ReLU', activation from ['gelu','relu'].<br>\n",
       "`res_attention`: bool=False, bool to use residual attention.<br>\n",
       "`batch_normalization`: bool=False, bool to use batch normalization.<br>\n",
       "`learn_pos_embedding`: bool=True, bool to learn positional embedding.<br>\n",
       "`loss`: PyTorch module, instantiated train loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
       "`valid_loss`: PyTorch module=`loss`, instantiated valid loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
       "`max_steps`: int=1000, maximum number of training steps.<br>\n",
       "`learning_rate`: float=1e-3, Learning rate between (0, 1).<br>\n",
       "`num_lr_decays`: int=-1, Number of learning rate decays, evenly distributed across max_steps.<br>\n",
       "`early_stop_patience_steps`: int=-1, Number of validation iterations before early stopping.<br>\n",
       "`val_check_steps`: int=100, Number of training steps between every validation loss check.<br>\n",
       "`batch_size`: int=32, number of different series in each batch.<br>\n",
       "`valid_batch_size`: int=None, number of different series in each validation and test batch, if None uses batch_size.<br>\n",
       "`windows_batch_size`: int=1024, number of windows to sample in each training batch, default uses all.<br>\n",
       "`inference_windows_batch_size`: int=1024, number of windows to sample in each inference batch.<br>\n",
       "`start_padding_enabled`: bool=False, if True, the model will pad the time series with zeros at the beginning, by input size.<br>\n",
       "`step_size`: int=1, step size between each window of temporal data.<br>\n",
       "`scaler_type`: str='identity', type of scaler for temporal inputs normalization see [temporal scalers](https://nixtla.github.io/neuralforecast/common.scalers.html).<br>\n",
       "`random_seed`: int, random_seed for pytorch initializer and numpy generators.<br>\n",
       "`drop_last_loader`: bool=False, if True `TimeSeriesDataLoader` drops last non-full batch.<br>\n",
       "`alias`: str, optional,  Custom name of the model.<br>\n",
       "`optimizer`: Subclass of 'torch.optim.Optimizer', optional, user specified optimizer instead of the default choice (Adam).<br>\n",
       "`optimizer_kwargs`: dict, optional, list of parameters used by the user specified `optimizer`.<br>\n",
       "`lr_scheduler`: Subclass of 'torch.optim.lr_scheduler.LRScheduler', optional, user specified lr_scheduler instead of the default choice (StepLR).<br>\n",
       "`lr_scheduler_kwargs`: dict, optional, list of parameters used by the user specified `lr_scheduler`.<br>    \n",
       "`dataloader_kwargs`: dict, optional, list of parameters passed into the PyTorch Lightning dataloader by the `TimeSeriesDataLoader`. <br>\n",
       "`**trainer_kwargs`: int,  keyword trainer arguments inherited from [PyTorch Lighning's trainer](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).<br>    \n",
       "\n",
       "**References:**<br>\n",
       "-[Nie, Y., Nguyen, N. H., Sinthong, P., & Kalagnanam, J. (2022). \"A Time Series is Worth 64 Words: Long-term Forecasting with Transformers\"](https://arxiv.org/pdf/2211.14730.pdf)*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/models/patchtst.py#L788){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PatchTST\n",
       "\n",
       ">      PatchTST (h, input_size, stat_exog_list=None, hist_exog_list=None,\n",
       ">                futr_exog_list=None, exclude_insample_y=False,\n",
       ">                encoder_layers:int=3, n_heads:int=16, hidden_size:int=128,\n",
       ">                linear_hidden_size:int=256, dropout:float=0.2,\n",
       ">                fc_dropout:float=0.2, head_dropout:float=0.0,\n",
       ">                attn_dropout:float=0.0, patch_len:int=16, stride:int=8,\n",
       ">                revin:bool=True, revin_affine:bool=False,\n",
       ">                revin_subtract_last:bool=True, activation:str='gelu',\n",
       ">                res_attention:bool=True, batch_normalization:bool=False,\n",
       ">                learn_pos_embed:bool=True, loss=MAE(), valid_loss=None,\n",
       ">                max_steps:int=5000, learning_rate:float=0.0001,\n",
       ">                num_lr_decays:int=-1, early_stop_patience_steps:int=-1,\n",
       ">                val_check_steps:int=100, batch_size:int=32,\n",
       ">                valid_batch_size:Optional[int]=None, windows_batch_size=1024,\n",
       ">                inference_windows_batch_size:int=1024,\n",
       ">                start_padding_enabled=False, step_size:int=1,\n",
       ">                scaler_type:str='identity', random_seed:int=1,\n",
       ">                drop_last_loader:bool=False, optimizer=None,\n",
       ">                optimizer_kwargs=None, lr_scheduler=None,\n",
       ">                lr_scheduler_kwargs=None, dataloader_kwargs=None,\n",
       ">                **trainer_kwargs)\n",
       "\n",
       "*PatchTST\n",
       "\n",
       "The PatchTST model is an efficient Transformer-based model for multivariate time series forecasting.\n",
       "\n",
       "It is based on two key components:\n",
       "- segmentation of time series into windows (patches) which are served as input tokens to Transformer\n",
       "- channel-independence, where each channel contains a single univariate time series.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`h`: int, Forecast horizon. <br>\n",
       "`input_size`: int, autorregresive inputs size, y=[1,2,3,4] input_size=2 -> y_[t-2:t]=[1,2].<br>\n",
       "`stat_exog_list`: str list, static exogenous columns.<br>\n",
       "`hist_exog_list`: str list, historic exogenous columns.<br>\n",
       "`futr_exog_list`: str list, future exogenous columns.<br>\n",
       "`exclude_insample_y`: bool=False, the model skips the autoregressive features y[t-input_size:t] if True.<br>\n",
       "`encoder_layers`: int, number of layers for encoder.<br>\n",
       "`n_heads`: int=16, number of multi-head's attention.<br>\n",
       "`hidden_size`: int=128, units of embeddings and encoders.<br>\n",
       "`linear_hidden_size`: int=256, units of linear layer.<br>\n",
       "`dropout`: float=0.1, dropout rate for residual connection.<br>\n",
       "`fc_dropout`: float=0.1, dropout rate for linear layer.<br>\n",
       "`head_dropout`: float=0.1, dropout rate for Flatten head layer.<br>\n",
       "`attn_dropout`: float=0.1, dropout rate for attention layer.<br>\n",
       "`patch_len`: int=32, length of patch. Note: patch_len = min(patch_len, input_size + stride).<br>\n",
       "`stride`: int=16, stride of patch.<br>\n",
       "`revin`: bool=True, bool to use RevIn.<br>\n",
       "`revin_affine`: bool=False, bool to use affine in RevIn.<br>\n",
       "`revin_substract_last`: bool=False, bool to use substract last in RevIn.<br>\n",
       "`activation`: str='ReLU', activation from ['gelu','relu'].<br>\n",
       "`res_attention`: bool=False, bool to use residual attention.<br>\n",
       "`batch_normalization`: bool=False, bool to use batch normalization.<br>\n",
       "`learn_pos_embedding`: bool=True, bool to learn positional embedding.<br>\n",
       "`loss`: PyTorch module, instantiated train loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
       "`valid_loss`: PyTorch module=`loss`, instantiated valid loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
       "`max_steps`: int=1000, maximum number of training steps.<br>\n",
       "`learning_rate`: float=1e-3, Learning rate between (0, 1).<br>\n",
       "`num_lr_decays`: int=-1, Number of learning rate decays, evenly distributed across max_steps.<br>\n",
       "`early_stop_patience_steps`: int=-1, Number of validation iterations before early stopping.<br>\n",
       "`val_check_steps`: int=100, Number of training steps between every validation loss check.<br>\n",
       "`batch_size`: int=32, number of different series in each batch.<br>\n",
       "`valid_batch_size`: int=None, number of different series in each validation and test batch, if None uses batch_size.<br>\n",
       "`windows_batch_size`: int=1024, number of windows to sample in each training batch, default uses all.<br>\n",
       "`inference_windows_batch_size`: int=1024, number of windows to sample in each inference batch.<br>\n",
       "`start_padding_enabled`: bool=False, if True, the model will pad the time series with zeros at the beginning, by input size.<br>\n",
       "`step_size`: int=1, step size between each window of temporal data.<br>\n",
       "`scaler_type`: str='identity', type of scaler for temporal inputs normalization see [temporal scalers](https://nixtla.github.io/neuralforecast/common.scalers.html).<br>\n",
       "`random_seed`: int, random_seed for pytorch initializer and numpy generators.<br>\n",
       "`drop_last_loader`: bool=False, if True `TimeSeriesDataLoader` drops last non-full batch.<br>\n",
       "`alias`: str, optional,  Custom name of the model.<br>\n",
       "`optimizer`: Subclass of 'torch.optim.Optimizer', optional, user specified optimizer instead of the default choice (Adam).<br>\n",
       "`optimizer_kwargs`: dict, optional, list of parameters used by the user specified `optimizer`.<br>\n",
       "`lr_scheduler`: Subclass of 'torch.optim.lr_scheduler.LRScheduler', optional, user specified lr_scheduler instead of the default choice (StepLR).<br>\n",
       "`lr_scheduler_kwargs`: dict, optional, list of parameters used by the user specified `lr_scheduler`.<br>    \n",
       "`dataloader_kwargs`: dict, optional, list of parameters passed into the PyTorch Lightning dataloader by the `TimeSeriesDataLoader`. <br>\n",
       "`**trainer_kwargs`: int,  keyword trainer arguments inherited from [PyTorch Lighning's trainer](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).<br>    \n",
       "\n",
       "**References:**<br>\n",
       "-[Nie, Y., Nguyen, N. H., Sinthong, P., & Kalagnanam, J. (2022). \"A Time Series is Worth 64 Words: Long-term Forecasting with Transformers\"](https://arxiv.org/pdf/2211.14730.pdf)*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(PatchTST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### PatchTST.fit\n",
       "\n",
       ">      PatchTST.fit (dataset, val_size=0, test_size=0, random_seed=None,\n",
       ">                    distributed_config=None)\n",
       "\n",
       "*Fit.\n",
       "\n",
       "The `fit` method, optimizes the neural network's weights using the\n",
       "initialization parameters (`learning_rate`, `windows_batch_size`, ...)\n",
       "and the `loss` function as defined during the initialization.\n",
       "Within `fit` we use a PyTorch Lightning `Trainer` that\n",
       "inherits the initialization's `self.trainer_kwargs`, to customize\n",
       "its inputs, see [PL's trainer arguments](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).\n",
       "\n",
       "The method is designed to be compatible with SKLearn-like classes\n",
       "and in particular to be compatible with the StatsForecast library.\n",
       "\n",
       "By default the `model` is not saving training checkpoints to protect\n",
       "disk memory, to get them change `enable_checkpointing=True` in `__init__`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`val_size`: int, validation size for temporal cross-validation.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`test_size`: int, test size for temporal cross-validation.<br>*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### PatchTST.fit\n",
       "\n",
       ">      PatchTST.fit (dataset, val_size=0, test_size=0, random_seed=None,\n",
       ">                    distributed_config=None)\n",
       "\n",
       "*Fit.\n",
       "\n",
       "The `fit` method, optimizes the neural network's weights using the\n",
       "initialization parameters (`learning_rate`, `windows_batch_size`, ...)\n",
       "and the `loss` function as defined during the initialization.\n",
       "Within `fit` we use a PyTorch Lightning `Trainer` that\n",
       "inherits the initialization's `self.trainer_kwargs`, to customize\n",
       "its inputs, see [PL's trainer arguments](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).\n",
       "\n",
       "The method is designed to be compatible with SKLearn-like classes\n",
       "and in particular to be compatible with the StatsForecast library.\n",
       "\n",
       "By default the `model` is not saving training checkpoints to protect\n",
       "disk memory, to get them change `enable_checkpointing=True` in `__init__`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`val_size`: int, validation size for temporal cross-validation.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`test_size`: int, test size for temporal cross-validation.<br>*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(PatchTST.fit, name='PatchTST.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### PatchTST.predict\n",
       "\n",
       ">      PatchTST.predict (dataset, test_size=None, step_size=1, random_seed=None,\n",
       ">                        **data_module_kwargs)\n",
       "\n",
       "*Predict.\n",
       "\n",
       "Neural network prediction with PL's `Trainer` execution of `predict_step`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`test_size`: int=None, test size for temporal cross-validation.<br>\n",
       "`step_size`: int=1, Step size between each window.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`**data_module_kwargs`: PL's TimeSeriesDataModule args, see [documentation](https://pytorch-lightning.readthedocs.io/en/1.6.1/extensions/datamodules.html#using-a-datamodule).*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### PatchTST.predict\n",
       "\n",
       ">      PatchTST.predict (dataset, test_size=None, step_size=1, random_seed=None,\n",
       ">                        **data_module_kwargs)\n",
       "\n",
       "*Predict.\n",
       "\n",
       "Neural network prediction with PL's `Trainer` execution of `predict_step`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`test_size`: int=None, test size for temporal cross-validation.<br>\n",
       "`step_size`: int=1, Step size between each window.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`**data_module_kwargs`: PL's TimeSeriesDataModule args, see [documentation](https://pytorch-lightning.readthedocs.io/en/1.6.1/extensions/datamodules.html#using-a-datamodule).*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(PatchTST.predict, name='PatchTST.predict')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type              | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | loss         | DistributionLoss  | 5      | train\n",
      "1 | padder_train | ConstantPad1d     | 0      | train\n",
      "2 | scaler       | TemporalNorm      | 0      | train\n",
      "3 | model        | PatchTST_backbone | 32.2 K | train\n",
      "-----------------------------------------------------------\n",
      "32.2 K    Trainable params\n",
      "8         Non-trainable params\n",
      "32.3 K    Total params\n",
      "0.129     Total estimated model params size (MB)\n",
      "89        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|| 1/1 [00:00<00:00, 25.75it/s, v_num=9332, train_loss_step=5.48e+3, train_loss_epoch=5.48e+3, valid_loss=13.70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ospra\\miniconda3\\envs\\neuralforecast\\lib\\site-packages\\utilsforecast\\processing.py:384: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(freq)\n",
      "c:\\Users\\ospra\\miniconda3\\envs\\neuralforecast\\lib\\site-packages\\utilsforecast\\processing.py:438: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(freq)\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 1/1 [00:00<00:00, 150.59it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import PatchTST\n",
    "from neuralforecast.losses.pytorch import DistributionLoss\n",
    "from neuralforecast.utils import AirPassengersPanel, AirPassengersStatic, augment_calendar_df\n",
    "\n",
    "AirPassengersPanel, calendar_cols = augment_calendar_df(df=AirPassengersPanel, freq='M')\n",
    "\n",
    "Y_train_df = AirPassengersPanel[AirPassengersPanel.ds<AirPassengersPanel['ds'].values[-12]] # 132 train\n",
    "Y_test_df = AirPassengersPanel[AirPassengersPanel.ds>=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n",
    "\n",
    "model = PatchTST(h=12,\n",
    "                 input_size=104,\n",
    "                 patch_len=24,\n",
    "                 stride=24,\n",
    "                 revin=False,\n",
    "                 hidden_size=16,\n",
    "                 n_heads=4,\n",
    "                 scaler_type='robust',\n",
    "                 loss=DistributionLoss(distribution='StudentT', level=[80, 90]),\n",
    "                 #loss=MAE(),\n",
    "                 learning_rate=1e-3,\n",
    "                 max_steps=500,\n",
    "                 val_check_steps=50,\n",
    "                 early_stop_patience_steps=2)\n",
    "\n",
    "nf = NeuralForecast(\n",
    "    models=[model],\n",
    "    freq='M'\n",
    ")\n",
    "nf.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\n",
    "forecasts = nf.predict(futr_df=Y_test_df)\n",
    "\n",
    "Y_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\n",
    "plot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\n",
    "plot_df = pd.concat([Y_train_df, plot_df])\n",
    "\n",
    "if model.loss.is_distribution_output:\n",
    "    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n",
    "    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n",
    "    plt.plot(plot_df['ds'], plot_df['PatchTST-median'], c='blue', label='median')\n",
    "    plt.fill_between(x=plot_df['ds'][-12:], \n",
    "                    y1=plot_df['PatchTST-lo-90'][-12:].values, \n",
    "                    y2=plot_df['PatchTST-hi-90'][-12:].values,\n",
    "                    alpha=0.4, label='level 90')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.plot()\n",
    "else:\n",
    "    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n",
    "    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n",
    "    plt.plot(plot_df['ds'], plot_df['PatchTST'], c='blue', label='Forecast')\n",
    "    plt.legend()\n",
    "    plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
