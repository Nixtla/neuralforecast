{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "524620c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp losses.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15392f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa25a4",
   "metadata": {},
   "source": [
    "# PyTorch Losses\n",
    "\n",
    "> NeuralForecast contains a collection PyTorch Loss classes aimed to be used during the models' optimization. The most important train signal is the forecast error, which is the difference between the observed value $y_{\\tau}$ and the prediction $\\hat{y}_{\\tau}$, at time $y_{\\tau}$:$$e_{\\tau} = y_{\\tau}-\\hat{y}_{\\tau} \\qquad \\qquad \\tau \\in \\{t+1,\\dots,t+H \\}$$ The train loss summarizes the forecast errors in different train optimization objectives.<br><br>All the losses are `torch.nn.modules` which helps to automatically moved them across CPU/GPU/TPU devices with Pytorch Lightning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acfa68dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Optional, Union, Tuple\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Distribution\n",
    "from torch.distributions import (\n",
    "    Bernoulli,\n",
    "    Normal, \n",
    "    StudentT, \n",
    "    Poisson,\n",
    "    NegativeBinomial\n",
    ")\n",
    "\n",
    "from torch.distributions import constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2508f7a9-1433-4ad8-8f2f-0078c6ed6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import matplotlib.pyplot as plt\n",
    "from fastcore.test import test_eq\n",
    "from nbdev.showdoc import show_doc\n",
    "from neuralforecast.utils import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84e07e98-b4c8-4ade-b3b6-1d27f367aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _divide_no_nan(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Auxiliary funtion to handle divide by 0\n",
    "    \"\"\"\n",
    "    div = a / b\n",
    "    div[div != div] = 0.0\n",
    "    div[div == float('inf')] = 0.0\n",
    "    return div"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a94d7d",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\">1. Scale-dependent Errors </span>\n",
    "\n",
    "These metrics are on the same scale as the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fc4679",
   "metadata": {},
   "source": [
    "## Mean Absolute Error (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e413fae-c590-4713-aab9-37c61ed37dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MAE(torch.nn.Module):\n",
    "    \"\"\"Mean Absolute Error\n",
    "\n",
    "    Calculates Mean Absolute Error between\n",
    "    `y` and `y_hat`. MAE measures the relative prediction\n",
    "    accuracy of a forecasting method by calculating the\n",
    "    deviation of the prediction and the true\n",
    "    value at a given time and averages these devations\n",
    "    over the length of the series.\n",
    "\n",
    "    $$ \\mathrm{MAE}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}_{\\\\tau}) = \\\\frac{1}{H} \\\\sum^{t+H}_{\\\\tau=t+1} |y_{\\\\tau} - \\hat{y}_{\\\\tau}| $$\n",
    "    \"\"\"    \n",
    "    def __init__(self):\n",
    "        super(MAE, self).__init__()\n",
    "        self.outputsize_multiplier = 1\n",
    "        self.output_names = ['']\n",
    "        self.is_distribution_output = False\n",
    "\n",
    "    def domain_map(self, y_hat: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Univariate loss operates in dimension [B,T,H]/[B,H]\n",
    "        This changes the network's output from [B,H,1]->[B,H]\n",
    "        \"\"\"\n",
    "        return y_hat.squeeze(-1)\n",
    "\n",
    "    def __call__(self, y: torch.Tensor, y_hat: torch.Tensor,\n",
    "                 mask: Union[torch.Tensor, None] = None):\n",
    "        \"\"\"\n",
    "        **Parameters:**<br>\n",
    "        `y`: tensor, Actual values.<br>\n",
    "        `y_hat`: tensor, Predicted values.<br>\n",
    "        `mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `mae`: tensor (single value).\n",
    "        \"\"\"\n",
    "        if mask is None:\n",
    "            mask = torch.ones_like(y)\n",
    "\n",
    "        mae = torch.abs(y - y_hat) * mask\n",
    "        mae = torch.mean(mae)\n",
    "        return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d004cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L31){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MAE.__init__\n",
       "\n",
       ">      MAE.__init__ ()\n",
       "\n",
       "Mean Absolute Error\n",
       "\n",
       "Calculates Mean Absolute Error between\n",
       "`y` and `y_hat`. MAE measures the relative prediction\n",
       "accuracy of a forecasting method by calculating the\n",
       "deviation of the prediction and the true\n",
       "value at a given time and averages these devations\n",
       "over the length of the series.\n",
       "\n",
       "$$ \\mathrm{MAE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} |y_{\\tau} - \\hat{y}_{\\tau}| $$"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L31){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MAE.__init__\n",
       "\n",
       ">      MAE.__init__ ()\n",
       "\n",
       "Mean Absolute Error\n",
       "\n",
       "Calculates Mean Absolute Error between\n",
       "`y` and `y_hat`. MAE measures the relative prediction\n",
       "accuracy of a forecasting method by calculating the\n",
       "deviation of the prediction and the true\n",
       "value at a given time and averages these devations\n",
       "over the length of the series.\n",
       "\n",
       "$$ \\mathrm{MAE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} |y_{\\tau} - \\hat{y}_{\\tau}| $$"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MAE, name='MAE.__init__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a20a273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L57){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MAE.__call__\n",
       "\n",
       ">      MAE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                    mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`mae`: tensor (single value)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L57){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MAE.__call__\n",
       "\n",
       ">      MAE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                    mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`mae`: tensor (single value)."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MAE.__call__, name='MAE.__call__', title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0292c74d",
   "metadata": {},
   "source": [
    "![](imgs_losses/mae_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f31cc3d",
   "metadata": {},
   "source": [
    "## Mean Squared Error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "472b63b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MSE(torch.nn.Module):\n",
    "    \"\"\"  Mean Squared Error\n",
    "\n",
    "    Calculates Mean Squared Error between\n",
    "    `y` and `y_hat`. MSE measures the relative prediction\n",
    "    accuracy of a forecasting method by calculating the \n",
    "    squared deviation of the prediction and the true\n",
    "    value at a given time, and averages these devations\n",
    "    over the length of the series.\n",
    "    \n",
    "    $$ \\mathrm{MSE}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}_{\\\\tau}) = \\\\frac{1}{H} \\\\sum^{t+H}_{\\\\tau=t+1} (y_{\\\\tau} - \\hat{y}_{\\\\tau})^{2} $$\n",
    "    \"\"\"    \n",
    "    def __init__(self):\n",
    "        super(MSE, self).__init__()\n",
    "        self.outputsize_multiplier = 1\n",
    "        self.output_names = ['']\n",
    "        self.is_distribution_output = False\n",
    "\n",
    "    def domain_map(self, y_hat: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Univariate loss operates in dimension [B,T,H]/[B,H]\n",
    "        This changes the network's output from [B,H,1]->[B,H]\n",
    "        \"\"\"\n",
    "        return y_hat.squeeze(-1)\n",
    "\n",
    "    def __call__(self, y: torch.Tensor, y_hat: torch.Tensor,\n",
    "                 mask: Union[torch.Tensor, None] = None):\n",
    "        \"\"\"\n",
    "        **Parameters:**<br>\n",
    "        `y`: tensor, Actual values.<br>\n",
    "        `y_hat`: tensor, Predicted values.<br>\n",
    "        `mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `mse`: tensor (single value).\n",
    "        \"\"\"\n",
    "        if mask is None:\n",
    "            mask = torch.ones_like(y_hat)\n",
    "\n",
    "        mse = (y - y_hat)**2\n",
    "        mse = mask * mse\n",
    "        mse = torch.mean(mse)\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8c65b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L80){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSE.__init__\n",
       "\n",
       ">      MSE.__init__ ()\n",
       "\n",
       "Mean Squared Error\n",
       "\n",
       "Calculates Mean Squared Error between\n",
       "`y` and `y_hat`. MSE measures the relative prediction\n",
       "accuracy of a forecasting method by calculating the \n",
       "squared deviation of the prediction and the true\n",
       "value at a given time, and averages these devations\n",
       "over the length of the series.\n",
       "\n",
       "$$ \\mathrm{MSE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} (y_{\\tau} - \\hat{y}_{\\tau})^{2} $$"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L80){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSE.__init__\n",
       "\n",
       ">      MSE.__init__ ()\n",
       "\n",
       "Mean Squared Error\n",
       "\n",
       "Calculates Mean Squared Error between\n",
       "`y` and `y_hat`. MSE measures the relative prediction\n",
       "accuracy of a forecasting method by calculating the \n",
       "squared deviation of the prediction and the true\n",
       "value at a given time, and averages these devations\n",
       "over the length of the series.\n",
       "\n",
       "$$ \\mathrm{MSE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} (y_{\\tau} - \\hat{y}_{\\tau})^{2} $$"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MSE, name='MSE.__init__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0126a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L106){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSE.__call__\n",
       "\n",
       ">      MSE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                    mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`mse`: tensor (single value)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L106){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSE.__call__\n",
       "\n",
       ">      MSE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                    mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`mse`: tensor (single value)."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MSE.__call__, name='MSE.__call__', title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b23f9c1",
   "metadata": {},
   "source": [
    "![](imgs_losses/mse_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b160140b",
   "metadata": {},
   "source": [
    "## Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab87149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RMSE(torch.nn.Module):\n",
    "    \"\"\" Root Mean Squared Error\n",
    "\n",
    "    Calculates Root Mean Squared Error between\n",
    "    `y` and `y_hat`. RMSE measures the relative prediction\n",
    "    accuracy of a forecasting method by calculating the squared deviation\n",
    "    of the prediction and the observed value at a given time and\n",
    "    averages these devations over the length of the series.\n",
    "    Finally the RMSE will be in the same scale\n",
    "    as the original time series so its comparison with other\n",
    "    series is possible only if they share a common scale. \n",
    "    RMSE has a direct connection to the L2 norm.\n",
    "    \n",
    "    $$ \\mathrm{RMSE}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}_{\\\\tau}) = \\\\sqrt{\\\\frac{1}{H} \\\\sum^{t+H}_{\\\\tau=t+1} (y_{\\\\tau} - \\hat{y}_{\\\\tau})^{2}} $$\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(RMSE, self).__init__()\n",
    "        self.outputsize_multiplier = 1\n",
    "        self.output_names = ['']\n",
    "        self.is_distribution_output = False\n",
    "\n",
    "    def domain_map(self, y_hat: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Univariate loss operates in dimension [B,T,H]/[B,H]\n",
    "        This changes the network's output from [B,H,1]->[B,H]\n",
    "        \"\"\"\n",
    "        return y_hat.squeeze(-1)\n",
    "\n",
    "    def __call__(self, y: torch.Tensor, y_hat: torch.Tensor, \n",
    "                 mask: Union[torch.Tensor, None] = None):\n",
    "        \"\"\"\n",
    "        **Parameters:**<br>\n",
    "        `y`: tensor, Actual values.<br>\n",
    "        `y_hat`: tensor, Predicted values.<br>\n",
    "        `mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `rmse`: tensor (single value).\n",
    "        \"\"\"\n",
    "        if mask is None: \n",
    "            mask = torch.ones_like(y_hat)\n",
    "\n",
    "        mse = (y - y_hat)**2\n",
    "        mse = mask * mse\n",
    "        mse = torch.mean(mse)\n",
    "        mse = torch.sqrt(mse)\n",
    "        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d961d383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L130){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### RMSE.__init__\n",
       "\n",
       ">      RMSE.__init__ ()\n",
       "\n",
       "Root Mean Squared Error\n",
       "\n",
       "Calculates Root Mean Squared Error between\n",
       "`y` and `y_hat`. RMSE measures the relative prediction\n",
       "accuracy of a forecasting method by calculating the squared deviation\n",
       "of the prediction and the observed value at a given time and\n",
       "averages these devations over the length of the series.\n",
       "Finally the RMSE will be in the same scale\n",
       "as the original time series so its comparison with other\n",
       "series is possible only if they share a common scale. \n",
       "RMSE has a direct connection to the L2 norm.\n",
       "\n",
       "$$ \\mathrm{RMSE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\sqrt{\\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} (y_{\\tau} - \\hat{y}_{\\tau})^{2}} $$"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L130){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### RMSE.__init__\n",
       "\n",
       ">      RMSE.__init__ ()\n",
       "\n",
       "Root Mean Squared Error\n",
       "\n",
       "Calculates Root Mean Squared Error between\n",
       "`y` and `y_hat`. RMSE measures the relative prediction\n",
       "accuracy of a forecasting method by calculating the squared deviation\n",
       "of the prediction and the observed value at a given time and\n",
       "averages these devations over the length of the series.\n",
       "Finally the RMSE will be in the same scale\n",
       "as the original time series so its comparison with other\n",
       "series is possible only if they share a common scale. \n",
       "RMSE has a direct connection to the L2 norm.\n",
       "\n",
       "$$ \\mathrm{RMSE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\sqrt{\\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} (y_{\\tau} - \\hat{y}_{\\tau})^{2}} $$"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(RMSE, name='RMSE.__init__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d398d3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L159){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### RMSE.__call__\n",
       "\n",
       ">      RMSE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                     mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`rmse`: tensor (single value)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L159){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### RMSE.__call__\n",
       "\n",
       ">      RMSE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                     mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`rmse`: tensor (single value)."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(RMSE.__call__, name='RMSE.__call__', title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4539e38",
   "metadata": {},
   "source": [
    "![](imgs_losses/rmse_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcf5488",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 2. Percentage errors </span>\n",
    "\n",
    "These metrics are unit-free, suitable for comparisons across series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eab97ec",
   "metadata": {},
   "source": [
    "## Mean Absolute Percentage Error (MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbddc1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MAPE(torch.nn.Module):\n",
    "    \"\"\" Mean Absolute Percentage Error\n",
    "\n",
    "    Calculates Mean Absolute Percentage Error  between\n",
    "    `y` and `y_hat`. MAPE measures the relative prediction\n",
    "    accuracy of a forecasting method by calculating the percentual deviation\n",
    "    of the prediction and the observed value at a given time and\n",
    "    averages these devations over the length of the series.\n",
    "    The closer to zero an observed value is, the higher penalty MAPE loss\n",
    "    assigns to the corresponding error.\n",
    "    \n",
    "    $$ \\mathrm{MAPE}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}_{\\\\tau}) = \\\\frac{1}{H} \\\\sum^{t+H}_{\\\\tau=t+1} \\\\frac{|y_{\\\\tau}-\\hat{y}_{\\\\tau}|}{|y_{\\\\tau}|} $$\n",
    "    \"\"\"    \n",
    "    def __init__(self):\n",
    "        super(MAPE, self).__init__()\n",
    "        self.outputsize_multiplier = 1\n",
    "        self.output_names = ['']\n",
    "        self.is_distribution_output = False\n",
    "\n",
    "    def domain_map(self, y_hat: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Univariate loss operates in dimension [B,T,H]/[B,H]\n",
    "        This changes the network's output from [B,H,1]->[B,H]\n",
    "        \"\"\"\n",
    "        return y_hat.squeeze(-1)\n",
    "\n",
    "    def __call__(self, y: torch.Tensor, y_hat: torch.Tensor, \n",
    "                 mask: Union[torch.Tensor, None] = None):\n",
    "        \"\"\"\n",
    "        **Parameters:**<br>\n",
    "        `y`: tensor, Actual values.<br>\n",
    "        `y_hat`: tensor, Predicted values.<br>\n",
    "        `mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `mape`: tensor (single value).\n",
    "        \"\"\"\n",
    "        if mask is None: \n",
    "            mask = torch.ones_like(y_hat)\n",
    "\n",
    "        mask = _divide_no_nan(mask, torch.abs(y))\n",
    "        mape = torch.abs(y - y_hat) * mask\n",
    "        mape = torch.mean(mape)\n",
    "        return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "174e8042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L184){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MAPE.__init__\n",
       "\n",
       ">      MAPE.__init__ ()\n",
       "\n",
       "Mean Absolute Percentage Error\n",
       "\n",
       "Calculates Mean Absolute Percentage Error  between\n",
       "`y` and `y_hat`. MAPE measures the relative prediction\n",
       "accuracy of a forecasting method by calculating the percentual deviation\n",
       "of the prediction and the observed value at a given time and\n",
       "averages these devations over the length of the series.\n",
       "The closer to zero an observed value is, the higher penalty MAPE loss\n",
       "assigns to the corresponding error.\n",
       "\n",
       "$$ \\mathrm{MAPE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\frac{|y_{\\tau}-\\hat{y}_{\\tau}|}{|y_{\\tau}|} $$"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L184){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MAPE.__init__\n",
       "\n",
       ">      MAPE.__init__ ()\n",
       "\n",
       "Mean Absolute Percentage Error\n",
       "\n",
       "Calculates Mean Absolute Percentage Error  between\n",
       "`y` and `y_hat`. MAPE measures the relative prediction\n",
       "accuracy of a forecasting method by calculating the percentual deviation\n",
       "of the prediction and the observed value at a given time and\n",
       "averages these devations over the length of the series.\n",
       "The closer to zero an observed value is, the higher penalty MAPE loss\n",
       "assigns to the corresponding error.\n",
       "\n",
       "$$ \\mathrm{MAPE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\frac{|y_{\\tau}-\\hat{y}_{\\tau}|}{|y_{\\tau}|} $$"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MAPE, name='MAPE.__init__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da63f136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L211){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MAPE.__call__\n",
       "\n",
       ">      MAPE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                     mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`mape`: tensor (single value)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L211){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MAPE.__call__\n",
       "\n",
       ">      MAPE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                     mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`mape`: tensor (single value)."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MAPE.__call__, name='MAPE.__call__', title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ccdc69",
   "metadata": {},
   "source": [
    "![](imgs_losses/mape_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb245891",
   "metadata": {},
   "source": [
    "## Symmetric MAPE (sMAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a71497ee-4485-4a17-97d9-81e324fade3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SMAPE(torch.nn.Module):\n",
    "    \"\"\" Symmetric Mean Absolute Percentage Error\n",
    "\n",
    "    Calculates Symmetric Mean Absolute Percentage Error between\n",
    "    `y` and `y_hat`. SMAPE measures the relative prediction\n",
    "    accuracy of a forecasting method by calculating the relative deviation\n",
    "    of the prediction and the observed value scaled by the sum of the\n",
    "    absolute values for the prediction and observed value at a\n",
    "    given time, then averages these devations over the length\n",
    "    of the series. This allows the SMAPE to have bounds between\n",
    "    0% and 200% which is desireble compared to normal MAPE that\n",
    "    may be undetermined when the target is zero.\n",
    "\n",
    "    $$ \\mathrm{sMAPE}_{2}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}_{\\\\tau}) = \\\\frac{1}{H} \\\\sum^{t+H}_{\\\\tau=t+1} \\\\frac{|y_{\\\\tau}-\\hat{y}_{\\\\tau}|}{|y_{\\\\tau}|+|\\hat{y}_{\\\\tau}|} $$\n",
    "\n",
    "    **References:**<br>\n",
    "    [Makridakis S., \"Accuracy measures: theoretical and practical concerns\".](https://www.sciencedirect.com/science/article/pii/0169207093900793)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(SMAPE, self).__init__()\n",
    "        self.outputsize_multiplier = 1\n",
    "        self.output_names = ['']\n",
    "        self.is_distribution_output = False\n",
    "\n",
    "    def domain_map(self, y_hat: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Univariate loss operates in dimension [B,T,H]/[B,H]\n",
    "        This changes the network's output from [B,H,1]->[B,H]\n",
    "        \"\"\"\n",
    "        return y_hat.squeeze(-1)\n",
    "\n",
    "    def __call__(self, y: torch.Tensor, y_hat: torch.Tensor, \n",
    "                 mask: Union[torch.Tensor, None] = None):\n",
    "        \"\"\"\n",
    "        **Parameters:**<br>\n",
    "        `y`: tensor, Actual values.<br>\n",
    "        `y_hat`: tensor, Predicted values.<br>\n",
    "        `mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `smape`: tensor (single value).\n",
    "        \"\"\"\n",
    "        if mask is None: \n",
    "            mask = torch.ones_like(y_hat)\n",
    "\n",
    "        delta_y = torch.abs((y - y_hat))\n",
    "        scale = torch.abs(y) + torch.abs(y_hat)\n",
    "        smape = _divide_no_nan(delta_y, scale)\n",
    "        smape = smape * mask\n",
    "        smape = 2 * torch.mean(smape)\n",
    "        return smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dee99fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L235){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SMAPE.__init__\n",
       "\n",
       ">      SMAPE.__init__ ()\n",
       "\n",
       "Symmetric Mean Absolute Percentage Error\n",
       "\n",
       "Calculates Symmetric Mean Absolute Percentage Error between\n",
       "`y` and `y_hat`. SMAPE measures the relative prediction\n",
       "accuracy of a forecasting method by calculating the relative deviation\n",
       "of the prediction and the observed value scaled by the sum of the\n",
       "absolute values for the prediction and observed value at a\n",
       "given time, then averages these devations over the length\n",
       "of the series. This allows the SMAPE to have bounds between\n",
       "0% and 200% which is desireble compared to normal MAPE that\n",
       "may be undetermined when the target is zero.\n",
       "\n",
       "$$ \\mathrm{sMAPE}_{2}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\frac{|y_{\\tau}-\\hat{y}_{\\tau}|}{|y_{\\tau}|+|\\hat{y}_{\\tau}|} $$\n",
       "\n",
       "**References:**<br>\n",
       "[Makridakis S., \"Accuracy measures: theoretical and practical concerns\".](https://www.sciencedirect.com/science/article/pii/0169207093900793)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L235){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SMAPE.__init__\n",
       "\n",
       ">      SMAPE.__init__ ()\n",
       "\n",
       "Symmetric Mean Absolute Percentage Error\n",
       "\n",
       "Calculates Symmetric Mean Absolute Percentage Error between\n",
       "`y` and `y_hat`. SMAPE measures the relative prediction\n",
       "accuracy of a forecasting method by calculating the relative deviation\n",
       "of the prediction and the observed value scaled by the sum of the\n",
       "absolute values for the prediction and observed value at a\n",
       "given time, then averages these devations over the length\n",
       "of the series. This allows the SMAPE to have bounds between\n",
       "0% and 200% which is desireble compared to normal MAPE that\n",
       "may be undetermined when the target is zero.\n",
       "\n",
       "$$ \\mathrm{sMAPE}_{2}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\frac{|y_{\\tau}-\\hat{y}_{\\tau}|}{|y_{\\tau}|+|\\hat{y}_{\\tau}|} $$\n",
       "\n",
       "**References:**<br>\n",
       "[Makridakis S., \"Accuracy measures: theoretical and practical concerns\".](https://www.sciencedirect.com/science/article/pii/0169207093900793)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SMAPE, name='SMAPE.__init__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db62a845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L267){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SMAPE.__call__\n",
       "\n",
       ">      SMAPE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                      mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`smape`: tensor (single value)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L267){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SMAPE.__call__\n",
       "\n",
       ">      SMAPE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                      mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`smape`: tensor (single value)."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SMAPE.__call__, name='SMAPE.__call__', title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3f2d6f",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 3. Scale-independent Errors </span>\n",
    "\n",
    "These metrics measure the relative improvements versus baselines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2dee1f",
   "metadata": {},
   "source": [
    "## Mean Absolute Scaled Error (MASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae7618c9-648a-41d5-9d17-dd7027a452ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MASE(torch.nn.Module):\n",
    "    \"\"\" Mean Absolute Scaled Error \n",
    "    Calculates the Mean Absolute Scaled Error between\n",
    "    `y` and `y_hat`. MASE measures the relative prediction\n",
    "    accuracy of a forecasting method by comparinng the mean absolute errors\n",
    "    of the prediction and the observed value against the mean\n",
    "    absolute errors of the seasonal naive model.\n",
    "    The MASE partially composed the Overall Weighted Average (OWA), \n",
    "    used in the M4 Competition.\n",
    "    \n",
    "    $$ \\mathrm{MASE}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}_{\\\\tau}, \\\\mathbf{\\hat{y}}^{season}_{\\\\tau}) = \\\\frac{1}{H} \\sum^{t+H}_{\\\\tau=t+1} \\\\frac{|y_{\\\\tau}-\\hat{y}_{\\\\tau}|}{\\mathrm{MAE}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}^{season}_{\\\\tau})} $$\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `seasonality`: int. Main frequency of the time series; Hourly 24,  Daily 7, Weekly 52, Monthly 12, Quarterly 4, Yearly 1.\n",
    "    \n",
    "    **References:**<br>\n",
    "    [Rob J. Hyndman, & Koehler, A. B. \"Another look at measures of forecast accuracy\".](https://www.sciencedirect.com/science/article/pii/S0169207006000239)<br>\n",
    "    [Spyros Makridakis, Evangelos Spiliotis, Vassilios Assimakopoulos, \"The M4 Competition: 100,000 time series and 61 forecasting methods\".](https://www.sciencedirect.com/science/article/pii/S0169207019301128)\n",
    "    \"\"\"\n",
    "    def __init__(self, seasonality: int):\n",
    "        super(MASE, self).__init__()\n",
    "        self.outputsize_multiplier = 1\n",
    "        self.seasonality = seasonality\n",
    "        self.output_names = ['']\n",
    "        self.is_distribution_output = False\n",
    "\n",
    "    def domain_map(self, y_hat: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Univariate loss operates in dimension [B,T,H]/[B,H]\n",
    "        This changes the network's output from [B,H,1]->[B,H]\n",
    "        \"\"\"\n",
    "        return y_hat.squeeze(-1)\n",
    "\n",
    "    def __call__(self, y: torch.Tensor, y_hat: torch.Tensor,  y_insample: torch.Tensor, \n",
    "                 mask: Union[torch.Tensor, None] = None):\n",
    "        \"\"\"\n",
    "        **Parameters:**<br>\n",
    "        `y`: tensor (batch_size, output_size), Actual values.<br>\n",
    "        `y_hat`: tensor (batch_size, output_size)), Predicted values.<br>\n",
    "        `y_insample`: tensor (batch_size, input_size), Actual insample Seasonal Naive predictions.<br>\n",
    "        `mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `mase`: tensor (single value).\n",
    "        \"\"\"\n",
    "        if mask is None: \n",
    "            mask = torch.ones_like(y_hat)\n",
    "\n",
    "        delta_y = torch.abs(y - y_hat)\n",
    "        scale = torch.mean(torch.abs(y_insample[:, self.seasonality:] - \\\n",
    "                                     y_insample[:, :-self.seasonality]), axis=1)\n",
    "        mase = _divide_no_nan(delta_y, scale[:, None])\n",
    "        mase = mase * mask\n",
    "        mase = torch.mean(mase)\n",
    "        return mase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6a4cf21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L293){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MASE.__init__\n",
       "\n",
       ">      MASE.__init__ (seasonality:int)\n",
       "\n",
       "Mean Absolute Scaled Error \n",
       "Calculates the Mean Absolute Scaled Error between\n",
       "`y` and `y_hat`. MASE measures the relative prediction\n",
       "accuracy of a forecasting method by comparinng the mean absolute errors\n",
       "of the prediction and the observed value against the mean\n",
       "absolute errors of the seasonal naive model.\n",
       "The MASE partially composed the Overall Weighted Average (OWA), \n",
       "used in the M4 Competition.\n",
       "\n",
       "$$ \\mathrm{MASE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}, \\mathbf{\\hat{y}}^{season}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\frac{|y_{\\tau}-\\hat{y}_{\\tau}|}{\\mathrm{MAE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}^{season}_{\\tau})} $$\n",
       "\n",
       "**Parameters:**<br>\n",
       "`seasonality`: int. Main frequency of the time series; Hourly 24,  Daily 7, Weekly 52, Monthly 12, Quarterly 4, Yearly 1.\n",
       "\n",
       "**References:**<br>\n",
       "[Rob J. Hyndman, & Koehler, A. B. \"Another look at measures of forecast accuracy\".](https://www.sciencedirect.com/science/article/pii/S0169207006000239)<br>\n",
       "[Spyros Makridakis, Evangelos Spiliotis, Vassilios Assimakopoulos, \"The M4 Competition: 100,000 time series and 61 forecasting methods\".](https://www.sciencedirect.com/science/article/pii/S0169207019301128)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L293){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MASE.__init__\n",
       "\n",
       ">      MASE.__init__ (seasonality:int)\n",
       "\n",
       "Mean Absolute Scaled Error \n",
       "Calculates the Mean Absolute Scaled Error between\n",
       "`y` and `y_hat`. MASE measures the relative prediction\n",
       "accuracy of a forecasting method by comparinng the mean absolute errors\n",
       "of the prediction and the observed value against the mean\n",
       "absolute errors of the seasonal naive model.\n",
       "The MASE partially composed the Overall Weighted Average (OWA), \n",
       "used in the M4 Competition.\n",
       "\n",
       "$$ \\mathrm{MASE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}, \\mathbf{\\hat{y}}^{season}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\frac{|y_{\\tau}-\\hat{y}_{\\tau}|}{\\mathrm{MAE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}^{season}_{\\tau})} $$\n",
       "\n",
       "**Parameters:**<br>\n",
       "`seasonality`: int. Main frequency of the time series; Hourly 24,  Daily 7, Weekly 52, Monthly 12, Quarterly 4, Yearly 1.\n",
       "\n",
       "**References:**<br>\n",
       "[Rob J. Hyndman, & Koehler, A. B. \"Another look at measures of forecast accuracy\".](https://www.sciencedirect.com/science/article/pii/S0169207006000239)<br>\n",
       "[Spyros Makridakis, Evangelos Spiliotis, Vassilios Assimakopoulos, \"The M4 Competition: 100,000 time series and 61 forecasting methods\".](https://www.sciencedirect.com/science/article/pii/S0169207019301128)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MASE, name='MASE.__init__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32a2c11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L327){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MASE.__call__\n",
       "\n",
       ">      MASE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                     y_insample:torch.Tensor,\n",
       ">                     mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor (batch_size, output_size), Actual values.<br>\n",
       "`y_hat`: tensor (batch_size, output_size)), Predicted values.<br>\n",
       "`y_insample`: tensor (batch_size, input_size), Actual insample Seasonal Naive predictions.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`mase`: tensor (single value)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L327){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MASE.__call__\n",
       "\n",
       ">      MASE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                     y_insample:torch.Tensor,\n",
       ">                     mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor (batch_size, output_size), Actual values.<br>\n",
       "`y_hat`: tensor (batch_size, output_size)), Predicted values.<br>\n",
       "`y_insample`: tensor (batch_size, input_size), Actual insample Seasonal Naive predictions.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`mase`: tensor (single value)."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MASE.__call__, name='MASE.__call__', title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c8fe5",
   "metadata": {},
   "source": [
    "![](imgs_losses/mase_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c828438e",
   "metadata": {},
   "source": [
    "# <span style=\"color:DarkBlue\"> 4. Probabilistic Errors </span>\n",
    "\n",
    "These measure absolute deviation non-symmetrically, that produce under/over estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d8cb2",
   "metadata": {},
   "source": [
    "## Quantile Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edcf7e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class QuantileLoss(torch.nn.Module):\n",
    "    \"\"\" Quantile Loss\n",
    "\n",
    "    Computes the quantile loss between `y` and `y_hat`.\n",
    "    QL measures the deviation of a quantile forecast.\n",
    "    By weighting the absolute deviation in a non symmetric way, the\n",
    "    loss pays more attention to under or over estimation.\n",
    "    A common value for q is 0.5 for the deviation from the median (Pinball loss).\n",
    "\n",
    "    $$ \\mathrm{QL}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}^{(q)}_{\\\\tau}) = \\\\frac{1}{H} \\\\sum^{t+H}_{\\\\tau=t+1} \\Big( (1-q)\\,( \\hat{y}^{(q)}_{\\\\tau} - y_{\\\\tau} )_{+} + q\\,( y_{\\\\tau} - \\hat{y}^{(q)}_{\\\\tau} )_{+} \\Big) $$\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `q`: float, between 0 and 1. The slope of the quantile loss, in the context of quantile regression, the q determines the conditional quantile level.<br>\n",
    "\n",
    "    **References:**<br>\n",
    "    [Roger Koenker and Gilbert Bassett, Jr., \"Regression Quantiles\".](https://www.jstor.org/stable/1913643)\n",
    "    \"\"\"\n",
    "    def __init__(self, q):\n",
    "        super(QuantileLoss, self).__init__()\n",
    "        self.outputsize_multiplier = 1\n",
    "        self.q = q\n",
    "        self.output_names = [f'_ql{q}']\n",
    "        self.is_distribution_output = False\n",
    "\n",
    "    def domain_map(self, y_hat: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Univariate loss operates in dimension [B,T,H]/[B,H]\n",
    "        This changes the network's output from [B,H,1]->[B,H]\n",
    "        \"\"\"\n",
    "        return y_hat.squeeze(-1)\n",
    "\n",
    "    def __call__(self, y: torch.Tensor, y_hat: torch.Tensor, \n",
    "                 mask: Union[torch.Tensor, None] = None):\n",
    "        \"\"\"\n",
    "        **Parameters:**<br>\n",
    "        `y`: tensor, Actual values.<br>\n",
    "        `y_hat`: tensor, Predicted values.<br>\n",
    "        `mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `quantile_loss`: tensor (single value).\n",
    "        \"\"\"\n",
    "        if mask is None: \n",
    "            mask = torch.ones_like(y_hat)\n",
    "\n",
    "        delta_y = y - y_hat\n",
    "        loss = torch.max(torch.mul(self.q, delta_y), torch.mul((self.q - 1), delta_y))\n",
    "        loss = loss * mask\n",
    "        quantile_loss = torch.mean(loss)\n",
    "        return quantile_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70bd46d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L360){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QuantileLoss.__init__\n",
       "\n",
       ">      QuantileLoss.__init__ (q)\n",
       "\n",
       "Quantile Loss\n",
       "\n",
       "Computes the quantile loss between `y` and `y_hat`.\n",
       "QL measures the deviation of a quantile forecast.\n",
       "By weighting the absolute deviation in a non symmetric way, the\n",
       "loss pays more attention to under or over estimation.\n",
       "A common value for q is 0.5 for the deviation from the median (Pinball loss).\n",
       "\n",
       "$$ \\mathrm{QL}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}^{(q)}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\Big( (1-q)\\,( \\hat{y}^{(q)}_{\\tau} - y_{\\tau} )_{+} + q\\,( y_{\\tau} - \\hat{y}^{(q)}_{\\tau} )_{+} \\Big) $$\n",
       "\n",
       "**Parameters:**<br>\n",
       "`q`: float, between 0 and 1. The slope of the quantile loss, in the context of quantile regression, the q determines the conditional quantile level.<br>\n",
       "\n",
       "**References:**<br>\n",
       "[Roger Koenker and Gilbert Bassett, Jr., \"Regression Quantiles\".](https://www.jstor.org/stable/1913643)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L360){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QuantileLoss.__init__\n",
       "\n",
       ">      QuantileLoss.__init__ (q)\n",
       "\n",
       "Quantile Loss\n",
       "\n",
       "Computes the quantile loss between `y` and `y_hat`.\n",
       "QL measures the deviation of a quantile forecast.\n",
       "By weighting the absolute deviation in a non symmetric way, the\n",
       "loss pays more attention to under or over estimation.\n",
       "A common value for q is 0.5 for the deviation from the median (Pinball loss).\n",
       "\n",
       "$$ \\mathrm{QL}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}^{(q)}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\Big( (1-q)\\,( \\hat{y}^{(q)}_{\\tau} - y_{\\tau} )_{+} + q\\,( y_{\\tau} - \\hat{y}^{(q)}_{\\tau} )_{+} \\Big) $$\n",
       "\n",
       "**Parameters:**<br>\n",
       "`q`: float, between 0 and 1. The slope of the quantile loss, in the context of quantile regression, the q determines the conditional quantile level.<br>\n",
       "\n",
       "**References:**<br>\n",
       "[Roger Koenker and Gilbert Bassett, Jr., \"Regression Quantiles\".](https://www.jstor.org/stable/1913643)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(QuantileLoss, name='QuantileLoss.__init__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b1588e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L392){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QuantileLoss.__call__\n",
       "\n",
       ">      QuantileLoss.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                             mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`quantile_loss`: tensor (single value)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L392){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QuantileLoss.__call__\n",
       "\n",
       ">      QuantileLoss.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                             mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`quantile_loss`: tensor (single value)."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(QuantileLoss.__call__, name='QuantileLoss.__call__', title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac874f",
   "metadata": {},
   "source": [
    "![](imgs_losses/q_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb8b5b2",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f575f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Accuracy(torch.nn.Module):\n",
    "    \"\"\" Accuracy\n",
    "\n",
    "    Computes the accuracy between categorical `y` and `y_hat`.\n",
    "    This evaluation metric is only meant for evalution, as it\n",
    "    is not differentiable.\n",
    "\n",
    "    $$ \\mathrm{Accuracy}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}_{\\\\tau}) = \\\\frac{1}{H} \\\\sum^{t+H}_{\\\\tau=t+1} \\mathrm{1}\\{\\\\mathbf{y}_{\\\\tau}==\\\\mathbf{\\hat{y}}_{\\\\tau}\\} $$\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,):\n",
    "        super(Accuracy, self).__init__()\n",
    "        self.is_distribution_output = False\n",
    "\n",
    "    def domain_map(self, y_hat: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Univariate loss operates in dimension [B,T,H]/[B,H]\n",
    "        This changes the network's output from [B,H,1]->[B,H]\n",
    "        \"\"\"\n",
    "        return y_hat.squeeze(-1)\n",
    "\n",
    "    def __call__(self, y: torch.Tensor, y_hat: torch.Tensor, \n",
    "                 mask: Union[torch.Tensor, None] = None):\n",
    "        \"\"\"\n",
    "        **Parameters:**<br>\n",
    "        `y`: tensor, Actual values.<br>\n",
    "        `y_hat`: tensor, Predicted values.<br>\n",
    "        `mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `accuracy`: tensor (single value).\n",
    "        \"\"\"\n",
    "        if mask is None:\n",
    "            mask = torch.ones_like(y_hat)\n",
    "\n",
    "        measure = (y.unsqueeze(-1) == y_hat) * mask.unsqueeze(-1)\n",
    "        accuracy = torch.mean(measure)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79afaf94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L417){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Accuracy.__init__\n",
       "\n",
       ">      Accuracy.__init__ ()\n",
       "\n",
       "Accuracy\n",
       "\n",
       "Computes the accuracy between categorical `y` and `y_hat`.\n",
       "This evaluation metric is only meant for evalution, as it\n",
       "is not differentiable.\n",
       "\n",
       "$$ \\mathrm{Accuracy}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\mathrm{1}\\{\\mathbf{y}_{\\tau}==\\mathbf{\\hat{y}}_{\\tau}\\} $$"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L417){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Accuracy.__init__\n",
       "\n",
       ">      Accuracy.__init__ ()\n",
       "\n",
       "Accuracy\n",
       "\n",
       "Computes the accuracy between categorical `y` and `y_hat`.\n",
       "This evaluation metric is only meant for evalution, as it\n",
       "is not differentiable.\n",
       "\n",
       "$$ \\mathrm{Accuracy}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\mathrm{1}\\{\\mathbf{y}_{\\tau}==\\mathbf{\\hat{y}}_{\\tau}\\} $$"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Accuracy, name='Accuracy.__init__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a37c53fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L441){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Accuracy.__call__\n",
       "\n",
       ">      Accuracy.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                         mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`accuracy`: tensor (single value)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L441){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Accuracy.__call__\n",
       "\n",
       ">      Accuracy.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                         mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`accuracy`: tensor (single value)."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(Accuracy.__call__, name='Accuracy.__call__', title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dbb002",
   "metadata": {},
   "source": [
    "## Multi Quantile Loss (MQLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "291a0530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def level_to_outputs(level):\n",
    "    qs = sum([[50-l/2, 50+l/2] for l in level], [])\n",
    "    output_names = sum([[f'-lo-{l}', f'-hi-{l}'] for l in level], [])\n",
    "\n",
    "    sort_idx = np.argsort(qs)\n",
    "    quantiles = np.array(qs)[sort_idx]\n",
    "\n",
    "    # Add default median\n",
    "    quantiles = np.concatenate([np.array([50]), quantiles])\n",
    "    quantiles = torch.Tensor(quantiles) / 100\n",
    "    output_names = list(np.array(output_names)[sort_idx])\n",
    "    output_names.insert(0, '-median')\n",
    "    \n",
    "    return quantiles, output_names\n",
    "\n",
    "def quantiles_to_outputs(quantiles):\n",
    "    output_names = []\n",
    "    for q in quantiles:\n",
    "        if q<.50:\n",
    "            output_names.append(f'-lo-{np.round(100-200*q,2)}')\n",
    "        elif q>.50:\n",
    "            output_names.append(f'-hi-{np.round(100-200*(1-q),2)}')\n",
    "        else:\n",
    "            output_names.append('-median')\n",
    "    return quantiles, output_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db3a5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MQLoss(torch.nn.Module):\n",
    "    \"\"\"  Multi-Quantile loss\n",
    "\n",
    "    Calculates the Multi-Quantile loss (MQL) between `y` and `y_hat`.\n",
    "    MQL calculates the average multi-quantile Loss for\n",
    "    a given set of quantiles, based on the absolute \n",
    "    difference between predicted quantiles and observed values.\n",
    "    \n",
    "    $$ \\mathrm{MQL}(\\\\mathbf{y}_{\\\\tau},[\\\\mathbf{\\hat{y}}^{(q_{1})}_{\\\\tau}, ... ,\\hat{y}^{(q_{n})}_{\\\\tau}]) = \\\\frac{1}{n} \\\\sum_{q_{i}} \\mathrm{QL}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}^{(q_{i})}_{\\\\tau}) $$\n",
    "    \n",
    "    The limit behavior of MQL allows to measure the accuracy \n",
    "    of a full predictive distribution $\\mathbf{\\hat{F}}_{\\\\tau}$ with \n",
    "    the continuous ranked probability score (CRPS). This can be achieved \n",
    "    through a numerical integration technique, that discretizes the quantiles \n",
    "    and treats the CRPS integral with a left Riemann approximation, averaging over \n",
    "    uniformly distanced quantiles.    \n",
    "    \n",
    "    $$ \\mathrm{CRPS}(y_{\\\\tau}, \\mathbf{\\hat{F}}_{\\\\tau}) = \\int^{1}_{0} \\mathrm{QL}(y_{\\\\tau}, \\hat{y}^{(q)}_{\\\\tau}) dq $$\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `level`: int list [0,100]. Probability levels for prediction intervals (Defaults median).\n",
    "    `quantiles`: float list [0., 1.]. Alternative to level, quantiles to estimate from y distribution.\n",
    "\n",
    "    **References:**<br>\n",
    "    [Roger Koenker and Gilbert Bassett, Jr., \"Regression Quantiles\".](https://www.jstor.org/stable/1913643)<br>\n",
    "    [James E. Matheson and Robert L. Winkler, \"Scoring Rules for Continuous Probability Distributions\".](https://www.jstor.org/stable/2629907)\n",
    "    \"\"\"\n",
    "    def __init__(self, level=[80, 90], quantiles=None):\n",
    "        super(MQLoss, self).__init__()\n",
    "        # Transform level to MQLoss parameters\n",
    "        qs, self.output_names = level_to_outputs(level)\n",
    "        qs = torch.Tensor(qs)\n",
    "\n",
    "        # Transform quantiles to homogeneus output names\n",
    "        if quantiles is not None:\n",
    "            _, self.output_names = quantiles_to_outputs(quantiles)\n",
    "            qs = torch.Tensor(quantiles)\n",
    "\n",
    "        self.quantiles = torch.nn.Parameter(qs, requires_grad=False)\n",
    "        self.outputsize_multiplier = len(self.quantiles)\n",
    "        self.is_distribution_output = False\n",
    "\n",
    "    def domain_map(self, y_hat: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Identity domain map [B,T,H,Q]/[B,H,Q]\n",
    "        \"\"\"\n",
    "        return y_hat\n",
    "\n",
    "    def __call__(self, y: torch.Tensor, y_hat: torch.Tensor, \n",
    "                 mask: Union[torch.Tensor, None] = None):\n",
    "        \"\"\"\n",
    "        **Parameters:**<br>\n",
    "        `y`: tensor, Actual values.<br>\n",
    "        `y_hat`: tensor, Predicted values.<br>\n",
    "        `mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `mqloss`: tensor (single value).\n",
    "        \"\"\"\n",
    "        if mask is None: \n",
    "            mask = torch.ones_like(y_hat)\n",
    "\n",
    "        n_q = len(self.quantiles)\n",
    "\n",
    "        error  = y_hat - y.unsqueeze(-1)\n",
    "        sq     = torch.maximum(-error, torch.zeros_like(error))\n",
    "        s1_q   = torch.maximum(error, torch.zeros_like(error))\n",
    "        mqloss = (self.quantiles * sq + (1 - self.quantiles) * s1_q)\n",
    "\n",
    "        # Match y/weights dimensions and compute weighted average\n",
    "        mask = mask / torch.sum(mask)\n",
    "        mask = mask.unsqueeze(-1)\n",
    "        mqloss = (1/n_q) * mqloss * mask\n",
    "        return torch.sum(mqloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f42ec82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L492){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MQLoss.__init__\n",
       "\n",
       ">      MQLoss.__init__ (level=[80, 90], quantiles=None)\n",
       "\n",
       "Multi-Quantile loss\n",
       "\n",
       "Calculates the Multi-Quantile loss (MQL) between `y` and `y_hat`.\n",
       "MQL calculates the average multi-quantile Loss for\n",
       "a given set of quantiles, based on the absolute \n",
       "difference between predicted quantiles and observed values.\n",
       "\n",
       "$$ \\mathrm{MQL}(\\mathbf{y}_{\\tau},[\\mathbf{\\hat{y}}^{(q_{1})}_{\\tau}, ... ,\\hat{y}^{(q_{n})}_{\\tau}]) = \\frac{1}{n} \\sum_{q_{i}} \\mathrm{QL}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}^{(q_{i})}_{\\tau}) $$\n",
       "\n",
       "The limit behavior of MQL allows to measure the accuracy \n",
       "of a full predictive distribution $\\mathbf{\\hat{F}}_{\\tau}$ with \n",
       "the continuous ranked probability score (CRPS). This can be achieved \n",
       "through a numerical integration technique, that discretizes the quantiles \n",
       "and treats the CRPS integral with a left Riemann approximation, averaging over \n",
       "uniformly distanced quantiles.    \n",
       "\n",
       "$$ \\mathrm{CRPS}(y_{\\tau}, \\mathbf{\\hat{F}}_{\\tau}) = \\int^{1}_{0} \\mathrm{QL}(y_{\\tau}, \\hat{y}^{(q)}_{\\tau}) dq $$\n",
       "\n",
       "**Parameters:**<br>\n",
       "`level`: int list [0,100]. Probability levels for prediction intervals (Defaults median).\n",
       "`quantiles`: float list [0., 1.]. Alternative to level, quantiles to estimate from y distribution.\n",
       "\n",
       "**References:**<br>\n",
       "[Roger Koenker and Gilbert Bassett, Jr., \"Regression Quantiles\".](https://www.jstor.org/stable/1913643)<br>\n",
       "[James E. Matheson and Robert L. Winkler, \"Scoring Rules for Continuous Probability Distributions\".](https://www.jstor.org/stable/2629907)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L492){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MQLoss.__init__\n",
       "\n",
       ">      MQLoss.__init__ (level=[80, 90], quantiles=None)\n",
       "\n",
       "Multi-Quantile loss\n",
       "\n",
       "Calculates the Multi-Quantile loss (MQL) between `y` and `y_hat`.\n",
       "MQL calculates the average multi-quantile Loss for\n",
       "a given set of quantiles, based on the absolute \n",
       "difference between predicted quantiles and observed values.\n",
       "\n",
       "$$ \\mathrm{MQL}(\\mathbf{y}_{\\tau},[\\mathbf{\\hat{y}}^{(q_{1})}_{\\tau}, ... ,\\hat{y}^{(q_{n})}_{\\tau}]) = \\frac{1}{n} \\sum_{q_{i}} \\mathrm{QL}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}^{(q_{i})}_{\\tau}) $$\n",
       "\n",
       "The limit behavior of MQL allows to measure the accuracy \n",
       "of a full predictive distribution $\\mathbf{\\hat{F}}_{\\tau}$ with \n",
       "the continuous ranked probability score (CRPS). This can be achieved \n",
       "through a numerical integration technique, that discretizes the quantiles \n",
       "and treats the CRPS integral with a left Riemann approximation, averaging over \n",
       "uniformly distanced quantiles.    \n",
       "\n",
       "$$ \\mathrm{CRPS}(y_{\\tau}, \\mathbf{\\hat{F}}_{\\tau}) = \\int^{1}_{0} \\mathrm{QL}(y_{\\tau}, \\hat{y}^{(q)}_{\\tau}) dq $$\n",
       "\n",
       "**Parameters:**<br>\n",
       "`level`: int list [0,100]. Probability levels for prediction intervals (Defaults median).\n",
       "`quantiles`: float list [0., 1.]. Alternative to level, quantiles to estimate from y distribution.\n",
       "\n",
       "**References:**<br>\n",
       "[Roger Koenker and Gilbert Bassett, Jr., \"Regression Quantiles\".](https://www.jstor.org/stable/1913643)<br>\n",
       "[James E. Matheson and Robert L. Winkler, \"Scoring Rules for Continuous Probability Distributions\".](https://www.jstor.org/stable/2629907)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MQLoss, name='MQLoss.__init__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bac2237a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L541){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MQLoss.__call__\n",
       "\n",
       ">      MQLoss.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                       mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`mqloss`: tensor (single value)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L541){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MQLoss.__call__\n",
       "\n",
       ">      MQLoss.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                       mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`mqloss`: tensor (single value)."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MQLoss.__call__, name='MQLoss.__call__', title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b66b0e",
   "metadata": {},
   "source": [
    "![](imgs_losses/mq_loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df65d575",
   "metadata": {},
   "source": [
    "## Weighted MQLoss (wMQLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1d34c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class wMQLoss(torch.nn.Module):\n",
    "    \"\"\" Weighted Multi-Quantile loss\n",
    "    \n",
    "    Calculates the Weighted Multi-Quantile loss (WMQL) between `y` and `y_hat`.\n",
    "    WMQL calculates the weighted average multi-quantile Loss for\n",
    "    a given set of quantiles, based on the absolute \n",
    "    difference between predicted quantiles and observed values.  \n",
    "        \n",
    "    $$ \\mathrm{wMQL}(\\\\mathbf{y}_{\\\\tau},[\\\\mathbf{\\hat{y}}^{(q_{1})}_{\\\\tau}, ... ,\\hat{y}^{(q_{n})}_{\\\\tau}]) = \\\\frac{1}{n} \\\\sum_{q_{i}} \\\\frac{\\mathrm{QL}(\\\\mathbf{y}_{\\\\tau}, \\\\mathbf{\\hat{y}}^{(q_{i})}_{\\\\tau})}{\\\\sum^{t+H}_{\\\\tau=t+1} |y_{\\\\tau}|} $$\n",
    "    \n",
    "    **Parameters:**<br>\n",
    "    `level`: int list [0,100]. Probability levels for prediction intervals (Defaults median).\n",
    "    `quantiles`: float list [0., 1.]. Alternative to level, quantiles to estimate from y distribution.\n",
    "\n",
    "    **References:**<br>\n",
    "    [Roger Koenker and Gilbert Bassett, Jr., \"Regression Quantiles\".](https://www.jstor.org/stable/1913643)<br>\n",
    "    [James E. Matheson and Robert L. Winkler, \"Scoring Rules for Continuous Probability Distributions\".](https://www.jstor.org/stable/2629907)\n",
    "    \"\"\"\n",
    "    def __init__(self, level=[80, 90], quantiles=None):\n",
    "        super(wMQLoss, self).__init__()\n",
    "        # Transform level to MQLoss parameters\n",
    "        qs, self.output_names = level_to_outputs(level)\n",
    "        qs = torch.Tensor(qs)\n",
    "\n",
    "        # Transform quantiles to homogeneus output names\n",
    "        if quantiles is not None:\n",
    "            _, self.output_names = quantiles_to_outputs(quantiles)\n",
    "            qs = torch.Tensor(quantiles)\n",
    "\n",
    "        self.quantiles = torch.nn.Parameter(qs, requires_grad=False)\n",
    "        self.outputsize_multiplier = len(self.quantiles)\n",
    "        self.is_distribution_output = False\n",
    "\n",
    "    def domain_map(self, y_hat: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Identity domain map [B,T,H,Q]/[B,H,Q]\n",
    "        \"\"\"\n",
    "        return y_hat\n",
    "\n",
    "    def __call__(self, y: torch.Tensor, y_hat: torch.Tensor, \n",
    "                 mask: Union[torch.Tensor, None] = None):\n",
    "        \"\"\"\n",
    "        **Parameters:**<br>\n",
    "        `y`: tensor, Actual values.<br>\n",
    "        `y_hat`: tensor, Predicted values.<br>\n",
    "        `mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `mqloss`: tensor (single value).\n",
    "        \"\"\"\n",
    "        if mask is None: \n",
    "            mask = torch.ones_like(y_hat)\n",
    "\n",
    "        error = y_hat - y.unsqueeze(-1)\n",
    "        \n",
    "        sq = torch.maximum(-error, torch.zeros_like(error))\n",
    "        s1_q = torch.maximum(error, torch.zeros_like(error))\n",
    "        loss = (self.quantiles * sq + (1 - self.quantiles) * s1_q)\n",
    "        \n",
    "        mask = mask.unsqueeze(-1)\n",
    "        wmqloss = _divide_no_nan(torch.sum(loss * mask, axis=-2), \n",
    "                                 torch.sum(torch.abs(y.unsqueeze(-1)) * mask, axis=-2))\n",
    "        return torch.mean(wmqloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8d916af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L573){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### wMQLoss.__init__\n",
       "\n",
       ">      wMQLoss.__init__ (level=[80, 90], quantiles=None)\n",
       "\n",
       "Weighted Multi-Quantile loss\n",
       "\n",
       "Calculates the Weighted Multi-Quantile loss (WMQL) between `y` and `y_hat`.\n",
       "WMQL calculates the weighted average multi-quantile Loss for\n",
       "a given set of quantiles, based on the absolute \n",
       "difference between predicted quantiles and observed values.  \n",
       "\n",
       "$$ \\mathrm{wMQL}(\\mathbf{y}_{\\tau},[\\mathbf{\\hat{y}}^{(q_{1})}_{\\tau}, ... ,\\hat{y}^{(q_{n})}_{\\tau}]) = \\frac{1}{n} \\sum_{q_{i}} \\frac{\\mathrm{QL}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}^{(q_{i})}_{\\tau})}{\\sum^{t+H}_{\\tau=t+1} |y_{\\tau}|} $$\n",
       "\n",
       "**Parameters:**<br>\n",
       "`level`: int list [0,100]. Probability levels for prediction intervals (Defaults median).\n",
       "`quantiles`: float list [0., 1.]. Alternative to level, quantiles to estimate from y distribution.\n",
       "\n",
       "**References:**<br>\n",
       "[Roger Koenker and Gilbert Bassett, Jr., \"Regression Quantiles\".](https://www.jstor.org/stable/1913643)<br>\n",
       "[James E. Matheson and Robert L. Winkler, \"Scoring Rules for Continuous Probability Distributions\".](https://www.jstor.org/stable/2629907)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L573){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### wMQLoss.__init__\n",
       "\n",
       ">      wMQLoss.__init__ (level=[80, 90], quantiles=None)\n",
       "\n",
       "Weighted Multi-Quantile loss\n",
       "\n",
       "Calculates the Weighted Multi-Quantile loss (WMQL) between `y` and `y_hat`.\n",
       "WMQL calculates the weighted average multi-quantile Loss for\n",
       "a given set of quantiles, based on the absolute \n",
       "difference between predicted quantiles and observed values.  \n",
       "\n",
       "$$ \\mathrm{wMQL}(\\mathbf{y}_{\\tau},[\\mathbf{\\hat{y}}^{(q_{1})}_{\\tau}, ... ,\\hat{y}^{(q_{n})}_{\\tau}]) = \\frac{1}{n} \\sum_{q_{i}} \\frac{\\mathrm{QL}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}^{(q_{i})}_{\\tau})}{\\sum^{t+H}_{\\tau=t+1} |y_{\\tau}|} $$\n",
       "\n",
       "**Parameters:**<br>\n",
       "`level`: int list [0,100]. Probability levels for prediction intervals (Defaults median).\n",
       "`quantiles`: float list [0., 1.]. Alternative to level, quantiles to estimate from y distribution.\n",
       "\n",
       "**References:**<br>\n",
       "[Roger Koenker and Gilbert Bassett, Jr., \"Regression Quantiles\".](https://www.jstor.org/stable/1913643)<br>\n",
       "[James E. Matheson and Robert L. Winkler, \"Scoring Rules for Continuous Probability Distributions\".](https://www.jstor.org/stable/2629907)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(wMQLoss, name='wMQLoss.__init__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81bdcbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L613){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### wMQLoss.__call__\n",
       "\n",
       ">      wMQLoss.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                        mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`mqloss`: tensor (single value)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L613){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### wMQLoss.__call__\n",
       "\n",
       ">      wMQLoss.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                        mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`mqloss`: tensor (single value)."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(wMQLoss.__call__, name='wMQLoss.__call__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da37f2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-lo-98.0', '-lo-80.0', '-median', '-hi-80.0', '-hi-98.0']\n",
      "Parameter containing:\n",
      "tensor([0.0100, 0.1000, 0.5000, 0.9000, 0.9900])\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "# Unit tests to check MQLoss' stored quantiles\n",
    "# attribute is correctly instantiated\n",
    "check = MQLoss(level=[80, 90])\n",
    "test_eq(len(check.quantiles), 5)\n",
    "\n",
    "check = MQLoss(quantiles=[0.0100, 0.1000, 0.5, 0.9000, 0.9900])\n",
    "print(check.output_names)\n",
    "print(check.quantiles)\n",
    "test_eq(len(check.quantiles), 5)\n",
    "\n",
    "check = MQLoss(quantiles=[0.0100, 0.1000, 0.9000, 0.9900])\n",
    "test_eq(len(check.quantiles), 4)\n",
    "\n",
    "check = wMQLoss(quantiles=[0.0100, 0.1000, 0.9000, 0.9900])\n",
    "test_eq(len(check.quantiles), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58924a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class sCRPS(torch.nn.Module):\n",
    "    \"\"\"Scaled Continues Ranked Probability Score\n",
    "\n",
    "    Calculates a scaled variation of the CRPS, as proposed by Rangapuram (2021),\n",
    "    to measure the accuracy of predicted quantiles `y_hat` compared to the observation `y`.\n",
    "\n",
    "    This metric averages percentual weighted absolute deviations as \n",
    "    defined by the quantile losses.\n",
    "\n",
    "    $$ \\mathrm{sCRPS}(\\\\mathbf{\\hat{y}}^{(q)}_{\\\\tau}, \\mathbf{y}_{\\\\tau}) = \\\\frac{2}{N} \\sum_{i}\n",
    "    \\int^{1}_{0}\n",
    "    \\\\frac{\\mathrm{QL}(\\\\mathbf{\\hat{y}}^{(q}_{\\\\tau} y_{i,\\\\tau})_{q}}{\\sum_{i} | y_{i,\\\\tau} |} dq $$\n",
    "\n",
    "    where $\\\\mathbf{\\hat{y}}^{(q}_{\\\\tau}$ is the estimated quantile, and $y_{i,\\\\tau}$\n",
    "    are the target variable realizations.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `level`: int list [0,100]. Probability levels for prediction intervals (Defaults median).\n",
    "    `quantiles`: float list [0., 1.]. Alternative to level, quantiles to estimate from y distribution.\n",
    "\n",
    "    **References:**<br>\n",
    "    - [Gneiting, Tilmann. (2011). \\\"Quantiles as optimal point forecasts\\\". \n",
    "    International Journal of Forecasting.](https://www.sciencedirect.com/science/article/pii/S0169207010000063)<br>\n",
    "    - [Spyros Makridakis, Evangelos Spiliotis, Vassilios Assimakopoulos, Zhi Chen, Anil Gaba, Ilia Tsetlin, Robert L. Winkler. (2022). \n",
    "    \\\"The M5 uncertainty competition: Results, findings and conclusions\\\". \n",
    "    International Journal of Forecasting.](https://www.sciencedirect.com/science/article/pii/S0169207021001722)<br>\n",
    "    - [Syama Sundar Rangapuram, Lucien D Werner, Konstantinos Benidis, Pedro Mercado, Jan Gasthaus, Tim Januschowski. (2021). \n",
    "    \\\"End-to-End Learning of Coherent Probabilistic Forecasts for Hierarchical Time Series\\\". \n",
    "    Proceedings of the 38th International Conference on Machine Learning (ICML).](https://proceedings.mlr.press/v139/rangapuram21a.html)\n",
    "    \"\"\"\n",
    "    def __init__(self, level=[80, 90], quantiles=None):\n",
    "        super(sCRPS, self).__init__()\n",
    "        self.mql = MQLoss(level=level, quantiles=quantiles)\n",
    "        self.is_distribution_output = False\n",
    "    \n",
    "    def __call__(self, y: torch.Tensor, y_hat: torch.Tensor, \n",
    "                 mask: Union[torch.Tensor, None] = None):\n",
    "        \"\"\"\n",
    "        **Parameters:**<br>\n",
    "        `y`: tensor, Actual values.<br>\n",
    "        `y_hat`: tensor, Predicted values.<br>\n",
    "        `mask`: tensor, Specifies date stamps per series to consider in loss.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `scrps`: tensor (single value).\n",
    "        \"\"\"\n",
    "        mql = self.mql(y=y, y_hat=y_hat, mask=mask)\n",
    "        norm = torch.sum(torch.abs(y))\n",
    "        unmean = torch.sum(mask)\n",
    "        scrps = 2 * mql * unmean / (norm + 1e-5)\n",
    "        return scrps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4401b7f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L645){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### sCRPS.__init__\n",
       "\n",
       ">      sCRPS.__init__ (level=[80, 90], quantiles=None)\n",
       "\n",
       "Scaled Continues Ranked Probability Score\n",
       "\n",
       "Calculates a scaled variation of the CRPS, as proposed by Rangapuram (2021),\n",
       "to measure the accuracy of predicted quantiles `y_hat` compared to the observation `y`.\n",
       "\n",
       "This metric averages percentual weighted absolute deviations as \n",
       "defined by the quantile losses.\n",
       "\n",
       "$$ \\mathrm{sCRPS}(\\mathbf{\\hat{y}}^{(q)}_{\\tau}, \\mathbf{y}_{\\tau}) = \\frac{2}{N} \\sum_{i}\n",
       "\\int^{1}_{0}\n",
       "\\frac{\\mathrm{QL}(\\mathbf{\\hat{y}}^{(q}_{\\tau} y_{i,\\tau})_{q}}{\\sum_{i} | y_{i,\\tau} |} dq $$\n",
       "\n",
       "where $\\mathbf{\\hat{y}}^{(q}_{\\tau}$ is the estimated quantile, and $y_{i,\\tau}$\n",
       "are the target variable realizations.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`level`: int list [0,100]. Probability levels for prediction intervals (Defaults median).\n",
       "`quantiles`: float list [0., 1.]. Alternative to level, quantiles to estimate from y distribution.\n",
       "\n",
       "**References:**<br>\n",
       "- [Gneiting, Tilmann. (2011). \"Quantiles as optimal point forecasts\". \n",
       "International Journal of Forecasting.](https://www.sciencedirect.com/science/article/pii/S0169207010000063)<br>\n",
       "- [Spyros Makridakis, Evangelos Spiliotis, Vassilios Assimakopoulos, Zhi Chen, Anil Gaba, Ilia Tsetlin, Robert L. Winkler. (2022). \n",
       "\"The M5 uncertainty competition: Results, findings and conclusions\". \n",
       "International Journal of Forecasting.](https://www.sciencedirect.com/science/article/pii/S0169207021001722)<br>\n",
       "- [Syama Sundar Rangapuram, Lucien D Werner, Konstantinos Benidis, Pedro Mercado, Jan Gasthaus, Tim Januschowski. (2021). \n",
       "\"End-to-End Learning of Coherent Probabilistic Forecasts for Hierarchical Time Series\". \n",
       "Proceedings of the 38th International Conference on Machine Learning (ICML).](https://proceedings.mlr.press/v139/rangapuram21a.html)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L645){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### sCRPS.__init__\n",
       "\n",
       ">      sCRPS.__init__ (level=[80, 90], quantiles=None)\n",
       "\n",
       "Scaled Continues Ranked Probability Score\n",
       "\n",
       "Calculates a scaled variation of the CRPS, as proposed by Rangapuram (2021),\n",
       "to measure the accuracy of predicted quantiles `y_hat` compared to the observation `y`.\n",
       "\n",
       "This metric averages percentual weighted absolute deviations as \n",
       "defined by the quantile losses.\n",
       "\n",
       "$$ \\mathrm{sCRPS}(\\mathbf{\\hat{y}}^{(q)}_{\\tau}, \\mathbf{y}_{\\tau}) = \\frac{2}{N} \\sum_{i}\n",
       "\\int^{1}_{0}\n",
       "\\frac{\\mathrm{QL}(\\mathbf{\\hat{y}}^{(q}_{\\tau} y_{i,\\tau})_{q}}{\\sum_{i} | y_{i,\\tau} |} dq $$\n",
       "\n",
       "where $\\mathbf{\\hat{y}}^{(q}_{\\tau}$ is the estimated quantile, and $y_{i,\\tau}$\n",
       "are the target variable realizations.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`level`: int list [0,100]. Probability levels for prediction intervals (Defaults median).\n",
       "`quantiles`: float list [0., 1.]. Alternative to level, quantiles to estimate from y distribution.\n",
       "\n",
       "**References:**<br>\n",
       "- [Gneiting, Tilmann. (2011). \"Quantiles as optimal point forecasts\". \n",
       "International Journal of Forecasting.](https://www.sciencedirect.com/science/article/pii/S0169207010000063)<br>\n",
       "- [Spyros Makridakis, Evangelos Spiliotis, Vassilios Assimakopoulos, Zhi Chen, Anil Gaba, Ilia Tsetlin, Robert L. Winkler. (2022). \n",
       "\"The M5 uncertainty competition: Results, findings and conclusions\". \n",
       "International Journal of Forecasting.](https://www.sciencedirect.com/science/article/pii/S0169207021001722)<br>\n",
       "- [Syama Sundar Rangapuram, Lucien D Werner, Konstantinos Benidis, Pedro Mercado, Jan Gasthaus, Tim Januschowski. (2021). \n",
       "\"End-to-End Learning of Coherent Probabilistic Forecasts for Hierarchical Time Series\". \n",
       "Proceedings of the 38th International Conference on Machine Learning (ICML).](https://proceedings.mlr.press/v139/rangapuram21a.html)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(sCRPS, name='sCRPS.__init__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c16a85d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L681){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### sCRPS.__call__\n",
       "\n",
       ">      sCRPS.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                      mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per series to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`scrps`: tensor (single value)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L681){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### sCRPS.__call__\n",
       "\n",
       ">      sCRPS.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                      mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per series to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`scrps`: tensor (single value)."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(sCRPS.__call__, name='sCRPS.__call__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28a3a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MSSE(torch.nn.Module):\n",
    "    \"\"\"Mean Squared Scaled Error\n",
    "    Computes Mean squared scaled error (MSSE), as proposed by Hyndman & Koehler (2006)\n",
    "    as an alternative to percentage errors, to avoid measure unstability.\n",
    "    $$ \\mathrm{MSSE}(\\\\mathbf{y}, \\\\mathbf{\\hat{y}}, \\\\mathbf{\\hat{y}}^{naive1}) =\n",
    "    \\\\frac{\\mathrm{MSE}(\\\\mathbf{y}, \\\\mathbf{\\hat{y}})}{\\mathrm{MSE}(\\\\mathbf{y}, \\\\mathbf{\\hat{y}}^{naive1})} $$\n",
    "    **Parameters:**<br>\n",
    "    `y_train`: numpy array, Training values.<br>\n",
    "    **References:**<br>\n",
    "    - [Hyndman, R. J and Koehler, A. B. (2006).\n",
    "       \"Another look at measures of forecast accuracy\",\n",
    "       International Journal of Forecasting, Volume 22, Issue 4.](https://www.sciencedirect.com/science/article/pii/S0169207006000239)<br>\n",
    "    - [Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker. \n",
    "       \"Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures. \n",
    "       Submitted to the International Journal Forecasting, Working paper available at arxiv.](https://arxiv.org/pdf/2110.13179.pdf)\n",
    "    \"\"\"\n",
    "    def __init__(self, y_train):\n",
    "        super(MSSE, self).__init__()\n",
    "        self.y_train = y_train\n",
    "        self.mse = MSE()\n",
    "        self.is_distribution_output = False\n",
    "    \n",
    "    def __call__(self, y: torch.Tensor, y_hat: torch.Tensor, \n",
    "                 mask: Union[torch.Tensor, None] = None):\n",
    "        \"\"\"\n",
    "        **Parameters:**<br>\n",
    "        `y`: tensor, Actual values.<br>\n",
    "        `y_hat`: tensor, Predicted values.<br>\n",
    "        `mask`: tensor, Specifies date stamps per series to consider in loss.<br>\n",
    "\n",
    "        **Returns:**<br>\n",
    "        `msse`: tensor (single value).\n",
    "        \"\"\"\n",
    "        if mask is None: \n",
    "            mask = torch.ones_like(y)\n",
    "        n_series, horizon = y.shape\n",
    "\n",
    "        last_col = self.y_train[:, -1].unsqueeze(1)\n",
    "        y_naive = last_col.repeat(1, horizon)\n",
    "            \n",
    "        norm = self.mse(y=y, y_hat=y_naive)\n",
    "        loss = self.mse(y=y, y_hat=y_hat, mask=mask)\n",
    "        loss = loss / (norm + 1e-5)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55451d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L703){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSSE.__init__\n",
       "\n",
       ">      MSSE.__init__ (y_train)\n",
       "\n",
       "Mean Squared Scaled Error\n",
       "Computes Mean squared scaled error (MSSE), as proposed by Hyndman & Koehler (2006)\n",
       "as an alternative to percentage errors, to avoid measure unstability.\n",
       "$$ \\mathrm{MSSE}(\\mathbf{y}, \\mathbf{\\hat{y}}, \\mathbf{\\hat{y}}^{naive1}) =\n",
       "\\frac{\\mathrm{MSE}(\\mathbf{y}, \\mathbf{\\hat{y}})}{\\mathrm{MSE}(\\mathbf{y}, \\mathbf{\\hat{y}}^{naive1})} $$\n",
       "**Parameters:**<br>\n",
       "`y_train`: numpy array, Training values.<br>\n",
       "**References:**<br>\n",
       "- [Hyndman, R. J and Koehler, A. B. (2006).\n",
       "   \"Another look at measures of forecast accuracy\",\n",
       "   International Journal of Forecasting, Volume 22, Issue 4.](https://www.sciencedirect.com/science/article/pii/S0169207006000239)<br>\n",
       "- [Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker. \n",
       "   \"Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures. \n",
       "   Submitted to the International Journal Forecasting, Working paper available at arxiv.](https://arxiv.org/pdf/2110.13179.pdf)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L703){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSSE.__init__\n",
       "\n",
       ">      MSSE.__init__ (y_train)\n",
       "\n",
       "Mean Squared Scaled Error\n",
       "Computes Mean squared scaled error (MSSE), as proposed by Hyndman & Koehler (2006)\n",
       "as an alternative to percentage errors, to avoid measure unstability.\n",
       "$$ \\mathrm{MSSE}(\\mathbf{y}, \\mathbf{\\hat{y}}, \\mathbf{\\hat{y}}^{naive1}) =\n",
       "\\frac{\\mathrm{MSE}(\\mathbf{y}, \\mathbf{\\hat{y}})}{\\mathrm{MSE}(\\mathbf{y}, \\mathbf{\\hat{y}}^{naive1})} $$\n",
       "**Parameters:**<br>\n",
       "`y_train`: numpy array, Training values.<br>\n",
       "**References:**<br>\n",
       "- [Hyndman, R. J and Koehler, A. B. (2006).\n",
       "   \"Another look at measures of forecast accuracy\",\n",
       "   International Journal of Forecasting, Volume 22, Issue 4.](https://www.sciencedirect.com/science/article/pii/S0169207006000239)<br>\n",
       "- [Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker. \n",
       "   \"Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures. \n",
       "   Submitted to the International Journal Forecasting, Working paper available at arxiv.](https://arxiv.org/pdf/2110.13179.pdf)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MSSE, name='MSSE.__init__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6ca8505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L726){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSSE.__call__\n",
       "\n",
       ">      MSSE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                     mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per series to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`msse`: tensor (single value)."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L726){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MSSE.__call__\n",
       "\n",
       ">      MSSE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n",
       ">                     mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "**Parameters:**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`y_hat`: tensor, Predicted values.<br>\n",
       "`mask`: tensor, Specifies date stamps per series to consider in loss.<br>\n",
       "\n",
       "**Returns:**<br>\n",
       "`msse`: tensor (single value)."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MSSE.__call__, name='MSSE.__call__', title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895ec0c0",
   "metadata": {},
   "source": [
    "## DistributionLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "801785b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def weighted_average(x: torch.Tensor, \n",
    "                     weights: Optional[torch.Tensor]=None, dim=None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes the weighted average of a given tensor across a given dim, masking\n",
    "    values associated with weight zero,\n",
    "    meaning instead of `nan * 0 = nan` you will get `0 * 0 = 0`.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `x`: Input tensor, of which the average must be computed.<br>\n",
    "    `weights`: Weights tensor, of the same shape as `x`.<br>\n",
    "    `dim`: The dim along which to average `x`.<br>\n",
    "\n",
    "    **Returns:**<br>\n",
    "    `Tensor`: The tensor with values averaged along the specified `dim`.<br>\n",
    "    \"\"\"\n",
    "    if weights is not None:\n",
    "        weighted_tensor = torch.where(\n",
    "            weights != 0, x * weights, torch.zeros_like(x)\n",
    "        )\n",
    "        sum_weights = torch.clamp(\n",
    "            weights.sum(dim=dim) if dim else weights.sum(), min=1.0\n",
    "        )\n",
    "        return (\n",
    "            weighted_tensor.sum(dim=dim) if dim else weighted_tensor.sum()\n",
    "        ) / sum_weights\n",
    "    else:\n",
    "        return x.mean(dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83b90c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def bernoulli_domain_map(input: torch.Tensor):\n",
    "    \"\"\" Bernoulli Domain Map\n",
    "    Maps input into distribution constraints, by construction input's \n",
    "    last dimension is of matching `distr_args` length.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `input`: tensor, of dimensions [B,T,H,theta] or [B,H,theta].<br>\n",
    "\n",
    "    **Returns:**<br>\n",
    "    `(probs,)`: tuple with tensors of Poisson distribution arguments.<br>\n",
    "    \"\"\"\n",
    "    return (input.squeeze(-1),)\n",
    "\n",
    "def bernoulli_scale_decouple(output, loc=None, scale=None):\n",
    "    \"\"\" Bernoulli Scale Decouple\n",
    "\n",
    "    Stabilizes model's output optimization, by learning residual\n",
    "    variance and residual location based on anchoring `loc`, `scale`.\n",
    "    Also adds Bernoulli domain protection to the distribution parameters.\n",
    "    \"\"\"\n",
    "    probs = output[0]\n",
    "    #if (loc is not None) and (scale is not None):\n",
    "    #    rate = (rate * scale) + loc\n",
    "    probs = F.sigmoid(probs)#.clone()\n",
    "    return (probs,)\n",
    "\n",
    "def student_domain_map(input: torch.Tensor):\n",
    "    \"\"\" Student T Domain Map\n",
    "    Maps input into distribution constraints, by construction input's \n",
    "    last dimension is of matching `distr_args` length.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `input`: tensor, of dimensions [B,T,H,theta] or [B,H,theta].<br>\n",
    "    `eps`: float, helps the initialization of scale for easier optimization.<br>\n",
    "\n",
    "    **Returns:**<br>\n",
    "    `(df, loc, scale)`: tuple with tensors of StudentT distribution arguments.<br>\n",
    "    \"\"\"\n",
    "    df, loc, scale = torch.tensor_split(input, 3, dim=-1)\n",
    "    return df.squeeze(-1), loc.squeeze(-1), scale.squeeze(-1)\n",
    "\n",
    "def student_scale_decouple(output, loc=None, scale=None, eps: float=0.1):\n",
    "    \"\"\" Normal Scale Decouple\n",
    "\n",
    "    Stabilizes model's output optimization, by learning residual\n",
    "    variance and residual location based on anchoring `loc`, `scale`.\n",
    "    Also adds StudentT domain protection to the distribution parameters.\n",
    "    \"\"\"\n",
    "    df, mean, tscale = output\n",
    "    tscale = F.softplus(tscale)\n",
    "    if (loc is not None) and (scale is not None):\n",
    "        mean = (mean * scale) + loc\n",
    "        tscale = (tscale + eps) * scale\n",
    "    df = 2.0 + F.softplus(df)\n",
    "    return (df, mean, tscale)\n",
    "\n",
    "def normal_domain_map(input: torch.Tensor):\n",
    "    \"\"\" Normal Domain Map\n",
    "    Maps input into distribution constraints, by construction input's \n",
    "    last dimension is of matching `distr_args` length.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `input`: tensor, of dimensions [B,T,H,theta] or [B,H,theta].<br>\n",
    "    `eps`: float, helps the initialization of scale for easier optimization.<br>\n",
    "\n",
    "    **Returns:**<br>\n",
    "    `(mean, std)`: tuple with tensors of Normal distribution arguments.<br>\n",
    "    \"\"\"\n",
    "    mean, std = torch.tensor_split(input, 2, dim=-1)\n",
    "    return mean.squeeze(-1), std.squeeze(-1)\n",
    "\n",
    "def normal_scale_decouple(output, loc=None, scale=None, eps: float=0.2):\n",
    "    \"\"\" Normal Scale Decouple\n",
    "\n",
    "    Stabilizes model's output optimization, by learning residual\n",
    "    variance and residual location based on anchoring `loc`, `scale`.\n",
    "    Also adds Normal domain protection to the distribution parameters.\n",
    "    \"\"\"\n",
    "    mean, std = output\n",
    "    std = F.softplus(std)\n",
    "    if (loc is not None) and (scale is not None):\n",
    "        mean = (mean * scale) + loc\n",
    "        std = (std + eps) * scale\n",
    "    return (mean, std)\n",
    "\n",
    "def poisson_domain_map(input: torch.Tensor):\n",
    "    \"\"\" Poisson Domain Map\n",
    "    Maps input into distribution constraints, by construction input's \n",
    "    last dimension is of matching `distr_args` length.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `input`: tensor, of dimensions [B,T,H,theta] or [B,H,theta].<br>\n",
    "\n",
    "    **Returns:**<br>\n",
    "    `(rate,)`: tuple with tensors of Poisson distribution arguments.<br>\n",
    "    \"\"\"\n",
    "    return (input.squeeze(-1),)\n",
    "\n",
    "def poisson_scale_decouple(output, loc=None, scale=None):\n",
    "    \"\"\" Poisson Scale Decouple\n",
    "\n",
    "    Stabilizes model's output optimization, by learning residual\n",
    "    variance and residual location based on anchoring `loc`, `scale`.\n",
    "    Also adds Poisson domain protection to the distribution parameters.\n",
    "    \"\"\"\n",
    "    eps  = 1e-10\n",
    "    rate = output[0]\n",
    "    if (loc is not None) and (scale is not None):\n",
    "        rate = (rate * scale) + loc\n",
    "    rate = F.softplus(rate) + eps\n",
    "    return (rate,)\n",
    "\n",
    "def nbinomial_domain_map(input: torch.Tensor):\n",
    "    \"\"\" Negative Binomial Domain Map\n",
    "    Maps input into distribution constraints, by construction input's \n",
    "    last dimension is of matching `distr_args` length.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `input`: tensor, of dimensions [B,T,H,theta] or [B,H,theta].<br>\n",
    "\n",
    "    **Returns:**<br>\n",
    "    `(total_count, alpha)`: tuple with tensors of N.Binomial distribution arguments.<br>\n",
    "    \"\"\"\n",
    "    mu, alpha = torch.tensor_split(input, 2, dim=-1)\n",
    "    return mu.squeeze(-1), alpha.squeeze(-1)\n",
    "\n",
    "def nbinomial_scale_decouple(output, loc=None, scale=None):\n",
    "    \"\"\" Negative Binomial Scale Decouple\n",
    "\n",
    "    Stabilizes model's output optimization, by learning total\n",
    "    count and logits based on anchoring `loc`, `scale`.\n",
    "    Also adds Negative Binomial domain protection to the distribution parameters.\n",
    "    \"\"\"\n",
    "    mu, alpha = output\n",
    "    mu = F.softplus(mu) + 1e-8\n",
    "    alpha = F.softplus(alpha) + 1e-8    # alpha = 1/total_counts\n",
    "    if (loc is not None) and (scale is not None):\n",
    "        mu *= loc\n",
    "        alpha /= (loc + 1.)\n",
    "\n",
    "    # mu = total_count * (probs/(1-probs))\n",
    "    # => probs = mu / (total_count + mu)\n",
    "    # => probs = mu / [total_count * (1 + mu * (1/total_count))]\n",
    "    total_count = 1.0 / alpha\n",
    "    probs = (mu * alpha / (1.0 + mu * alpha)) + 1e-8\n",
    "    return (total_count, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03294edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def est_lambda(mu, rho):\n",
    "    return mu ** (2 - rho) / (2 - rho)\n",
    "\n",
    "def est_alpha(rho):\n",
    "    return (2 - rho) / (rho - 1)\n",
    "\n",
    "def est_beta(mu, rho):\n",
    "    return mu ** (1 - rho) / (rho - 1)\n",
    "\n",
    "\n",
    "class Tweedie(Distribution):\n",
    "    \"\"\" Tweedie Distribution\n",
    "\n",
    "    The Tweedie distribution is a compound probability, special case of exponential\n",
    "    dispersion models EDMs defined by its mean-variance relationship.\n",
    "    The distribution particularly useful to model sparse series as the probability has\n",
    "    possitive mass at zero but otherwise is continuous.\n",
    "\n",
    "    $Y \\sim \\mathrm{ED}(\\\\mu,\\\\sigma^{2}) \\qquad\n",
    "    \\mathbb{P}(y|\\\\mu ,\\\\sigma^{2})=h(\\\\sigma^{2},y) \\\\exp \\\\left({\\\\frac {\\\\theta y-A(\\\\theta )}{\\\\sigma^{2}}}\\\\right)$<br>\n",
    "    \n",
    "    $\\mu =A'(\\\\theta ) \\qquad \\mathrm{Var}(Y) = \\\\sigma^{2} \\\\mu^{\\\\rho}$\n",
    "    \n",
    "    Cases of the variance relationship include Normal (`rho` = 0), Poisson (`rho` = 1),\n",
    "    Gamma (`rho` = 2), inverse Gaussian (`rho` = 3).\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `log_mu`: tensor, with log of means.<br>\n",
    "    `rho`: float, Tweedie variance power (1,2). Fixed across all observations.<br>\n",
    "    `sigma2`: tensor, Tweedie variance. Currently fixed in 1.<br>\n",
    "\n",
    "    **References:**<br>\n",
    "    - [Tweedie, M. C. K. (1984). An index which distinguishes between some important exponential families. Statistics: Applications and New Directions. \n",
    "    Proceedings of the Indian Statistical Institute Golden Jubilee International Conference (Eds. J. K. Ghosh and J. Roy), pp. 579-604. Calcutta: Indian Statistical Institute.]()<br>\n",
    "    - [Jorgensen, B. (1987). Exponential Dispersion Models. Journal of the Royal Statistical Society. \n",
    "       Series B (Methodological), 49(2), 127–162. http://www.jstor.org/stable/2345415](http://www.jstor.org/stable/2345415)<br>\n",
    "    \"\"\"\n",
    "    def __init__(self, log_mu, rho, validate_args=None):\n",
    "        # TODO: add sigma2 dispersion\n",
    "        # TODO add constraints\n",
    "        # arg_constraints = {'log_mu': constraints.real, 'rho': constraints.positive}\n",
    "        # support = constraints.real\n",
    "        self.log_mu = log_mu\n",
    "        self.rho = rho\n",
    "        assert rho>1 and rho<2, f'rho={rho} parameter needs to be between (1,2).'\n",
    "\n",
    "        batch_shape = log_mu.size()\n",
    "        super(Tweedie, self).__init__(batch_shape, validate_args=validate_args)\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        return torch.exp(self.log_mu)\n",
    "\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return torch.ones_line(self.log_mu) #TODO need to be assigned\n",
    "\n",
    "    def sample(self, sample_shape=torch.Size()):\n",
    "        shape = self._extended_shape(sample_shape)\n",
    "        with torch.no_grad():\n",
    "            mu   = self.mean\n",
    "            rho  = self.rho * torch.ones_like(mu)\n",
    "            sigma2 = 1 #TODO\n",
    "\n",
    "            rate  = est_lambda(mu, rho) / sigma2  # rate for poisson\n",
    "            alpha = est_alpha(rho)                # alpha for Gamma distribution\n",
    "            beta  = est_beta(mu, rho) / sigma2    # beta for Gamma distribution\n",
    "            \n",
    "            # Expand for sample\n",
    "            rate = rate.expand(shape)\n",
    "            alpha = alpha.expand(shape)\n",
    "            beta = beta.expand(shape)\n",
    "\n",
    "            N = torch.poisson(rate)\n",
    "            gamma = torch.distributions.gamma.Gamma(N*alpha, beta)\n",
    "            samples = gamma.sample()\n",
    "            samples[N==0] = 0\n",
    "\n",
    "            return samples\n",
    "\n",
    "    def log_prob(self, y_true):\n",
    "        rho = self.rho\n",
    "        y_pred = self.log_mu\n",
    "\n",
    "        a = y_true * torch.exp((1 - rho) * y_pred) / (1 - rho)\n",
    "        b = torch.exp((2 - rho) * y_pred) / (2 - rho)\n",
    "\n",
    "        return a - b\n",
    "\n",
    "def tweedie_domain_map(input: torch.Tensor):\n",
    "    \"\"\" Tweedie Domain Map\n",
    "    Maps input into distribution constraints, by construction input's \n",
    "    last dimension is of matching `distr_args` length.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `input`: tensor, of dimensions [B,T,H,theta] or [B,H,theta].<br>\n",
    "\n",
    "    **Returns:**<br>\n",
    "    `(log_mu,)`: tuple with tensors of Tweedie distribution arguments.<br>\n",
    "    \"\"\"\n",
    "    # log_mu, probs = torch.tensor_split(input, 2, dim=-1)\n",
    "    return (input.squeeze(-1),)\n",
    "\n",
    "def tweedie_scale_decouple(output, loc=None, scale=None):\n",
    "    \"\"\" Tweedie Scale Decouple\n",
    "\n",
    "    Stabilizes model's output optimization, by learning total\n",
    "    count and logits based on anchoring `loc`, `scale`.\n",
    "    Also adds Tweedie domain protection to the distribution parameters.\n",
    "    \"\"\"\n",
    "    log_mu = output[0]\n",
    "    if (loc is not None) and (scale is not None):\n",
    "        log_mu += torch.log(loc) # TODO : rho scaling\n",
    "    return (log_mu,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5931f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DistributionLoss(torch.nn.Module):\n",
    "    \"\"\" DistributionLoss\n",
    "\n",
    "    This PyTorch module wraps the `torch.distribution` classes allowing it to \n",
    "    interact with NeuralForecast models modularly. It shares the negative \n",
    "    log-likelihood as the optimization objective and a sample method to \n",
    "    generate empirically the quantiles defined by the `level` list.\n",
    "\n",
    "    Additionally, it implements a distribution transformation that factorizes the\n",
    "    scale-dependent likelihood parameters into a base scale and a multiplier \n",
    "    efficiently learnable within the network's non-linearities operating ranges.\n",
    "\n",
    "    Available distributions:\n",
    "    - Poisson\n",
    "    - Normal\n",
    "    - StudentT\n",
    "    - NegativeBinomial\n",
    "    - Tweedie\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `distribution`: str, identifier of a torch.distributions.Distribution class.<br>\n",
    "    `level`: float list [0,100], confidence levels for prediction intervals.<br>\n",
    "    `quantiles`: float list [0,1], alternative to level list, target quantiles.<br>\n",
    "    `num_samples`: int=500, number of samples for the empirical quantiles.<br>\n",
    "    `return_params`: bool=False, wether or not return the Distribution parameters.<br><br>\n",
    "\n",
    "    **References:**<br>\n",
    "    - [PyTorch Probability Distributions Package: StudentT.](https://pytorch.org/docs/stable/distributions.html#studentt)<br>\n",
    "    - [David Salinas, Valentin Flunkert, Jan Gasthaus, Tim Januschowski (2020).\n",
    "       \"DeepAR: Probabilistic forecasting with autoregressive recurrent networks\". International Journal of Forecasting.](https://www.sciencedirect.com/science/article/pii/S0169207019301888)<br>\n",
    "    \"\"\"\n",
    "    def __init__(self, distribution, level=[80, 90], quantiles=None,\n",
    "                 num_samples=1000, return_params=False, **distribution_kwargs):\n",
    "       super(DistributionLoss, self).__init__()\n",
    "\n",
    "       available_distributions = dict(\n",
    "                          Bernoulli=Bernoulli,\n",
    "                          Normal=Normal,\n",
    "                          Poisson=Poisson,\n",
    "                          StudentT=StudentT,\n",
    "                          NegativeBinomial=NegativeBinomial,\n",
    "                          Tweedie=Tweedie)\n",
    "       domain_maps = dict(Bernoulli=bernoulli_domain_map,\n",
    "                          Normal=normal_domain_map,\n",
    "                          Poisson=poisson_domain_map,\n",
    "                          StudentT=student_domain_map,\n",
    "                          NegativeBinomial=nbinomial_domain_map,\n",
    "                          Tweedie=tweedie_domain_map)\n",
    "       scale_decouples = dict(\n",
    "                          Bernoulli=bernoulli_scale_decouple,\n",
    "                          Normal=normal_scale_decouple,\n",
    "                          Poisson=poisson_scale_decouple,\n",
    "                          StudentT=student_scale_decouple,\n",
    "                          NegativeBinomial=nbinomial_scale_decouple,\n",
    "                          Tweedie=tweedie_scale_decouple)\n",
    "       param_names = dict(Bernoulli=[\"-logits\"],\n",
    "                          Normal=[\"-loc\", \"-scale\"],\n",
    "                          Poisson=[\"-loc\"],\n",
    "                          StudentT=[\"-df\", \"-loc\", \"-scale\"],\n",
    "                          NegativeBinomial=[\"-total_count\", \"-logits\"],\n",
    "                          Tweedie=[\"-log_mu\"])\n",
    "       assert (distribution in available_distributions.keys()), f'{distribution} not available'\n",
    "\n",
    "       self.distribution = distribution\n",
    "       self._base_distribution = available_distributions[distribution]\n",
    "       self.domain_map = domain_maps[distribution]\n",
    "       self.scale_decouple = scale_decouples[distribution]\n",
    "       self.param_names = param_names[distribution]\n",
    "\n",
    "       self.distribution_kwargs = distribution_kwargs\n",
    "\n",
    "       qs, self.output_names = level_to_outputs(level)\n",
    "       qs = torch.Tensor(qs)\n",
    "\n",
    "        # Transform quantiles to homogeneus output names\n",
    "       if quantiles is not None:\n",
    "              _, self.output_names = quantiles_to_outputs(quantiles)\n",
    "              qs = torch.Tensor(quantiles)\n",
    "       self.quantiles = torch.nn.Parameter(qs, requires_grad=False)\n",
    "       self.num_samples = num_samples\n",
    "\n",
    "       # If True, predict_step will return Distribution's parameters\n",
    "       self.return_params = return_params\n",
    "       if self.return_params:\n",
    "            self.output_names = self.output_names + self.param_names\n",
    "\n",
    "       # Add first output entry for the sample_mean\n",
    "       self.output_names.insert(0, \"\")            \n",
    "\n",
    "       self.outputsize_multiplier = len(self.param_names)\n",
    "       self.is_distribution_output = True\n",
    "\n",
    "    def get_distribution(self, distr_args, **distribution_kwargs) -> Distribution:\n",
    "        \"\"\"\n",
    "        Construct the associated Pytorch Distribution, given the collection of\n",
    "        constructor arguments and, optionally, location and scale tensors.\n",
    "\n",
    "        **Parameters**<br>\n",
    "        `distr_args`: Constructor arguments for the underlying Distribution type.<br>\n",
    "\n",
    "        **Returns**<br>\n",
    "        `Distribution`: AffineTransformed distribution.<br>\n",
    "        \"\"\"\n",
    "        # TransformedDistribution(distr, [AffineTransform(loc=loc, scale=scale)])\n",
    "        distr = self._base_distribution(*distr_args, **distribution_kwargs)\n",
    "        \n",
    "        if self.distribution =='Poisson':\n",
    "              distr.support = constraints.nonnegative\n",
    "        return distr\n",
    "\n",
    "    def sample(self,\n",
    "               distr_args: torch.Tensor,\n",
    "               num_samples: Optional[int] = None):\n",
    "        \"\"\"\n",
    "        Construct the empirical quantiles from the estimated Distribution,\n",
    "        sampling from it `num_samples` independently.\n",
    "\n",
    "        **Parameters**<br>\n",
    "        `distr_args`: Constructor arguments for the underlying Distribution type.<br>\n",
    "        `loc`: Optional tensor, of the same shape as the batch_shape + event_shape\n",
    "               of the resulting distribution.<br>\n",
    "        `scale`: Optional tensor, of the same shape as the batch_shape+event_shape \n",
    "               of the resulting distribution.<br>\n",
    "        `num_samples`: int=500, overwrite number of samples for the empirical quantiles.<br>\n",
    "\n",
    "        **Returns**<br>\n",
    "        `samples`: tensor, shape [B,H,`num_samples`].<br>\n",
    "        `quantiles`: tensor, empirical quantiles defined by `levels`.<br>\n",
    "        \"\"\"\n",
    "        if num_samples is None:\n",
    "            num_samples = self.num_samples\n",
    "\n",
    "        B, H = distr_args[0].size()\n",
    "        Q = len(self.quantiles)\n",
    "\n",
    "        # Instantiate Scaled Decoupled Distribution\n",
    "        distr = self.get_distribution(distr_args=distr_args, **self.distribution_kwargs)\n",
    "        samples = distr.sample(sample_shape=(num_samples,))\n",
    "        samples = samples.permute(1,2,0) # [samples,B,H] -> [B,H,samples]\n",
    "        samples = samples.to(distr_args[0].device)\n",
    "        samples = samples.view(B*H, num_samples)\n",
    "        sample_mean = torch.mean(samples, dim=-1)\n",
    "\n",
    "        # Compute quantiles\n",
    "        quantiles_device = self.quantiles.to(distr_args[0].device)\n",
    "        quants = torch.quantile(input=samples, \n",
    "                                q=quantiles_device, dim=1)\n",
    "        quants = quants.permute((1,0)) # [Q, B*H] -> [B*H, Q]\n",
    "\n",
    "        # Final reshapes\n",
    "        samples = samples.view(B, H, num_samples)\n",
    "        sample_mean = sample_mean.view(B, H, 1)\n",
    "        quants  = quants.view(B, H, Q)\n",
    "\n",
    "        return samples, sample_mean, quants\n",
    "\n",
    "    def __call__(self,\n",
    "                 y: torch.Tensor,\n",
    "                 distr_args: torch.Tensor,\n",
    "                 mask: Union[torch.Tensor, None] = None):\n",
    "        \"\"\"\n",
    "        Computes the negative log-likelihood objective function. \n",
    "        To estimate the following predictive distribution:\n",
    "\n",
    "        $$\\mathrm{P}(\\mathbf{y}_{\\\\tau}\\,|\\,\\\\theta) \\\\quad \\mathrm{and} \\\\quad -\\log(\\mathrm{P}(\\mathbf{y}_{\\\\tau}\\,|\\,\\\\theta))$$\n",
    "\n",
    "        where $\\\\theta$ represents the distributions parameters. It aditionally \n",
    "        summarizes the objective signal using a weighted average using the `mask` tensor. \n",
    "\n",
    "        **Parameters**<br>\n",
    "        `y`: tensor, Actual values.<br>\n",
    "        `distr_args`: Constructor arguments for the underlying Distribution type.<br>\n",
    "        `loc`: Optional tensor, of the same shape as the batch_shape + event_shape\n",
    "               of the resulting distribution.<br>\n",
    "        `scale`: Optional tensor, of the same shape as the batch_shape+event_shape \n",
    "               of the resulting distribution.<br>\n",
    "        `mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
    "\n",
    "        **Returns**<br>\n",
    "        `loss`: scalar, weighted loss function against which backpropagation will be performed.<br>\n",
    "        \"\"\"\n",
    "        # Instantiate Scaled Decoupled Distribution\n",
    "        distr = self.get_distribution(distr_args=distr_args, **self.distribution_kwargs)\n",
    "        loss_values = -distr.log_prob(y)\n",
    "        loss_weights = mask\n",
    "        return weighted_average(loss_values, weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a462101b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1060){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DistributionLoss.__init__\n",
       "\n",
       ">      DistributionLoss.__init__ (distribution, level=[80, 90], quantiles=None,\n",
       ">                                 num_samples=1000, return_params=False,\n",
       ">                                 **distribution_kwargs)\n",
       "\n",
       "DistributionLoss\n",
       "\n",
       "This PyTorch module wraps the `torch.distribution` classes allowing it to \n",
       "interact with NeuralForecast models modularly. It shares the negative \n",
       "log-likelihood as the optimization objective and a sample method to \n",
       "generate empirically the quantiles defined by the `level` list.\n",
       "\n",
       "Additionally, it implements a distribution transformation that factorizes the\n",
       "scale-dependent likelihood parameters into a base scale and a multiplier \n",
       "efficiently learnable within the network's non-linearities operating ranges.\n",
       "\n",
       "Available distributions:\n",
       "- Poisson\n",
       "- Normal\n",
       "- StudentT\n",
       "- NegativeBinomial\n",
       "- Tweedie\n",
       "\n",
       "**Parameters:**<br>\n",
       "`distribution`: str, identifier of a torch.distributions.Distribution class.<br>\n",
       "`level`: float list [0,100], confidence levels for prediction intervals.<br>\n",
       "`quantiles`: float list [0,1], alternative to level list, target quantiles.<br>\n",
       "`num_samples`: int=500, number of samples for the empirical quantiles.<br>\n",
       "`return_params`: bool=False, wether or not return the Distribution parameters.<br><br>\n",
       "\n",
       "**References:**<br>\n",
       "- [PyTorch Probability Distributions Package: StudentT.](https://pytorch.org/docs/stable/distributions.html#studentt)<br>\n",
       "- [David Salinas, Valentin Flunkert, Jan Gasthaus, Tim Januschowski (2020).\n",
       "   \"DeepAR: Probabilistic forecasting with autoregressive recurrent networks\". International Journal of Forecasting.](https://www.sciencedirect.com/science/article/pii/S0169207019301888)<br>"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1060){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DistributionLoss.__init__\n",
       "\n",
       ">      DistributionLoss.__init__ (distribution, level=[80, 90], quantiles=None,\n",
       ">                                 num_samples=1000, return_params=False,\n",
       ">                                 **distribution_kwargs)\n",
       "\n",
       "DistributionLoss\n",
       "\n",
       "This PyTorch module wraps the `torch.distribution` classes allowing it to \n",
       "interact with NeuralForecast models modularly. It shares the negative \n",
       "log-likelihood as the optimization objective and a sample method to \n",
       "generate empirically the quantiles defined by the `level` list.\n",
       "\n",
       "Additionally, it implements a distribution transformation that factorizes the\n",
       "scale-dependent likelihood parameters into a base scale and a multiplier \n",
       "efficiently learnable within the network's non-linearities operating ranges.\n",
       "\n",
       "Available distributions:\n",
       "- Poisson\n",
       "- Normal\n",
       "- StudentT\n",
       "- NegativeBinomial\n",
       "- Tweedie\n",
       "\n",
       "**Parameters:**<br>\n",
       "`distribution`: str, identifier of a torch.distributions.Distribution class.<br>\n",
       "`level`: float list [0,100], confidence levels for prediction intervals.<br>\n",
       "`quantiles`: float list [0,1], alternative to level list, target quantiles.<br>\n",
       "`num_samples`: int=500, number of samples for the empirical quantiles.<br>\n",
       "`return_params`: bool=False, wether or not return the Distribution parameters.<br><br>\n",
       "\n",
       "**References:**<br>\n",
       "- [PyTorch Probability Distributions Package: StudentT.](https://pytorch.org/docs/stable/distributions.html#studentt)<br>\n",
       "- [David Salinas, Valentin Flunkert, Jan Gasthaus, Tim Januschowski (2020).\n",
       "   \"DeepAR: Probabilistic forecasting with autoregressive recurrent networks\". International Journal of Forecasting.](https://www.sciencedirect.com/science/article/pii/S0169207019301888)<br>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DistributionLoss, name='DistributionLoss.__init__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8c367f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1183){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DistributionLoss.sample\n",
       "\n",
       ">      DistributionLoss.sample (distr_args:torch.Tensor,\n",
       ">                               num_samples:Union[int,NoneType]=None)\n",
       "\n",
       "Construct the empirical quantiles from the estimated Distribution,\n",
       "sampling from it `num_samples` independently.\n",
       "\n",
       "**Parameters**<br>\n",
       "`distr_args`: Constructor arguments for the underlying Distribution type.<br>\n",
       "`loc`: Optional tensor, of the same shape as the batch_shape + event_shape\n",
       "       of the resulting distribution.<br>\n",
       "`scale`: Optional tensor, of the same shape as the batch_shape+event_shape \n",
       "       of the resulting distribution.<br>\n",
       "`num_samples`: int=500, overwrite number of samples for the empirical quantiles.<br>\n",
       "\n",
       "**Returns**<br>\n",
       "`samples`: tensor, shape [B,H,`num_samples`].<br>\n",
       "`quantiles`: tensor, empirical quantiles defined by `levels`.<br>"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1183){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DistributionLoss.sample\n",
       "\n",
       ">      DistributionLoss.sample (distr_args:torch.Tensor,\n",
       ">                               num_samples:Union[int,NoneType]=None)\n",
       "\n",
       "Construct the empirical quantiles from the estimated Distribution,\n",
       "sampling from it `num_samples` independently.\n",
       "\n",
       "**Parameters**<br>\n",
       "`distr_args`: Constructor arguments for the underlying Distribution type.<br>\n",
       "`loc`: Optional tensor, of the same shape as the batch_shape + event_shape\n",
       "       of the resulting distribution.<br>\n",
       "`scale`: Optional tensor, of the same shape as the batch_shape+event_shape \n",
       "       of the resulting distribution.<br>\n",
       "`num_samples`: int=500, overwrite number of samples for the empirical quantiles.<br>\n",
       "\n",
       "**Returns**<br>\n",
       "`samples`: tensor, shape [B,H,`num_samples`].<br>\n",
       "`quantiles`: tensor, empirical quantiles defined by `levels`.<br>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DistributionLoss.sample, name='DistributionLoss.sample', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "04e32679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1223){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DistributionLoss.__call__\n",
       "\n",
       ">      DistributionLoss.__call__ (y:torch.Tensor, distr_args:torch.Tensor,\n",
       ">                                 mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "Computes the negative log-likelihood objective function. \n",
       "To estimate the following predictive distribution:\n",
       "\n",
       "$$\\mathrm{P}(\\mathbf{y}_{\\tau}\\,|\\,\\theta) \\quad \\mathrm{and} \\quad -\\log(\\mathrm{P}(\\mathbf{y}_{\\tau}\\,|\\,\\theta))$$\n",
       "\n",
       "where $\\theta$ represents the distributions parameters. It aditionally \n",
       "summarizes the objective signal using a weighted average using the `mask` tensor. \n",
       "\n",
       "**Parameters**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`distr_args`: Constructor arguments for the underlying Distribution type.<br>\n",
       "`loc`: Optional tensor, of the same shape as the batch_shape + event_shape\n",
       "       of the resulting distribution.<br>\n",
       "`scale`: Optional tensor, of the same shape as the batch_shape+event_shape \n",
       "       of the resulting distribution.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns**<br>\n",
       "`loss`: scalar, weighted loss function against which backpropagation will be performed.<br>"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1223){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DistributionLoss.__call__\n",
       "\n",
       ">      DistributionLoss.__call__ (y:torch.Tensor, distr_args:torch.Tensor,\n",
       ">                                 mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "Computes the negative log-likelihood objective function. \n",
       "To estimate the following predictive distribution:\n",
       "\n",
       "$$\\mathrm{P}(\\mathbf{y}_{\\tau}\\,|\\,\\theta) \\quad \\mathrm{and} \\quad -\\log(\\mathrm{P}(\\mathbf{y}_{\\tau}\\,|\\,\\theta))$$\n",
       "\n",
       "where $\\theta$ represents the distributions parameters. It aditionally \n",
       "summarizes the objective signal using a weighted average using the `mask` tensor. \n",
       "\n",
       "**Parameters**<br>\n",
       "`y`: tensor, Actual values.<br>\n",
       "`distr_args`: Constructor arguments for the underlying Distribution type.<br>\n",
       "`loc`: Optional tensor, of the same shape as the batch_shape + event_shape\n",
       "       of the resulting distribution.<br>\n",
       "`scale`: Optional tensor, of the same shape as the batch_shape+event_shape \n",
       "       of the resulting distribution.<br>\n",
       "`mask`: tensor, Specifies date stamps per serie to consider in loss.<br>\n",
       "\n",
       "**Returns**<br>\n",
       "`loss`: scalar, weighted loss function against which backpropagation will be performed.<br>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DistributionLoss.__call__, name='DistributionLoss.__call__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14a7e381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '-lo-98.0', '-lo-80.0', '-median', '-hi-80.0', '-hi-98.0']\n",
      "Parameter containing:\n",
      "tensor([0.0100, 0.1000, 0.5000, 0.9000, 0.9900])\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "# Unit tests to check DistributionLoss' stored quantiles\n",
    "# attribute is correctly instantiated\n",
    "check = DistributionLoss(distribution='Normal', level=[80, 90])\n",
    "test_eq(len(check.quantiles), 5)\n",
    "\n",
    "check = DistributionLoss(distribution='Normal', \n",
    "                         quantiles=[0.0100, 0.1000, 0.5, 0.9000, 0.9900])\n",
    "print(check.output_names)\n",
    "print(check.quantiles)\n",
    "test_eq(len(check.quantiles), 5)\n",
    "\n",
    "check = DistributionLoss(distribution='Normal',\n",
    "                         quantiles=[0.0100, 0.1000, 0.9000, 0.9900])\n",
    "test_eq(len(check.quantiles), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f459b8",
   "metadata": {},
   "source": [
    "## Poisson Mixture Mesh (PMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "46ec688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PMM(torch.nn.Module):\n",
    "    \"\"\" Poisson Mixture Mesh\n",
    "\n",
    "    This Poisson Mixture statistical model assumes independence across groups of \n",
    "    data $\\mathcal{G}=\\{[g_{i}]\\}$, and estimates relationships within the group.\n",
    "\n",
    "    $$ \\mathrm{P}\\\\left(\\mathbf{y}_{[b][t+1:t+H]}\\\\right) = \n",
    "    \\prod_{ [g_{i}] \\in \\mathcal{G}} \\mathrm{P} \\\\left(\\mathbf{y}_{[g_{i}][\\\\tau]} \\\\right) =\n",
    "    \\prod_{\\\\beta\\in[g_{i}]} \n",
    "    \\\\left(\\sum_{k=1}^{K} w_k \\prod_{(\\\\beta,\\\\tau) \\in [g_i][t+1:t+H]} \\mathrm{Poisson}(y_{\\\\beta,\\\\tau}, \\hat{\\\\lambda}_{\\\\beta,\\\\tau,k}) \\\\right)$$\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `n_components`: int=10, the number of mixture components.<br>\n",
    "    `level`: float list [0,100], confidence levels for prediction intervals.<br>\n",
    "    `quantiles`: float list [0,1], alternative to level list, target quantiles.<br>\n",
    "    `return_params`: bool=False, wether or not return the Distribution parameters.<br>\n",
    "    `batch_correlation`: bool=False, wether or not model batch correlations.<br>\n",
    "    `horizon_correlation`: bool=False, wether or not model horizon correlations.<br>\n",
    "\n",
    "    **References:**<br>\n",
    "    [Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker. \n",
    "    Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures. Submitted to the International \n",
    "    Journal Forecasting, Working paper available at arxiv.](https://arxiv.org/pdf/2110.13179.pdf)\n",
    "    \"\"\"\n",
    "    def __init__(self, n_components=10, level=[80, 90], quantiles=None,\n",
    "                 num_samples=1000, return_params=False,\n",
    "                 batch_correlation=False, horizon_correlation=False):\n",
    "        super(PMM, self).__init__()\n",
    "        # Transform level to MQLoss parameters\n",
    "        qs, self.output_names = level_to_outputs(level)\n",
    "        qs = torch.Tensor(qs)\n",
    "\n",
    "        # Transform quantiles to homogeneus output names\n",
    "        if quantiles is not None:\n",
    "            _, self.output_names = quantiles_to_outputs(quantiles)\n",
    "            qs = torch.Tensor(quantiles)\n",
    "        self.quantiles = torch.nn.Parameter(qs, requires_grad=False)\n",
    "        self.num_samples = num_samples\n",
    "        self.batch_correlation = batch_correlation\n",
    "        self.horizon_correlation = horizon_correlation\n",
    "\n",
    "        # If True, predict_step will return Distribution's parameters\n",
    "        self.return_params = return_params\n",
    "        if self.return_params:\n",
    "            self.param_names = [f\"-lambda-{i}\" for i in range(1, n_components + 1)]\n",
    "            self.output_names = self.output_names + self.param_names\n",
    "\n",
    "        # Add first output entry for the sample_mean\n",
    "        self.output_names.insert(0, \"\")\n",
    "\n",
    "        self.outputsize_multiplier = n_components\n",
    "        self.is_distribution_output = True\n",
    "\n",
    "    def domain_map(self, output: torch.Tensor):\n",
    "        return (output,)#, weights\n",
    "        \n",
    "    def scale_decouple(self, \n",
    "                       output,\n",
    "                       loc: Optional[torch.Tensor] = None,\n",
    "                       scale: Optional[torch.Tensor] = None):\n",
    "        \"\"\" Scale Decouple\n",
    "\n",
    "        Stabilizes model's output optimization, by learning residual\n",
    "        variance and residual location based on anchoring `loc`, `scale`.\n",
    "        Also adds domain protection to the distribution parameters.\n",
    "        \"\"\"\n",
    "        lambdas = output[0]\n",
    "        if (loc is not None) and (scale is not None):\n",
    "            loc = loc.view(lambdas.size(dim=0), 1, -1)\n",
    "            scale = scale.view(lambdas.size(dim=0), 1, -1)\n",
    "            lambdas = (lambdas * scale) + loc\n",
    "        lambdas = F.softplus(lambdas)\n",
    "        return (lambdas,)\n",
    "\n",
    "    def sample(self, distr_args, num_samples=None):\n",
    "        \"\"\"\n",
    "        Construct the empirical quantiles from the estimated Distribution,\n",
    "        sampling from it `num_samples` independently.\n",
    "\n",
    "        **Parameters**<br>\n",
    "        `distr_args`: Constructor arguments for the underlying Distribution type.<br>\n",
    "        `loc`: Optional tensor, of the same shape as the batch_shape + event_shape\n",
    "               of the resulting distribution.<br>\n",
    "        `scale`: Optional tensor, of the same shape as the batch_shape+event_shape \n",
    "               of the resulting distribution.<br>\n",
    "        `num_samples`: int=500, overwrites number of samples for the empirical quantiles.<br>\n",
    "\n",
    "        **Returns**<br>\n",
    "        `samples`: tensor, shape [B,H,`num_samples`].<br>\n",
    "        `quantiles`: tensor, empirical quantiles defined by `levels`.<br>\n",
    "        \"\"\"\n",
    "        if num_samples is None:\n",
    "            num_samples = self.num_samples\n",
    "\n",
    "        lambdas = distr_args[0]\n",
    "        B, H, K = lambdas.size()\n",
    "        Q = len(self.quantiles)\n",
    "\n",
    "        # Sample K ~ Mult(weights)\n",
    "        # shared across B, H\n",
    "        # weights = torch.repeat_interleave(input=weights, repeats=H, dim=2)\n",
    "        weights = (1/K) * torch.ones_like(lambdas).to(lambdas.device)\n",
    "\n",
    "        # Avoid loop, vectorize\n",
    "        weights = weights.reshape(-1, K)\n",
    "        lambdas = lambdas.flatten()        \n",
    "\n",
    "        # Vectorization trick to recover row_idx\n",
    "        sample_idxs = torch.multinomial(input=weights, \n",
    "                                        num_samples=num_samples,\n",
    "                                        replacement=True)\n",
    "        aux_col_idx = torch.unsqueeze(torch.arange(B*H),-1) * K\n",
    "\n",
    "        # To device\n",
    "        sample_idxs = sample_idxs.to(lambdas.device)\n",
    "        aux_col_idx = aux_col_idx.to(lambdas.device)\n",
    "\n",
    "        sample_idxs = sample_idxs + aux_col_idx\n",
    "        sample_idxs = sample_idxs.flatten()\n",
    "\n",
    "        sample_lambdas = lambdas[sample_idxs]\n",
    "\n",
    "        # Sample y ~ Poisson(lambda) independently\n",
    "        samples = torch.poisson(sample_lambdas).to(lambdas.device)\n",
    "        samples = samples.view(B*H, num_samples)\n",
    "        sample_mean = torch.mean(samples, dim=-1)\n",
    "\n",
    "        # Compute quantiles\n",
    "        quantiles_device = self.quantiles.to(lambdas.device)\n",
    "        quants = torch.quantile(input=samples, q=quantiles_device, dim=1)\n",
    "        quants = quants.permute((1,0)) # Q, B*H\n",
    "\n",
    "        # Final reshapes\n",
    "        samples = samples.view(B, H, num_samples)\n",
    "        sample_mean = sample_mean.view(B, H, 1)\n",
    "        quants  = quants.view(B, H, Q)\n",
    "\n",
    "        return samples, sample_mean, quants\n",
    "    \n",
    "    def neglog_likelihood(self,\n",
    "                          y: torch.Tensor,\n",
    "                          distr_args: Tuple[torch.Tensor],\n",
    "                          mask: Union[torch.Tensor, None] = None,):\n",
    "        if mask is None: \n",
    "            mask = (y > 0) * 1\n",
    "        else:\n",
    "            mask = mask * ((y > 0) * 1)\n",
    "\n",
    "        eps  = 1e-10\n",
    "        lambdas = distr_args[0]\n",
    "        B, H, K = lambdas.size()\n",
    "\n",
    "        weights = (1/K) * torch.ones_like(lambdas).to(lambdas.device)\n",
    "\n",
    "        y = y[:,:,None]\n",
    "        mask = mask[:,:,None]\n",
    "\n",
    "        y = y * mask # Protect y negative entries\n",
    "        \n",
    "        # Single Poisson likelihood\n",
    "        log_pi = y.xlogy(lambdas + eps) - lambdas - (y + 1).lgamma()\n",
    "\n",
    "        if self.batch_correlation:\n",
    "            log_pi  = torch.sum(log_pi, dim=0, keepdim=True)\n",
    "\n",
    "        if self.horizon_correlation:\n",
    "            log_pi  = torch.sum(log_pi, dim=1, keepdim=True)\n",
    "\n",
    "        # Numerically Stable Mixture loglikelihood\n",
    "        loglik = torch.logsumexp((torch.log(weights) + log_pi), dim=2, keepdim=True)\n",
    "        loglik = loglik * mask\n",
    "\n",
    "        mean   = torch.sum(weights * lambdas, axis=-1, keepdims=True)\n",
    "        reglrz = torch.mean(torch.square(y - mean) * mask)\n",
    "        loss   = -torch.mean(loglik) + 0.001 * reglrz\n",
    "        return loss\n",
    "\n",
    "    def __call__(self, y: torch.Tensor,\n",
    "                 distr_args: Tuple[torch.Tensor],\n",
    "                 mask: Union[torch.Tensor, None] = None):\n",
    "\n",
    "        return self.neglog_likelihood(y=y, distr_args=distr_args, mask=mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62d7daba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1257){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PMM.__init__\n",
       "\n",
       ">      PMM.__init__ (n_components=10, level=[80, 90], quantiles=None,\n",
       ">                    num_samples=1000, return_params=False,\n",
       ">                    batch_correlation=False, horizon_correlation=False)\n",
       "\n",
       "Poisson Mixture Mesh\n",
       "\n",
       "This Poisson Mixture statistical model assumes independence across groups of \n",
       "data $\\mathcal{G}=\\{[g_{i}]\\}$, and estimates relationships within the group.\n",
       "\n",
       "$$ \\mathrm{P}\\left(\\mathbf{y}_{[b][t+1:t+H]}\\right) = \n",
       "\\prod_{ [g_{i}] \\in \\mathcal{G}} \\mathrm{P} \\left(\\mathbf{y}_{[g_{i}][\\tau]} \\right) =\n",
       "\\prod_{\\beta\\in[g_{i}]} \n",
       "\\left(\\sum_{k=1}^{K} w_k \\prod_{(\\beta,\\tau) \\in [g_i][t+1:t+H]} \\mathrm{Poisson}(y_{\\beta,\\tau}, \\hat{\\lambda}_{\\beta,\\tau,k}) \\right)$$\n",
       "\n",
       "**Parameters:**<br>\n",
       "`n_components`: int=10, the number of mixture components.<br>\n",
       "`level`: float list [0,100], confidence levels for prediction intervals.<br>\n",
       "`quantiles`: float list [0,1], alternative to level list, target quantiles.<br>\n",
       "`return_params`: bool=False, wether or not return the Distribution parameters.<br>\n",
       "`batch_correlation`: bool=False, wether or not model batch correlations.<br>\n",
       "`horizon_correlation`: bool=False, wether or not model horizon correlations.<br>\n",
       "\n",
       "**References:**<br>\n",
       "[Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker. \n",
       "Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures. Submitted to the International \n",
       "Journal Forecasting, Working paper available at arxiv.](https://arxiv.org/pdf/2110.13179.pdf)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1257){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PMM.__init__\n",
       "\n",
       ">      PMM.__init__ (n_components=10, level=[80, 90], quantiles=None,\n",
       ">                    num_samples=1000, return_params=False,\n",
       ">                    batch_correlation=False, horizon_correlation=False)\n",
       "\n",
       "Poisson Mixture Mesh\n",
       "\n",
       "This Poisson Mixture statistical model assumes independence across groups of \n",
       "data $\\mathcal{G}=\\{[g_{i}]\\}$, and estimates relationships within the group.\n",
       "\n",
       "$$ \\mathrm{P}\\left(\\mathbf{y}_{[b][t+1:t+H]}\\right) = \n",
       "\\prod_{ [g_{i}] \\in \\mathcal{G}} \\mathrm{P} \\left(\\mathbf{y}_{[g_{i}][\\tau]} \\right) =\n",
       "\\prod_{\\beta\\in[g_{i}]} \n",
       "\\left(\\sum_{k=1}^{K} w_k \\prod_{(\\beta,\\tau) \\in [g_i][t+1:t+H]} \\mathrm{Poisson}(y_{\\beta,\\tau}, \\hat{\\lambda}_{\\beta,\\tau,k}) \\right)$$\n",
       "\n",
       "**Parameters:**<br>\n",
       "`n_components`: int=10, the number of mixture components.<br>\n",
       "`level`: float list [0,100], confidence levels for prediction intervals.<br>\n",
       "`quantiles`: float list [0,1], alternative to level list, target quantiles.<br>\n",
       "`return_params`: bool=False, wether or not return the Distribution parameters.<br>\n",
       "`batch_correlation`: bool=False, wether or not model batch correlations.<br>\n",
       "`horizon_correlation`: bool=False, wether or not model horizon correlations.<br>\n",
       "\n",
       "**References:**<br>\n",
       "[Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker. \n",
       "Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures. Submitted to the International \n",
       "Journal Forecasting, Working paper available at arxiv.](https://arxiv.org/pdf/2110.13179.pdf)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(PMM, name='PMM.__init__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa8da65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1338){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PMM.sample\n",
       "\n",
       ">      PMM.sample (distr_args, num_samples=None)\n",
       "\n",
       "Construct the empirical quantiles from the estimated Distribution,\n",
       "sampling from it `num_samples` independently.\n",
       "\n",
       "**Parameters**<br>\n",
       "`distr_args`: Constructor arguments for the underlying Distribution type.<br>\n",
       "`loc`: Optional tensor, of the same shape as the batch_shape + event_shape\n",
       "       of the resulting distribution.<br>\n",
       "`scale`: Optional tensor, of the same shape as the batch_shape+event_shape \n",
       "       of the resulting distribution.<br>\n",
       "`num_samples`: int=500, overwrites number of samples for the empirical quantiles.<br>\n",
       "\n",
       "**Returns**<br>\n",
       "`samples`: tensor, shape [B,H,`num_samples`].<br>\n",
       "`quantiles`: tensor, empirical quantiles defined by `levels`.<br>"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1338){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PMM.sample\n",
       "\n",
       ">      PMM.sample (distr_args, num_samples=None)\n",
       "\n",
       "Construct the empirical quantiles from the estimated Distribution,\n",
       "sampling from it `num_samples` independently.\n",
       "\n",
       "**Parameters**<br>\n",
       "`distr_args`: Constructor arguments for the underlying Distribution type.<br>\n",
       "`loc`: Optional tensor, of the same shape as the batch_shape + event_shape\n",
       "       of the resulting distribution.<br>\n",
       "`scale`: Optional tensor, of the same shape as the batch_shape+event_shape \n",
       "       of the resulting distribution.<br>\n",
       "`num_samples`: int=500, overwrites number of samples for the empirical quantiles.<br>\n",
       "\n",
       "**Returns**<br>\n",
       "`samples`: tensor, shape [B,H,`num_samples`].<br>\n",
       "`quantiles`: tensor, empirical quantiles defined by `levels`.<br>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(PMM.sample, name='PMM.sample', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba75717c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1441){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PMM.__call__\n",
       "\n",
       ">      PMM.__call__ (y:torch.Tensor, distr_args:Tuple[torch.Tensor],\n",
       ">                    mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "Call self as a function."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1441){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PMM.__call__\n",
       "\n",
       ">      PMM.__call__ (y:torch.Tensor, distr_args:Tuple[torch.Tensor],\n",
       ">                    mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "Call self as a function."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(PMM.__call__, name='PMM.__call__', title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7518450",
   "metadata": {},
   "source": [
    "![](imgs_losses/pmm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4a20e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '-lo-98.0', '-lo-80.0', '-median', '-hi-80.0', '-hi-98.0']\n",
      "Parameter containing:\n",
      "tensor([0.0100, 0.1000, 0.5000, 0.9000, 0.9900])\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "# Unit tests to check PMM's stored quantiles\n",
    "# attribute is correctly instantiated\n",
    "check = PMM(n_components=2, level=[80, 90])\n",
    "test_eq(len(check.quantiles), 5)\n",
    "\n",
    "check = PMM(n_components=2, \n",
    "            quantiles=[0.0100, 0.1000, 0.5, 0.9000, 0.9900])\n",
    "print(check.output_names)\n",
    "print(check.quantiles)\n",
    "test_eq(len(check.quantiles), 5)\n",
    "\n",
    "check = PMM(n_components=2,\n",
    "            quantiles=[0.0100, 0.1000, 0.9000, 0.9900])\n",
    "test_eq(len(check.quantiles), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a56a2fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights.shape (N,H,K) \t torch.Size([2, 1, 3])\n",
      "lambdas.shape (N,H,K) \t torch.Size([2, 2, 3])\n",
      "samples.shape (N,H,num_samples)  torch.Size([2, 2, 1000])\n",
      "sample_mean.shape (N,H)  torch.Size([2, 2, 1])\n",
      "quants.shape  (N,H,Q) \t\t torch.Size([2, 2, 5])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 370x290 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 370x290 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "# Create single mixture and broadcast to N,H,K\n",
    "weights = torch.ones((1,3))[None, :, :]\n",
    "lambdas = torch.Tensor([[5,10,15], [10,20,30]])[None, :, :]\n",
    "\n",
    "# Create repetitions for the batch dimension N.\n",
    "N=2\n",
    "weights = torch.repeat_interleave(input=weights, repeats=N, dim=0)\n",
    "lambdas = torch.repeat_interleave(input=lambdas, repeats=N, dim=0)\n",
    "\n",
    "print('weights.shape (N,H,K) \\t', weights.shape)\n",
    "print('lambdas.shape (N,H,K) \\t', lambdas.shape)\n",
    "\n",
    "distr = PMM(quantiles=[0.1, 0.40, 0.5, 0.60, 0.9])\n",
    "distr_args = (lambdas,)\n",
    "samples, sample_mean, quants = distr.sample(distr_args)\n",
    "\n",
    "print('samples.shape (N,H,num_samples) ', samples.shape)\n",
    "print('sample_mean.shape (N,H) ', sample_mean.shape)\n",
    "print('quants.shape  (N,H,Q) \\t\\t', quants.shape)\n",
    "\n",
    "# Plot synthethic data\n",
    "x_plot = range(quants.shape[1]) # H length\n",
    "y_plot_hat = quants[0,:,:]  # Filter N,G,T -> H,Q\n",
    "samples_hat = samples[0,:,:]  # Filter N,G,T -> H,num_samples\n",
    "\n",
    "# Kernel density plot for single forecast horizon \\tau = t+1\n",
    "fig, ax = plt.subplots(figsize=(3.7, 2.9))\n",
    "\n",
    "ax.hist(samples_hat[0,:], alpha=0.5, label=r'Horizon $\\tau+1$')\n",
    "ax.hist(samples_hat[1,:], alpha=0.5, label=r'Horizon $\\tau+2$')\n",
    "ax.set(xlabel='Y values', ylabel='Probability')\n",
    "plt.title('Single horizon Distributions')\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot simulated trajectory\n",
    "fig, ax = plt.subplots(figsize=(3.7, 2.9))\n",
    "plt.plot(x_plot, y_plot_hat[:,2], color='black', label='median [q50]')\n",
    "plt.fill_between(x_plot,\n",
    "                 y1=y_plot_hat[:,1], y2=y_plot_hat[:,3],\n",
    "                 facecolor='blue', alpha=0.4, label='[p25-p75]')\n",
    "plt.fill_between(x_plot,\n",
    "                 y1=y_plot_hat[:,0], y2=y_plot_hat[:,4],\n",
    "                 facecolor='blue', alpha=0.2, label='[p1-p99]')\n",
    "ax.set(xlabel='Horizon', ylabel='Y values')\n",
    "plt.title('PMM Probabilistic Predictions')\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84e0dd4",
   "metadata": {},
   "source": [
    "## Gaussian Mixture Mesh (GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6928b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GMM(torch.nn.Module):\n",
    "    \"\"\" Gaussian Mixture Mesh\n",
    "\n",
    "    This Gaussian Mixture statistical model assumes independence across groups of \n",
    "    data $\\mathcal{G}=\\{[g_{i}]\\}$, and estimates relationships within the group.\n",
    "\n",
    "    $$ \\mathrm{P}\\\\left(\\mathbf{y}_{[b][t+1:t+H]}\\\\right) = \n",
    "    \\prod_{ [g_{i}] \\in \\mathcal{G}} \\mathrm{P}\\left(\\mathbf{y}_{[g_{i}][\\\\tau]}\\\\right)=\n",
    "    \\prod_{\\\\beta\\in[g_{i}]}\n",
    "    \\\\left(\\sum_{k=1}^{K} w_k \\prod_{(\\\\beta,\\\\tau) \\in [g_i][t+1:t+H]} \n",
    "    \\mathrm{Gaussian}(y_{\\\\beta,\\\\tau}, \\hat{\\mu}_{\\\\beta,\\\\tau,k}, \\sigma_{\\\\beta,\\\\tau,k})\\\\right)$$\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `n_components`: int=10, the number of mixture components.<br>\n",
    "    `level`: float list [0,100], confidence levels for prediction intervals.<br>\n",
    "    `quantiles`: float list [0,1], alternative to level list, target quantiles.<br>\n",
    "    `return_params`: bool=False, wether or not return the Distribution parameters.<br>\n",
    "    `batch_correlation`: bool=False, wether or not model batch correlations.<br>\n",
    "    `horizon_correlation`: bool=False, wether or not model horizon correlations.<br><br>\n",
    "\n",
    "    **References:**<br>\n",
    "    [Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker. \n",
    "    Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures. Submitted to the International \n",
    "    Journal Forecasting, Working paper available at arxiv.](https://arxiv.org/pdf/2110.13179.pdf)\n",
    "    \"\"\"\n",
    "    def __init__(self, n_components=1, level=[80, 90], quantiles=None, \n",
    "                 num_samples=1000, return_params=False,\n",
    "                 batch_correlation=False, horizon_correlation=False):\n",
    "        super(GMM, self).__init__()\n",
    "        # Transform level to MQLoss parameters\n",
    "        qs, self.output_names = level_to_outputs(level)\n",
    "        qs = torch.Tensor(qs)\n",
    "\n",
    "        # Transform quantiles to homogeneus output names\n",
    "        if quantiles is not None:\n",
    "            _, self.output_names = quantiles_to_outputs(quantiles)\n",
    "            qs = torch.Tensor(quantiles)\n",
    "        self.quantiles = torch.nn.Parameter(qs, requires_grad=False)\n",
    "        self.num_samples = num_samples\n",
    "        self.batch_correlation = batch_correlation\n",
    "        self.horizon_correlation = horizon_correlation        \n",
    "\n",
    "        # If True, predict_step will return Distribution's parameters\n",
    "        self.return_params = return_params\n",
    "        if self.return_params:\n",
    "            mu_names = [f\"-mu-{i}\" for i in range(1, n_components + 1)]\n",
    "            std_names = [f\"-std-{i}\" for i in range(1, n_components + 1)]\n",
    "            mu_std_names = [i for j in zip(mu_names, std_names) for i in j]\n",
    "            self.output_names = self.output_names + mu_std_names\n",
    "\n",
    "        # Add first output entry for the sample_mean\n",
    "        self.output_names.insert(0, \"\")\n",
    "\n",
    "        self.outputsize_multiplier = 2 * n_components\n",
    "        self.is_distribution_output = True\n",
    "\n",
    "    def domain_map(self, output: torch.Tensor):\n",
    "        means, stds = torch.tensor_split(output, 2, dim=-1)\n",
    "        return (means, stds)\n",
    "\n",
    "    def scale_decouple(self, \n",
    "                       output,\n",
    "                       loc: Optional[torch.Tensor] = None,\n",
    "                       scale: Optional[torch.Tensor] = None,\n",
    "                       eps: float=0.2):\n",
    "        \"\"\" Scale Decouple\n",
    "\n",
    "        Stabilizes model's output optimization, by learning residual\n",
    "        variance and residual location based on anchoring `loc`, `scale`.\n",
    "        Also adds domain protection to the distribution parameters.\n",
    "        \"\"\"\n",
    "        means, stds = output\n",
    "        stds = F.softplus(stds)\n",
    "        if (loc is not None) and (scale is not None):\n",
    "            loc = loc.view(means.size(dim=0), 1, -1)\n",
    "            scale = scale.view(means.size(dim=0), 1, -1)            \n",
    "            means = (means * scale) + loc\n",
    "            stds = (stds + eps) * scale\n",
    "        return (means, stds)\n",
    "\n",
    "    def sample(self, distr_args, num_samples=None):\n",
    "        \"\"\"\n",
    "        Construct the empirical quantiles from the estimated Distribution,\n",
    "        sampling from it `num_samples` independently.\n",
    "\n",
    "        **Parameters**<br>\n",
    "        `distr_args`: Constructor arguments for the underlying Distribution type.<br>\n",
    "        `loc`: Optional tensor, of the same shape as the batch_shape + event_shape\n",
    "               of the resulting distribution.<br>\n",
    "        `scale`: Optional tensor, of the same shape as the batch_shape+event_shape \n",
    "               of the resulting distribution.<br>\n",
    "        `num_samples`: int=500, number of samples for the empirical quantiles.<br>\n",
    "\n",
    "        **Returns**<br>\n",
    "        `samples`: tensor, shape [B,H,`num_samples`].<br>\n",
    "        `quantiles`: tensor, empirical quantiles defined by `levels`.<br>\n",
    "        \"\"\"\n",
    "        if num_samples is None:\n",
    "            num_samples = self.num_samples\n",
    "            \n",
    "        means, stds = distr_args\n",
    "        B, H, K = means.size()\n",
    "        Q = len(self.quantiles)\n",
    "        assert means.shape == stds.shape\n",
    "\n",
    "        # Sample K ~ Mult(weights)\n",
    "        # shared across B, H\n",
    "        # weights = torch.repeat_interleave(input=weights, repeats=H, dim=2)\n",
    "        \n",
    "        weights = (1/K) * torch.ones_like(means).to(means.device)\n",
    "        \n",
    "        # Avoid loop, vectorize\n",
    "        weights = weights.reshape(-1, K)\n",
    "        means = means.flatten()\n",
    "        stds = stds.flatten()\n",
    "\n",
    "        # Vectorization trick to recover row_idx\n",
    "        sample_idxs = torch.multinomial(input=weights, \n",
    "                                        num_samples=num_samples,\n",
    "                                        replacement=True)\n",
    "        aux_col_idx = torch.unsqueeze(torch.arange(B*H),-1) * K\n",
    "\n",
    "        # To device\n",
    "        sample_idxs = sample_idxs.to(means.device)\n",
    "        aux_col_idx = aux_col_idx.to(means.device)\n",
    "\n",
    "        sample_idxs = sample_idxs + aux_col_idx\n",
    "        sample_idxs = sample_idxs.flatten()\n",
    "\n",
    "        sample_means = means[sample_idxs]\n",
    "        sample_stds  = stds[sample_idxs]\n",
    "\n",
    "        # Sample y ~ Normal(mu, std) independently\n",
    "        samples = torch.normal(sample_means, sample_stds).to(means.device)\n",
    "        samples = samples.view(B*H, num_samples)\n",
    "        sample_mean = torch.mean(samples, dim=-1)\n",
    "\n",
    "        # Compute quantiles\n",
    "        quantiles_device = self.quantiles.to(means.device)\n",
    "        quants = torch.quantile(input=samples, q=quantiles_device, dim=1)\n",
    "        quants = quants.permute((1,0)) # Q, B*H\n",
    "\n",
    "        # Final reshapes\n",
    "        samples = samples.view(B, H, num_samples)\n",
    "        sample_mean = sample_mean.view(B, H, 1)\n",
    "        quants  = quants.view(B, H, Q)\n",
    "\n",
    "        return samples, sample_mean, quants\n",
    "\n",
    "    def neglog_likelihood(self,\n",
    "                          y: torch.Tensor,\n",
    "                          distr_args: Tuple[torch.Tensor, torch.Tensor],\n",
    "                          mask: Union[torch.Tensor, None] = None):\n",
    "\n",
    "        if mask is None: \n",
    "            mask = torch.ones_like(y)\n",
    "            \n",
    "        means, stds = distr_args\n",
    "        B, H, K = means.size()\n",
    "        \n",
    "        weights = (1/K) * torch.ones_like(means).to(means.device)\n",
    "        \n",
    "        y = y[:,:, None]\n",
    "        mask = mask[:,:,None]\n",
    "        \n",
    "        var = stds ** 2\n",
    "        log_stds = torch.log(stds)\n",
    "        log_pi = - ((y - means) ** 2 / (2 * var)) - log_stds \\\n",
    "                 - math.log(math.sqrt(2 * math.pi))\n",
    "\n",
    "        if self.batch_correlation:\n",
    "            log_pi  = torch.sum(log_pi, dim=0, keepdim=True)\n",
    "\n",
    "        if self.horizon_correlation:    \n",
    "            log_pi  = torch.sum(log_pi, dim=1, keepdim=True)\n",
    "\n",
    "        # Numerically Stable Mixture loglikelihood\n",
    "        loglik = torch.logsumexp((torch.log(weights) + log_pi), dim=2, keepdim=True)\n",
    "        loglik  = loglik * mask\n",
    "\n",
    "        loss = -torch.mean(loglik)\n",
    "        return loss\n",
    "    \n",
    "    def __call__(self, y: torch.Tensor,\n",
    "                 distr_args: Tuple[torch.Tensor, torch.Tensor],\n",
    "                 mask: Union[torch.Tensor, None] = None,):\n",
    "\n",
    "        return self.neglog_likelihood(y=y, distr_args=distr_args, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec4ebf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1450){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GMM.__init__\n",
       "\n",
       ">      GMM.__init__ (n_components=1, level=[80, 90], quantiles=None,\n",
       ">                    num_samples=1000, return_params=False,\n",
       ">                    batch_correlation=False, horizon_correlation=False)\n",
       "\n",
       "Gaussian Mixture Mesh\n",
       "\n",
       "This Gaussian Mixture statistical model assumes independence across groups of \n",
       "data $\\mathcal{G}=\\{[g_{i}]\\}$, and estimates relationships within the group.\n",
       "\n",
       "$$ \\mathrm{P}\\left(\\mathbf{y}_{[b][t+1:t+H]}\\right) = \n",
       "\\prod_{ [g_{i}] \\in \\mathcal{G}} \\mathrm{P}\\left(\\mathbf{y}_{[g_{i}][\\tau]}\\right)=\n",
       "\\prod_{\\beta\\in[g_{i}]}\n",
       "\\left(\\sum_{k=1}^{K} w_k \\prod_{(\\beta,\\tau) \\in [g_i][t+1:t+H]} \n",
       "\\mathrm{Gaussian}(y_{\\beta,\\tau}, \\hat{\\mu}_{\\beta,\\tau,k}, \\sigma_{\\beta,\\tau,k})\\right)$$\n",
       "\n",
       "**Parameters:**<br>\n",
       "`n_components`: int=10, the number of mixture components.<br>\n",
       "`level`: float list [0,100], confidence levels for prediction intervals.<br>\n",
       "`quantiles`: float list [0,1], alternative to level list, target quantiles.<br>\n",
       "`return_params`: bool=False, wether or not return the Distribution parameters.<br>\n",
       "`batch_correlation`: bool=False, wether or not model batch correlations.<br>\n",
       "`horizon_correlation`: bool=False, wether or not model horizon correlations.<br><br>\n",
       "\n",
       "**References:**<br>\n",
       "[Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker. \n",
       "Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures. Submitted to the International \n",
       "Journal Forecasting, Working paper available at arxiv.](https://arxiv.org/pdf/2110.13179.pdf)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1450){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GMM.__init__\n",
       "\n",
       ">      GMM.__init__ (n_components=1, level=[80, 90], quantiles=None,\n",
       ">                    num_samples=1000, return_params=False,\n",
       ">                    batch_correlation=False, horizon_correlation=False)\n",
       "\n",
       "Gaussian Mixture Mesh\n",
       "\n",
       "This Gaussian Mixture statistical model assumes independence across groups of \n",
       "data $\\mathcal{G}=\\{[g_{i}]\\}$, and estimates relationships within the group.\n",
       "\n",
       "$$ \\mathrm{P}\\left(\\mathbf{y}_{[b][t+1:t+H]}\\right) = \n",
       "\\prod_{ [g_{i}] \\in \\mathcal{G}} \\mathrm{P}\\left(\\mathbf{y}_{[g_{i}][\\tau]}\\right)=\n",
       "\\prod_{\\beta\\in[g_{i}]}\n",
       "\\left(\\sum_{k=1}^{K} w_k \\prod_{(\\beta,\\tau) \\in [g_i][t+1:t+H]} \n",
       "\\mathrm{Gaussian}(y_{\\beta,\\tau}, \\hat{\\mu}_{\\beta,\\tau,k}, \\sigma_{\\beta,\\tau,k})\\right)$$\n",
       "\n",
       "**Parameters:**<br>\n",
       "`n_components`: int=10, the number of mixture components.<br>\n",
       "`level`: float list [0,100], confidence levels for prediction intervals.<br>\n",
       "`quantiles`: float list [0,1], alternative to level list, target quantiles.<br>\n",
       "`return_params`: bool=False, wether or not return the Distribution parameters.<br>\n",
       "`batch_correlation`: bool=False, wether or not model batch correlations.<br>\n",
       "`horizon_correlation`: bool=False, wether or not model horizon correlations.<br><br>\n",
       "\n",
       "**References:**<br>\n",
       "[Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker. \n",
       "Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures. Submitted to the International \n",
       "Journal Forecasting, Working paper available at arxiv.](https://arxiv.org/pdf/2110.13179.pdf)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(GMM, name='GMM.__init__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bea56d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1537){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GMM.sample\n",
       "\n",
       ">      GMM.sample (distr_args, num_samples=None)\n",
       "\n",
       "Construct the empirical quantiles from the estimated Distribution,\n",
       "sampling from it `num_samples` independently.\n",
       "\n",
       "**Parameters**<br>\n",
       "`distr_args`: Constructor arguments for the underlying Distribution type.<br>\n",
       "`loc`: Optional tensor, of the same shape as the batch_shape + event_shape\n",
       "       of the resulting distribution.<br>\n",
       "`scale`: Optional tensor, of the same shape as the batch_shape+event_shape \n",
       "       of the resulting distribution.<br>\n",
       "`num_samples`: int=500, number of samples for the empirical quantiles.<br>\n",
       "\n",
       "**Returns**<br>\n",
       "`samples`: tensor, shape [B,H,`num_samples`].<br>\n",
       "`quantiles`: tensor, empirical quantiles defined by `levels`.<br>"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1537){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GMM.sample\n",
       "\n",
       ">      GMM.sample (distr_args, num_samples=None)\n",
       "\n",
       "Construct the empirical quantiles from the estimated Distribution,\n",
       "sampling from it `num_samples` independently.\n",
       "\n",
       "**Parameters**<br>\n",
       "`distr_args`: Constructor arguments for the underlying Distribution type.<br>\n",
       "`loc`: Optional tensor, of the same shape as the batch_shape + event_shape\n",
       "       of the resulting distribution.<br>\n",
       "`scale`: Optional tensor, of the same shape as the batch_shape+event_shape \n",
       "       of the resulting distribution.<br>\n",
       "`num_samples`: int=500, number of samples for the empirical quantiles.<br>\n",
       "\n",
       "**Returns**<br>\n",
       "`samples`: tensor, shape [B,H,`num_samples`].<br>\n",
       "`quantiles`: tensor, empirical quantiles defined by `levels`.<br>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(GMM.sample, name='GMM.sample', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f16e4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1642){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GMM.__call__\n",
       "\n",
       ">      GMM.__call__ (y:torch.Tensor,\n",
       ">                    distr_args:Tuple[torch.Tensor,torch.Tensor],\n",
       ">                    mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "Call self as a function."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1642){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### GMM.__call__\n",
       "\n",
       ">      GMM.__call__ (y:torch.Tensor,\n",
       ">                    distr_args:Tuple[torch.Tensor,torch.Tensor],\n",
       ">                    mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "Call self as a function."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(GMM.__call__, name='GMM.__call__', title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed232a4",
   "metadata": {},
   "source": [
    "![](imgs_losses/gmm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8ebe4250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '-lo-98.0', '-lo-80.0', '-median', '-hi-80.0', '-hi-98.0']\n",
      "Parameter containing:\n",
      "tensor([0.0100, 0.1000, 0.5000, 0.9000, 0.9900])\n"
     ]
    }
   ],
   "source": [
    "# | hide\n",
    "# Unit tests to check PMM's stored quantiles\n",
    "# attribute is correctly instantiated\n",
    "check = GMM(n_components=2, level=[80, 90])\n",
    "test_eq(len(check.quantiles), 5)\n",
    "\n",
    "check = GMM(n_components=2, \n",
    "            quantiles=[0.0100, 0.1000, 0.5, 0.9000, 0.9900])\n",
    "print(check.output_names)\n",
    "print(check.quantiles)\n",
    "test_eq(len(check.quantiles), 5)\n",
    "\n",
    "check = GMM(n_components=2,\n",
    "            quantiles=[0.0100, 0.1000, 0.9000, 0.9900])\n",
    "test_eq(len(check.quantiles), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "684d2382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights.shape (N,H,K) \t torch.Size([2, 2, 3])\n",
      "means.shape (N,H,K) \t torch.Size([2, 2, 3])\n",
      "stds.shape (N,H,K) \t torch.Size([2, 2, 3])\n",
      "samples.shape (N,H,num_samples)  torch.Size([2, 2, 1000])\n",
      "sample_mean.shape (N,H)  torch.Size([2, 2, 1])\n",
      "quants.shape  (N,H,Q) \t\t torch.Size([2, 2, 5])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 370x290 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 370x290 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "# Create single mixture and broadcast to N,H,K\n",
    "means   = torch.Tensor([[5,10,15], [10,20,30]])[None, :, :]\n",
    "\n",
    "# # Create repetitions for the batch dimension N.\n",
    "N=2\n",
    "means = torch.repeat_interleave(input=means, repeats=N, dim=0)\n",
    "weights = torch.ones_like(means)\n",
    "stds  = torch.ones_like(means)\n",
    "\n",
    "print('weights.shape (N,H,K) \\t', weights.shape)\n",
    "print('means.shape (N,H,K) \\t', means.shape)\n",
    "print('stds.shape (N,H,K) \\t', stds.shape)\n",
    "\n",
    "distr = GMM(quantiles=[0.1, 0.40, 0.5, 0.60, 0.9])\n",
    "distr_args = (means, stds)\n",
    "samples, sample_mean, quants = distr.sample(distr_args)\n",
    "\n",
    "print('samples.shape (N,H,num_samples) ', samples.shape)\n",
    "print('sample_mean.shape (N,H) ', sample_mean.shape)\n",
    "print('quants.shape  (N,H,Q) \\t\\t', quants.shape)\n",
    "\n",
    "# Plot synthethic data\n",
    "x_plot = range(quants.shape[1]) # H length\n",
    "y_plot_hat = quants[0,:,:]  # Filter N,G,T -> H,Q\n",
    "samples_hat = samples[0,:,:]  # Filter N,G,T -> H,num_samples\n",
    "\n",
    "# Kernel density plot for single forecast horizon \\tau = t+1\n",
    "fig, ax = plt.subplots(figsize=(3.7, 2.9))\n",
    "\n",
    "ax.hist(samples_hat[0,:], alpha=0.5, bins=50,\n",
    "        label=r'Horizon $\\tau+1$')\n",
    "ax.hist(samples_hat[1,:], alpha=0.5, bins=50,\n",
    "        label=r'Horizon $\\tau+2$')\n",
    "ax.set(xlabel='Y values', ylabel='Probability')\n",
    "plt.title('Single horizon Distributions')\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot simulated trajectory\n",
    "fig, ax = plt.subplots(figsize=(3.7, 2.9))\n",
    "plt.plot(x_plot, y_plot_hat[:,2], color='black', label='median [q50]')\n",
    "plt.fill_between(x_plot,\n",
    "                 y1=y_plot_hat[:,1], y2=y_plot_hat[:,3],\n",
    "                 facecolor='blue', alpha=0.4, label='[p25-p75]')\n",
    "plt.fill_between(x_plot,\n",
    "                 y1=y_plot_hat[:,0], y2=y_plot_hat[:,4],\n",
    "                 facecolor='blue', alpha=0.2, label='[p1-p99]')\n",
    "ax.set(xlabel='Horizon', ylabel='Y values')\n",
    "plt.title('GMM Probabilistic Predictions')\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694a2afe",
   "metadata": {},
   "source": [
    "## Negative Binomial Mixture Mesh (NBMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9cdbe5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NBMM(torch.nn.Module):\n",
    "    \"\"\" Negative Binomial Mixture Mesh\n",
    "\n",
    "    This N. Binomial Mixture statistical model assumes independence across groups of \n",
    "    data $\\mathcal{G}=\\{[g_{i}]\\}$, and estimates relationships within the group.\n",
    "\n",
    "    $$ \\mathrm{P}\\\\left(\\mathbf{y}_{[b][t+1:t+H]}\\\\right) = \n",
    "    \\prod_{ [g_{i}] \\in \\mathcal{G}} \\mathrm{P}\\left(\\mathbf{y}_{[g_{i}][\\\\tau]}\\\\right)=\n",
    "    \\prod_{\\\\beta\\in[g_{i}]}\n",
    "    \\\\left(\\sum_{k=1}^{K} w_k \\prod_{(\\\\beta,\\\\tau) \\in [g_i][t+1:t+H]} \n",
    "    \\mathrm{NBinomial}(y_{\\\\beta,\\\\tau}, \\hat{r}_{\\\\beta,\\\\tau,k}, \\hat{p}_{\\\\beta,\\\\tau,k})\\\\right)$$\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `n_components`: int=10, the number of mixture components.<br>\n",
    "    `level`: float list [0,100], confidence levels for prediction intervals.<br>\n",
    "    `quantiles`: float list [0,1], alternative to level list, target quantiles.<br>\n",
    "    `return_params`: bool=False, wether or not return the Distribution parameters.<br><br>\n",
    "\n",
    "    **References:**<br>\n",
    "    [Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker. \n",
    "    Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures. Submitted to the International \n",
    "    Journal Forecasting, Working paper available at arxiv.](https://arxiv.org/pdf/2110.13179.pdf)\n",
    "    \"\"\"\n",
    "    def __init__(self, n_components=1, level=[80, 90], quantiles=None, \n",
    "                 num_samples=1000, return_params=False):\n",
    "        super(NBMM, self).__init__()\n",
    "        # Transform level to MQLoss parameters\n",
    "        qs, self.output_names = level_to_outputs(level)\n",
    "        qs = torch.Tensor(qs)\n",
    "\n",
    "        # Transform quantiles to homogeneus output names\n",
    "        if quantiles is not None:\n",
    "            _, self.output_names = quantiles_to_outputs(quantiles)\n",
    "            qs = torch.Tensor(quantiles)\n",
    "        self.quantiles = torch.nn.Parameter(qs, requires_grad=False)\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "        # If True, predict_step will return Distribution's parameters\n",
    "        self.return_params = return_params\n",
    "        if self.return_params:\n",
    "            total_count_names = [f\"-total_count-{i}\" for i in range(1, n_components + 1)]\n",
    "            probs_names = [f\"-probs-{i}\" for i in range(1, n_components + 1)]\n",
    "            param_names = [i for j in zip(total_count_names, probs_names) for i in j]\n",
    "            self.output_names = self.output_names + param_names\n",
    "\n",
    "        # Add first output entry for the sample_mean\n",
    "        self.output_names.insert(0, \"\")            \n",
    "\n",
    "        self.outputsize_multiplier = 2 * n_components\n",
    "        self.is_distribution_output = True\n",
    "\n",
    "    def domain_map(self, output: torch.Tensor):\n",
    "        mu, alpha = torch.tensor_split(output, 2, dim=-1)\n",
    "        return (mu, alpha)\n",
    "\n",
    "    def scale_decouple(self, \n",
    "                       output,\n",
    "                       loc: Optional[torch.Tensor] = None,\n",
    "                       scale: Optional[torch.Tensor] = None,\n",
    "                       eps: float=0.2):\n",
    "        \"\"\" Scale Decouple\n",
    "\n",
    "        Stabilizes model's output optimization, by learning residual\n",
    "        variance and residual location based on anchoring `loc`, `scale`.\n",
    "        Also adds domain protection to the distribution parameters.\n",
    "        \"\"\"\n",
    "        # Efficient NBinomial parametrization\n",
    "        mu, alpha = output\n",
    "        mu = F.softplus(mu) + 1e-8\n",
    "        alpha = F.softplus(alpha) + 1e-8    # alpha = 1/total_counts\n",
    "        if (loc is not None) and (scale is not None):\n",
    "            loc = loc.view(mu.size(dim=0), 1, -1)\n",
    "            mu *= loc\n",
    "            alpha /= (loc + 1.)\n",
    "\n",
    "        # mu = total_count * (probs/(1-probs))\n",
    "        # => probs = mu / (total_count + mu)\n",
    "        # => probs = mu / [total_count * (1 + mu * (1/total_count))]\n",
    "        total_count = 1.0 / alpha\n",
    "        probs = (mu * alpha / (1.0 + mu * alpha)) + 1e-8 \n",
    "        return (total_count, probs)\n",
    "\n",
    "    def sample(self, distr_args, num_samples=None):\n",
    "        \"\"\"\n",
    "        Construct the empirical quantiles from the estimated Distribution,\n",
    "        sampling from it `num_samples` independently.\n",
    "\n",
    "        **Parameters**<br>\n",
    "        `distr_args`: Constructor arguments for the underlying Distribution type.<br>\n",
    "        `loc`: Optional tensor, of the same shape as the batch_shape + event_shape\n",
    "               of the resulting distribution.<br>\n",
    "        `scale`: Optional tensor, of the same shape as the batch_shape+event_shape \n",
    "               of the resulting distribution.<br>\n",
    "        `num_samples`: int=500, number of samples for the empirical quantiles.<br>\n",
    "\n",
    "        **Returns**<br>\n",
    "        `samples`: tensor, shape [B,H,`num_samples`].<br>\n",
    "        `quantiles`: tensor, empirical quantiles defined by `levels`.<br>\n",
    "        \"\"\"\n",
    "        if num_samples is None:\n",
    "            num_samples = self.num_samples\n",
    "            \n",
    "        total_count, probs = distr_args\n",
    "        B, H, K = total_count.size()\n",
    "        Q = len(self.quantiles)\n",
    "        assert total_count.shape == probs.shape\n",
    "\n",
    "        # Sample K ~ Mult(weights)\n",
    "        # shared across B, H\n",
    "        # weights = torch.repeat_interleave(input=weights, repeats=H, dim=2)\n",
    "        \n",
    "        weights = (1/K) * torch.ones_like(probs).to(probs.device)\n",
    "        \n",
    "        # Avoid loop, vectorize\n",
    "        weights = weights.reshape(-1, K)\n",
    "        total_count = total_count.flatten()\n",
    "        probs = probs.flatten()\n",
    "\n",
    "        # Vectorization trick to recover row_idx\n",
    "        sample_idxs = torch.multinomial(input=weights, \n",
    "                                        num_samples=num_samples,\n",
    "                                        replacement=True)\n",
    "        aux_col_idx = torch.unsqueeze(torch.arange(B*H),-1) * K\n",
    "\n",
    "        # To device\n",
    "        sample_idxs = sample_idxs.to(probs.device)\n",
    "        aux_col_idx = aux_col_idx.to(probs.device)\n",
    "\n",
    "        sample_idxs = sample_idxs + aux_col_idx\n",
    "        sample_idxs = sample_idxs.flatten()\n",
    "\n",
    "        sample_total_count = total_count[sample_idxs]\n",
    "        sample_probs  = probs[sample_idxs]\n",
    "\n",
    "        # Sample y ~ NBinomial(total_count, probs) independently\n",
    "        dist = NegativeBinomial(total_count=sample_total_count, \n",
    "                                probs=sample_probs)\n",
    "        samples = dist.sample(sample_shape=(1,)).to(probs.device)[0]\n",
    "        samples = samples.view(B*H, num_samples)\n",
    "        sample_mean = torch.mean(samples, dim=-1)\n",
    "\n",
    "        # Compute quantiles\n",
    "        quantiles_device = self.quantiles.to(probs.device)\n",
    "        quants = torch.quantile(input=samples, q=quantiles_device, dim=1)\n",
    "        quants = quants.permute((1,0)) # Q, B*H\n",
    "\n",
    "        # Final reshapes\n",
    "        samples = samples.view(B, H, num_samples)\n",
    "        sample_mean = sample_mean.view(B, H, 1)\n",
    "        quants  = quants.view(B, H, Q)\n",
    "\n",
    "        return samples, sample_mean, quants\n",
    "\n",
    "    def neglog_likelihood(self,\n",
    "                          y: torch.Tensor,\n",
    "                          distr_args: Tuple[torch.Tensor, torch.Tensor],\n",
    "                          mask: Union[torch.Tensor, None] = None):\n",
    "\n",
    "        if mask is None: \n",
    "            mask = torch.ones_like(y)\n",
    "            \n",
    "        total_count, probs = distr_args\n",
    "        B, H, K = total_count.size()\n",
    "        \n",
    "        weights = (1/K) * torch.ones_like(probs).to(probs.device)\n",
    "        \n",
    "        y = y[:,:, None]\n",
    "        mask = mask[:,:,None]\n",
    "\n",
    "        log_unnormalized_prob = (total_count * torch.log(1.-probs) + y * torch.log(probs))\n",
    "        log_normalization = (-torch.lgamma(total_count + y) + torch.lgamma(1. + y) +\n",
    "                             torch.lgamma(total_count))\n",
    "        log_normalization[total_count + y == 0.] = 0.\n",
    "        log =  log_unnormalized_prob - log_normalization\n",
    "\n",
    "        #log  = torch.sum(log, dim=0, keepdim=True) # Joint within batch/group\n",
    "        #log  = torch.sum(log, dim=1, keepdim=True) # Joint within horizon\n",
    "\n",
    "        # Numerical stability mixture and loglik\n",
    "        log_max = torch.amax(log, dim=2, keepdim=True) # [1,1,K] (collapsed joints)\n",
    "        lik     = weights * torch.exp(log-log_max)     # Take max\n",
    "        loglik  = torch.log(torch.sum(lik, dim=2, keepdim=True)) + log_max # Return max\n",
    "        \n",
    "        loglik  = loglik * mask #replace with mask\n",
    "\n",
    "        loss = -torch.mean(loglik)\n",
    "        return loss\n",
    "    \n",
    "    def __call__(self, y: torch.Tensor,\n",
    "                 distr_args: Tuple[torch.Tensor, torch.Tensor],\n",
    "                 mask: Union[torch.Tensor, None] = None,):\n",
    "\n",
    "        return self.neglog_likelihood(y=y, distr_args=distr_args, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eed5e73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1651){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NBMM.__init__\n",
       "\n",
       ">      NBMM.__init__ (n_components=1, level=[80, 90], quantiles=None,\n",
       ">                     num_samples=1000, return_params=False)\n",
       "\n",
       "Negative Binomial Mixture Mesh\n",
       "\n",
       "This N. Binomial Mixture statistical model assumes independence across groups of \n",
       "data $\\mathcal{G}=\\{[g_{i}]\\}$, and estimates relationships within the group.\n",
       "\n",
       "$$ \\mathrm{P}\\left(\\mathbf{y}_{[b][t+1:t+H]}\\right) = \n",
       "\\prod_{ [g_{i}] \\in \\mathcal{G}} \\mathrm{P}\\left(\\mathbf{y}_{[g_{i}][\\tau]}\\right)=\n",
       "\\prod_{\\beta\\in[g_{i}]}\n",
       "\\left(\\sum_{k=1}^{K} w_k \\prod_{(\\beta,\\tau) \\in [g_i][t+1:t+H]} \n",
       "\\mathrm{NBinomial}(y_{\\beta,\\tau}, \\hat{r}_{\\beta,\\tau,k}, \\hat{p}_{\\beta,\\tau,k})\\right)$$\n",
       "\n",
       "**Parameters:**<br>\n",
       "`n_components`: int=10, the number of mixture components.<br>\n",
       "`level`: float list [0,100], confidence levels for prediction intervals.<br>\n",
       "`quantiles`: float list [0,1], alternative to level list, target quantiles.<br>\n",
       "`return_params`: bool=False, wether or not return the Distribution parameters.<br><br>\n",
       "\n",
       "**References:**<br>\n",
       "[Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker. \n",
       "Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures. Submitted to the International \n",
       "Journal Forecasting, Working paper available at arxiv.](https://arxiv.org/pdf/2110.13179.pdf)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1651){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NBMM.__init__\n",
       "\n",
       ">      NBMM.__init__ (n_components=1, level=[80, 90], quantiles=None,\n",
       ">                     num_samples=1000, return_params=False)\n",
       "\n",
       "Negative Binomial Mixture Mesh\n",
       "\n",
       "This N. Binomial Mixture statistical model assumes independence across groups of \n",
       "data $\\mathcal{G}=\\{[g_{i}]\\}$, and estimates relationships within the group.\n",
       "\n",
       "$$ \\mathrm{P}\\left(\\mathbf{y}_{[b][t+1:t+H]}\\right) = \n",
       "\\prod_{ [g_{i}] \\in \\mathcal{G}} \\mathrm{P}\\left(\\mathbf{y}_{[g_{i}][\\tau]}\\right)=\n",
       "\\prod_{\\beta\\in[g_{i}]}\n",
       "\\left(\\sum_{k=1}^{K} w_k \\prod_{(\\beta,\\tau) \\in [g_i][t+1:t+H]} \n",
       "\\mathrm{NBinomial}(y_{\\beta,\\tau}, \\hat{r}_{\\beta,\\tau,k}, \\hat{p}_{\\beta,\\tau,k})\\right)$$\n",
       "\n",
       "**Parameters:**<br>\n",
       "`n_components`: int=10, the number of mixture components.<br>\n",
       "`level`: float list [0,100], confidence levels for prediction intervals.<br>\n",
       "`quantiles`: float list [0,1], alternative to level list, target quantiles.<br>\n",
       "`return_params`: bool=False, wether or not return the Distribution parameters.<br><br>\n",
       "\n",
       "**References:**<br>\n",
       "[Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker. \n",
       "Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures. Submitted to the International \n",
       "Journal Forecasting, Working paper available at arxiv.](https://arxiv.org/pdf/2110.13179.pdf)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NBMM, name='NBMM.__init__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41ea98ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1741){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NBMM.sample\n",
       "\n",
       ">      NBMM.sample (distr_args, num_samples=None)\n",
       "\n",
       "Construct the empirical quantiles from the estimated Distribution,\n",
       "sampling from it `num_samples` independently.\n",
       "\n",
       "**Parameters**<br>\n",
       "`distr_args`: Constructor arguments for the underlying Distribution type.<br>\n",
       "`loc`: Optional tensor, of the same shape as the batch_shape + event_shape\n",
       "       of the resulting distribution.<br>\n",
       "`scale`: Optional tensor, of the same shape as the batch_shape+event_shape \n",
       "       of the resulting distribution.<br>\n",
       "`num_samples`: int=500, number of samples for the empirical quantiles.<br>\n",
       "\n",
       "**Returns**<br>\n",
       "`samples`: tensor, shape [B,H,`num_samples`].<br>\n",
       "`quantiles`: tensor, empirical quantiles defined by `levels`.<br>"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1741){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NBMM.sample\n",
       "\n",
       ">      NBMM.sample (distr_args, num_samples=None)\n",
       "\n",
       "Construct the empirical quantiles from the estimated Distribution,\n",
       "sampling from it `num_samples` independently.\n",
       "\n",
       "**Parameters**<br>\n",
       "`distr_args`: Constructor arguments for the underlying Distribution type.<br>\n",
       "`loc`: Optional tensor, of the same shape as the batch_shape + event_shape\n",
       "       of the resulting distribution.<br>\n",
       "`scale`: Optional tensor, of the same shape as the batch_shape+event_shape \n",
       "       of the resulting distribution.<br>\n",
       "`num_samples`: int=500, number of samples for the empirical quantiles.<br>\n",
       "\n",
       "**Returns**<br>\n",
       "`samples`: tensor, shape [B,H,`num_samples`].<br>\n",
       "`quantiles`: tensor, empirical quantiles defined by `levels`.<br>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NBMM.sample, name='NBMM.sample', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c7189c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1850){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NBMM.__call__\n",
       "\n",
       ">      NBMM.__call__ (y:torch.Tensor,\n",
       ">                     distr_args:Tuple[torch.Tensor,torch.Tensor],\n",
       ">                     mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "Call self as a function."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/losses/pytorch.py#L1850){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NBMM.__call__\n",
       "\n",
       ">      NBMM.__call__ (y:torch.Tensor,\n",
       ">                     distr_args:Tuple[torch.Tensor,torch.Tensor],\n",
       ">                     mask:Union[torch.Tensor,NoneType]=None)\n",
       "\n",
       "Call self as a function."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NBMM.__call__, name='NBMM.__call__', title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b67e2931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights.shape (N,H,K) \t torch.Size([2, 2, 3])\n",
      "counts.shape (N,H,K) \t torch.Size([2, 2, 3])\n",
      "probs.shape (N,H,K) \t torch.Size([2, 2, 3])\n",
      "samples.shape (N,H,num_samples)  torch.Size([2, 2, 2000])\n",
      "sample_mean.shape (N,H)  torch.Size([2, 2, 1])\n",
      "quants.shape  (N,H,Q) \t\t torch.Size([2, 2, 5])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 370x290 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 370x290 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| hide\n",
    "# Create single mixture and broadcast to N,H,K\n",
    "counts   = torch.Tensor([[10,20,30], [20,40,60]])[None, :, :]\n",
    "\n",
    "# # Create repetitions for the batch dimension N.\n",
    "N=2\n",
    "counts = torch.repeat_interleave(input=counts, repeats=N, dim=0)\n",
    "weights = torch.ones_like(counts)\n",
    "probs  = torch.ones_like(counts) * 0.5\n",
    "\n",
    "print('weights.shape (N,H,K) \\t', weights.shape)\n",
    "print('counts.shape (N,H,K) \\t', counts.shape)\n",
    "print('probs.shape (N,H,K) \\t', probs.shape)\n",
    "\n",
    "model = NBMM(quantiles=[0.1, 0.40, 0.5, 0.60, 0.9])\n",
    "distr_args = (counts, probs)\n",
    "samples, sample_mean, quants = model.sample(distr_args, num_samples=2000)\n",
    "\n",
    "print('samples.shape (N,H,num_samples) ', samples.shape)\n",
    "print('sample_mean.shape (N,H) ', sample_mean.shape)\n",
    "print('quants.shape  (N,H,Q) \\t\\t', quants.shape)\n",
    "\n",
    "# Plot synthethic data\n",
    "x_plot = range(quants.shape[1]) # H length\n",
    "y_plot_hat = quants[0,:,:]  # Filter N,G,T -> H,Q\n",
    "samples_hat = samples[0,:,:]  # Filter N,G,T -> H,num_samples\n",
    "\n",
    "# Kernel density plot for single forecast horizon \\tau = t+1\n",
    "fig, ax = plt.subplots(figsize=(3.7, 2.9))\n",
    "\n",
    "ax.hist(samples_hat[0,:], alpha=0.5, bins=30,\n",
    "        label=r'Horizon $\\tau+1$')\n",
    "ax.hist(samples_hat[1,:], alpha=0.5, bins=30,\n",
    "        label=r'Horizon $\\tau+2$')\n",
    "ax.set(xlabel='Y values', ylabel='Probability')\n",
    "plt.title('Single horizon Distributions')\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot simulated trajectory\n",
    "fig, ax = plt.subplots(figsize=(3.7, 2.9))\n",
    "plt.plot(x_plot, y_plot_hat[:,2], color='black', label='median [q50]')\n",
    "plt.fill_between(x_plot,\n",
    "                 y1=y_plot_hat[:,1], y2=y_plot_hat[:,3],\n",
    "                 facecolor='blue', alpha=0.4, label='[p25-p75]')\n",
    "plt.fill_between(x_plot,\n",
    "                 y1=y_plot_hat[:,0], y2=y_plot_hat[:,4],\n",
    "                 facecolor='blue', alpha=0.2, label='[p1-p99]')\n",
    "ax.set(xlabel='Horizon', ylabel='Y values')\n",
    "plt.title('NBM Probabilistic Predictions')\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left', ncol=1)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb99f88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
