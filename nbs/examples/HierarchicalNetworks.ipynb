{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Forecast Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook offers a step by step guide to create a hierarchical forecasting pipeline.\n",
    "\n",
    "In the pipeline we will use `NeuralForecast` and `HINT` class, to create fit, predict and reconcile forecasts.\n",
    "\n",
    "We will use the TourismL dataset that summarizes large Australian national visitor survey.\n",
    "\n",
    "Outline\n",
    "1. Installing packages\n",
    "2. Load hierarchical dataset\n",
    "3. Fit and Predict HINT\n",
    "4. Forecast Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run these experiments using GPU with Google Colab.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/Nixtla/neuralforecast/blob/main/nbs/examples/HierarchicalNetworks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install git+https://github.com/Nixtla/neuralforecast.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install datasetsforecast hierarchicalforecast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load hierarchical dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This detailed Australian Tourism Dataset comes from the National Visitor Survey, managed by the Tourism Research Australia, it is composed of 555 monthly series from 1998 to 2016, it is organized geographically, and purpose of travel. The natural geographical hierarchy comprises seven states, divided further in 27 zones and 76 regions. The purpose of travel categories are holiday, visiting friends and relatives (VFR), business and other. The MinT (Wickramasuriya et al., 2019), among other hierarchical forecasting studies has used the dataset it in the past. The dataset can be accessed in the [MinT reconciliation webpage](https://robjhyndman.com/publications/mint/), although other sources are available.\n",
    "\n",
    "| Geographical Division | Number of series per division | Number of series per purpose | Total |\n",
    "|          ---          |               ---             |              ---             |  ---  |\n",
    "|  Australia            |              1                |               4              |   5   |\n",
    "|  States               |              7                |              28              |  35   |\n",
    "|  Zones                |             27                |              108             |  135  |\n",
    "|  Regions              |             76                |              304             |  380  |\n",
    "|  Total                |            111                |              444             |  555  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasetsforecast.hierarchical import HierarchicalData\n",
    "from hierarchicalforecast.utils import aggregate, HierarchicalPlot\n",
    "\n",
    "def sort_df_hier(Y_df, S):\n",
    "    # NeuralForecast core, sorts unique_id lexicographically\n",
    "    # by default, this class matches S_df and Y_hat_df order.\n",
    "    Y_df.unique_id = Y_df.unique_id.astype('category')\n",
    "    Y_df.unique_id = Y_df.unique_id.cat.set_categories(S.index)\n",
    "    Y_df = Y_df.sort_values(by=['unique_id', 'ds'])\n",
    "    return Y_df\n",
    "\n",
    "# Load hierarchical dataset\n",
    "Y_df, S_df, tags = HierarchicalData.load('./data', 'TourismLarge')\n",
    "Y_df['ds'] = pd.to_datetime(Y_df['ds'])\n",
    "Y_df = sort_df_hier(Y_df, S_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically a hierarchical multivariate time series can be denoted by the vector $\\mathbf{y}_{[a,b],t}$ defined by the following aggregation constraint: \n",
    "$$\n",
    "\\mathbf{y}_{[a,b],t}  = \\mathbf{S}_{[a,b][b]} \\mathbf{y}_{[b],t} \\quad \\Leftrightarrow \\quad \n",
    "\\begin{bmatrix}\\mathbf{y}_{[a],t}\n",
    "\\\\ %\\hline\n",
    "\\mathbf{y}_{[b],t}\\end{bmatrix} \n",
    "= \\begin{bmatrix}\n",
    "\\mathbf{A}_{[a][b]}\\\\ %\\hline\n",
    "\\mathbf{I}_{[b][b]}\n",
    "\\end{bmatrix}\n",
    "\\mathbf{y}_{[b],t}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{y}_{[a],t}$ are the aggregate series, $\\mathbf{y}_{[b],t}$ are the bottom level series and $\\mathbf{S}_{[a,b][b]}$ are the hierarchical aggregation constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we plot the hierarchical constraints matrix\n",
    "hplot = HierarchicalPlot(S=S_df, tags=tags)\n",
    "hplot.plot_summing_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we plot the top most series from the dataset\n",
    "# that corresponds to the total tourist monthly visits to Australia\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(Y_df[Y_df['unique_id']=='TotalAll']['ds'], Y_df[Y_df['unique_id']=='TotalAll']['y'])\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Tourist Arrivals')\n",
    "plt.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit and Predict HINT\n",
    "\n",
    "The Hierarchical Forecast Network (HINT) combines into an easy to use model three components: \n",
    "1. SoTA deep learning models. \n",
    "2. An efficient and flexible multivariate probability distribution.\n",
    "3. Builtin reconciliation capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NHITS, HINT\n",
    "from neuralforecast.losses.pytorch import GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizon and quantiles\n",
    "horizon = 12\n",
    "level = np.arange(0, 100, 2)\n",
    "qs = [[50-lv/2, 50+lv/2] for lv in level]\n",
    "quantiles = np.sort(np.concatenate(qs)/100)\n",
    "\n",
    "# Base model\n",
    "nhits = NHITS(h=horizon,\n",
    "             input_size=24,\n",
    "             loss=GMM(n_components=10, quantiles=quantiles),\n",
    "             max_steps=1000,\n",
    "             early_stop_patience_steps=3,\n",
    "             val_check_steps=100,\n",
    "             scaler_type='robust',\n",
    "             learning_rate=1e-3)\n",
    "\n",
    "# HINT := Network + Distribution + Reconciliation\n",
    "model = HINT(h=horizon, model=nhits, S=S_df.values, reconciliation='MinTraceOLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "nf = NeuralForecast(models=[model], freq='MS')\n",
    "forecasts = nf.cross_validation(df=Y_df, val_size=12, n_windows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id = 'TotalAll'\n",
    "Y_plot_df = Y_df[Y_df.unique_id==unique_id].tail(12*5)\n",
    "plot_df = forecasts[forecasts.unique_id==unique_id]\n",
    "plot_df = Y_plot_df.merge(plot_df, on=['ds', 'unique_id'], how='left')\n",
    "\n",
    "plt.plot(plot_df['ds'], plot_df['y_x'], c='black', label='True')\n",
    "plt.plot(plot_df['ds'], plot_df['HINT-median'], c='blue', label='median')\n",
    "plt.fill_between(x=plot_df['ds'][-12:],\n",
    "                 y1=plot_df['HINT-lo-90.0'][-12:].values,\n",
    "                 y2=plot_df['HINT-hi-90.0'][-12:].values,\n",
    "                 alpha=0.4, label='level 90')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Forecast Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the coherent probabilistic predictions we use the scaled Continuous Ranked Probability Score (sCRPS), defined as follows:\n",
    "\n",
    "$$\n",
    "\\mathrm{CRPS}(\\hat{F}_{[a,b],\\tau},\\mathbf{y}_{[a,b],\\tau}) = \\frac{2}{N_{a}+N_{b}} \\sum_{i}\n",
    "    \\int^{1}_{0}\n",
    "    \\mathrm{QL}(\\hat{F}_{i,\\tau}, y_{i,\\tau})_{q} dq \\\\ \n",
    "\\mathrm{sCRPS}(\\hat{F}_{[a,b\\,],\\tau},\\mathbf{y}_{[a,b\\,],\\tau}) = \n",
    "    \\frac{\\mathrm{CRPS}(\\hat{F}_{[a,b\\,],\\tau},\\mathbf{y}_{[a,b\\,],\\tau})}{\\sum_{i} | y_{i,\\tau} |}\n",
    "$$\n",
    "\n",
    "As you can see the HINT model achieves state of the art accuracy under minimal tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.evaluation import scaled_crps\n",
    "\n",
    "n_series = len(S_df)\n",
    "n_quantiles = len(quantiles)\n",
    "\n",
    "# Drop ds, unique_id, and y to keep only quantiles\n",
    "quantiles_columns = nhits.loss.output_names\n",
    "y_rec = forecasts.iloc[:, 3:-1].values \n",
    "y_test = forecasts['y'].values\n",
    "\n",
    "y_rec = y_rec.reshape(n_series, horizon, n_quantiles)\n",
    "y_test = y_test.reshape(n_series, horizon)\n",
    "\n",
    "scrps = scaled_crps(y=y_test, y_hat=y_rec, quantiles=quantiles)\n",
    "\n",
    "print('scaled CRPS')\n",
    "print(f'HINT:\\t\\t {np.round(scrps, 3)}')\n",
    "print(f'HierE2E:\\t 0.1472')\n",
    "print(f'ARIMA-MinTrace:\\t 0.1371')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker (2022).\"Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures\". International Journal Forecasting, accepted paper available at arxiv.](https://arxiv.org/pdf/2110.13179.pdf)\n",
    "- [Kin G. Olivares, Federico Garza, David Luo, Cristian Challu, Max Mergenthaler, Souhaib Ben Taieb, Shanika Wickramasuriya, and Artur Dubrawski (2022). \"HierarchicalForecast: A reference framework for hierarchical forecasting in python\". Journal of Machine Learning Research, submitted, abs/2207.03517, 2022b.](https://arxiv.org/abs/2207.03517)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
