{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Large Datasets\n",
    "> Tutorial on how to train neuralforecast models on datasets that cannot fit into memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard DataLoader class used by NeuralForecast expects the dataset to be represented by a single DataFrame, which is entirely loaded into memory when fitting the model. However, when the dataset is too large for this, we can instead use the custom large-scale DataLoader. This custom loader assumes that each timeseries is split across a collection of Parquet files, and ensure that only one timeseries is ever loaded into memory at a given time.\n",
    "\n",
    "In this notebook, we will demonstrate the expected format of these files, how to train the model and and how to perform inference using this large-scale DataLoader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import NHITS\n",
    "from utilsforecast.evaluation import evaluate\n",
    "from utilsforecast.losses import mae, rmse, smape\n",
    "from neuralforecast.utils import AirPassengersPanel, AirPassengersStatic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Each timeseries should be stored in a directory named **unique_id=timeseries_id**. Within this directory, the timeseries can be entirely contained in a single Parquet file or split across multiple Parquet files. Regardless of the format, the timeseries must be ordered by time.\n",
    "\n",
    "For example, the following code splits the AirPassengers DataFrame (of which each timeseries is already sorted by time) into the below format:\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**\\>**&nbsp;&nbsp;data  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**\\>**&nbsp;&nbsp;unique_id=Airline1  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -&nbsp;&nbsp;a59945617fdb40d1bc6caa4aadad881c-0.parquet  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**\\>**&nbsp;&nbsp;unique_id=Airline2  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -&nbsp;&nbsp;a59945617fdb40d1bc6caa4aadad881c-0.parquet  \n",
    "\n",
    "<br>\n",
    "We then simply input a list of the paths to these directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>trend</th>\n",
       "      <th>y_[lag12]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airline1</td>\n",
       "      <td>1949-01-31</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airline1</td>\n",
       "      <td>1949-02-28</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Airline1</td>\n",
       "      <td>1949-03-31</td>\n",
       "      <td>132.0</td>\n",
       "      <td>2</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Airline1</td>\n",
       "      <td>1949-04-30</td>\n",
       "      <td>129.0</td>\n",
       "      <td>3</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Airline1</td>\n",
       "      <td>1949-05-31</td>\n",
       "      <td>121.0</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1960-08-31</td>\n",
       "      <td>906.0</td>\n",
       "      <td>283</td>\n",
       "      <td>859.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1960-09-30</td>\n",
       "      <td>808.0</td>\n",
       "      <td>284</td>\n",
       "      <td>763.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1960-10-31</td>\n",
       "      <td>761.0</td>\n",
       "      <td>285</td>\n",
       "      <td>707.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1960-11-30</td>\n",
       "      <td>690.0</td>\n",
       "      <td>286</td>\n",
       "      <td>662.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1960-12-31</td>\n",
       "      <td>732.0</td>\n",
       "      <td>287</td>\n",
       "      <td>705.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_id         ds      y  trend  y_[lag12]\n",
       "0    Airline1 1949-01-31  112.0      0      112.0\n",
       "1    Airline1 1949-02-28  118.0      1      118.0\n",
       "2    Airline1 1949-03-31  132.0      2      132.0\n",
       "3    Airline1 1949-04-30  129.0      3      129.0\n",
       "4    Airline1 1949-05-31  121.0      4      121.0\n",
       "..        ...        ...    ...    ...        ...\n",
       "283  Airline2 1960-08-31  906.0    283      859.0\n",
       "284  Airline2 1960-09-30  808.0    284      763.0\n",
       "285  Airline2 1960-10-31  761.0    285      707.0\n",
       "286  Airline2 1960-11-30  690.0    286      662.0\n",
       "287  Airline2 1960-12-31  732.0    287      705.0\n",
       "\n",
       "[288 rows x 5 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_df = AirPassengersPanel.copy()\n",
    "Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/unique_id=Airline2', 'data/unique_id=Airline1']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid = Y_df.groupby('unique_id').tail(72)\n",
    "# from now on we will use the id_col as the unique identifier for the timeseries (this is because we are using the unique_id column to partition the data into parquet files)\n",
    "valid = valid.rename(columns={'unique_id': 'id_col'})\n",
    "\n",
    "train = Y_df.drop(valid.index)\n",
    "train['id_col'] = train['unique_id'].copy()\n",
    "train.to_parquet('./data', partition_cols=['unique_id'], index=False)\n",
    "\n",
    "files_list = [f\"data/{dir}\" for dir in os.listdir('./data')]\n",
    "files_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataLoader class still expects the static data to be passed in as a single DataFrame with one row per timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_col</th>\n",
       "      <th>airline1</th>\n",
       "      <th>airline2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airline1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_col  airline1  airline2\n",
       "0  Airline1         0         1\n",
       "1  Airline2         1         0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static = AirPassengersStatic.rename(columns={'unique_id': 'id_col'})\n",
    "static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "We now train a NHITS model on the above dataset. \n",
    "It is worth noting that NeuralForecast currently does not support scaling when using this DataLoader. If you want to scale the timeseries this should be done before passing it in to the `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name         | Type          | Params\n",
      "-----------------------------------------------\n",
      "0 | loss         | MAE           | 0     \n",
      "1 | padder_train | ConstantPad1d | 0     \n",
      "2 | scaler       | TemporalNorm  | 0     \n",
      "3 | blocks       | ModuleList    | 802 K \n",
      "-----------------------------------------------\n",
      "802 K     Trainable params\n",
      "0         Non-trainable params\n",
      "802 K     Total params\n",
      "3.211     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7b5200538d4f1c8d5a3557a12f357a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad3247bdfcf46afb1ade374e504d6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20debb56e1b748428faec83d8581ba2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n"
     ]
    }
   ],
   "source": [
    "horizon = 12\n",
    "stacks = 3\n",
    "models = [NHITS(input_size=5 * horizon,\n",
    "                h=horizon,\n",
    "                futr_exog_list=['trend', 'y_[lag12]'],\n",
    "                stat_exog_list=['airline1', 'airline2'],\n",
    "                max_steps=100,\n",
    "                stack_types = stacks*['identity'],\n",
    "                n_blocks = stacks*[1],\n",
    "                mlp_units = [[256,256] for _ in range(stacks)],\n",
    "                n_pool_kernel_size = stacks*[1])]\n",
    "nf = NeuralForecast(models=models, freq='M')\n",
    "nf.fit(df=files_list, static_df=static, id_col='id_col')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting\n",
    "\n",
    "When working with large datasets, we need to provide a single DataFrame containing the input timesteps of all the timeseries for which wish to generate predictions. If we have future exogenous features, we should also include the future values of these features in the separate `futr_df` DataFrame. \n",
    "\n",
    "For the below prediction we are assuming we only want to predict the next 12 timesteps for Airline2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasminerienecker/miniconda3/envs/neuralforecast/lib/python3.10/site-packages/utilsforecast/processing.py:382: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(freq)\n",
      "/home/jasminerienecker/miniconda3/envs/neuralforecast/lib/python3.10/site-packages/utilsforecast/processing.py:436: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(freq)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d723f4d6fbb547c7ad3887ca4c744abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jasminerienecker/Desktop/neuralforecast/neuralforecast/core.py:203: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "valid_df = valid[valid['id_col'] == 'Airline2']\n",
    "# we set input_size=60 and horizon=12 when fitting the model\n",
    "pred_df = valid_df[:60]\n",
    "futr_df = valid_df[60:72]\n",
    "futr_df = futr_df.drop([\"y\"], axis=1)\n",
    "\n",
    "predictions = nf.predict(df=pred_df, futr_df=futr_df, static_df=static).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_col</th>\n",
       "      <th>ds</th>\n",
       "      <th>NHITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1960-01-31</td>\n",
       "      <td>705.761780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1960-02-29</td>\n",
       "      <td>735.606262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1960-03-31</td>\n",
       "      <td>744.876282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1960-04-30</td>\n",
       "      <td>778.747192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1960-05-31</td>\n",
       "      <td>822.874390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1960-06-30</td>\n",
       "      <td>859.136719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1960-07-31</td>\n",
       "      <td>910.383240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1960-08-31</td>\n",
       "      <td>890.466064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1960-09-30</td>\n",
       "      <td>849.356995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1960-10-31</td>\n",
       "      <td>813.761475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1960-11-30</td>\n",
       "      <td>767.320618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Airline2</td>\n",
       "      <td>1960-12-31</td>\n",
       "      <td>736.092285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_col         ds       NHITS\n",
       "0   Airline2 1960-01-31  705.761780\n",
       "1   Airline2 1960-02-29  735.606262\n",
       "2   Airline2 1960-03-31  744.876282\n",
       "3   Airline2 1960-04-30  778.747192\n",
       "4   Airline2 1960-05-31  822.874390\n",
       "5   Airline2 1960-06-30  859.136719\n",
       "6   Airline2 1960-07-31  910.383240\n",
       "7   Airline2 1960-08-31  890.466064\n",
       "8   Airline2 1960-09-30  849.356995\n",
       "9   Airline2 1960-10-31  813.761475\n",
       "10  Airline2 1960-11-30  767.320618\n",
       "11  Airline2 1960-12-31  736.092285"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = valid_df[60:72]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NHITS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mae</th>\n",
       "      <td>31.430094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse</th>\n",
       "      <td>37.789986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smape</th>\n",
       "      <td>0.020317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NHITS\n",
       "metric           \n",
       "mae     31.430094\n",
       "rmse    37.789986\n",
       "smape    0.020317"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(\n",
    "    evaluate(\n",
    "        predictions.merge(target.drop([\"trend\", \"y_[lag12]\"], axis=1), on=['id_col', 'ds']),\n",
    "        metrics=[mae, rmse, smape],\n",
    "        id_col='id_col',\n",
    "    )\n",
    "    .drop(columns='id_col')\n",
    "    .groupby('metric')\n",
    "    .mean()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
