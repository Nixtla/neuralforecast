{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving and loading trained Deep Learning models has multiple valuable uses. These models are often costly to train; storing a pre-trained model can help reduce costs as it can be loaded and reused to forecast multiple times. Moreover, it enables Transfer learning capabilities, consisting of pre-training a flexible model on a large dataset and using it later on other data with little to no training. It is one of the most outstanding ðŸš€ achievements in Machine Learning ðŸ§  and has many practical applications.\n",
    "\n",
    "In this notebook we show an example on how to save and load `NeuralForecast` models.\n",
    "\n",
    "The two methods to consider are:<br>\n",
    "1. `NeuralForecast.save`: Saves models into disk, allows save dataset and config.<br>\n",
    "2. `NeuralForecast.load`: Loads models from a given path.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "This Guide assumes basic knowledge on the NeuralForecast library. For a minimal example visit the [Getting Started](./Getting_Started.ipynb) guide.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run these experiments using GPU with Google Colab.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/Nixtla/neuralforecast/blob/main/nbs/examples/Save_Load_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing NeuralForecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install neuralforecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading AirPassengers Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we will use the classical [AirPassenger Data set](https://www.kaggle.com/datasets/rakannimer/air-passengers). Import the pre-processed AirPassenger from `utils`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.utils import AirPassengersDF\n",
    "\n",
    "Y_df = AirPassengersDF\n",
    "Y_df = Y_df.reset_index(drop=True)\n",
    "Y_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we instantiate and train three models: `NBEATS`, `NHITS`, and `AutoMLP`. The models with their hyperparameters are defined in the `models` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "\n",
    "from neuralforecast.core import NeuralForecast\n",
    "from neuralforecast.auto import AutoMLP\n",
    "from neuralforecast.models import NBEATS, NHITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "horizon = 12\n",
    "models = [NBEATS(input_size=2 * horizon, h=horizon, max_steps=50),\n",
    "          NHITS(input_size=2 * horizon, h=horizon, max_steps=50),\n",
    "          AutoMLP(# Ray tune explore config\n",
    "                  config=dict(max_steps=100, # Operates with steps not epochs\n",
    "                              input_size=tune.choice([3*horizon]),\n",
    "                              learning_rate=tune.choice([1e-3])),\n",
    "                  h=horizon,\n",
    "                  num_samples=1, cpus=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "nf = NeuralForecast(models=models, freq='M')\n",
    "nf.fit(df=Y_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce the forecasts with the `predict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_df = nf.predict().reset_index()\n",
    "Y_hat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the forecasts for each model. Note how the two `NBEATS` models are differentiated with a numerical suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.concat([Y_df, Y_hat_df]).set_index('ds') # Concatenate the train and forecast dataframes\n",
    "\n",
    "plt.figure(figsize = (12, 3))\n",
    "plot_df[['y', 'NBEATS', 'NHITS', 'AutoMLP']].plot(linewidth=2)\n",
    "\n",
    "plt.title('AirPassengers Forecast', fontsize=10)\n",
    "plt.ylabel('Monthly Passengers', fontsize=10)\n",
    "plt.xlabel('Timestamp [t]', fontsize=10)\n",
    "plt.axvline(x=plot_df.index[-horizon], color='k', linestyle='--', linewidth=2)\n",
    "plt.legend(prop={'size': 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save all the trained models use the `save` method. This method will save both the hyperparameters and the learnable weights (parameters).\n",
    "\n",
    "The `save` method has the following inputs:\n",
    "\n",
    "* `path`: directory where models will be saved.\n",
    "* `model_index`: optional list to specify which models to save. For example, to only save the `NHITS` model use `model_index=[2]`.\n",
    "* `overwrite`: boolean to overwrite existing files in `path`. When True, the method will only overwrite models with conflicting names.\n",
    "* `save_dataset`: boolean to save `Dataset` object with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf.save(path='./checkpoints/test_run/',\n",
    "        model_index=None, \n",
    "        overwrite=True,\n",
    "        save_dataset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each model, two files are created and stored:\n",
    "\n",
    "* `[model_name]_[suffix].ckpt`: Pytorch Lightning checkpoint file with the model parameters and hyperparameters.\n",
    "* `[model_name]_[suffix].pkl`: Dictionary with configuration attributes.\n",
    "\n",
    "Where `model_name` corresponds to the name of the model in lowercase (eg. `nhits`). We use a numerical suffix to distinguish multiple models of each class. In this example the names will be `automlp_0`, `nbeats_0`, and `nhits_0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "The `Auto` models will be stored as their base model. For example, the `AutoMLP` trained above is stored as an `MLP` model, with the best hyparparameters found during tuning.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the saved models with the `load` method, specifying the `path`, and use the new `nf2` object to produce forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf2 = NeuralForecast.load(path='./checkpoints/test_run/')\n",
    "Y_hat_df = nf2.predict().reset_index()\n",
    "Y_hat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, plot the forecasts to confirm they are identical to the original forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.concat([Y_df, Y_hat_df]).set_index('ds') # Concatenate the train and forecast dataframes\n",
    "\n",
    "plt.figure(figsize = (12, 3))\n",
    "plot_df[['y', 'NBEATS', 'NHITS', 'MLP']].plot(linewidth=2)\n",
    "\n",
    "plt.title('AirPassengers Forecast', fontsize=10)\n",
    "plt.ylabel('Monthly Passengers', fontsize=10)\n",
    "plt.xlabel('Timestamp [t]', fontsize=10)\n",
    "plt.axvline(x=plot_df.index[-horizon], color='k', linestyle='--', linewidth=2)\n",
    "plt.legend(prop={'size': 10})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://pytorch-lightning.readthedocs.io/en/stable/common/checkpointing_basic.html\n",
    "\n",
    "[Oreshkin, B. N., Carpov, D., Chapados, N., & Bengio, Y. (2019). N-BEATS: Neural basis expansion analysis for interpretable time series forecasting. ICLR 2020](https://arxiv.org/abs/1905.10437)\n",
    "\n",
    "[Cristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2021). N-HiTS: Neural Hierarchical Interpolation for Time Series Forecasting. Accepted at AAAI 2023.](https://arxiv.org/abs/2201.12886)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
