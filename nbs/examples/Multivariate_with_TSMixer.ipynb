{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate forecasting\n",
    "> Tutorial on how to do multivariate forecasting using TSMixer models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In _multivariate_ forecasting, we use the information from every time series to produce all forecasts for all time series jointly. In contrast, in _univariate_ forecasting we only consider the information from every individual time series and produce forecasts for every time series separately. Multivariate forecasting methods thus use more information to produce every forecast, and thus should be able to provide better forecasting results. However, multivariate forecasting methods also scale with the number of time series, which means these methods are commonly less well suited for large-scale problems (i.e. forecasting many, many time series).\n",
    "\n",
    "In this notebook, we will demonstrate the performance of a state-of-the-art multivariate forecasting architecture `TSMixer` / `TSMixerx` when compared to a univariate forecasting method (`NHITS`).\n",
    "\n",
    "We will show how to:\n",
    "* Load the [ETTm2](https://github.com/zhouhaoyi/ETDataset) benchmark dataset, used in the academic literature.\n",
    "* Train a TSMixer and TSMixerx model\n",
    "* Forecast the test set\n",
    "* Optimize the hyperparameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run these experiments using GPU with Google Colab.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/Nixtla/neuralforecast/blob/main/nbs/examples/LongHorizon_with_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install neuralforecast datasetsforecast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load ETTm2 Data\n",
    "\n",
    "The `LongHorizon` class will automatically download the complete ETTm2 dataset and process it.\n",
    "\n",
    "It return three Dataframes: `Y_df` contains the values for the target variables, `X_df` contains exogenous calendar features and `S_df` contains static features for each time-series (none for ETTm2). For this example we will use `Y_df` and `X_df`. \n",
    "\n",
    "In `TSMixerx`, we can make use of the additional exogenous features contained in `X_df`. In `TSMixer`, there is _no_ support for exogenous features. Hence, if you want to use exogenous features, you should use `TSMixerx`. \n",
    "\n",
    "If you want to use your own data just replace `Y_df` and `X_df`. Be sure to use a long format and make sure to have a similar structure as our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datasetsforecast.long_horizon import LongHorizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to your own data to try the model\n",
    "Y_df, X_df, _ = LongHorizon.load(directory='./', group='ETTm2')\n",
    "Y_df['ds'] = pd.to_datetime(Y_df['ds'])\n",
    "\n",
    "# X_df contains the exogenous features, which we add to Y_df\n",
    "X_df['ds'] = pd.to_datetime(X_df['ds'])\n",
    "Y_df = Y_df.merge(X_df, on=['unique_id', 'ds'], how='left')\n",
    "\n",
    "# We make validation and test splits\n",
    "n_time = len(Y_df.ds.unique())\n",
    "val_size = int(.2 * n_time)\n",
    "test_size = int(.2 * n_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train models\n",
    "\n",
    "We will train models using the `cross_validation` method, which allows users to automatically simulate multiple historic forecasts (in the test set).\n",
    "\n",
    "The `cross_validation` method will use the validation set for hyperparameter selection and early stopping, and will then produce the forecasts for the test set.\n",
    "\n",
    "First, instantiate each model in the `models` list, specifying the `horizon`, `input_size`, and training iterations. In this notebook, we compare against the `NHITS` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "from neuralforecast.core import NeuralForecast\n",
    "from neuralforecast.models import TSMixer, TSMixerx, NHITS\n",
    "from neuralforecast.losses.pytorch import MSE, MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "horizon = 96\n",
    "input_size = 512\n",
    "models = [\n",
    "          TSMixer(h=horizon,\n",
    "                input_size=input_size,\n",
    "                n_series=7,\n",
    "                max_steps=1000,\n",
    "                val_check_steps=100,\n",
    "                early_stop_patience_steps=5,\n",
    "                scaler_type='identity',\n",
    "                valid_loss=MAE(),\n",
    "                random_seed=12345678,\n",
    "                ),  \n",
    "          TSMixerx(h=horizon,\n",
    "                input_size=input_size,\n",
    "                n_series=7,\n",
    "                max_steps=1000,\n",
    "                val_check_steps=100,\n",
    "                early_stop_patience_steps=5,\n",
    "                scaler_type='identity',\n",
    "                dropout=0.7,\n",
    "                valid_loss=MAE(),\n",
    "                random_seed=12345678,\n",
    "                futr_exog_list=['ex_1', 'ex_2', 'ex_3', 'ex_4'],\n",
    "                ),                          \n",
    "           NHITS(h=horizon,\n",
    "                input_size=horizon,\n",
    "                max_steps=1000,\n",
    "                val_check_steps=100,\n",
    "                early_stop_patience_steps=5,\n",
    "                scaler_type='robust',\n",
    "                valid_loss=MAE(),\n",
    "                random_seed=12345678,\n",
    "                ),                                                                       \n",
    "         ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-tip}\n",
    "Check our `auto` models for automatic hyperparameter optimization, and see the end of this tutorial for an example of hyperparameter tuning.\n",
    ":::"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a `NeuralForecast` object with the following required parameters:\n",
    "\n",
    "* `models`: a list of models.\n",
    "\n",
    "* `freq`: a string indicating the frequency of the data. (See [panda's available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases).)\n",
    "\n",
    "Second, use the `cross_validation` method, specifying the dataset (`Y_df`), validation size and test size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "nf = NeuralForecast(\n",
    "    models=models,\n",
    "    freq='15min')\n",
    "\n",
    "Y_hat_df = nf.cross_validation(df=Y_df,\n",
    "                               val_size=val_size,\n",
    "                               test_size=test_size,\n",
    "                               n_windows=None\n",
    "                               )                                 \n",
    "Y_hat_df = Y_hat_df.reset_index()                               "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `cross_validation` method will return the forecasts for each model on the test set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we plot the forecasts on the test set for the `OT` variable for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "Y_plot = Y_hat_df[Y_hat_df['unique_id']=='OT'] # OT dataset\n",
    "cutoffs = Y_hat_df['cutoff'].unique()[::horizon]\n",
    "Y_plot = Y_plot[Y_hat_df['cutoff'].isin(cutoffs)]\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(Y_plot['ds'], Y_plot['y'], label='True')\n",
    "plt.plot(Y_plot['ds'], Y_plot['TSMixer'], label='TSMixer')\n",
    "plt.plot(Y_plot['ds'], Y_plot['TSMixerx'], label='TSMixerx')\n",
    "plt.plot(Y_plot['ds'], Y_plot['NHITS'], label='NHITS')\n",
    "plt.xlabel('Datestamp')\n",
    "plt.ylabel('OT')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compute the test errors using the Mean Absolute Error (MAE) and Mean Squared Error (MSE):\n",
    "\n",
    "$\\qquad MAE = \\frac{1}{Windows * Horizon} \\sum_{\\tau} |y_{\\tau} - \\hat{y}_{\\tau}| \\qquad$ and $\\qquad MSE = \\frac{1}{Windows * Horizon} \\sum_{\\tau} (y_{\\tau} - \\hat{y}_{\\tau})^{2} \\qquad$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.losses.numpy import mse, mae\n",
    "\n",
    "mae_tsmixer = mae(Y_hat_df['y'], Y_hat_df['TSMixer'])\n",
    "mse_tsmixer = mse(Y_hat_df['y'], Y_hat_df['TSMixer'])\n",
    "mae_tsmixerx = mae(Y_hat_df['y'], Y_hat_df['TSMixerx'])\n",
    "mse_tsmixerx = mse(Y_hat_df['y'], Y_hat_df['TSMixerx'])\n",
    "mae_nhits = mae(Y_hat_df['y'], Y_hat_df['NHITS'])\n",
    "mse_nhits = mse(Y_hat_df['y'], Y_hat_df['NHITS'])\n",
    "\n",
    "\n",
    "print(f'TSMixer horizon {horizon} - MAE: {mae_tsmixer:.3f}')\n",
    "print(f'TSMixer horizon {horizon} - MSE: {mse_tsmixer:.3f}')\n",
    "print(f'TSMixerx horizon {horizon} - MAE: {mae_tsmixerx:.3f}')\n",
    "print(f'TSMixerx horizon {horizon} - MSE: {mse_tsmixerx:.3f}')\n",
    "print(f'NHITS horizon {horizon} - MAE: {mae_nhits:.3f}')\n",
    "print(f'NHITS horizon {horizon} - MSE: {mse_nhits:.3f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, we can check the performance when compared to self-reported performance in the paper. We find that `TSMixer` provides better results than the _univariate_ method `NHITS`. Also, our implementation of `TSMixer` very closely tracks the results of the original paper. Finally, it seems that there is little benefit of using the additional exogenous variables contained in the dataframe `X_df` as `TSMixerx` performs worse than `TSMixer`, especially on longer horizons. \n",
    "\n",
    "Mean Absolute Error (MAE)\n",
    "\n",
    "| Horizon   |TSMixer<br> (this notebook) | TSMixer <br>(paper) | TSMixerx<br> (this notebook) |  NHITS <br>(this notebook)    | NHITS <br>(paper) \n",
    "|---        |---        |---        |---        |---        |---       \n",
    "|  96       | **0.250** | 0.252     | 0.257     |  0.251    |   0.255      \n",
    "|  192      | **0.288** | 0.290     | 0.300     |  0.291    |   0.305      \n",
    "|  336      | **0.323** | 0.324     | 0.380     |  0.344    |   0.346      \n",
    "|  720      | **0.377** | 0.422     | 0.464     |  0.417    |   0.413     \n",
    "\n",
    "Mean Squared Error (MSE)\n",
    "\n",
    "| Horizon   |TSMixer<br> (this notebook) | TSMixer <br>(paper) | TSMixerx<br> (this notebook) | NHITS <br>(this notebook)    | NHITS <br>(paper) \n",
    "|---        |---        |---            |---        |---                |---            \n",
    "|  96       | **0.163** | **0.163**     | 0.170     |  0.179            |   0.176      \n",
    "|  192      | 0.220     | **0.216**     | 0.231     |  0.239            |   0.245       \n",
    "|  336      | 0.272     | **0.268**     | 0.361     |  0.311            |   0.295       \n",
    "|  720      | **0.356** | 0.420         | 0.493     |  0.451            |   0.401      \n",
    "\n",
    "Note that for the table above, we use the same hyperparameters for all methods for all horizons, whereas the original papers tune the hyperparameters for each horizon."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tuning the hyperparameters\n",
    "The `AutoTSMixer` / `AutoTSMixerx` class will automatically perform hyperparamter tunning using the [Tune library](https://docs.ray.io/en/latest/tune/index.html), exploring a user-defined or default search space. Models are selected based on the error on a validation set and the best model is then stored and used during inference. \n",
    "\n",
    "The `AutoTSMixer.default_config` / `AutoTSMixerx.default_config`  attribute contains a suggested hyperparameter space. Here, we specify a different search space following the paper's hyperparameters. Feel free to play around with this space.\n",
    "\n",
    "For this example, we will optimize the hyperparameters for `horizon = 96`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from neuralforecast.auto import AutoTSMixer, AutoTSMixerx\n",
    "\n",
    "horizon = 96 # 24hrs = 4 * 15 min.\n",
    "\n",
    "tsmixer_config = {\n",
    "       \"input_size\": input_size,                                                 # Size of input window\n",
    "       \"max_steps\": tune.choice([500, 1000, 2000]),                              # Number of training iterations\n",
    "       \"val_check_steps\": 100,                                                   # Compute validation every x steps\n",
    "       \"early_stop_patience_steps\": 5,                                           # Early stopping steps\n",
    "       \"learning_rate\": tune.loguniform(1e-4, 1e-2),                             # Initial Learning rate\n",
    "       \"n_block\": tune.choice([1, 2, 4, 6, 8]),                                  # Number of mixing layers\n",
    "       \"dropout\": tune.uniform(0.0, 0.99),                                       # Dropout\n",
    "       \"ff_dim\": tune.choice([32, 64, 128]),                                     # Dimension of the feature linear layer\n",
    "       \"scaler_type\": 'identity',       \n",
    "    }\n",
    "\n",
    "tsmixerx_config = tsmixer_config.copy()\n",
    "tsmixerx_config['futr_exog_list'] = ['ex_1', 'ex_2', 'ex_3', 'ex_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To instantiate `AutoTSMixer` and `AutoTSMixerx` you need to define:\n",
    "\n",
    "* `h`: forecasting horizon\n",
    "* `n_series`: number of time series in the multivariate time series problem.\n",
    "\n",
    "In addition, we define the following parameters (if these are not given, the `AutoTSMixer`/`AutoTSMixerx` class will use a pre-defined value):\n",
    "* `loss`: training loss. Use the `DistributionLoss` to produce probabilistic forecasts.\n",
    "* `config`: hyperparameter search space. If `None`, the `AutoTSMixer` class will use a pre-defined suggested hyperparameter space.\n",
    "* `num_samples`: number of configurations explored. For this example, we only use a limited amount of `10`.\n",
    "* `search_alg`: type of search algorithm used for selecting parameter values within the hyperparameter space.\n",
    "* `backend`: the backend used for the hyperparameter optimization search, either `ray` or `optuna`. \n",
    "* `valid_loss`: the loss used for the validation sets in the optimization procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoTSMixer(h=horizon,\n",
    "                    n_series=7,\n",
    "                    loss=MAE(),\n",
    "                    config=tsmixer_config,\n",
    "                    num_samples=10,\n",
    "                    search_alg=HyperOptSearch(),\n",
    "                    backend='ray',\n",
    "                    valid_loss=MAE())\n",
    "\n",
    "modelx = AutoTSMixerx(h=horizon,\n",
    "                    n_series=7,\n",
    "                    loss=MAE(),\n",
    "                    config=tsmixerx_config,\n",
    "                    num_samples=10,\n",
    "                    search_alg=HyperOptSearch(),\n",
    "                    backend='ray',\n",
    "                    valid_loss=MAE())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we fit the model by instantiating a `NeuralForecast` object with the following required parameters:\n",
    "\n",
    "* `models`: a list of models.\n",
    "\n",
    "* `freq`: a string indicating the frequency of the data. (See [panda's available frequencies](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases).)\n",
    "\n",
    "The `cross_validation` method allows you to simulate multiple historic forecasts, greatly simplifying pipelines by replacing for loops with `fit` and `predict` methods.\n",
    "\n",
    "With time series data, cross validation is done by defining a sliding window across the historical data and predicting the period following it. This form of cross validation allows us to arrive at a better estimation of our modelâ€™s predictive abilities across a wider range of temporal instances while also keeping the data in the training set contiguous as is required by our models.\n",
    "\n",
    "The `cross_validation` method will use the validation set for hyperparameter selection, and will then produce the forecasts for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "nf = NeuralForecast(models=[model, modelx], freq='15min')\n",
    "Y_hat_df = nf.cross_validation(df=Y_df, val_size=val_size,\n",
    "                               test_size=test_size, n_windows=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Results\n",
    "\n",
    "The `AutoTSMixer`/`AutoTSMixerx` class contains a `results` attribute that stores information of each configuration explored. It contains the validation loss and best validation hyperparameter. The result dataframe `Y_hat_df` that we obtained in the previous step is based on the best config of the hyperparameter search. For `AutoTSMixer`, the best config is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf.models[0].results.get_best_result().config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and for `AutoTSMixerx`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf.models[1].results.get_best_result().config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the test errors of the best config for the two metrics of interest:\n",
    "\n",
    "$\\qquad MAE = \\frac{1}{Windows * Horizon} \\sum_{\\tau} |y_{\\tau} - \\hat{y}_{\\tau}| \\qquad$ and $\\qquad MSE = \\frac{1}{Windows * Horizon} \\sum_{\\tau} (y_{\\tau} - \\hat{y}_{\\tau})^{2} \\qquad$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = Y_hat_df.y.values\n",
    "y_hat_tsmixer = Y_hat_df['AutoTSMixer'].values\n",
    "y_hat_tsmixerx = Y_hat_df['AutoTSMixerx'].values\n",
    "\n",
    "print(f'MAE TSMixer: {mae(y_hat_tsmixer, y_true):.3f}')\n",
    "print(f'MSE TSMixer: {mse(y_hat_tsmixer, y_true):.3f}')\n",
    "print(f'MAE TSMixerx: {mae(y_hat_tsmixerx, y_true):.3f}')\n",
    "print(f'MSE TSMixerx: {mse(y_hat_tsmixerx, y_true):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the error metrics for our optimized setting to the earlier setting in which we used the default hyperparameters. In this case, for a horizon of 96, we got slightly improved results for `TSMixer` on `MAE`. Interestingly, we did not improve for `TSMixerx` as compared to the default settings. For this dataset, it seems there is limited value in using exogenous features with the `TSMixerx` architecture for a horizon of 96.\n",
    "\n",
    "| Metric    |TSMixer<br> (optimized) | TSMixer <br>(default)  | TSMixer <br>(paper)   |TSMixerx<br> (optimized) | TSMixerx <br>(default) \n",
    "|---        |---                     |---                     |---                    |---                      |---\n",
    "| MAE       | **0.247**              | 0.250                  | 0.252                 | 0.258                   | 0.257 \n",
    "| MSE       | **0.162**              | 0.163                  | **0.163**             | 0.174                   | 0.170\n",
    "\n",
    "Note that we only evaluated 10 hyperparameter configurations (`num_samples=10`), which may suggest that it is possible to further improve forecasting performance by exploring more hyperparameter configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[Chen, Si-An, Chun-Liang Li, Nate Yoder, Sercan O. Arik, and Tomas Pfister (2023). \"TSMixer: An All-MLP Architecture for Time Series Forecasting.\"](http://arxiv.org/abs/2303.06053) <br>\n",
    "[Cristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2021). NHITS: Neural Hierarchical Interpolation for Time Series Forecasting. Accepted at AAAI 2023.](https://arxiv.org/abs/2201.12886)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
