{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Maintenance\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictive maintenance (PdM) is a data-driven preventive maintanance program. It is a proactive maintenance strategy that uses sensors to monitor the performance and equipment conditions during operation. The PdM methods constantly analyze the data to predict when optimal maintenance schedules. It can reduce maintenance costs and prevent catastrophic equipment failure when used correctly. \n",
    "\n",
    "In this notebook, we will apply NeuralForecast to perform a supervised Remaining Useful Life (RUL) estimation on the classic PHM2008 aircraft degradation dataset.\n",
    "\n",
    "Outline<br>\n",
    "1. Installing Packages<br>\n",
    "2. Load PHM2008 aircraft degradation dataset<br>\n",
    "3. Fit and Predict NeuralForecast<br>\n",
    "4. Evaluate Predictions\n",
    "\n",
    "You can run these experiments using GPU with Google Colab.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/Nixtla/neuralforecast/blob/main/nbs/examples/Predictive_Maintenance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install git+https://github.com/Nixtla/neuralforecast.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install git+https://github.com/Nixtla/datasetsforecast.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "from neuralforecast.models import NBEATSx, MLP\n",
    "from neuralforecast import NeuralForecast\n",
    "#from neuralforecast.losses.pytorch import DistributionLoss, HuberMQLoss, MQLoss\n",
    "from neuralforecast.losses.pytorch import HuberLoss, MAE\n",
    "\n",
    "from datasetsforecast.phm2008 import PHM2008"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load PHM2008 aircraft degradation dataset\n",
    "\n",
    "Here we will load the Prognosis and Health Management 2008 challenge dataset. This dataset used the Commercial Modular Aero-Propulsion System Simulation to recreate the degradation process of turbofan engines for different aircraft with varying wear and manufacturing starting under normal conditions. The training dataset consists of complete run-to-failure simulations, while the test dataset comprises sequences before failure."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/Nixtla/neuralforecast/blob/main/nbs/imgs_losses/turbofan_engine.png?raw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_df, Y_test_df = PHM2008.load(directory='./data', group='FD001', clip_rul=False)\n",
    "Y_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df1 = Y_train_df[Y_train_df['unique_id']==1]\n",
    "plot_df2 = Y_train_df[Y_train_df['unique_id']==2]\n",
    "plot_df3 = Y_train_df[Y_train_df['unique_id']==3]\n",
    "\n",
    "plt.plot(plot_df1.ds, np.minimum(plot_df1.y, 125), color='#2D6B8F', linestyle='--')\n",
    "plt.plot(plot_df1.ds, plot_df1.y, color='#2D6B8F', label='Engine 1')\n",
    "\n",
    "plt.plot(plot_df2.ds, np.minimum(plot_df2.y, 125)+1.5, color='#CA6F6A', linestyle='--')\n",
    "plt.plot(plot_df2.ds, plot_df2.y+1.5, color='#CA6F6A', label='Engine 2')\n",
    "\n",
    "plt.plot(plot_df3.ds, np.minimum(plot_df3.y, 125)-1.5, color='#D5BC67', linestyle='--')\n",
    "plt.plot(plot_df3.ds, plot_df3.y-1.5, color='#D5BC67', label='Engine 3')\n",
    "\n",
    "plt.ylabel('Remaining Useful Life (RUL)', fontsize=15)\n",
    "plt.xlabel('Time Cycle', fontsize=15)\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(s, b = 0.98):\n",
    "    v = np.zeros(len(s)+1) #v_0 is already 0.\n",
    "    bc = np.zeros(len(s)+1)\n",
    "    for i in range(1, len(v)): #v_t = 0.95\n",
    "        v[i] = (b * v[i-1] + (1-b) * s[i-1]) \n",
    "        bc[i] = 1 - b**i\n",
    "    sm = v[1:] / bc[1:]\n",
    "    return sm\n",
    "\n",
    "unique_id = 1\n",
    "plot_df = Y_train_df[Y_train_df.unique_id == unique_id].copy()\n",
    "\n",
    "fig, axes = plt.subplots(2,3, figsize = (8,5))\n",
    "fig.tight_layout()\n",
    "\n",
    "j = -1\n",
    "#, 's_11', 's_12', 's_13', 's_14', 's_15', 's_17', 's_20', 's_21'\n",
    "for feature in ['s_2', 's_3', 's_4', 's_7', 's_8', 's_9']:\n",
    "    if ('s' in feature) and ('smoothed' not in feature):\n",
    "        j += 1\n",
    "        axes[j // 3, j % 3].plot(plot_df.ds, plot_df[feature], \n",
    "                                 c = '#2D6B8F', label = 'original')\n",
    "        axes[j // 3, j % 3].plot(plot_df.ds, smooth(plot_df[feature].values), \n",
    "                                 c = '#CA6F6A', label = 'smoothed')\n",
    "        #axes[j // 3, j % 3].plot([10,10],[0,1], c = 'black')\n",
    "        axes[j // 3, j % 3].set_title(feature)\n",
    "        axes[j // 3, j % 3].grid()\n",
    "        axes[j // 3, j % 3].legend()\n",
    "        \n",
    "plt.suptitle(f'Engine {unique_id} sensor records')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit and Predict NeuralForecast\n",
    "\n",
    "NeuralForecast methods are capable of addressing regression problems involving various variables. The regression problem involves predicting the target variable $y_{t+h}$ based on its lags $y_{:t}$, temporal exogenous features $x^{(h)}_{:t}$, exogenous features available at the time of prediction $x^{(f)}_{:t+h}$, and static features $x^{(s)}$. \n",
    "\n",
    "The task of estimating the remaining useful life (RUL) simplifies the problem to a single horizon prediction $h=1$, where the objective is to predict $y_{t+1}$ based on the exogenous features $x^{(f)}_{:t+1}$ and static features $x^{(s)}$. In the RUL estimation task, the exogenous features typically correspond to sensor monitoring information, while the target variable represents the RUL itself.\n",
    "\n",
    "$$P(y_{t+1}\\;|\\;x^{(f)}_{:t+1},x^{(s)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_df, Y_test_df = PHM2008.load(directory='./data', group='FD001', clip_rul=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "futr_exog_list =['s_2', 's_3', 's_4', 's_7', 's_8', 's_9', 's_11',\n",
    "                 's_12', 's_13', 's_14', 's_15', 's_17', 's_20', 's_21']\n",
    "\n",
    "model = NBEATSx(h=1, input_size=24,\n",
    "                loss=HuberLoss(),\n",
    "                scaler_type='robust',\n",
    "                stack_types=['identity', 'identity', 'identity'],\n",
    "                dropout_prob_theta=0.5,\n",
    "                futr_exog_list=futr_exog_list,\n",
    "                exclude_insample_y = True,\n",
    "                max_steps=1000)\n",
    "nf = NeuralForecast(models=[model], freq='M')\n",
    "\n",
    "nf.fit(df=Y_train_df)\n",
    "Y_hat_df = nf.predict(futr_df=Y_test_df).reset_index() # By default last window?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "filter_test_df = Y_test_df.groupby('unique_id').tail(31).reset_index()\n",
    "Y_hat_df2 = nf.cross_validation(df=filter_test_df, n_windows=30, fit_models=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate Predictions\n",
    "\n",
    "In the original PHM2008 dataset the true RUL values for the test set are only provided for the last time cycle of each enginge.\n",
    "We will filter the predictions to only evaluate the last time cycle.\n",
    "\n",
    "$$RMSE(\\mathbf{y}_{T},\\hat{\\mathbf{y}}_{T}) = \\sqrt{\\frac{1}{|\\mathcal{D}_{test}|} \\sum_{i} (y_{i,T}-\\hat{y}_{i,T})^{2}}$$\n",
    "\n",
    "$$R2(\\mathbf{y}_{T},\\hat{\\mathbf{y}}_{T}) = 1- \\frac{\\sum_{i} (y_{i,T}-\\hat{y}_{i,T})^{2}}{\\sum_{i} (y_{i,T}-\\bar{y}_{i,T})^{2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from neuralforecast.losses.numpy import rmse\n",
    "\n",
    "model_name = repr(nf.models[0])\n",
    "y_last = Y_test_df[['unique_id', 'y']].groupby('unique_id').last().reset_index()\n",
    "y_hat_last = Y_hat_df[['unique_id', model_name]].groupby('unique_id').last().reset_index()\n",
    "y_last = y_last['y']\n",
    "y_hat_last = y_hat_last[model_name]\n",
    "\n",
    "rmse_eval = rmse(y=y_last, y_hat=y_hat_last)\n",
    "r2_eval = r2_score(y_true=y_last, y_pred=y_hat_last)\n",
    "\n",
    "print(f'{model_name} Prognosis Evaluation')\n",
    "print(f'RMSE:\\t {rmse_eval:.3f}')\n",
    "print(f'R2:\\t {r2_eval:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_last, y_hat_last)\n",
    "plt.xlabel('True RUL', fontsize=15)\n",
    "plt.ylabel('RUL Prediction', fontsize=15)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df1 = Y_hat_df2[Y_hat_df2['unique_id']==1]\n",
    "plot_df2 = Y_hat_df2[Y_hat_df2['unique_id']==2]\n",
    "plot_df3 = Y_hat_df2[Y_hat_df2['unique_id']==3]\n",
    "\n",
    "plt.plot(plot_df1.ds, plot_df1['y'], c='#2D6B8F', label='E1 true RUL')\n",
    "plt.plot(plot_df1.ds, plot_df1[model_name]+1, c='#2D6B8F', linestyle='--', label='E1 predicted RUL')\n",
    "\n",
    "plt.plot(plot_df1.ds, plot_df2['y'], c='#CA6F6A', label='E2 true RUL')\n",
    "plt.plot(plot_df1.ds, plot_df2[model_name]+1, c='#CA6F6A', linestyle='--', label='E2 predicted RUL')\n",
    "\n",
    "plt.plot(plot_df1.ds, plot_df3['y'], c='#D5BC67', label='E3 true RUL')\n",
    "plt.plot(plot_df1.ds, plot_df3[model_name]+1, c='#D5BC67', linestyle='--', label='E3 predicted RUL')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [R. Keith Mobley (2002). \"An Introduction to Predictive Maintenance\"](https://www.irantpm.ir/wp-content/uploads/2008/02/an-introduction-to-predictive-maintenance.pdf)<br>\n",
    "- [Saxena, A., Goebel, K., Simon, D.,&Eklund, N. (2008). \"Damage propagation modeling for aircraft engine run-to-failure simulation\". International conference on prognostics and health management.](https://ntrs.nasa.gov/api/citations/20090029214/downloads/20090029214.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
