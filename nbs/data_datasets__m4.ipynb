{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.datasets.m4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M4 dataset\n",
    "\n",
    "> API details.\n",
    "- https://mofc.unic.ac.cy/m4/\n",
    "- https://www.sciencedirect.com/science/article/pii/S0169207019301128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nixtla.data.datasets.utils import download_file, Info, TimeSeriesDataclass\n",
    "from nixtla.data.tsdataset import TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "SOURCE_URL = 'https://raw.githubusercontent.com/Mcompetitions/M4-methods/master/Dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M4 meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Yearly:\n",
    "    seasonality: int = 1\n",
    "    horizon: int = 6\n",
    "    freq: str = 'Y'\n",
    "    name: str = 'Yearly'\n",
    "    n_ts: int = 23_000\n",
    "\n",
    "@dataclass\n",
    "class Quarterly:\n",
    "    seasonality: int = 4\n",
    "    horizon: int = 8\n",
    "    freq: str = 'Q'\n",
    "    name: str = 'Quarterly'\n",
    "    n_ts: int = 24_000\n",
    "\n",
    "@dataclass\n",
    "class Monthly:\n",
    "    seasonality: int = 12\n",
    "    horizon: int = 18\n",
    "    freq: str = 'M'\n",
    "    name: str = 'Monthly'\n",
    "    n_ts: int = 48_000\n",
    "\n",
    "@dataclass\n",
    "class Weekly:\n",
    "    seasonality: int = 52\n",
    "    horizon: int = 13\n",
    "    freq: str = 'W'\n",
    "    name: str = 'Weekly'\n",
    "    n_ts: int = 359\n",
    "        \n",
    "@dataclass\n",
    "class Daily:\n",
    "    seasonality: int = 7\n",
    "    horizon: int = 14\n",
    "    freq: str = 'D'\n",
    "    name: str = 'Daily'\n",
    "    n_ts: int = 4_227\n",
    "\n",
    "@dataclass\n",
    "class Hourly:\n",
    "    seasonality: int = 24\n",
    "    horizon: int = 48\n",
    "    freq: str = 'H'\n",
    "    name: str = 'Hourly'\n",
    "    n_ts: int = 414\n",
    "\n",
    "        \n",
    "@dataclass\n",
    "class Other:\n",
    "    seasonality: int = 1\n",
    "    horizon: int = 8\n",
    "    freq: str = 'D'\n",
    "    name: str = 'Other'\n",
    "    n_ts: int = 5_000\n",
    "    included_groups: Tuple = ('Weekly', 'Daily', 'Hourly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "M4Info = Info(groups=('Yearly', 'Quarterly', 'Monthly', 'Weekly', 'Daily', 'Hourly', 'Other'),\n",
    "              class_groups=(Yearly, Quarterly, Monthly, Weekly, Daily, Hourly, Other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class M4(TimeSeriesDataclass):\n",
    "\n",
    "    @staticmethod\n",
    "    def load(directory: str,\n",
    "             group: str) -> Tuple[pd.DataFrame, \n",
    "                                  Optional[pd.DataFrame], \n",
    "                                  Optional[pd.DataFrame]]:\n",
    "        \"\"\"\n",
    "        Downloads and loads M4 data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'Yearly', 'Quarterly', 'Monthly', \n",
    "                            'Weekly', 'Daily', 'Hourly'.\n",
    "            \n",
    "        Notes\n",
    "        -----\n",
    "        [1] Returns train+test sets.\n",
    "        \"\"\"\n",
    "        if group == 'Other':\n",
    "            #Special case.\n",
    "            included_dfs = [M4.load(directory, gr) \\\n",
    "                            for gr in M4Info['Other'].included_groups]\n",
    "            df, *_ = zip(*included_dfs)\n",
    "            df = pd.concat(df)\n",
    "        else:\n",
    "            path = Path(directory) / 'm4' / 'datasets'\n",
    "\n",
    "            M4.download(directory)\n",
    "\n",
    "            class_group = M4Info[group]\n",
    "\n",
    "            def read_and_melt(file): \n",
    "                df = pd.read_csv(file)\n",
    "                df.columns = ['unique_id'] + list(range(1, df.shape[1]))\n",
    "                df = pd.melt(df, id_vars=['unique_id'], var_name='ds', value_name='y')\n",
    "                df = df.dropna()\n",
    "\n",
    "                return df\n",
    "\n",
    "            df_train = read_and_melt(path / f'{group}-train.csv')\n",
    "            df_test = read_and_melt(path / f'{group}-test.csv')\n",
    "\n",
    "            len_train = df_train.groupby('unique_id').agg({'ds': 'max'}).reset_index()\n",
    "            len_train.columns = ['unique_id', 'len_serie']\n",
    "            df_test = df_test.merge(len_train, on=['unique_id'])\n",
    "            df_test['ds'] = df_test['ds'] + df_test['len_serie']\n",
    "            df_test.drop('len_serie', axis=1, inplace=True)\n",
    "\n",
    "            df = pd.concat([df_train, df_test])\n",
    "            df = df.sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "            \n",
    "        return df, None, None\n",
    "\n",
    "    @staticmethod\n",
    "    def download(directory: Path) -> None:\n",
    "        \"\"\"Download M4 Dataset.\"\"\"\n",
    "        path = Path(directory) / 'm4' / 'datasets'\n",
    "        if not path.exists():\n",
    "            for group in M4Info.groups:\n",
    "                download_file(path, f'{SOURCE_URL}/Train/{group}-train.csv')\n",
    "                download_file(path, f'{SOURCE_URL}/Test/{group}-test.csv')\n",
    "            download_file(path, f'{SOURCE_URL}/M4-info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group, meta in M4Info:\n",
    "    data, *_ = M4.load(directory='../data', group=group)\n",
    "    unique_elements = data.groupby(['unique_id', 'ds']).size()\n",
    "    unique_ts = data.groupby('unique_id').size()\n",
    "\n",
    "    assert (unique_elements != 1).sum() == 0, f'Duplicated records found: {group}'\n",
    "    assert unique_ts.shape[0] == meta.n_ts, f'Number of time series not match: {group}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
