{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.nhits.nhits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import math\n",
    "import random\n",
    "from functools import partial\n",
    "from typing import Tuple, List\n",
    "from fastcore.foundation import patch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import multiprocessing\n",
    "NUM_WORKERS = min(multiprocessing.cpu_count(), 6)\n",
    "\n",
    "from neuralforecast.models.components.tcn import _TemporalConvNet\n",
    "from neuralforecast.models.components.common import Chomp1d, RepeatVector\n",
    "from neuralforecast.losses.utils import LossFunction\n",
    "from neuralforecast.data.tsdataset import WindowsDataset\n",
    "from neuralforecast.data.tsloader import TimeSeriesLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _StaticFeaturesEncoder(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(_StaticFeaturesEncoder, self).__init__()\n",
    "        layers = [nn.Dropout(p=0.5),\n",
    "                  nn.Linear(in_features=in_features, out_features=out_features),\n",
    "                  nn.ReLU()]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "class _sEncoder(nn.Module):\n",
    "    def __init__(self, in_features, out_features, n_time_in):\n",
    "        super(_sEncoder, self).__init__()\n",
    "        layers = [nn.Dropout(p=0.5),\n",
    "                  nn.Linear(in_features=in_features, out_features=out_features),\n",
    "                  nn.ReLU()]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "        self.repeat = RepeatVector(repeats=n_time_in)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode and repeat values to match time\n",
    "        x = self.encoder(x)\n",
    "        x = self.repeat(x) # [N,S_out] -> [N,S_out,T]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _IdentityBasis(nn.Module):\n",
    "    def __init__(self, backcast_size: int, forecast_size: int, interpolation_mode: str):\n",
    "        super().__init__()\n",
    "        assert (interpolation_mode in ['linear','nearest']) or ('cubic' in interpolation_mode)\n",
    "        self.forecast_size = forecast_size\n",
    "        self.backcast_size = backcast_size\n",
    "        self.interpolation_mode = interpolation_mode\n",
    " \n",
    "    def forward(self, theta: t.Tensor, insample_x_t: t.Tensor,\n",
    "                outsample_x_t: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "\n",
    "        backcast = theta[:, :self.backcast_size]\n",
    "        knots = theta[:, self.backcast_size:]\n",
    "\n",
    "        if self.interpolation_mode=='nearest':\n",
    "            knots = knots[:,None,:]\n",
    "            forecast = F.interpolate(knots, size=self.forecast_size, \n",
    "                                     mode=self.interpolation_mode)\n",
    "            forecast = forecast[:,0,:]\n",
    "        elif self.interpolation_mode=='linear':\n",
    "            knots = knots[:,None,:]\n",
    "            forecast = F.interpolate(knots, size=self.forecast_size,\n",
    "                                     mode=self.interpolation_mode, align_corners=False)\n",
    "            forecast = forecast[:,0,:]\n",
    "        elif 'cubic' in self.interpolation_mode:\n",
    "            batch_size = len(backcast)\n",
    "            knots = knots[:,None,None,:]\n",
    "            forecast = t.zeros((len(knots), self.forecast_size)).to(knots.device)\n",
    "            n_batches = int(np.ceil(len(knots)/batch_size))\n",
    "            for i in range(n_batches):\n",
    "                forecast_i = F.interpolate(knots[i*batch_size:(i+1)*batch_size],\n",
    "                                           size=self.forecast_size, mode='bicubic')\n",
    "                forecast[i*batch_size:(i+1)*batch_size] += forecast_i[:,0,0,:]\n",
    "\n",
    "        return backcast, forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _ExogenousBasisInterpretable(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, theta: t.Tensor, insample_x_t: t.Tensor, outsample_x_t: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "        backcast_basis = insample_x_t\n",
    "        forecast_basis = outsample_x_t\n",
    "\n",
    "        cut_point = forecast_basis.shape[1]\n",
    "        backcast = t.einsum('bp,bpt->bt', theta[:, cut_point:], backcast_basis)\n",
    "        forecast = t.einsum('bp,bpt->bt', theta[:, :cut_point], forecast_basis)\n",
    "        return backcast, forecast\n",
    "\n",
    "class _ExogenousBasisWavenet(nn.Module):\n",
    "    def __init__(self, out_features, in_features, num_levels=4, kernel_size=3, dropout_prob=0):\n",
    "        super().__init__()\n",
    "        # Shape of (1, in_features, 1) to broadcast over b and t\n",
    "        self.weight = nn.Parameter(t.Tensor(1, in_features, 1), requires_grad=True)\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(0.5))\n",
    "\n",
    "        padding = (kernel_size - 1) * (2**0)\n",
    "        input_layer = [nn.Conv1d(in_channels=in_features, out_channels=out_features,\n",
    "                                 kernel_size=kernel_size, padding=padding, dilation=2**0),\n",
    "                                 Chomp1d(padding),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(dropout_prob)]\n",
    "        conv_layers = []\n",
    "        for i in range(1, num_levels):\n",
    "            dilation = 2**i\n",
    "            padding = (kernel_size - 1) * dilation\n",
    "            conv_layers.append(nn.Conv1d(in_channels=out_features, out_channels=out_features,\n",
    "                                         padding=padding, kernel_size=3, dilation=dilation))\n",
    "            conv_layers.append(Chomp1d(padding))\n",
    "            conv_layers.append(nn.ReLU())\n",
    "        conv_layers = input_layer + conv_layers\n",
    "\n",
    "        self.wavenet = nn.Sequential(*conv_layers)\n",
    "        \n",
    "    def transform(self, insample_x_t, outsample_x_t):\n",
    "        n_time_in = insample_x_t.shape[2]\n",
    "        \n",
    "        x_t = t.cat([insample_x_t, outsample_x_t], dim=2)\n",
    "        \n",
    "        x_t = x_t * self.weight # Element-wise multiplication, broadcasted on b and t. Weights used in L1 regularization\n",
    "        x_t = self.wavenet(x_t)[:]\n",
    "\n",
    "        backcast_basis = x_t[:,:, :n_time_in]\n",
    "        forecast_basis = x_t[:,:, n_time_in:]\n",
    "\n",
    "        return backcast_basis, forecast_basis\n",
    "\n",
    "    def forward(self, theta: t.Tensor, insample_x_t: t.Tensor, \n",
    "                outsample_x_t: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "        backcast_basis, forecast_basis = self.transform(insample_x_t, outsample_x_t)\n",
    "\n",
    "        cut_point = forecast_basis.shape[1]\n",
    "        backcast = t.einsum('bp,bpt->bt', theta[:, cut_point:], backcast_basis)\n",
    "        forecast = t.einsum('bp,bpt->bt', theta[:, :cut_point], forecast_basis)\n",
    "        return backcast, forecast\n",
    "\n",
    "class _ExogenousBasisTCN(nn.Module):\n",
    "    def __init__(self, out_features, in_features, num_levels = 4, kernel_size=2, dropout_prob=0):\n",
    "        super().__init__()\n",
    "        n_channels = num_levels * [out_features]\n",
    "        self.tcn = _TemporalConvNet(num_inputs=in_features, num_channels=n_channels, \n",
    "                                    kernel_size=kernel_size, dropout=dropout_prob)\n",
    "        \n",
    "    def transform(self, insample_x_t, outsample_x_t):\n",
    "        n_time_in = insample_x_t.shape[2]\n",
    "        \n",
    "        x_t = t.cat([insample_x_t, outsample_x_t], dim=2)\n",
    "        \n",
    "        x_t = self.tcn(x_t)[:]\n",
    "        backcast_basis = x_t[:,:, :n_time_in]\n",
    "        forecast_basis = x_t[:,:, n_time_in:]\n",
    "\n",
    "        return backcast_basis, forecast_basis\n",
    "\n",
    "    def forward(self, theta: t.Tensor, insample_x_t: t.Tensor, \n",
    "                outsample_x_t: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "        backcast_basis, forecast_basis = self.transform(insample_x_t, outsample_x_t)\n",
    "\n",
    "        cut_point = forecast_basis.shape[1]\n",
    "        backcast = t.einsum('bp,bpt->bt', theta[:, cut_point:], backcast_basis)\n",
    "        forecast = t.einsum('bp,bpt->bt', theta[:, :cut_point], forecast_basis)\n",
    "        return backcast, forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _init_weights(module, initialization):\n",
    "    if type(module) == t.nn.Linear:\n",
    "        if initialization == 'orthogonal':\n",
    "            t.nn.init.orthogonal_(module.weight)\n",
    "        elif initialization == 'he_uniform':\n",
    "            t.nn.init.kaiming_uniform_(module.weight)\n",
    "        elif initialization == 'he_normal':\n",
    "            t.nn.init.kaiming_normal_(module.weight)\n",
    "        elif initialization == 'glorot_uniform':\n",
    "            t.nn.init.xavier_uniform_(module.weight)\n",
    "        elif initialization == 'glorot_normal':\n",
    "            t.nn.init.xavier_normal_(module.weight)\n",
    "        elif initialization == 'lecun_normal':\n",
    "            pass #t.nn.init.normal_(module.weight, 0.0, std=1/np.sqrt(module.weight.numel()))\n",
    "        else:\n",
    "            assert 1<0, f'Initialization {initialization} not found'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "ACTIVATIONS = ['ReLU',\n",
    "               'Softplus',\n",
    "               'Tanh',\n",
    "               'SELU',\n",
    "               'LeakyReLU',\n",
    "               'PReLU',\n",
    "               'Sigmoid']\n",
    "\n",
    "class _NHITSBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    N-BEATS block which takes a basis function as an argument.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_time_in: int, n_time_out: int, n_x: int,\n",
    "                 n_s: int, n_s_hidden: int, n_theta: int, n_mlp_units: list,\n",
    "                 n_pool_kernel_size: int, pooling_mode: str, basis: nn.Module,\n",
    "                 n_layers: int,  batch_normalization: bool, dropout_prob: float, activation: str):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        assert (pooling_mode in ['max','average'])\n",
    "\n",
    "        n_time_in_pooled = int(np.ceil(n_time_in/n_pool_kernel_size))\n",
    "\n",
    "        if n_s == 0:\n",
    "            n_s_hidden = 0\n",
    "        n_mlp_units = [n_time_in_pooled + (n_time_in+n_time_out)*n_x + n_s_hidden] + n_mlp_units\n",
    "        \n",
    "        self.n_time_in = n_time_in\n",
    "        self.n_time_out = n_time_out\n",
    "        self.n_s = n_s\n",
    "        self.n_s_hidden = n_s_hidden\n",
    "        self.n_x = n_x\n",
    "        self.n_pool_kernel_size = n_pool_kernel_size\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.dropout_prob = dropout_prob\n",
    "        \n",
    "        assert activation in ACTIVATIONS, f'{activation} is not in {ACTIVATIONS}'\n",
    "        activ = getattr(nn, activation)()\n",
    "\n",
    "        if pooling_mode == 'max':\n",
    "            self.pooling_layer = nn.MaxPool1d(kernel_size=self.n_pool_kernel_size,\n",
    "                                              stride=self.n_pool_kernel_size, ceil_mode=True)\n",
    "        elif pooling_mode == 'average':\n",
    "            self.pooling_layer = nn.AvgPool1d(kernel_size=self.n_pool_kernel_size,\n",
    "                                              stride=self.n_pool_kernel_size, ceil_mode=True)\n",
    "\n",
    "        hidden_layers = []\n",
    "        for i in range(n_layers):\n",
    "            hidden_layers.append(nn.Linear(in_features=n_mlp_units[i], out_features=n_mlp_units[i+1]))\n",
    "            hidden_layers.append(activ)\n",
    "\n",
    "            if self.batch_normalization:\n",
    "                hidden_layers.append(nn.BatchNorm1d(num_features=n_mlp_units[i+1]))\n",
    "\n",
    "            if self.dropout_prob>0:\n",
    "                hidden_layers.append(nn.Dropout(p=self.dropout_prob))\n",
    "\n",
    "        output_layer = [nn.Linear(in_features=n_mlp_units[-1], out_features=n_theta)]\n",
    "        layers = hidden_layers + output_layer\n",
    "\n",
    "        # n_s is computed with data, n_s_hidden is provided by user, if 0 no statics are used\n",
    "        if (self.n_s > 0) and (self.n_s_hidden > 0):\n",
    "            self.static_encoder = _StaticFeaturesEncoder(in_features=n_s, out_features=n_s_hidden)\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.basis = basis\n",
    "\n",
    "    def forward(self, insample_y: t.Tensor, insample_x_t: t.Tensor,\n",
    "                outsample_x_t: t.Tensor, x_s: t.Tensor) -> Tuple[t.Tensor, t.Tensor]:\n",
    "\n",
    "        insample_y = insample_y.unsqueeze(1)\n",
    "        insample_y = self.pooling_layer(insample_y)\n",
    "        insample_y = insample_y.squeeze(1)\n",
    "\n",
    "        batch_size = len(insample_y)\n",
    "        if self.n_x > 0:\n",
    "            insample_y = t.cat(( insample_y, insample_x_t.reshape(batch_size, -1) ), 1)\n",
    "            insample_y = t.cat(( insample_y, outsample_x_t.reshape(batch_size, -1) ), 1)\n",
    "        \n",
    "        # Static exogenous\n",
    "        if (self.n_s > 0) and (self.n_s_hidden > 0):\n",
    "            x_s = self.static_encoder(x_s)\n",
    "            insample_y = t.cat((insample_y, x_s), 1)\n",
    "\n",
    "        # Compute local projection weights and projection\n",
    "        theta = self.layers(insample_y)\n",
    "        backcast, forecast = self.basis(theta, insample_x_t, outsample_x_t)\n",
    "\n",
    "        return backcast, forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _NHITS(nn.Module):\n",
    "    \"\"\"\n",
    "    NHITS Model.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 n_time_in,\n",
    "                 n_time_out,\n",
    "                 n_s,\n",
    "                 n_x,\n",
    "                 n_s_hidden,\n",
    "                 n_x_hidden,\n",
    "                 stack_types: list,\n",
    "                 n_blocks: list,\n",
    "                 n_layers: list,\n",
    "                 n_mlp_units: list,\n",
    "                 n_pool_kernel_size: list,\n",
    "                 n_freq_downsample: list,\n",
    "                 pooling_mode,\n",
    "                 interpolation_mode,\n",
    "                 dropout_prob_theta,\n",
    "                 activation,\n",
    "                 initialization,\n",
    "                 batch_normalization,\n",
    "                 shared_weights):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_time_out = n_time_out\n",
    "\n",
    "        blocks = self.create_stack(stack_types=stack_types, \n",
    "                                   n_blocks=n_blocks,\n",
    "                                   n_time_in=n_time_in,\n",
    "                                   n_time_out=n_time_out,\n",
    "                                   n_x=n_x,\n",
    "                                   n_x_hidden=n_x_hidden,\n",
    "                                   n_s=n_s,\n",
    "                                   n_s_hidden=n_s_hidden,\n",
    "                                   n_layers=n_layers,\n",
    "                                   n_mlp_units=n_mlp_units,\n",
    "                                   n_pool_kernel_size=n_pool_kernel_size,\n",
    "                                   n_freq_downsample=n_freq_downsample,\n",
    "                                   pooling_mode=pooling_mode,\n",
    "                                   interpolation_mode=interpolation_mode,\n",
    "                                   batch_normalization=batch_normalization,\n",
    "                                   dropout_prob_theta=dropout_prob_theta,\n",
    "                                   activation=activation,\n",
    "                                   shared_weights=shared_weights,\n",
    "                                   initialization=initialization)\n",
    "        self.blocks = t.nn.ModuleList(blocks)\n",
    "\n",
    "    def create_stack(self, stack_types, n_blocks, \n",
    "                     n_time_in, n_time_out, \n",
    "                     n_x, n_x_hidden, n_s, n_s_hidden, \n",
    "                     n_layers, n_mlp_units, \n",
    "                     n_pool_kernel_size, n_freq_downsample, pooling_mode, interpolation_mode,\n",
    "                     batch_normalization, dropout_prob_theta, \n",
    "                     activation, shared_weights, initialization):                     \n",
    "        block_list = []\n",
    "        for i in range(len(stack_types)):\n",
    "            assert stack_types[i] in ['identity', 'exogenous', 'exogenous_tcn', 'exogenous_wavenet'], 'f Invalid stack type {stack_types[i]}'\n",
    "            for block_id in range(n_blocks[i]):\n",
    "                \n",
    "                # Batch norm only on first block\n",
    "                if (len(block_list)==0) and (batch_normalization):\n",
    "                    batch_normalization_block = True\n",
    "                else:\n",
    "                    batch_normalization_block = False\n",
    "\n",
    "                # Shared weights\n",
    "                if shared_weights and block_id>0:\n",
    "                    nbeats_block = block_list[-1]\n",
    "                else:\n",
    "                    if stack_types[i] == 'identity':\n",
    "                        n_theta = (n_time_in + max(n_time_out//n_freq_downsample[i], 1) )\n",
    "                        basis = _IdentityBasis(backcast_size=n_time_in,\n",
    "                                              forecast_size=n_time_out,\n",
    "                                              interpolation_mode=interpolation_mode)                        \n",
    "\n",
    "                    elif stack_types[i] == 'exogenous':\n",
    "                        n_theta = 2 * n_x\n",
    "                        basis = _ExogenousBasisInterpretable()\n",
    "\n",
    "                    elif stack_types[i] == 'exogenous_tcn':\n",
    "                        n_theta = 2 * n_x_hidden\n",
    "                        basis = _ExogenousBasisTCN(n_x_hidden, n_x)\n",
    "\n",
    "                    elif stack_types[i] == 'exogenous_wavenet':\n",
    "                        n_theta = 2 * n_x_hidden\n",
    "                        basis = _ExogenousBasisWavenet(n_x_hidden, n_x)\n",
    "\n",
    "                    nbeats_block = _NHITSBlock(n_time_in=n_time_in,\n",
    "                                               n_time_out=n_time_out,\n",
    "                                               n_x=n_x,\n",
    "                                               n_s=n_s,\n",
    "                                               n_s_hidden=n_s_hidden,\n",
    "                                               n_theta=n_theta,\n",
    "                                               n_mlp_units=n_mlp_units[i],\n",
    "                                               n_pool_kernel_size=n_pool_kernel_size[i],\n",
    "                                               pooling_mode=pooling_mode,\n",
    "                                               basis=basis,\n",
    "                                               n_layers=n_layers[i],\n",
    "                                               batch_normalization=batch_normalization_block,\n",
    "                                               dropout_prob=dropout_prob_theta,\n",
    "                                               activation=activation)\n",
    "\n",
    "                # Select type of evaluation and apply it to all layers of block\n",
    "                init_function = partial(_init_weights, initialization=initialization)                                             \n",
    "                nbeats_block.layers.apply(init_function)\n",
    "                block_list.append(nbeats_block)\n",
    "        return block_list\n",
    "\n",
    "    def forward(self, S: t.Tensor, Y: t.Tensor, X: t.Tensor, \n",
    "                insample_mask: t.Tensor, outsample_mask: t.Tensor,\n",
    "                return_decomposition: bool=False):\n",
    "        \n",
    "        # insample\n",
    "        insample_y    = Y[:, :-self.n_time_out]\n",
    "        insample_x_t  = X[:, :, :-self.n_time_out]\n",
    "        insample_mask = insample_mask[:, :-self.n_time_out]\n",
    "        \n",
    "        # outsample\n",
    "        outsample_y   = Y[:, -self.n_time_out:]\n",
    "        outsample_x_t = X[:, :, -self.n_time_out:]\n",
    "        outsample_mask = outsample_mask[:, -self.n_time_out:]\n",
    "\n",
    "        if return_decomposition:\n",
    "            forecast, block_forecasts = self.forecast_decomposition(insample_y=insample_y, \n",
    "                                                                    insample_x_t=insample_x_t, \n",
    "                                                                    insample_mask=insample_mask,\n",
    "                                                                    outsample_x_t=outsample_x_t,\n",
    "                                                                    x_s=S)\n",
    "            return outsample_y, forecast, block_forecasts, outsample_mask\n",
    "        \n",
    "        else:\n",
    "            forecast = self.forecast(insample_y=insample_y,\n",
    "                                     insample_x_t=insample_x_t, \n",
    "                                     insample_mask=insample_mask,\n",
    "                                     outsample_x_t=outsample_x_t,\n",
    "                                     x_s=S)\n",
    "            return outsample_y, forecast, outsample_mask\n",
    "\n",
    "    def forecast(self, insample_y: t.Tensor, insample_x_t: t.Tensor, insample_mask: t.Tensor,\n",
    "                 outsample_x_t: t.Tensor, x_s: t.Tensor):\n",
    "\n",
    "        residuals = insample_y.flip(dims=(-1,))\n",
    "        insample_x_t = insample_x_t.flip(dims=(-1,))\n",
    "        insample_mask = insample_mask.flip(dims=(-1,))\n",
    "\n",
    "        forecast = insample_y[:, -1:] # Level with Naive1\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            backcast, block_forecast = block(insample_y=residuals, insample_x_t=insample_x_t,\n",
    "                                             outsample_x_t=outsample_x_t, x_s=x_s)\n",
    "            residuals = (residuals - backcast) * insample_mask\n",
    "            forecast = forecast + block_forecast\n",
    "\n",
    "        return forecast\n",
    "\n",
    "    def forecast_decomposition(self, insample_y: t.Tensor, insample_x_t: t.Tensor, insample_mask: t.Tensor,\n",
    "                               outsample_x_t: t.Tensor, x_s: t.Tensor):\n",
    "\n",
    "        residuals = insample_y.flip(dims=(-1,))\n",
    "        insample_x_t = insample_x_t.flip(dims=(-1,))\n",
    "        insample_mask = insample_mask.flip(dims=(-1,))\n",
    "        \n",
    "        n_batch, n_channels, n_t = outsample_x_t.size(0), outsample_x_t.size(1), outsample_x_t.size(2)\n",
    "        \n",
    "        level = insample_y[:, -1:] # Level with Naive1\n",
    "        block_forecasts = [ level.repeat(1, n_t) ]\n",
    "                \n",
    "        forecast = level\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            backcast, block_forecast = block(insample_y=residuals, insample_x_t=insample_x_t,\n",
    "                                             outsample_x_t=outsample_x_t, x_s=x_s)\n",
    "            residuals = (residuals - backcast) * insample_mask\n",
    "            forecast = forecast + block_forecast\n",
    "            block_forecasts.append(block_forecast)\n",
    "            \n",
    "        # (n_batch, n_blocks, n_t)\n",
    "        block_forecasts = t.stack(block_forecasts)\n",
    "        block_forecasts = block_forecasts.permute(1,0,2)\n",
    "\n",
    "        return forecast, block_forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-HiTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new model for long-horizon forecasting which incorporates novel hierarchical interpolation and multi-rate data sampling techniques to specialize blocks of its architecture to different frequency band of the time-series signal. It achieves SoTA performance on several benchmark datasets, outperforming current Transformer-based models by more than 25%. Paper available at https://arxiv.org/abs/2201.12886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NHITS(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 n_time_in: int,\n",
    "                 n_time_out: int,\n",
    "                 n_x: int,\n",
    "                 n_s: int,\n",
    "                 shared_weights: bool,\n",
    "                 activation: str,\n",
    "                 initialization: str,\n",
    "                 stack_types: List[str],\n",
    "                 n_blocks: List[int],\n",
    "                 n_layers: List[int],\n",
    "                 n_mlp_units: List[List[int]],\n",
    "                 n_x_hidden: int,\n",
    "                 n_s_hidden: int,\n",
    "                 n_pool_kernel_size: List[int],\n",
    "                 n_freq_downsample: List[int],\n",
    "                 pooling_mode: str,\n",
    "                 interpolation_mode: str,\n",
    "                 batch_normalization: bool,\n",
    "                 dropout_prob_theta: float,\n",
    "                 learning_rate: float,\n",
    "                 lr_decay: float,\n",
    "                 lr_decay_step_size: int,\n",
    "                 weight_decay: float,\n",
    "                 loss_train: str,\n",
    "                 loss_hypar: float,\n",
    "                 loss_valid: str,\n",
    "                 frequency: str,\n",
    "                 random_seed: int):\n",
    "        \"\"\"\n",
    "        N-HiTS model.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            n_time_in: int\n",
    "                Multiplier to get insample size.\n",
    "                Insample size = n_time_in * output_size\n",
    "            n_time_out: int\n",
    "                Forecast horizon.\n",
    "            n_x: int\n",
    "                Number of exogenous variables.\n",
    "            n_s: int\n",
    "                Number of static variables.\n",
    "            shared_weights: bool\n",
    "                If True, all blocks within each stack will share parameters.\n",
    "            activation: str\n",
    "                Activation function.\n",
    "                An item from ['ReLU', 'Softplus', 'Tanh', 'SELU', 'LeakyReLU', 'PReLU', 'Sigmoid'].\n",
    "            initialization: str\n",
    "                Initialization function.\n",
    "                An item from ['orthogonal', 'he_uniform', 'glorot_uniform', 'glorot_normal', 'lecun_normal'].\n",
    "            stack_types: List[str]\n",
    "                List of stack types.\n",
    "                Subset from ['seasonality', 'trend', 'identity', 'exogenous', 'exogenous_tcn', 'exogenous_wavenet'].\n",
    "            n_blocks: List[int]\n",
    "                Number of blocks for each stack.\n",
    "                Note that len(n_blocks) = len(stack_types).\n",
    "            n_layers: List[int]\n",
    "                Number of layers for each stack type.\n",
    "                Note that len(n_layers) = len(stack_types).\n",
    "            n_mlp_units: List[List[int]]\n",
    "                Structure of hidden layers for each stack type.\n",
    "                Each internal list should contain the number of units of each hidden layer.\n",
    "                Note that len(n_hidden) = len(stack_types).\n",
    "            n_x_hidden: int\n",
    "                Number of hidden output channels of exogenous_tcn and exogenous_wavenet stacks. \n",
    "            n_s_hidden: int\n",
    "                Number of encoded static features, output dim of _StaticFeaturesEncoder. \n",
    "            n_pool_kernel_size List[int]:\n",
    "                Pooling size for input for each stack.\n",
    "                Note that len(n_pool_kernel_size) = len(stack_types).\n",
    "            n_freq_downsample List[int]:\n",
    "                Downsample multiplier of output for each stack. Expressivity ratio (r) = 1/n_freq_downsample\n",
    "                Note that len(n_freq_downsample) = len(stack_types).\n",
    "            pooling_mode: str\n",
    "                Pooling type.\n",
    "                An item from ['average', 'max']\n",
    "            interpolation_mode: str\n",
    "                Interpolation function.\n",
    "                An item from ['linear', 'nearest', 'cubic']\n",
    "            batch_normalization: bool\n",
    "                Whether perform batch normalization.\n",
    "            dropout_prob_theta: float\n",
    "                Float between (0, 1).\n",
    "                Dropout for Nbeats basis.\n",
    "            learning_rate: float\n",
    "                Learning rate between (0, 1).\n",
    "            lr_decay: float\n",
    "                Decreasing multiplier for the learning rate.\n",
    "            lr_decay_step_size: int\n",
    "                Steps between each learning rate decay.\n",
    "            weight_decay: float\n",
    "                L2 penalty for optimizer.\n",
    "            loss_train: str\n",
    "                Loss to optimize.\n",
    "                An item from ['MAPE', 'MASE', 'SMAPE', 'MSE', 'MAE', 'QUANTILE', 'QUANTILE2'].\n",
    "            loss_hypar: float\n",
    "                Hyperparameter for chosen loss.\n",
    "            loss_valid: str\n",
    "                Validation loss.\n",
    "                An item from ['MAPE', 'MASE', 'SMAPE', 'RMSE', 'MAE', 'QUANTILE'].\n",
    "            frequency: str\n",
    "                Time series frequency.\n",
    "            random_seed: int\n",
    "                random_seed for pseudo random pytorch initializer and\n",
    "                numpy random generator.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(NHITS, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        if activation == 'SELU': initialization = 'lecun_normal'\n",
    "\n",
    "        #------------------------ Model Attributes ------------------------#\n",
    "        # Architecture parameters\n",
    "        self.n_time_in = n_time_in\n",
    "        self.n_time_out = n_time_out\n",
    "        self.n_x = n_x\n",
    "        self.n_x_hidden = n_x_hidden\n",
    "        self.n_s = n_s\n",
    "        self.n_s_hidden = n_s_hidden\n",
    "        self.shared_weights = shared_weights\n",
    "        self.activation = activation\n",
    "        self.initialization = initialization\n",
    "        self.stack_types = stack_types\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_layers = n_layers\n",
    "        self.n_mlp_units = n_mlp_units\n",
    "        self.n_pool_kernel_size = n_pool_kernel_size\n",
    "        self.n_freq_downsample = n_freq_downsample\n",
    "        self.pooling_mode = pooling_mode\n",
    "        self.interpolation_mode = interpolation_mode\n",
    "\n",
    "        # Loss functions\n",
    "        self.loss_train = loss_train\n",
    "        self.loss_hypar = loss_hypar\n",
    "        self.loss_valid = loss_valid\n",
    "        self.loss_fn_train = LossFunction(loss_train,\n",
    "                                          percentile=self.loss_hypar,\n",
    "                                          seasonality=self.loss_hypar)\n",
    "        self.loss_fn_valid = LossFunction(loss_valid,\n",
    "                                          percentile=self.loss_hypar,\n",
    "                                          seasonality=self.loss_hypar)\n",
    "        \n",
    "        # Regularization and optimization parameters\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.dropout_prob_theta = dropout_prob_theta        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.lr_decay = lr_decay\n",
    "        self.weight_decay = weight_decay\n",
    "        self.lr_decay_step_size = lr_decay_step_size\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        # Data parameters\n",
    "        self.frequency = frequency\n",
    "        self.return_decomposition = False\n",
    "\n",
    "        self.model = _NHITS(n_time_in=self.n_time_in,\n",
    "                            n_time_out=self.n_time_out,\n",
    "                            n_s=self.n_s,\n",
    "                            n_x=self.n_x,\n",
    "                            n_s_hidden=self.n_s_hidden,\n",
    "                            n_x_hidden=self.n_x_hidden,\n",
    "                            stack_types=self.stack_types,\n",
    "                            n_blocks=self.n_blocks,\n",
    "                            n_layers=self.n_layers,\n",
    "                            n_mlp_units=self.n_mlp_units,\n",
    "                            n_pool_kernel_size=self.n_pool_kernel_size,\n",
    "                            n_freq_downsample=self.n_freq_downsample,\n",
    "                            pooling_mode=self.pooling_mode,\n",
    "                            interpolation_mode=self.interpolation_mode,\n",
    "                            dropout_prob_theta=self.dropout_prob_theta,\n",
    "                            activation=self.activation,\n",
    "                            initialization=self.initialization,\n",
    "                            batch_normalization=self.batch_normalization,\n",
    "                            shared_weights=self.shared_weights)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        S = batch['S']\n",
    "        Y = batch['Y']\n",
    "        X = batch['X']\n",
    "        sample_mask = batch['sample_mask']\n",
    "        available_mask = batch['available_mask']\n",
    "\n",
    "        outsample_y, forecast, outsample_mask = self.model(S=S, Y=Y, X=X,\n",
    "                                                           insample_mask=available_mask,\n",
    "                                                           outsample_mask=sample_mask,\n",
    "                                                           return_decomposition=False)\n",
    "\n",
    "        loss = self.loss_fn_train(y=outsample_y,\n",
    "                                  y_hat=forecast,\n",
    "                                  mask=outsample_mask,\n",
    "                                  y_insample=Y)\n",
    "\n",
    "        self.log('train_loss', loss, prog_bar=True, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, idx):\n",
    "        S = batch['S']\n",
    "        Y = batch['Y']\n",
    "        X = batch['X']\n",
    "        sample_mask = batch['sample_mask']\n",
    "        available_mask = batch['available_mask']\n",
    "\n",
    "        outsample_y, forecast, outsample_mask = self.model(S=S, Y=Y, X=X,\n",
    "                                                           insample_mask=available_mask,\n",
    "                                                           outsample_mask=sample_mask,\n",
    "                                                           return_decomposition=False)\n",
    "\n",
    "        loss = self.loss_fn_valid(y=outsample_y,\n",
    "                                  y_hat=forecast,\n",
    "                                  mask=outsample_mask,\n",
    "                                  y_insample=Y)\n",
    "\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def on_fit_start(self):\n",
    "        t.manual_seed(self.random_seed)\n",
    "        np.random.seed(self.random_seed)\n",
    "        random.seed(self.random_seed) #TODO: interaccion rara con window_sampling de validacion\n",
    "\n",
    "    def forward(self, batch):\n",
    "        S = batch['S']\n",
    "        Y = batch['Y']\n",
    "        X = batch['X']\n",
    "        sample_mask = batch['sample_mask']\n",
    "        available_mask = batch['available_mask']\n",
    "\n",
    "        if self.return_decomposition:\n",
    "            outsample_y, forecast, block_forecast, outsample_mask = self.model(S=S, Y=Y, X=X,\n",
    "                                                                     insample_mask=available_mask,\n",
    "                                                                     outsample_mask=sample_mask,\n",
    "                                                                     return_decomposition=True)\n",
    "            return outsample_y, forecast, block_forecast, outsample_mask\n",
    "\n",
    "        outsample_y, forecast, outsample_mask = self.model(S=S, Y=Y, X=X,\n",
    "                                                           insample_mask=available_mask,\n",
    "                                                           outsample_mask=sample_mask,\n",
    "                                                           return_decomposition=False)\n",
    "        return outsample_y, forecast, outsample_mask\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.model.parameters(),\n",
    "                               lr=self.learning_rate, \n",
    "                               weight_decay=self.weight_decay)\n",
    "        \n",
    "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                                 step_size=self.lr_decay_step_size, \n",
    "                                                 gamma=self.lr_decay)\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': lr_scheduler}\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def forecast(self: NHITS, \n",
    "             Y_df: pd.DataFrame, \n",
    "             X_df: pd.DataFrame = None, S_df: pd.DataFrame = None, \n",
    "             batch_size: int =1, trainer: pl.Trainer =None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Method for forecasting self.n_time_out periods after last timestamp of Y_df.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Y_df: pd.DataFrame\n",
    "        Dataframe with target time-series data, needs 'unique_id','ds' and 'y' columns.\n",
    "    X_df: pd.DataFrame\n",
    "        Dataframe with exogenous time-series data, needs 'unique_id' and 'ds' columns.\n",
    "        Note that 'unique_id' and 'ds' must match Y_df plus the forecasting horizon.\n",
    "    S_df: pd.DataFrame\n",
    "        Dataframe with static data, needs 'unique_id' column.\n",
    "    bath_size: int\n",
    "        Batch size for forecasting.\n",
    "    trainer: pl.Trainer\n",
    "        Trainer object for model training and evaluation.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    forecast_df: pd.DataFrame\n",
    "        Dataframe with forecasts.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add forecast dates to Y_df\n",
    "    Y_df = Y_df.reset_index(drop=True)\n",
    "    Y_df['ds'] = pd.to_datetime(Y_df['ds'])\n",
    "    if X_df is not None:\n",
    "        X_df = X_df.reset_index(drop=True)\n",
    "        X_df['ds'] = pd.to_datetime(X_df['ds'])\n",
    "        \n",
    "    forecast_dates = pd.date_range(Y_df['ds'].max(), \n",
    "                                   periods=self.n_time_out+1, freq=self.frequency)[1:]\n",
    "    index = pd.MultiIndex.from_product([Y_df['unique_id'].unique(), \n",
    "                                        forecast_dates], names=['unique_id', 'ds'])\n",
    "    forecast_df = pd.DataFrame({'y':[0]}, index=index).reset_index()\n",
    "    Y_df = Y_df.append(forecast_df).sort_values(['unique_id','ds']).reset_index(drop=True)\n",
    "\n",
    "    # Dataset, loader and trainer\n",
    "    dataset = WindowsDataset(S_df=S_df, Y_df=Y_df, X_df=X_df,\n",
    "                             mask_df=None, f_cols=[],\n",
    "                             input_size=self.n_time_in,\n",
    "                             output_size=self.n_time_out,\n",
    "                             sample_freq=1,\n",
    "                             complete_windows=True,\n",
    "                             ds_in_test=self.n_time_out,\n",
    "                             is_test=True,\n",
    "                             verbose=True)\n",
    "\n",
    "    loader = TimeSeriesLoader(dataset=dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=NUM_WORKERS,\n",
    "                              shuffle=False)\n",
    "\n",
    "    if trainer is None:\n",
    "        gpus = -1 if t.cuda.is_available() else 0\n",
    "        trainer = pl.Trainer(enable_progress_bar=True,\n",
    "                             gpus=gpus,\n",
    "                             logger=False)\n",
    "\n",
    "    # Forecast\n",
    "    outputs = trainer.predict(self, loader)\n",
    "\n",
    "    # Process forecast and include in forecast_df\n",
    "    _, forecast, _ = [t.cat(output).cpu().numpy() for output in zip(*outputs)]\n",
    "    forecast_df['y'] = forecast.flatten()\n",
    "\n",
    "    return forecast_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-HITS Usage Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from neuralforecast.data.datasets.epf import EPF\n",
    "from neuralforecast.data.tsloader import TimeSeriesLoader\n",
    "\n",
    "import pylab as plt\n",
    "from pylab import rcParams\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "FONTSIZE = 19\n",
    "\n",
    "# Load and plot data\n",
    "Y_df, X_df, S_df = EPF.load_groups(directory='./data', groups=['NP','FR'])\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "plt.plot(Y_df[Y_df['unique_id']=='NP'].ds, Y_df[Y_df['unique_id']=='NP'].y.values, color='#628793', linewidth=0.4)\n",
    "plt.ylabel('Price [EUR/MWh]', fontsize=19)\n",
    "plt.xlabel('Date', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare Model and Data Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "model                                             n-hits\n",
      "mode                                              simple\n",
      "activation                                          SELU\n",
      "n_time_in                                             72\n",
      "n_time_out                                            24\n",
      "n_x_hidden                                             8\n",
      "n_s_hidden                                             0\n",
      "stack_types               [identity, identity, identity]\n",
      "constant_n_blocks                                      1\n",
      "constant_n_layers                                      2\n",
      "constant_n_mlp_units                                 256\n",
      "n_pool_kernel_size                             [4, 2, 1]\n",
      "n_freq_downsample                            [24, 12, 1]\n",
      "pooling_mode                                         max\n",
      "interpolation_mode                                linear\n",
      "shared_weights                                     False\n",
      "initialization                              lecun_normal\n",
      "learning_rate                                      0.001\n",
      "batch_size                                             1\n",
      "n_windows                                             32\n",
      "lr_decay                                             0.5\n",
      "lr_decay_step_size                                     2\n",
      "max_epochs                                             1\n",
      "max_steps                                           1000\n",
      "early_stop_patience                                   20\n",
      "eval_freq                                            500\n",
      "batch_normalization                                False\n",
      "dropout_prob_theta                                   0.0\n",
      "dropout_prob_exogenous                               0.0\n",
      "weight_decay                                           0\n",
      "loss_train                                           MAE\n",
      "loss_hypar                                           0.5\n",
      "loss_valid                                           MAE\n",
      "random_seed                                            1\n",
      "idx_to_sample_freq                                     1\n",
      "val_idx_to_sample_freq                                 1\n",
      "n_val_weeks                                           52\n",
      "normalizer_y                                        None\n",
      "normalizer_x                                      median\n",
      "complete_windows                                   False\n",
      "frequency                                              H\n",
      "dtype: object\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Architecture parameters\n",
    "mc = {}\n",
    "mc['model'] = 'n-hits'\n",
    "mc['mode'] = 'simple'\n",
    "mc['activation'] = 'SELU'\n",
    "\n",
    "mc['n_time_in'] = 24*3\n",
    "mc['n_time_out'] = 24\n",
    "mc['n_x_hidden'] = 8\n",
    "mc['n_s_hidden'] = 0\n",
    "\n",
    "mc['stack_types'] = ['identity', 'identity', 'identity']\n",
    "mc['constant_n_blocks'] = 1\n",
    "mc['constant_n_layers'] = 2\n",
    "mc['constant_n_mlp_units'] = 256\n",
    "mc['n_pool_kernel_size'] = [4, 2, 1]\n",
    "mc['n_freq_downsample'] = [24, 12, 1]\n",
    "mc['pooling_mode'] = 'max'\n",
    "mc['interpolation_mode'] = 'linear'\n",
    "mc['shared_weights'] = False\n",
    "\n",
    "# Optimization and regularization parameters\n",
    "mc['initialization'] = 'lecun_normal'\n",
    "mc['learning_rate'] = 0.001\n",
    "mc['batch_size'] = 1\n",
    "mc['n_windows'] = 32\n",
    "mc['lr_decay'] = 0.5\n",
    "mc['lr_decay_step_size'] = 2\n",
    "mc['max_epochs'] = 1\n",
    "mc['max_steps'] = 1000\n",
    "mc['early_stop_patience'] = 20\n",
    "mc['eval_freq'] = 500\n",
    "mc['batch_normalization'] = False\n",
    "mc['dropout_prob_theta'] = 0.0\n",
    "mc['dropout_prob_exogenous'] = 0.0\n",
    "mc['weight_decay'] = 0\n",
    "mc['loss_train'] = 'MAE'\n",
    "mc['loss_hypar'] = 0.5\n",
    "mc['loss_valid'] = mc['loss_train']\n",
    "mc['random_seed'] = 1\n",
    "\n",
    "# Data Parameters\n",
    "mc['idx_to_sample_freq'] = 1\n",
    "mc['val_idx_to_sample_freq'] = 1\n",
    "mc['n_val_weeks'] = 52\n",
    "mc['normalizer_y'] = None\n",
    "mc['normalizer_x'] = 'median'\n",
    "mc['complete_windows'] = False\n",
    "mc['frequency'] = 'H'\n",
    "\n",
    "print(65*'=')\n",
    "print(pd.Series(mc))\n",
    "print(65*'=')\n",
    "\n",
    "mc['n_mlp_units'] = len(mc['stack_types']) * [ mc['constant_n_layers'] * [int(mc['constant_n_mlp_units'])] ]\n",
    "mc['n_blocks'] =  len(mc['stack_types']) * [ mc['constant_n_blocks'] ]\n",
    "mc['n_layers'] =  len(mc['stack_types']) * [ mc['constant_n_layers'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Loaders and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast.experiments.utils import create_datasets\n",
    "\n",
    "train_dataset, val_dataset, test_dataset, scaler_y = create_datasets(mc=mc,\n",
    "                                                                     S_df=S_df, Y_df=Y_df, X_df=X_df,\n",
    "                                                                     f_cols=['Exogenous1', 'Exogenous2'],\n",
    "                                                                     ds_in_val=294*24,\n",
    "                                                                     ds_in_test=728*24)\n",
    "\n",
    "train_loader = TimeSeriesLoader(dataset=train_dataset,\n",
    "                                batch_size=int(mc['batch_size']),\n",
    "                                n_windows=mc['n_windows'],\n",
    "                                num_workers=NUM_WORKERS,\n",
    "                                shuffle=True)\n",
    "\n",
    "val_loader = TimeSeriesLoader(dataset=val_dataset,\n",
    "                              batch_size=int(mc['batch_size']),\n",
    "                              num_workers=NUM_WORKERS,\n",
    "                              shuffle=False)\n",
    "\n",
    "test_loader = TimeSeriesLoader(dataset=test_dataset,\n",
    "                               batch_size=int(mc['batch_size']),\n",
    "                               num_workers=NUM_WORKERS,\n",
    "                               shuffle=False)\n",
    "\n",
    "mc['n_x'], mc['n_s'] = train_dataset.get_n_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NHITS(n_time_in=int(mc['n_time_in']),\n",
    "              n_time_out=int(mc['n_time_out']),\n",
    "              n_x=mc['n_x'],\n",
    "              n_s=mc['n_s'],\n",
    "              n_s_hidden=int(mc['n_s_hidden']),\n",
    "              n_x_hidden=int(mc['n_x_hidden']),\n",
    "              shared_weights=mc['shared_weights'],\n",
    "              initialization=mc['initialization'],\n",
    "              activation=mc['activation'],\n",
    "              stack_types=mc['stack_types'],\n",
    "              n_blocks=mc['n_blocks'],\n",
    "              n_layers=mc['n_layers'],\n",
    "              n_mlp_units=mc['n_mlp_units'],\n",
    "              n_pool_kernel_size=mc['n_pool_kernel_size'],\n",
    "              n_freq_downsample=mc['n_freq_downsample'],\n",
    "              pooling_mode=mc['pooling_mode'],\n",
    "              interpolation_mode=mc['interpolation_mode'],\n",
    "              batch_normalization = mc['batch_normalization'],\n",
    "              dropout_prob_theta=mc['dropout_prob_theta'],\n",
    "              learning_rate=float(mc['learning_rate']),\n",
    "              lr_decay=float(mc['lr_decay']),\n",
    "              lr_decay_step_size=float(mc['lr_decay_step_size']),\n",
    "              weight_decay=mc['weight_decay'],\n",
    "              loss_train=mc['loss_train'],\n",
    "              loss_hypar=float(mc['loss_hypar']),\n",
    "              loss_valid=mc['loss_valid'],\n",
    "              frequency=mc['frequency'],\n",
    "              random_seed=int(mc['random_seed']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33caba85d7a47c4be62f9c8f6a1fd45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/neuralforecast/lib/python3.7/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /tmp/pip-req-build-up3bu5e5/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", \n",
    "                               min_delta=1e-4, \n",
    "                               patience=mc['early_stop_patience'],\n",
    "                               verbose=False,\n",
    "                               mode=\"min\")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=mc['max_epochs'], \n",
    "                     max_steps=mc['max_steps'],\n",
    "                     gradient_clip_val=1.0,\n",
    "                     enable_progress_bar=True, \n",
    "                     log_every_n_steps=2, \n",
    "                     check_val_every_n_epoch=1,\n",
    "                     callbacks=[early_stopping])\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kingtzolivares/Desktop/neuralforecast/neuralforecast/data/tsloader.py:47: UserWarning: This class wraps the pytorch `DataLoader` with a special collate function. If you want to use yours simply use `DataLoader`. Removing collate_fn\n",
      "  'This class wraps the pytorch `DataLoader` with a '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497a0cfacb4248838fc76dad2907023f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 2it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs[0][0].shape torch.Size([7033, 24])\n",
      "outputs[0][1].shape torch.Size([7033, 24])\n",
      "outputs[0][2].shape torch.Size([7033, 24])\n"
     ]
    }
   ],
   "source": [
    "model.return_decomposition = False\n",
    "outputs = trainer.predict(model, val_loader)\n",
    "\n",
    "print(\"outputs[0][0].shape\", outputs[0][0].shape)\n",
    "print(\"outputs[0][1].shape\", outputs[0][1].shape)\n",
    "print(\"outputs[0][2].shape\", outputs[0][2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87355</th>\n",
       "      <td>NP</td>\n",
       "      <td>2016-12-26 19:00:00</td>\n",
       "      <td>27.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87356</th>\n",
       "      <td>NP</td>\n",
       "      <td>2016-12-26 20:00:00</td>\n",
       "      <td>27.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87357</th>\n",
       "      <td>NP</td>\n",
       "      <td>2016-12-26 21:00:00</td>\n",
       "      <td>26.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87358</th>\n",
       "      <td>NP</td>\n",
       "      <td>2016-12-26 22:00:00</td>\n",
       "      <td>26.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87359</th>\n",
       "      <td>NP</td>\n",
       "      <td>2016-12-26 23:00:00</td>\n",
       "      <td>25.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id                  ds      y\n",
       "87355        NP 2016-12-26 19:00:00  27.44\n",
       "87356        NP 2016-12-26 20:00:00  27.11\n",
       "87357        NP 2016-12-26 21:00:00  26.82\n",
       "87358        NP 2016-12-26 22:00:00  26.65\n",
       "87359        NP 2016-12-26 23:00:00  25.68"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_forecast_df = Y_df[Y_df['ds']<'2016-12-27']\n",
    "Y_forecast_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>Exogenous1</th>\n",
       "      <th>Exogenous2</th>\n",
       "      <th>week_day</th>\n",
       "      <th>day_0</th>\n",
       "      <th>day_1</th>\n",
       "      <th>day_2</th>\n",
       "      <th>day_3</th>\n",
       "      <th>day_4</th>\n",
       "      <th>day_5</th>\n",
       "      <th>day_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87379</th>\n",
       "      <td>NP</td>\n",
       "      <td>2016-12-27 19:00:00</td>\n",
       "      <td>0.133135</td>\n",
       "      <td>-0.566365</td>\n",
       "      <td>-0.67449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.927498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87380</th>\n",
       "      <td>NP</td>\n",
       "      <td>2016-12-27 20:00:00</td>\n",
       "      <td>0.010193</td>\n",
       "      <td>-0.569435</td>\n",
       "      <td>-0.67449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.927498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87381</th>\n",
       "      <td>NP</td>\n",
       "      <td>2016-12-27 21:00:00</td>\n",
       "      <td>-0.088980</td>\n",
       "      <td>-0.572021</td>\n",
       "      <td>-0.67449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.927498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87382</th>\n",
       "      <td>NP</td>\n",
       "      <td>2016-12-27 22:00:00</td>\n",
       "      <td>-0.221603</td>\n",
       "      <td>-0.576345</td>\n",
       "      <td>-0.67449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.927498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87383</th>\n",
       "      <td>NP</td>\n",
       "      <td>2016-12-27 23:00:00</td>\n",
       "      <td>-0.426087</td>\n",
       "      <td>-0.583618</td>\n",
       "      <td>-0.67449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.927498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_id                  ds  Exogenous1  Exogenous2  week_day  day_0  \\\n",
       "87379        NP 2016-12-27 19:00:00    0.133135   -0.566365  -0.67449    0.0   \n",
       "87380        NP 2016-12-27 20:00:00    0.010193   -0.569435  -0.67449    0.0   \n",
       "87381        NP 2016-12-27 21:00:00   -0.088980   -0.572021  -0.67449    0.0   \n",
       "87382        NP 2016-12-27 22:00:00   -0.221603   -0.576345  -0.67449    0.0   \n",
       "87383        NP 2016-12-27 23:00:00   -0.426087   -0.583618  -0.67449    0.0   \n",
       "\n",
       "          day_1  day_2  day_3  day_4  day_5  day_6  \n",
       "87379  1.927498    0.0    0.0    0.0    0.0    0.0  \n",
       "87380  1.927498    0.0    0.0    0.0    0.0    0.0  \n",
       "87381  1.927498    0.0    0.0    0.0    0.0    0.0  \n",
       "87382  1.927498    0.0    0.0    0.0    0.0    0.0  \n",
       "87383  1.927498    0.0    0.0    0.0    0.0    0.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_forecast_df = X_df[X_df['ds']<'2016-12-28']\n",
    "X_forecast_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Validation splits\n",
      "\n",
      "INFO:root:                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "FR        0           2011-01-09 2016-12-26 23:00:00\n",
      "          1           2016-12-27 2016-12-27 23:00:00\n",
      "NP        0           2013-01-01 2016-12-26 23:00:00\n",
      "          1           2016-12-27 2016-12-27 23:00:00\n",
      "INFO:root:\n",
      "Total data \t\t\t87288 time stamps \n",
      "Available percentage=100.0, \t87288 time stamps \n",
      "Insample  percentage=0.05, \t48 time stamps \n",
      "Outsample percentage=99.95, \t87240 time stamps \n",
      "\n",
      "/Users/kingtzolivares/Desktop/neuralforecast/neuralforecast/data/tsloader.py:47: UserWarning: This class wraps the pytorch `DataLoader` with a special collate function. If you want to use yours simply use `DataLoader`. Removing collate_fn\n",
      "  'This class wraps the pytorch `DataLoader` with a '\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bdc811ecc284a35bd59c819c0c43ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.return_decomposition = False\n",
    "forecast_df = model.forecast(Y_df=Y_forecast_df, \n",
    "                             X_df=X_forecast_df, \n",
    "                             S_df=S_df, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FR</td>\n",
       "      <td>2016-12-27 00:00:00</td>\n",
       "      <td>46.181789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FR</td>\n",
       "      <td>2016-12-27 01:00:00</td>\n",
       "      <td>35.732353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FR</td>\n",
       "      <td>2016-12-27 02:00:00</td>\n",
       "      <td>42.350479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FR</td>\n",
       "      <td>2016-12-27 03:00:00</td>\n",
       "      <td>37.398766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FR</td>\n",
       "      <td>2016-12-27 04:00:00</td>\n",
       "      <td>37.400967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_id                  ds          y\n",
       "0        FR 2016-12-27 00:00:00  46.181789\n",
       "1        FR 2016-12-27 01:00:00  35.732353\n",
       "2        FR 2016-12-27 02:00:00  42.350479\n",
       "3        FR 2016-12-27 03:00:00  37.398766\n",
       "4        FR 2016-12-27 04:00:00  37.400967"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
