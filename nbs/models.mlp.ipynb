{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77bc74d-58a1-4c14-b477-f52d28f2a869",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15392f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12fa25a4",
   "metadata": {},
   "source": [
    "# MLP\n",
    "> One of the simplest neural architectures are Multi Layer Perceptrons (`MLP`) composed of stacked Fully Connected Neural Networks trained with backpropagation. Each node in the architecture is capable of modeling non-linear relationships granted by their activation functions. Novel activations like Rectified Linear Units (`ReLU`) have greatly improved the ability to fit deeper networks overcoming gradient vanishing problems that were associated with `Sigmoid` and `TanH` activations. For the forecasting task the last layer is changed to follow a auto-regression problem.<br><br>**References**<br>-[Rosenblatt, F. (1958). \"The perceptron: A probabilistic model for information storage and organization in the brain.\"](https://psycnet.apa.org/record/1959-09865-001)<br>-[Fukushima, K. (1975). \"Cognitron: A self-organizing multilayered neural network.\"](https://pascal-francis.inist.fr/vibad/index.php?action=getRecordDetail&idt=PASCAL7750396723)<br>-[Vinod Nair, Geoffrey E. Hinton (2010). \"Rectified Linear Units Improve Restricted Boltzmann Machines\"](https://www.cs.toronto.edu/~fritz/absps/reluICML.pdf)<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6036ce9",
   "metadata": {},
   "source": [
    "![Figure 1. Three layer MLP with autorregresive inputs.](imgs_models/mlp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2508f7a9-1433-4ad8-8f2f-0078c6ed6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import test_eq\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44065066-e72a-431f-938f-1528adef9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from typing import Optional, Callable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "from neuralforecast.common._base_windows import BaseWindows\n",
    "from neuralforecast.common._modules import RevIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2885bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export     \n",
    "\n",
    "class GLU_FFN(nn.Module):\n",
    "    def __init__(self, d_hidden: int, d_ff: int, dropout: float = 0.1, activation: Callable = F.relu, bias: bool = True) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Implementation of Feedforward model\n",
    "        self.linear1 = nn.Linear(d_hidden, d_ff, bias=bias)\n",
    "        self.linear1g = nn.Linear(d_hidden, d_ff, bias=bias)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(d_ff, d_hidden, bias=bias)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x1 = self.dropout1(self.linear1(x))\n",
    "        x2 = self.linear1g(x)\n",
    "        hidden = self.activation(x1) * x2\n",
    "        return self.dropout2(self.linear2(hidden))\n",
    "\n",
    "class PatchMixLayer(nn.Module):\n",
    "    def __init__(self, d_hidden: int, n_patches: int, d_ff: int, dropout: float = 0.1, activation: Callable = F.relu, bias: bool = True) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Patch FFN\n",
    "        self.patch_ffn = GLU_FFN(d_hidden, d_ff, dropout, activation, bias)\n",
    "        self.norm1 = nn.BatchNorm1d(n_patches)\n",
    "\n",
    "        # Feature ffn\n",
    "        self.feature_ffn = GLU_FFN(n_patches, d_ff, dropout, activation, bias)\n",
    "        self.norm2 = nn.BatchNorm1d(d_hidden)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:                # [B, n_patches, hidden_size]\n",
    "        \n",
    "        x = self.norm1(x + self.patch_ffn(x))\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.norm2(x + self.feature_ffn(x))\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce70cd14-ecb1-4205-8511-fecbd26c8408",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MLP(BaseWindows):\n",
    "    \"\"\" MLP\n",
    "\n",
    "    Modified MLP\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `h`: int, forecast horizon.<br>\n",
    "    `input_size`: int, considered autorregresive inputs (lags), y=[1,2,3,4] input_size=2 -> lags=[1,2].<br>\n",
    "    `hidden_size`: int=16, units for the hidden state size.<br>\n",
    "    `dropout`: float=0.1, dropout rate used for the dropout layers throughout the architecture.<br>\n",
    "    `futr_exog_list`: str list, future exogenous columns.<br>\n",
    "    `hist_exog_list`: str list, historic exogenous columns.<br>\n",
    "    `stat_exog_list`: str list, static exogenous columns.<br>\n",
    "    `exclude_insample_y`: bool=False, the model skips the autoregressive features y[t-input_size:t] if True.<br>\n",
    "    `loss`: PyTorch module, instantiated train loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
    "    `valid_loss`: PyTorch module=`loss`, instantiated valid loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
    "    `max_steps`: int=1000, maximum number of training steps.<br>\n",
    "    `learning_rate`: float=1e-3, Learning rate between (0, 1).<br>\n",
    "    `num_lr_decays`: int=-1, Number of learning rate decays, evenly distributed across max_steps.<br>\n",
    "    `early_stop_patience_steps`: int=-1, Number of validation iterations before early stopping.<br>\n",
    "    `val_check_steps`: int=100, Number of training steps between every validation loss check.<br>\n",
    "    `batch_size`: int=32, number of different series in each batch.<br>\n",
    "    `valid_batch_size`: int=None, number of different series in each validation and test batch, if None uses batch_size.<br>\n",
    "    `windows_batch_size`: int=1024, number of windows to sample in each training batch, default uses all.<br>\n",
    "    `inference_windows_batch_size`: int=-1, number of windows to sample in each inference batch, -1 uses all.<br>\n",
    "    `start_padding_enabled`: bool=False, if True, the model will pad the time series with zeros at the beginning, by input size.<br>\n",
    "    `step_size`: int=1, step size between each window of temporal data.<br>\n",
    "    `scaler_type`: str='identity', type of scaler for temporal inputs normalization see [temporal scalers](https://nixtla.github.io/neuralforecast/common.scalers.html).<br>\n",
    "    `random_seed`: int=1, random_seed for pytorch initializer and numpy generators.<br>\n",
    "    `drop_last_loader`: bool=False, if True `TimeSeriesDataLoader` drops last non-full batch.<br>\n",
    "    `alias`: str, optional,  Custom name of the model.<br>\n",
    "    `optimizer`: Subclass of 'torch.optim.Optimizer', optional, user specified optimizer instead of the default choice (Adam).<br>\n",
    "    `optimizer_kwargs`: dict, optional, list of parameters used by the user specified `optimizer`.<br>\n",
    "    `lr_scheduler`: Subclass of 'torch.optim.lr_scheduler.LRScheduler', optional, user specified lr_scheduler instead of the default choice (StepLR).<br>\n",
    "    `lr_scheduler_kwargs`: dict, optional, list of parameters used by the user specified `lr_scheduler`.<br>\n",
    "    `dataloader_kwargs`: dict, optional, list of parameters passed into the PyTorch Lightning dataloader by the `TimeSeriesDataLoader`. <br>\n",
    "    `**trainer_kwargs`: int,  keyword trainer arguments inherited from [PyTorch Lighning's trainer](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).<br>    \n",
    "\n",
    "    **References**<br>  \n",
    "\n",
    "    \"\"\"\n",
    "    # Class attributes\n",
    "    SAMPLING_TYPE = 'windows'\n",
    "    EXOGENOUS_FUTR = False\n",
    "    EXOGENOUS_HIST = False\n",
    "    EXOGENOUS_STAT = False\n",
    "\n",
    "    def __init__(\n",
    "                self,\n",
    "                h: int,\n",
    "                input_size: int,\n",
    "                encoder_layers: int = 3,\n",
    "                hidden_size: int = 128,\n",
    "                linear_hidden_size: int = 256,\n",
    "                dropout: float = 0.2,\n",
    "                patch_len: int = 16,\n",
    "                stride: int = 8,\n",
    "                revin: bool = True,\n",
    "                linear_bias: bool = True,\n",
    "                activation: Callable = F.gelu,\n",
    "                futr_exog_list=None,\n",
    "                hist_exog_list=None,\n",
    "                stat_exog_list=None,\n",
    "                exclude_insample_y=False,\n",
    "                loss=MAE(),\n",
    "                valid_loss=None,\n",
    "                max_steps: int = 5000,\n",
    "                learning_rate: float = 1e-4,\n",
    "                num_lr_decays: int = -1,\n",
    "                early_stop_patience_steps: int = -1,\n",
    "                val_check_steps: int = 100,\n",
    "                batch_size: int = 32,\n",
    "                valid_batch_size: Optional[int] = None,\n",
    "                windows_batch_size=1024,\n",
    "                inference_windows_batch_size=1024,\n",
    "                start_padding_enabled=False,\n",
    "                step_size: int = 1,\n",
    "                scaler_type: str = \"identity\",\n",
    "                random_seed: int = 1,\n",
    "                drop_last_loader: bool = False,\n",
    "                optimizer=None,\n",
    "                optimizer_kwargs=None,\n",
    "                lr_scheduler=None,\n",
    "                lr_scheduler_kwargs=None,\n",
    "                dataloader_kwargs=None,\n",
    "                **trainer_kwargs\n",
    "            ):\n",
    "        super(MLP, self).__init__(\n",
    "            h=h,\n",
    "            input_size=input_size,\n",
    "            futr_exog_list=futr_exog_list,\n",
    "            hist_exog_list=hist_exog_list,\n",
    "            stat_exog_list=stat_exog_list,\n",
    "            exclude_insample_y = exclude_insample_y,\n",
    "            loss=loss,\n",
    "            valid_loss=valid_loss,\n",
    "            max_steps=max_steps,\n",
    "            learning_rate=learning_rate,\n",
    "            num_lr_decays=num_lr_decays,\n",
    "            early_stop_patience_steps=early_stop_patience_steps,\n",
    "            val_check_steps=val_check_steps,\n",
    "            batch_size=batch_size,\n",
    "            valid_batch_size=valid_batch_size,\n",
    "            windows_batch_size=windows_batch_size,\n",
    "            inference_windows_batch_size=inference_windows_batch_size,\n",
    "            start_padding_enabled=start_padding_enabled,\n",
    "            step_size=step_size,\n",
    "            scaler_type=scaler_type,\n",
    "            random_seed=random_seed,\n",
    "            drop_last_loader=drop_last_loader,\n",
    "            optimizer=optimizer,\n",
    "            optimizer_kwargs=optimizer_kwargs,\n",
    "            lr_scheduler=lr_scheduler,\n",
    "            lr_scheduler_kwargs=lr_scheduler_kwargs,\n",
    "            dataloader_kwargs=dataloader_kwargs,\n",
    "            **trainer_kwargs\n",
    "        )\n",
    "\n",
    "        #----------------------------------- Parse dimensions -----------------------------------#\n",
    "        self.h = h\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # RevIN\n",
    "        self.revin = revin\n",
    "        if self.revin:\n",
    "          self.revin_layer = RevIN(1, affine=False, subtract_last=True)\n",
    "\n",
    "        # Patches\n",
    "        n_patches = int((input_size - patch_len) / stride + 1)\n",
    "        self.padding_patch_layer = nn.ReplicationPad1d((0, stride))\n",
    "        n_patches += 1\n",
    "        self.patch_len = min(input_size + stride, patch_len)\n",
    "        self.stride = stride\n",
    "\n",
    "        # Linear projection\n",
    "        self.linear_projection = nn.Linear(patch_len, hidden_size)       \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "      \n",
    "        # Patchmixer\n",
    "        patchmix_layers = [PatchMixLayer(hidden_size, n_patches, linear_hidden_size, dropout, activation, linear_bias) for _ in range(encoder_layers)]\n",
    "        self.patchmixer = nn.Sequential(*patchmix_layers)\n",
    "\n",
    "        # Decoder\n",
    "        self.linear_decoder = nn.Sequential(\n",
    "            nn.Flatten(start_dim=-2),\n",
    "            nn.Linear(n_patches * hidden_size, h * self.loss.outputsize_multiplier),\n",
    "        )            \n",
    "\n",
    "    def forward(self, windows_batch):\n",
    "        # Parse windows_batch\n",
    "        x    = windows_batch['insample_y']                          #   [B, L] \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # RevIN\n",
    "        if self.revin:\n",
    "            x = self.revin_layer(x.unsqueeze(-1), mode=\"norm\")      #   [B, L] -> [B, L, 1]\n",
    "            x = x.squeeze(-1)                                       #   [B, L, 1] -> [B, L]\n",
    "\n",
    "        # Padding\n",
    "        x = self.padding_patch_layer(x.unsqueeze(1))                #   [B, 1, L] -> [B, 1, L + stride]\n",
    "        x = x.squeeze(1)                                            #   [B, 1, L + stride] -> [B, L + stride]\n",
    "\n",
    "        # Unfold patches\n",
    "        x = x.unfold(-1, self.patch_len, self.stride)               #   [B, L] -> [B, n_patches, patch_len]\n",
    "\n",
    "        # Linear projection\n",
    "        x = self.dropout(self.linear_projection(x))                 #   [B, n_patches, patch_len] -> [B, n_patches, hidden_size]\n",
    "        \n",
    "        # Encoder\n",
    "        x = self.patchmixer(x)                                      #   [B, n_patches, hidden_size] -> [B, n_patches, hidden_size]        \n",
    "\n",
    "        # Decoder\n",
    "        x = self.linear_decoder(x)                                  #   [B, n_patches, hidden_size] -> [B, h * n_outputs]       \n",
    "        x = x.reshape(batch_size, self.h, -1)                       #   [B, h * n_outputs] -> [B, h, n_outputs]\n",
    "\n",
    "        # RevIN\n",
    "        if self.revin:\n",
    "            x = self.revin_layer(x, mode=\"denorm\")\n",
    "\n",
    "        # Map to output domain\n",
    "        forecast = self.loss.domain_map(x)\n",
    "        \n",
    "        return forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc06a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/models/mlp.py#L218){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MLP\n",
       "\n",
       ">      MLP (h:int, input_size:int, encoder_layers:int=3, hidden_size:int=128,\n",
       ">           linear_hidden_size:int=256, dropout:float=0.2, patch_len:int=16,\n",
       ">           stride:int=8, revin:bool=True, linear_bias:bool=True,\n",
       ">           activation:Callable=<built-in function gelu>, futr_exog_list=None,\n",
       ">           hist_exog_list=None, stat_exog_list=None, exclude_insample_y=False,\n",
       ">           loss=MAE(), valid_loss=None, max_steps:int=5000,\n",
       ">           learning_rate:float=0.0001, num_lr_decays:int=-1,\n",
       ">           early_stop_patience_steps:int=-1, val_check_steps:int=100,\n",
       ">           batch_size:int=32, valid_batch_size:Optional[int]=None,\n",
       ">           windows_batch_size=1024, inference_windows_batch_size=1024,\n",
       ">           start_padding_enabled=False, step_size:int=1,\n",
       ">           scaler_type:str='identity', random_seed:int=1,\n",
       ">           drop_last_loader:bool=False, optimizer=None, optimizer_kwargs=None,\n",
       ">           lr_scheduler=None, lr_scheduler_kwargs=None, dataloader_kwargs=None,\n",
       ">           **trainer_kwargs)\n",
       "\n",
       "*MLP\n",
       "\n",
       "Modified MLP\n",
       "\n",
       "**Parameters:**<br>\n",
       "`h`: int, forecast horizon.<br>\n",
       "`input_size`: int, considered autorregresive inputs (lags), y=[1,2,3,4] input_size=2 -> lags=[1,2].<br>\n",
       "`hidden_size`: int=16, units for the hidden state size.<br>\n",
       "`dropout`: float=0.1, dropout rate used for the dropout layers throughout the architecture.<br>\n",
       "`futr_exog_list`: str list, future exogenous columns.<br>\n",
       "`hist_exog_list`: str list, historic exogenous columns.<br>\n",
       "`stat_exog_list`: str list, static exogenous columns.<br>\n",
       "`exclude_insample_y`: bool=False, the model skips the autoregressive features y[t-input_size:t] if True.<br>\n",
       "`loss`: PyTorch module, instantiated train loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
       "`valid_loss`: PyTorch module=`loss`, instantiated valid loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
       "`max_steps`: int=1000, maximum number of training steps.<br>\n",
       "`learning_rate`: float=1e-3, Learning rate between (0, 1).<br>\n",
       "`num_lr_decays`: int=-1, Number of learning rate decays, evenly distributed across max_steps.<br>\n",
       "`early_stop_patience_steps`: int=-1, Number of validation iterations before early stopping.<br>\n",
       "`val_check_steps`: int=100, Number of training steps between every validation loss check.<br>\n",
       "`batch_size`: int=32, number of different series in each batch.<br>\n",
       "`valid_batch_size`: int=None, number of different series in each validation and test batch, if None uses batch_size.<br>\n",
       "`windows_batch_size`: int=1024, number of windows to sample in each training batch, default uses all.<br>\n",
       "`inference_windows_batch_size`: int=-1, number of windows to sample in each inference batch, -1 uses all.<br>\n",
       "`start_padding_enabled`: bool=False, if True, the model will pad the time series with zeros at the beginning, by input size.<br>\n",
       "`step_size`: int=1, step size between each window of temporal data.<br>\n",
       "`scaler_type`: str='identity', type of scaler for temporal inputs normalization see [temporal scalers](https://nixtla.github.io/neuralforecast/common.scalers.html).<br>\n",
       "`random_seed`: int=1, random_seed for pytorch initializer and numpy generators.<br>\n",
       "`drop_last_loader`: bool=False, if True `TimeSeriesDataLoader` drops last non-full batch.<br>\n",
       "`alias`: str, optional,  Custom name of the model.<br>\n",
       "`optimizer`: Subclass of 'torch.optim.Optimizer', optional, user specified optimizer instead of the default choice (Adam).<br>\n",
       "`optimizer_kwargs`: dict, optional, list of parameters used by the user specified `optimizer`.<br>\n",
       "`lr_scheduler`: Subclass of 'torch.optim.lr_scheduler.LRScheduler', optional, user specified lr_scheduler instead of the default choice (StepLR).<br>\n",
       "`lr_scheduler_kwargs`: dict, optional, list of parameters used by the user specified `lr_scheduler`.<br>\n",
       "`dataloader_kwargs`: dict, optional, list of parameters passed into the PyTorch Lightning dataloader by the `TimeSeriesDataLoader`. <br>\n",
       "`**trainer_kwargs`: int,  keyword trainer arguments inherited from [PyTorch Lighning's trainer](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).<br>    \n",
       "\n",
       "**References**<br>*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/models/mlp.py#L218){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MLP\n",
       "\n",
       ">      MLP (h:int, input_size:int, encoder_layers:int=3, hidden_size:int=128,\n",
       ">           linear_hidden_size:int=256, dropout:float=0.2, patch_len:int=16,\n",
       ">           stride:int=8, revin:bool=True, linear_bias:bool=True,\n",
       ">           activation:Callable=<built-in function gelu>, futr_exog_list=None,\n",
       ">           hist_exog_list=None, stat_exog_list=None, exclude_insample_y=False,\n",
       ">           loss=MAE(), valid_loss=None, max_steps:int=5000,\n",
       ">           learning_rate:float=0.0001, num_lr_decays:int=-1,\n",
       ">           early_stop_patience_steps:int=-1, val_check_steps:int=100,\n",
       ">           batch_size:int=32, valid_batch_size:Optional[int]=None,\n",
       ">           windows_batch_size=1024, inference_windows_batch_size=1024,\n",
       ">           start_padding_enabled=False, step_size:int=1,\n",
       ">           scaler_type:str='identity', random_seed:int=1,\n",
       ">           drop_last_loader:bool=False, optimizer=None, optimizer_kwargs=None,\n",
       ">           lr_scheduler=None, lr_scheduler_kwargs=None, dataloader_kwargs=None,\n",
       ">           **trainer_kwargs)\n",
       "\n",
       "*MLP\n",
       "\n",
       "Modified MLP\n",
       "\n",
       "**Parameters:**<br>\n",
       "`h`: int, forecast horizon.<br>\n",
       "`input_size`: int, considered autorregresive inputs (lags), y=[1,2,3,4] input_size=2 -> lags=[1,2].<br>\n",
       "`hidden_size`: int=16, units for the hidden state size.<br>\n",
       "`dropout`: float=0.1, dropout rate used for the dropout layers throughout the architecture.<br>\n",
       "`futr_exog_list`: str list, future exogenous columns.<br>\n",
       "`hist_exog_list`: str list, historic exogenous columns.<br>\n",
       "`stat_exog_list`: str list, static exogenous columns.<br>\n",
       "`exclude_insample_y`: bool=False, the model skips the autoregressive features y[t-input_size:t] if True.<br>\n",
       "`loss`: PyTorch module, instantiated train loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
       "`valid_loss`: PyTorch module=`loss`, instantiated valid loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
       "`max_steps`: int=1000, maximum number of training steps.<br>\n",
       "`learning_rate`: float=1e-3, Learning rate between (0, 1).<br>\n",
       "`num_lr_decays`: int=-1, Number of learning rate decays, evenly distributed across max_steps.<br>\n",
       "`early_stop_patience_steps`: int=-1, Number of validation iterations before early stopping.<br>\n",
       "`val_check_steps`: int=100, Number of training steps between every validation loss check.<br>\n",
       "`batch_size`: int=32, number of different series in each batch.<br>\n",
       "`valid_batch_size`: int=None, number of different series in each validation and test batch, if None uses batch_size.<br>\n",
       "`windows_batch_size`: int=1024, number of windows to sample in each training batch, default uses all.<br>\n",
       "`inference_windows_batch_size`: int=-1, number of windows to sample in each inference batch, -1 uses all.<br>\n",
       "`start_padding_enabled`: bool=False, if True, the model will pad the time series with zeros at the beginning, by input size.<br>\n",
       "`step_size`: int=1, step size between each window of temporal data.<br>\n",
       "`scaler_type`: str='identity', type of scaler for temporal inputs normalization see [temporal scalers](https://nixtla.github.io/neuralforecast/common.scalers.html).<br>\n",
       "`random_seed`: int=1, random_seed for pytorch initializer and numpy generators.<br>\n",
       "`drop_last_loader`: bool=False, if True `TimeSeriesDataLoader` drops last non-full batch.<br>\n",
       "`alias`: str, optional,  Custom name of the model.<br>\n",
       "`optimizer`: Subclass of 'torch.optim.Optimizer', optional, user specified optimizer instead of the default choice (Adam).<br>\n",
       "`optimizer_kwargs`: dict, optional, list of parameters used by the user specified `optimizer`.<br>\n",
       "`lr_scheduler`: Subclass of 'torch.optim.lr_scheduler.LRScheduler', optional, user specified lr_scheduler instead of the default choice (StepLR).<br>\n",
       "`lr_scheduler_kwargs`: dict, optional, list of parameters used by the user specified `lr_scheduler`.<br>\n",
       "`dataloader_kwargs`: dict, optional, list of parameters passed into the PyTorch Lightning dataloader by the `TimeSeriesDataLoader`. <br>\n",
       "`**trainer_kwargs`: int,  keyword trainer arguments inherited from [PyTorch Lighning's trainer](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).<br>    \n",
       "\n",
       "**References**<br>*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a23696b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### MLP.fit\n",
       "\n",
       ">      MLP.fit (dataset, val_size=0, test_size=0, random_seed=None,\n",
       ">               distributed_config=None)\n",
       "\n",
       "*Fit.\n",
       "\n",
       "The `fit` method, optimizes the neural network's weights using the\n",
       "initialization parameters (`learning_rate`, `windows_batch_size`, ...)\n",
       "and the `loss` function as defined during the initialization.\n",
       "Within `fit` we use a PyTorch Lightning `Trainer` that\n",
       "inherits the initialization's `self.trainer_kwargs`, to customize\n",
       "its inputs, see [PL's trainer arguments](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).\n",
       "\n",
       "The method is designed to be compatible with SKLearn-like classes\n",
       "and in particular to be compatible with the StatsForecast library.\n",
       "\n",
       "By default the `model` is not saving training checkpoints to protect\n",
       "disk memory, to get them change `enable_checkpointing=True` in `__init__`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`val_size`: int, validation size for temporal cross-validation.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`test_size`: int, test size for temporal cross-validation.<br>*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### MLP.fit\n",
       "\n",
       ">      MLP.fit (dataset, val_size=0, test_size=0, random_seed=None,\n",
       ">               distributed_config=None)\n",
       "\n",
       "*Fit.\n",
       "\n",
       "The `fit` method, optimizes the neural network's weights using the\n",
       "initialization parameters (`learning_rate`, `windows_batch_size`, ...)\n",
       "and the `loss` function as defined during the initialization.\n",
       "Within `fit` we use a PyTorch Lightning `Trainer` that\n",
       "inherits the initialization's `self.trainer_kwargs`, to customize\n",
       "its inputs, see [PL's trainer arguments](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).\n",
       "\n",
       "The method is designed to be compatible with SKLearn-like classes\n",
       "and in particular to be compatible with the StatsForecast library.\n",
       "\n",
       "By default the `model` is not saving training checkpoints to protect\n",
       "disk memory, to get them change `enable_checkpointing=True` in `__init__`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`val_size`: int, validation size for temporal cross-validation.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`test_size`: int, test size for temporal cross-validation.<br>*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MLP.fit, name='MLP.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8475d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### MLP.predict\n",
       "\n",
       ">      MLP.predict (dataset, test_size=None, step_size=1, random_seed=None,\n",
       ">                   **data_module_kwargs)\n",
       "\n",
       "*Predict.\n",
       "\n",
       "Neural network prediction with PL's `Trainer` execution of `predict_step`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`test_size`: int=None, test size for temporal cross-validation.<br>\n",
       "`step_size`: int=1, Step size between each window.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`**data_module_kwargs`: PL's TimeSeriesDataModule args, see [documentation](https://pytorch-lightning.readthedocs.io/en/1.6.1/extensions/datamodules.html#using-a-datamodule).*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### MLP.predict\n",
       "\n",
       ">      MLP.predict (dataset, test_size=None, step_size=1, random_seed=None,\n",
       ">                   **data_module_kwargs)\n",
       "\n",
       "*Predict.\n",
       "\n",
       "Neural network prediction with PL's `Trainer` execution of `predict_step`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`test_size`: int=None, test size for temporal cross-validation.<br>\n",
       "`step_size`: int=1, Step size between each window.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`**data_module_kwargs`: PL's TimeSeriesDataModule args, see [documentation](https://pytorch-lightning.readthedocs.io/en/1.6.1/extensions/datamodules.html#using-a-datamodule).*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MLP.predict, name='MLP.predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac34472d-5670-45b5-a7c5-1dba54f8e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuralforecast.utils import AirPassengersDF as Y_df\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c61645f",
   "metadata": {},
   "source": [
    "## Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b60ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                | Type             | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0 | loss                | MAE              | 0      | train\n",
      "1 | padder_train        | ConstantPad1d    | 0      | train\n",
      "2 | scaler              | TemporalNorm     | 0      | train\n",
      "3 | revin_layer         | RevIN            | 0      | train\n",
      "4 | padding_patch_layer | ReplicationPad1d | 0      | train\n",
      "5 | linear_projection   | Linear           | 2.2 K  | train\n",
      "6 | dropout             | Dropout          | 0      | train\n",
      "7 | patchmixer          | Sequential       | 306 K  | train\n",
      "8 | linear_decoder      | Sequential       | 4.6 K  | train\n",
      "-----------------------------------------------------------------\n",
      "312 K     Trainable params\n",
      "0         Non-trainable params\n",
      "312 K     Total params\n",
      "1.251     Total estimated model params size (MB)\n",
      "56        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399: 100%|██████████| 1/1 [00:00<00:00, 20.94it/s, v_num=11669, train_loss_step=0.439, train_loss_epoch=0.439, valid_loss=35.00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ospra\\miniconda3\\envs\\neuralforecast\\lib\\site-packages\\utilsforecast\\processing.py:384: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(freq)\n",
      "c:\\Users\\ospra\\miniconda3\\envs\\neuralforecast\\lib\\site-packages\\utilsforecast\\processing.py:438: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(freq)\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 113.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "# from neuralforecast.models import MLP\n",
    "from neuralforecast.losses.pytorch import DistributionLoss, GMM\n",
    "from neuralforecast.utils import AirPassengersPanel, AirPassengersStatic\n",
    "\n",
    "Y_train_df = AirPassengersPanel[AirPassengersPanel.ds<AirPassengersPanel['ds'].values[-12]] # 132 train\n",
    "Y_test_df = AirPassengersPanel[AirPassengersPanel.ds>=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n",
    "\n",
    "model = MLP(h=12, \n",
    "            input_size=24,\n",
    "            # loss=GMM(n_components=7, return_params=True, level=[80,90]),\n",
    "            # loss=DistributionLoss(distribution='Normal', level=[80, 90]),\n",
    "            scaler_type=\"robust\",\n",
    "            max_steps=1000,\n",
    "            early_stop_patience_steps=3,\n",
    "            revin=True,\n",
    "            )\n",
    "\n",
    "fcst = NeuralForecast(\n",
    "    models=[model],\n",
    "    freq='M'\n",
    ")\n",
    "fcst.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\n",
    "forecasts = fcst.predict(futr_df=Y_test_df)\n",
    "\n",
    "Y_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\n",
    "plot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\n",
    "plot_df = pd.concat([Y_train_df, plot_df])\n",
    "\n",
    "plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n",
    "plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n",
    "plt.plot(plot_df['ds'], plot_df['MLP'], c='blue', label='median')\n",
    "# plt.fill_between(x=plot_df['ds'][-12:], \n",
    "                #  y1=plot_df['MLP-lo-90'][-12:].values, \n",
    "                #  y2=plot_df['MLP-hi-90'][-12:].values,\n",
    "                #  alpha=0.4, label='level 90')\n",
    "# plt.plot(plot_df['ds'], plot_df['MLP-median'], c='blue', label='median')\n",
    "# plt.fill_between(x=plot_df['ds'][-12:], \n",
    "#                  y1=plot_df['MLP-lo-90'][-12:].values, \n",
    "#                  y2=plot_df['MLP-hi-90'][-12:].values,\n",
    "#                  alpha=0.4, label='level 90')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
