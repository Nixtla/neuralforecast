{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp experiments.utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Utils\n",
    "> Set of functions to easily perform experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "ENV_VARS = dict(OMP_NUM_THREADS='2',\n",
    "                OPENBLAS_NUM_THREADS='2',\n",
    "                MKL_NUM_THREADS='3',\n",
    "                VECLIB_MAXIMUM_THREADS='2',\n",
    "                NUMEXPR_NUM_THREADS='3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os\n",
    "# Limit number of threads in numpy and others to avoid throttling\n",
    "os.environ.update(ENV_VARS)\n",
    "import random\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch as t\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "\n",
    "from nixtlats.data.scalers import Scaler\n",
    "from nixtlats.data.tsdataset import TimeSeriesDataset\n",
    "from nixtlats.data.tsloader import TimeSeriesLoader\n",
    "from nixtlats.models.esrnn.esrnn import ESRNN\n",
    "from nixtlats.models.esrnn.mqesrnn import MQESRNN\n",
    "from nixtlats.models.nbeats.nbeats import NBEATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_mask_dfs(Y_df, ds_in_val, ds_in_test):\n",
    "    # train mask\n",
    "    train_mask_df = Y_df.copy()[['unique_id', 'ds']]\n",
    "    train_mask_df.sort_values(by=['unique_id', 'ds'], inplace=True)\n",
    "    train_mask_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    train_mask_df['sample_mask'] = 1\n",
    "    train_mask_df['available_mask'] = 1\n",
    "    \n",
    "    idx_out = train_mask_df.groupby('unique_id').tail(ds_in_val+ds_in_test).index\n",
    "    train_mask_df.loc[idx_out, 'sample_mask'] = 0\n",
    "    \n",
    "    # test mask\n",
    "    test_mask_df = train_mask_df.copy()\n",
    "    test_mask_df['sample_mask'] = 0\n",
    "    idx_test = test_mask_df.groupby('unique_id').tail(ds_in_test).index\n",
    "    test_mask_df.loc[idx_test, 'sample_mask'] = 1\n",
    "    \n",
    "    # validation mask\n",
    "    val_mask_df = train_mask_df.copy()\n",
    "    val_mask_df['sample_mask'] = 1\n",
    "    val_mask_df['sample_mask'] = val_mask_df['sample_mask'] - train_mask_df['sample_mask']\n",
    "    val_mask_df['sample_mask'] = val_mask_df['sample_mask'] - test_mask_df['sample_mask']\n",
    "\n",
    "    assert len(train_mask_df)==len(Y_df), \\\n",
    "        f'The mask_df length {len(train_mask_df)} is not equal to Y_df length {len(Y_df)}'\n",
    "    \n",
    "    return train_mask_df, val_mask_df, test_mask_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_random_mask_dfs(Y_df, ds_in_test, \n",
    "                        n_val_windows, n_ds_val_window,\n",
    "                        n_uids, freq):\n",
    "    \"\"\"\n",
    "    Generates train, test and random validation mask.\n",
    "    Train mask begins by avoiding ds_in_test\n",
    "    \n",
    "    Validation mask: 1) samples n_uids unique ids\n",
    "                     2) creates windows of size n_ds_val_window\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds_in_test: int\n",
    "        Number of ds in test.\n",
    "    n_uids: int\n",
    "        Number of unique ids in validation.\n",
    "    n_val_windows: int\n",
    "        Number of windows for validation.\n",
    "    n_ds_val_window: int\n",
    "        Number of ds in each validation window.\n",
    "    periods: int  \n",
    "        ds_in_test multiplier.\n",
    "    freq: str\n",
    "        string that determines datestamp frequency, used in\n",
    "        random windows creation.\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    #----------------------- Train mask -----------------------#\n",
    "    # Initialize masks\n",
    "    train_mask_df, val_mask_df, test_mask_df = get_mask_dfs(Y_df=Y_df,\n",
    "                                                            ds_in_val=0,\n",
    "                                                            ds_in_test=ds_in_test)\n",
    "    \n",
    "    assert val_mask_df['sample_mask'].sum()==0, 'Muerte'\n",
    "    \n",
    "    #----------------- Random Validation mask -----------------#\n",
    "    # Overwrite validation with random windows\n",
    "    uids = train_mask_df['unique_id'].unique()\n",
    "    val_uids = np.random.choice(uids, n_uids, replace=False)\n",
    "    \n",
    "    # Validation avoids test\n",
    "    idx_test = train_mask_df.groupby('unique_id').tail(ds_in_test).index\n",
    "    available_ds = train_mask_df.loc[~train_mask_df.index.isin(idx_test)]['ds'].unique()\n",
    "    val_init_ds = np.random.choice(available_ds, n_val_windows, replace=False)\n",
    "    \n",
    "    # Creates windows \n",
    "    val_ds = [pd.date_range(init, periods=n_ds_val_window, freq=freq) for init in val_init_ds]\n",
    "    val_ds = np.concatenate(val_ds)\n",
    "\n",
    "    # Cleans random windows from train mask\n",
    "    val_idx = train_mask_df.query('unique_id in @val_uids & ds in @val_ds').index\n",
    "    train_mask_df.loc[val_idx, 'sample_mask'] = 0\n",
    "    val_mask_df.loc[val_idx, 'sample_mask'] = 1\n",
    "    \n",
    "    return train_mask_df, val_mask_df, test_mask_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def scale_data(Y_df, X_df, mask_df, normalizer_y, normalizer_x):\n",
    "    mask = mask_df['available_mask'].values * mask_df['sample_mask'].values\n",
    "    \n",
    "    if normalizer_y is not None:\n",
    "        scaler_y = Scaler(normalizer=normalizer_y)\n",
    "        Y_df['y'] = scaler_y.scale(x=Y_df['y'].values, mask=mask)\n",
    "    else:\n",
    "        scaler_y = None\n",
    "\n",
    "    if normalizer_x is not None:\n",
    "        X_cols = [col for col in X_df.columns if col not in ['unique_id','ds']]\n",
    "        for col in X_cols:\n",
    "            scaler_x = Scaler(normalizer=normalizer_x)\n",
    "            X_df[col] = scaler_x.scale(x=X_df[col].values, mask=mask)\n",
    "\n",
    "    return Y_df, X_df, scaler_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_datasets(mc, S_df, Y_df, X_df, f_cols,\n",
    "                    ds_in_test, ds_in_val,\n",
    "                    n_uids, n_val_windows, freq,\n",
    "                    is_val_random):\n",
    "    #------------------------------------- Available and Validation Mask ------------------------------------#\n",
    "    if is_val_random:\n",
    "        train_mask_df, val_mask_df, test_mask_df = get_random_mask_dfs(Y_df=Y_df, \n",
    "                                                                       ds_in_test=ds_in_test,\n",
    "                                                                       n_uids=n_uids, \n",
    "                                                                       n_val_windows=n_val_windows, \n",
    "                                                                       n_ds_val_window=ds_in_val//n_val_windows,\n",
    "                                                                       freq=freq)\n",
    "    else:\n",
    "        train_mask_df, val_mask_df, test_mask_df = get_mask_dfs(Y_df=Y_df,\n",
    "                                                                ds_in_test=ds_in_test, \n",
    "                                                                ds_in_val=ds_in_val)\n",
    "\n",
    "    #---------------------------------------------- Scale Data ----------------------------------------------#\n",
    "    Y_df, X_df, scaler_y = scale_data(Y_df=Y_df, X_df=X_df, mask_df=train_mask_df,\n",
    "                                      normalizer_y=mc['normalizer_y'], normalizer_x=mc['normalizer_x'])\n",
    "\n",
    "    #----------------------------------------- Declare Dataset and Loaders ----------------------------------#\n",
    "    train_dataset = TimeSeriesDataset(S_df=S_df, Y_df=Y_df, X_df=X_df, \n",
    "                                      mask_df=train_mask_df, f_cols=f_cols, \n",
    "                                      mode=mc['mode'],\n",
    "                                      window_sampling_limit=int(mc['window_sampling_limit']),\n",
    "                                      input_size=int(mc['n_time_in']),\n",
    "                                      output_size=int(mc['n_time_out']),\n",
    "                                      idx_to_sample_freq=int(mc['idx_to_sample_freq']),\n",
    "                                      len_sample_chunks=mc['len_sample_chunks'],\n",
    "                                      complete_inputs=mc['complete_inputs'],\n",
    "                                      verbose=True)\n",
    "    val_dataset   = TimeSeriesDataset(S_df=S_df, Y_df=Y_df, X_df=X_df, \n",
    "                                      mask_df=val_mask_df, f_cols=f_cols, \n",
    "                                      mode=mc['mode'],\n",
    "                                      window_sampling_limit=int(mc['window_sampling_limit']),\n",
    "                                      input_size=int(mc['n_time_in']),\n",
    "                                      output_size=int(mc['n_time_out']),\n",
    "                                      idx_to_sample_freq=int(mc['val_idx_to_sample_freq']),\n",
    "                                      len_sample_chunks=mc['len_sample_chunks'],\n",
    "                                      complete_inputs=mc['complete_inputs'],\n",
    "                                      verbose=True)\n",
    "    test_dataset  = TimeSeriesDataset(S_df=S_df, Y_df=Y_df, X_df=X_df, \n",
    "                                      mask_df=test_mask_df, f_cols=f_cols,\n",
    "                                      mode=mc['mode'],\n",
    "                                      window_sampling_limit=int(mc['window_sampling_limit']),\n",
    "                                      input_size=int(mc['n_time_in']),\n",
    "                                      output_size=int(mc['n_time_out']),\n",
    "                                      idx_to_sample_freq=mc['val_idx_to_sample_freq'],\n",
    "                                      len_sample_chunks=mc['len_sample_chunks'],\n",
    "                                      complete_inputs=False,\n",
    "                                      verbose=True)\n",
    "    \n",
    "    if ds_in_test == 0:\n",
    "        test_dataset = None\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset, scaler_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def instantiate_loaders(mc, train_dataset, val_dataset, test_dataset):\n",
    "    train_loader = TimeSeriesLoader(dataset=train_dataset,\n",
    "                                    batch_size=int(mc['batch_size']),\n",
    "                                    eq_batch_size=mc.get('eq_batch_size') or True,\n",
    "                                    shuffle=True)\n",
    "    if val_dataset is not None:\n",
    "        val_loader = TimeSeriesLoader(dataset=val_dataset,\n",
    "                                      batch_size=1,\n",
    "                                      shuffle=False)\n",
    "        \n",
    "    else:\n",
    "        val_loader = None\n",
    "\n",
    "    if test_dataset is not None:\n",
    "        test_loader = TimeSeriesLoader(dataset=test_dataset,\n",
    "                                       batch_size=1,\n",
    "                                       shuffle=False)\n",
    "    else:\n",
    "        test_loader = None\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def instantiate_nbeats(mc):\n",
    "    mc['n_theta_hidden'] = len(mc['stack_types']) * [ [int(mc['n_hidden']), int(mc['n_hidden'])] ]\n",
    "    model = NBEATS(n_time_in=int(mc['n_time_in']),\n",
    "                   n_time_out=int(mc['n_time_out']),\n",
    "                   n_x=mc['n_x'],\n",
    "                   n_s=mc['n_s'],\n",
    "                   n_s_hidden=int(mc['n_s_hidden']),\n",
    "                   n_x_hidden=int(mc['n_x_hidden']),\n",
    "                   shared_weights=mc['shared_weights'],\n",
    "                   initialization=mc['initialization'],\n",
    "                   activation=mc['activation'],\n",
    "                   stack_types=mc['stack_types'],\n",
    "                   n_blocks=mc['n_blocks'],\n",
    "                   n_layers=mc['n_layers'],\n",
    "                   n_theta_hidden=mc['n_theta_hidden'],\n",
    "                   n_harmonics=int(mc['n_harmonics']),\n",
    "                   n_polynomials=int(mc['n_polynomials']),\n",
    "                   batch_normalization = mc['batch_normalization'],\n",
    "                   dropout_prob_theta=mc['dropout_prob_theta'],\n",
    "                   learning_rate=float(mc['learning_rate']),\n",
    "                   lr_decay=float(mc['lr_decay']),\n",
    "                   lr_decay_step_size=float(mc['lr_decay_step_size']),\n",
    "                   weight_decay=mc['weight_decay'],\n",
    "                   loss_train=mc['loss_train'],\n",
    "                   loss_hypar=float(mc['loss_hypar']),\n",
    "                   loss_valid=mc['loss_valid'],\n",
    "                   frequency=mc['frequency'],\n",
    "                   seasonality=int(mc['seasonality']),\n",
    "                   random_seed=int(mc['random_seed']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def instantiate_esrnn(mc):    \n",
    "    model = ESRNN(# Architecture parameters\n",
    "                  n_series=mc['n_series'],\n",
    "                  n_x=mc['n_x'],\n",
    "                  n_s=mc['n_s'],\n",
    "                  idx_to_sample_freq=int(mc['idx_to_sample_freq']),\n",
    "                  input_size=int(mc['n_time_in']),\n",
    "                  output_size=int(mc['n_time_out']),\n",
    "                  es_component=mc['es_component'],\n",
    "                  cell_type=mc['cell_type'],\n",
    "                  state_hsize=int(mc['state_hsize']),\n",
    "                  dilations=mc['dilations'],\n",
    "                  add_nl_layer=mc['add_nl_layer'],\n",
    "                  # Optimization parameters                \n",
    "                  learning_rate=mc['learning_rate'],\n",
    "                  lr_scheduler_step_size=int(mc['lr_decay_step_size']),\n",
    "                  lr_decay=mc['lr_decay'],\n",
    "                  per_series_lr_multip=mc['per_series_lr_multip'],\n",
    "                  gradient_eps=mc['gradient_eps'],\n",
    "                  gradient_clipping_threshold=mc['gradient_clipping_threshold'],\n",
    "                  rnn_weight_decay=mc['rnn_weight_decay'],\n",
    "                  noise_std=mc['noise_std'],\n",
    "                  level_variability_penalty=mc['level_variability_penalty'],\n",
    "                  testing_percentile=mc['testing_percentile'],\n",
    "                  training_percentile=mc['training_percentile'],\n",
    "                  loss=mc['loss_train'],\n",
    "                  val_loss=mc['loss_valid'],\n",
    "                  seasonality=mc['seasonality']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def instantiate_mqesrnn(mc):    \n",
    "    model = MQESRNN(# Architecture parameters\n",
    "                    n_series=mc['n_series'],\n",
    "                    n_x=mc['n_x'],\n",
    "                    n_s=mc['n_s'],\n",
    "                    idx_to_sample_freq=int(mc['idx_to_sample_freq']),\n",
    "                    input_size=int(mc['n_time_in']),\n",
    "                    output_size=int(mc['n_time_out']),\n",
    "                    es_component=mc['es_component'],\n",
    "                    cell_type=mc['cell_type'],\n",
    "                    state_hsize=int(mc['state_hsize']),\n",
    "                    dilations=mc['dilations'],\n",
    "                    add_nl_layer=mc['add_nl_layer'],\n",
    "                    # Optimization parameters                 \n",
    "                    learning_rate=mc['learning_rate'],\n",
    "                    lr_scheduler_step_size=int(mc['lr_decay_step_size']),\n",
    "                    lr_decay=mc['lr_decay'],\n",
    "                    gradient_eps=mc['gradient_eps'],\n",
    "                    gradient_clipping_threshold=mc['gradient_clipping_threshold'],\n",
    "                    rnn_weight_decay=mc['rnn_weight_decay'],\n",
    "                    noise_std=mc['noise_std'],\n",
    "                    testing_percentiles=list(mc['testing_percentiles']),\n",
    "                    training_percentiles=list(mc['training_percentiles']),\n",
    "                    loss=mc['loss_train'],\n",
    "                    val_loss=mc['loss_valid']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def instantiate_model(mc):\n",
    "    MODEL_DICT = {'nbeats': instantiate_nbeats,\n",
    "                  'esrnn': instantiate_esrnn,\n",
    "                  'mqesrnn': instantiate_mqesrnn,}\n",
    "    return MODEL_DICT[mc['model']](mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def model_fit_predict(mc, S_df, Y_df, X_df, f_cols,\n",
    "                      ds_in_test, ds_in_val,\n",
    "                      n_uids, n_val_windows, freq,\n",
    "                      is_val_random):\n",
    "    \n",
    "    # Protect inplace modifications\n",
    "    Y_df = Y_df.copy()\n",
    "    if X_df is not None:\n",
    "        X_df = X_df.copy()\n",
    "    if S_df is not None:\n",
    "        S_df = S_df.copy()        \n",
    "\n",
    "    #----------------------------------------------- Datasets -----------------------------------------------#\n",
    "    train_dataset, val_dataset, test_dataset, scaler_y = create_datasets(mc=mc,\n",
    "                                                                         S_df=S_df, Y_df=Y_df, X_df=X_df,\n",
    "                                                                         f_cols=f_cols,\n",
    "                                                                         ds_in_test=ds_in_test,\n",
    "                                                                         ds_in_val=ds_in_val,\n",
    "                                                                         n_uids=n_uids, \n",
    "                                                                         n_val_windows=n_val_windows,\n",
    "                                                                         freq=freq, is_val_random=is_val_random)\n",
    "    mc['n_x'], mc['n_s'] = train_dataset.get_n_variables()\n",
    "\n",
    "    #------------------------------------------- Instantiate & fit -------------------------------------------#\n",
    "    train_loader, val_loader, test_loader = instantiate_loaders(mc=mc,\n",
    "                                                                train_dataset=train_dataset,\n",
    "                                                                val_dataset=val_dataset,\n",
    "                                                                test_dataset=test_dataset)\n",
    "    model = instantiate_model(mc=mc)\n",
    "    callbacks = []\n",
    "    if mc['early_stop_patience']:\n",
    "        early_stopping = pl.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-4, \n",
    "                                                    patience=mc['early_stop_patience'],\n",
    "                                                    verbose=True, \n",
    "                                                    mode='min') \n",
    "        callbacks=[early_stopping]\n",
    "\n",
    "    gpus = -1 if t.cuda.is_available() else 0\n",
    "    trainer = pl.Trainer(max_epochs=mc['max_epochs'], \n",
    "                         max_steps=mc['max_steps'],\n",
    "                         callbacks=callbacks)\n",
    "    trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "    #------------------------------------------------ Predict ------------------------------------------------#\n",
    "    # Predict test if available\n",
    "    if ds_in_test > 0:\n",
    "        outputs = trainer.predict(model, test_loader)\n",
    "        y_true, y_hat, mask = [t.cat(output).cpu().numpy() for output in zip(*outputs)]\n",
    "        meta_data = test_loader.dataset.meta_data\n",
    "    else:\n",
    "        outputs = trainer.predict(model, val_loader)\n",
    "        y_true, y_hat, mask = [t.cat(output).cpu().numpy()[:, -1] for output in zip(*outputs)]\n",
    "        meta_data = val_loader.dataset.meta_data\n",
    "    \n",
    "    # Scale to original scale\n",
    "    if mc['normalizer_y'] is not None:\n",
    "        y_true_shape = y_true.shape\n",
    "        y_true = scaler_y.inv_scale(x=y_true.flatten())\n",
    "        y_true = np.reshape(y_true, y_true_shape)\n",
    "\n",
    "        y_hat = scaler_y.inv_scale(x=y_hat.flatten())\n",
    "        y_hat = np.reshape(y_hat, y_true_shape)\n",
    "\n",
    "    print(f\"y_true.shape (#n_series, #n_fcds, #lt): {y_true.shape}\")\n",
    "    print(f\"y_hat.shape (#n_series, #n_fcds, #lt): {y_hat.shape}\")\n",
    "    print(\"\\n\")\n",
    "    return y_true, y_hat, mask, meta_data, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def evaluate_model(mc, loss_function, \n",
    "                   S_df, Y_df, X_df, f_cols,\n",
    "                   ds_in_test, ds_in_val,\n",
    "                   n_uids, n_val_windows, freq,\n",
    "                   is_val_random,\n",
    "                   loss_kwargs):\n",
    "    \n",
    "    print(47*'=' + '\\n')\n",
    "    print(pd.Series(mc))\n",
    "    print(47*'=' + '\\n')\n",
    "    \n",
    "    # Some asserts due to work in progress\n",
    "    n_series = Y_df['unique_id'].nunique()\n",
    "    if n_series > 1:\n",
    "        assert mc['normalizer_y'] is None, 'Data scaling not implemented with multiple time series'\n",
    "        assert mc['normalizer_x'] is None, 'Data scaling not implemented with multiple time series'\n",
    "\n",
    "    assert ds_in_test % mc['val_idx_to_sample_freq']==0, 'outsample size should be multiple of val_idx_to_sample_freq'\n",
    "\n",
    "    # Make predictions\n",
    "    start = time.time()\n",
    "    y_true, y_hat, mask, meta_data, model = model_fit_predict(mc=mc,\n",
    "                                                              S_df=S_df, \n",
    "                                                              Y_df=Y_df,\n",
    "                                                              X_df=X_df,\n",
    "                                                              f_cols=f_cols,\n",
    "                                                              ds_in_test=ds_in_test, \n",
    "                                                              ds_in_val=ds_in_val,\n",
    "                                                              n_uids=n_uids,\n",
    "                                                              n_val_windows=n_val_windows,\n",
    "                                                              freq=freq,\n",
    "                                                              is_val_random=is_val_random)\n",
    "    run_time = time.time() - start\n",
    "\n",
    "    # Evaluate predictions\n",
    "    loss = loss_function(y=y_true, y_hat=y_hat, weights=mask, **loss_kwargs)\n",
    "\n",
    "    result =  {'loss': loss,\n",
    "               'mc': mc,\n",
    "               'y_true': y_true,\n",
    "               'y_hat': y_hat,\n",
    "               'run_time': run_time,\n",
    "               'status': STATUS_OK}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def hyperopt_tunning(space, hyperopt_max_evals, loss_function,\n",
    "                     S_df, Y_df, X_df, f_cols,\n",
    "                     ds_in_val,\n",
    "                     n_uids, n_val_windows, freq,\n",
    "                     is_val_random,\n",
    "                     save_trials=False,\n",
    "                     loss_kwargs=None):\n",
    "    trials = Trials()\n",
    "    fmin_objective = partial(evaluate_model, loss_function=loss_function, \n",
    "                             S_df=S_df, Y_df=Y_df, X_df=X_df, f_cols=f_cols,\n",
    "                             ds_in_test=0, ds_in_val=ds_in_val,\n",
    "                             n_uids=n_uids, n_val_windows=n_val_windows, freq=freq,\n",
    "                             is_val_random=is_val_random,\n",
    "                             loss_kwargs=loss_kwargs or {})\n",
    "\n",
    "    fmin(fmin_objective, space=space, algo=tpe.suggest, max_evals=hyperopt_max_evals, trials=trials, verbose=True)\n",
    "\n",
    "    return trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Utils Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from nixtlats.losses.numpy import mae, mape, smape, rmse, pinball_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "if t.cuda.is_available(): device = 'cuda'  \n",
    "\n",
    "nbeats_space= {# Architecture parameters\n",
    "               'model':'nbeats',\n",
    "               'mode': 'simple',\n",
    "               'n_time_in': hp.choice('n_time_in', [7*24]),\n",
    "               'n_time_out': hp.choice('n_time_out', [24]),\n",
    "               'n_x_hidden': hp.quniform('n_x_hidden', 1, 10, 1),\n",
    "               'n_s_hidden': hp.choice('n_s_hidden', [0]),\n",
    "               'shared_weights': hp.choice('shared_weights', [False]),\n",
    "               'activation': hp.choice('activation', ['SELU']),\n",
    "               'initialization':  hp.choice('initialization', ['glorot_normal','he_normal']),\n",
    "               'stack_types': hp.choice('stack_types', [2*['identity'],\n",
    "                                                        1*['identity']+1*['exogenous_tcn'],\n",
    "                                                        1*['exogenous_tcn']+1*['identity'] ]),\n",
    "               'n_blocks': hp.choice('n_blocks', [ [1, 1] ]),\n",
    "               'n_layers': hp.choice('n_layers', [ [2, 2] ]),\n",
    "               'n_hidden': hp.choice('n_hidden', [ 256 ]),\n",
    "               'n_harmonics': hp.choice('n_harmonics', [1]),\n",
    "               'n_polynomials': hp.choice('n_polynomials', [2]),\n",
    "               # Regularization and optimization parameters\n",
    "               'batch_normalization': hp.choice('batch_normalization', [False]),\n",
    "               'dropout_prob_theta': hp.uniform('dropout_prob_theta', 0, 0.5),\n",
    "               'dropout_prob_exogenous': hp.uniform('dropout_prob_exogenous', 0, 0.5),\n",
    "               'learning_rate': hp.loguniform('learning_rate', np.log(5e-4), np.log(0.001)),\n",
    "               'lr_decay': hp.uniform('lr_decay', 0.3, 0.5),\n",
    "               'lr_decay_step_size': hp.choice('lr_decay_step_size', [100]), \n",
    "               'weight_decay': hp.loguniform('weight_decay', np.log(5e-5), np.log(5e-3)),\n",
    "               'max_epochs': hp.choice('max_epochs', [10]), #'n_iterations': hp.choice('n_iterations', [10])\n",
    "               'max_steps': hp.choice('max_steps', [None]),\n",
    "               'early_stop_patience': hp.choice('early_stop_patience', [16]),\n",
    "               'eval_freq': hp.choice('eval_freq', [50]),\n",
    "               'n_val_weeks': hp.choice('n_val_weeks', [52*2]),\n",
    "               'loss_train': hp.choice('loss', ['MAE']),\n",
    "               'loss_hypar': hp.choice('loss_hypar', [0.5]),                \n",
    "               'loss_valid': hp.choice('loss_valid', ['MAE']), #[args.val_loss]),\n",
    "               'l1_theta': hp.choice('l1_theta', [0]),\n",
    "               # Data parameters\n",
    "               'len_sample_chunks': hp.choice('len_sample_chunks', [None]),\n",
    "               'normalizer_y': hp.choice('normalizer_y', [None]),\n",
    "               'normalizer_x': hp.choice('normalizer_x', ['median']),\n",
    "               'window_sampling_limit': hp.choice('window_sampling_limit', [100_000]),\n",
    "               'complete_inputs': hp.choice('complete_inputs', [False]),\n",
    "               'complete_sample': hp.choice('complete_sample', [False]),                \n",
    "               'frequency': hp.choice('frequency', ['H']),\n",
    "               'seasonality': hp.choice('seasonality', [24]),      \n",
    "               'idx_to_sample_freq': hp.choice('idx_to_sample_freq', [24]),\n",
    "               'val_idx_to_sample_freq': hp.choice('val_idx_to_sample_freq', [24]),\n",
    "               'batch_size': hp.choice('batch_size', [256]),\n",
    "               'n_series_per_batch': hp.choice('n_series_per_batch', [1]),\n",
    "               'random_seed': hp.quniform('random_seed', 10, 20, 1),\n",
    "               'device': hp.choice('device', [device])}\n",
    "\n",
    "mc = {'model':'nbeats',\n",
    "      # Architecture parameters\n",
    "      'n_time_in': 7*24,\n",
    "      'n_time_out': 24,\n",
    "      'n_x_hidden': 3,\n",
    "      'n_s_hidden': 0,\n",
    "      'shared_weights': False,\n",
    "      'activation': 'SELU',\n",
    "      'initialization': 'he_normal',\n",
    "      'stack_types': ['exogenous_tcn']+1*['identity'],\n",
    "      'n_blocks': [1, 1],\n",
    "      'n_layers': [2, 2],\n",
    "      'n_hidden': 364,\n",
    "      'n_polynomials': 2,\n",
    "      'n_harmonics': 1,\n",
    "      # Regularization and optimization parameters\n",
    "      'max_epochs': 10, #'n_iterations': 100,\n",
    "      'max_steps': None,      \n",
    "      'early_stop_patience': 8,\n",
    "      'batch_normalization': False,\n",
    "      'dropout_prob_theta': 0.2,\n",
    "      'learning_rate': 0.0005, #0.002,\n",
    "      'lr_decay': 0.64,\n",
    "      'lr_decay_step_size': 100,\n",
    "      'weight_decay': 0.00015,\n",
    "      'eval_freq': 50,\n",
    "      'n_val_weeks': 52*2,\n",
    "      'loss_train': 'PINBALL',\n",
    "      'loss_hypar': 0.5, #0.49,\n",
    "      'loss_valid': 'MAE',\n",
    "      'l1_theta': 0,\n",
    "      # Data parameters\n",
    "      'normalizer_y': None,\n",
    "      'normalizer_x': 'median',\n",
    "      'window_sampling_limit': 100_000,\n",
    "      'complete_inputs': False,\n",
    "      'frequency':'H',\n",
    "      'seasonality': 24,\n",
    "      'idx_to_sample_freq': 24,\n",
    "      'val_idx_to_sample_freq': 24,\n",
    "      'batch_size': 256,\n",
    "      'n_series_per_batch': 1,\n",
    "      'random_seed': 10,\n",
    "      'device': 'cpu'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esrnn_space = {'model': hp.choice('model', ['esrnn']),\n",
    "               'mode': 'full',\n",
    "               # Architecture parameters\n",
    "               'input_size_multiplier': hp.choice('input_size_multiplier', [7]),\n",
    "               'output_size': hp.choice('output_size', [24]),\n",
    "               'dilations': hp.choice('dilations', [ [[1, 2]], [[1,2], [7, 14]] ]),\n",
    "               'es_component': hp.choice('es_component', ['multiplicative']),\n",
    "               'cell_type': hp.choice('cell_type', ['LSTM']),\n",
    "               'state_hsize': hp.quniform('state_hsize', 10, 100, 10),\n",
    "               'add_nl_layer': hp.choice('add_nl_layer', [True, False]),\n",
    "               'seasonality': hp.choice('seasonality', [ [24] ]),\n",
    "               # Regularization and optimization parameters\n",
    "               'max_epochs':hp.choice('max_epochs', [10]),\n",
    "               'max_steps':hp.choice('max_steps', [None]),\n",
    "               'early_stop_patience':hp.choice('early_stop_patience', [10]),\n",
    "               'eval_freq': hp.choice('eval_freq', [10]),\n",
    "               'batch_size': hp.choice('batch_size', [32]),\n",
    "               'learning_rate': hp.loguniform('learning_rate', np.log(5e-4), np.log(0.01)),\n",
    "               'lr_decay': hp.quniform('lr_decay', 0.5, 0.8, 0.1),\n",
    "               'lr_decay_step_size': hp.choice('lr_decay_step_size', [100]), \n",
    "               'per_series_lr_multip': hp.choice('per_series_lr_multip', [0.5, 1.0, 1.5, 2.0, 3.0]),\n",
    "               'gradient_eps': hp.choice('gradient_eps', [1e-8]),\n",
    "               'gradient_clipping_threshold': hp.choice('gradient_clipping_threshold', [10, 50]),\n",
    "               'rnn_weight_decay': hp.choice('rnn_weight_decay', [0, 0.0005, 0.005]),\n",
    "               'noise_std': hp.loguniform('noise_std', np.log(0.0001), np.log(0.001)),\n",
    "               'level_variability_penalty': hp.quniform('level_variability_penalty', 0, 100, 10),\n",
    "               'testing_percentile': hp.choice('testing_percentile', [50]),\n",
    "               'training_percentile': hp.choice('training_percentile', [48, 49, 50, 51]),\n",
    "               'random_seed': hp.quniform('random_seed', 1, 1000, 1),\n",
    "               'loss_train': hp.choice('loss_train', ['SMYL']),\n",
    "               'loss_valid': hp.choice('loss_valid', ['MAE']),\n",
    "               # Data parameters\n",
    "               'len_sample_chunks': hp.choice('len_sample_chunks', [7*3*24]),\n",
    "               'window_sampling_limit': hp.choice('window_sampling_limit', [500_000]),\n",
    "               'complete_inputs': hp.choice('complete_inputs', [True]),\n",
    "               'complete_sample': hp.choice('complete_sample', [True]),\n",
    "               'idx_to_sample_freq': hp.choice('idx_to_sample_freq', [24]),\n",
    "               'val_idx_to_sample_freq': hp.choice('val_idx_to_sample_freq', [24]),\n",
    "               'n_series_per_batch': hp.choice('n_series_per_batch', [1]),\n",
    "               'normalizer_y': hp.choice('normalizer_y', [None]),\n",
    "               'normalizer_x': hp.choice('normalizer_x',  [None])}\n",
    "\n",
    "mc = {'model':'esrnn',\n",
    "      'mode': 'full',\n",
    "      # Architecture parameters\n",
    "      'n_series': 1,\n",
    "      'n_time_in': 7*24,\n",
    "      'n_time_out': 24,\n",
    "      'n_x': 1,\n",
    "      'n_s': 1,\n",
    "      'dilations': [[1,2], [7]],\n",
    "      'es_component': 'multiplicative',\n",
    "      'cell_type': 'LSTM',\n",
    "      'state_hsize': 50,\n",
    "      'add_nl_layer': False,\n",
    "      'seasonality': [24],\n",
    "      # Regularization and optimization parameters\n",
    "      'max_epochs': 10, #'n_iterations': 100,\n",
    "      'max_steps': None,\n",
    "      'early_stop_patience': 10,\n",
    "      'eval_freq': 10,\n",
    "      'batch_size': 32,\n",
    "      'eq_batch_size': False,\n",
    "      'learning_rate': 0.0005,\n",
    "      'lr_decay': 0.8,\n",
    "      'lr_decay_step_size': 100,\n",
    "      'per_series_lr_multip': 1.5,\n",
    "      'gradient_eps': 1e-8, \n",
    "      'gradient_clipping_threshold': 20,\n",
    "      'rnn_weight_decay': 0.0,\n",
    "      'noise_std': 0.0005,\n",
    "      'level_variability_penalty': 10,\n",
    "      'testing_percentile': 50,\n",
    "      'training_percentile': 50,\n",
    "      'random_seed': 1,\n",
    "      'loss_train': 'SMYL',\n",
    "      'loss_valid': 'MAE',\n",
    "      # Data parameters\n",
    "      'len_sample_chunks': 7*4*24,\n",
    "      'window_sampling_limit': 500_000,\n",
    "      'complete_inputs': True,\n",
    "      'idx_to_sample_freq': 24,\n",
    "      'val_idx_to_sample_freq': 24,\n",
    "      'n_series_per_batch': 1,\n",
    "      'normalizer_y': None,\n",
    "      'normalizer_x': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = instantiate_esrnn(mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nixtlats.data.datasets.epf import EPF, EPFInfo\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = ['NP']\n",
    "\n",
    "Y_df, X_df, S_df = EPF.load_groups(directory='data', groups=dataset)\n",
    "\n",
    "X_df = X_df[['unique_id', 'ds', 'week_day']]\n",
    "Y_min = Y_df.y.min()\n",
    "#Y_df.y = Y_df.y - Y_min + 20\n",
    "\n",
    "plt.plot(Y_df.y.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Validation splits\n",
      "\n",
      "INFO:root:                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0           2016-12-27 2018-12-24 23:00:00\n",
      "          1           2013-01-01 2016-12-26 23:00:00\n",
      "INFO:root:\n",
      "Total data \t\t\t52416 time stamps \n",
      "Available percentage=100.0, \t52416 time stamps \n",
      "Insample  percentage=66.67, \t34944 time stamps \n",
      "Outsample percentage=33.33, \t17472 time stamps \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "\n",
      "model                                   esrnn\n",
      "mode                                     full\n",
      "n_series                                    1\n",
      "n_time_in                                 168\n",
      "n_time_out                                 24\n",
      "n_x                                         1\n",
      "n_s                                         1\n",
      "dilations                       [[1, 2], [7]]\n",
      "es_component                   multiplicative\n",
      "cell_type                                LSTM\n",
      "state_hsize                                50\n",
      "add_nl_layer                            False\n",
      "seasonality                              [24]\n",
      "max_epochs                                 10\n",
      "max_steps                                None\n",
      "early_stop_patience                        10\n",
      "eval_freq                                  10\n",
      "batch_size                                 32\n",
      "eq_batch_size                           False\n",
      "learning_rate                          0.0005\n",
      "lr_decay                                  0.8\n",
      "lr_decay_step_size                        100\n",
      "per_series_lr_multip                      1.5\n",
      "gradient_eps                              0.0\n",
      "gradient_clipping_threshold                20\n",
      "rnn_weight_decay                          0.0\n",
      "noise_std                              0.0005\n",
      "level_variability_penalty                  10\n",
      "testing_percentile                         50\n",
      "training_percentile                        50\n",
      "random_seed                                 1\n",
      "loss_train                               SMYL\n",
      "loss_valid                                MAE\n",
      "len_sample_chunks                         672\n",
      "window_sampling_limit                  500000\n",
      "complete_inputs                          True\n",
      "idx_to_sample_freq                         24\n",
      "val_idx_to_sample_freq                     24\n",
      "n_series_per_batch                          1\n",
      "normalizer_y                             None\n",
      "normalizer_x                             None\n",
      "dtype: object\n",
      "===============================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Validation splits\n",
      "\n",
      "INFO:root:                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0           2013-01-01 2016-12-26 23:00:00\n",
      "          1           2016-12-27 2018-12-24 23:00:00\n",
      "INFO:root:\n",
      "Total data \t\t\t52416 time stamps \n",
      "Available percentage=100.0, \t52416 time stamps \n",
      "Insample  percentage=33.33, \t17472 time stamps \n",
      "Outsample percentage=66.67, \t34944 time stamps \n",
      "\n",
      "INFO:root:Train Validation splits\n",
      "\n",
      "INFO:root:                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0           2013-01-01 2018-12-24 23:00:00\n",
      "INFO:root:\n",
      "Total data \t\t\t52416 time stamps \n",
      "Available percentage=100.0, \t52416 time stamps \n",
      "Insample  percentage=0.0, \t0 time stamps \n",
      "Outsample percentage=100.0, \t52416 time stamps \n",
      "\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/ubuntu/anaconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | esrnn | _ESRNN | 124 K \n",
      "---------------------------------\n",
      "124 K     Trainable params\n",
      "0         Non-trainable params\n",
      "124 K     Total params\n",
      "0.499     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea33e6f68fac495883024464c0e44c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ubuntu/anaconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998b98519d91420289afbbe705446017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b353fb3d2406463db39fd96223f0f4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 4.635\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91f81ab45934a90bdd66d0c343cfe5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.307 >= min_delta = 0.0001. New best score: 4.328\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0c60ebf9ee4b09bc754698b3321bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.218 >= min_delta = 0.0001. New best score: 4.110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a27fb0c06941f08aff98abb431daea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.166 >= min_delta = 0.0001. New best score: 3.944\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8645e22ab1d4940ac9722b1b310d09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.136 >= min_delta = 0.0001. New best score: 3.808\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951a08cddeb1453989671809aa6e2e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.114 >= min_delta = 0.0001. New best score: 3.694\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5440f326069e404cbea25dad33842f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.094 >= min_delta = 0.0001. New best score: 3.600\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d229c9783f42af815222d6effb0004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.080 >= min_delta = 0.0001. New best score: 3.520\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd28609d3860410daf79853dc26c8610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.066 >= min_delta = 0.0001. New best score: 3.454\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c30847bd2b2f4ed09190c5b3ed4df73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.054 >= min_delta = 0.0001. New best score: 3.399\n",
      "/home/ubuntu/anaconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, predict dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ac1d8ef2d44506b0aa55590be3b732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true.shape (#n_series, #n_fcds, #lt): (728, 24)\n",
      "y_hat.shape (#n_series, #n_fcds, #lt): (728, 24)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 3.4991977,\n",
       " 'mc': {'model': 'esrnn',\n",
       "  'mode': 'full',\n",
       "  'n_series': 1,\n",
       "  'n_time_in': 168,\n",
       "  'n_time_out': 24,\n",
       "  'n_x': 1,\n",
       "  'n_s': 1,\n",
       "  'dilations': [[1, 2], [7]],\n",
       "  'es_component': 'multiplicative',\n",
       "  'cell_type': 'LSTM',\n",
       "  'state_hsize': 50,\n",
       "  'add_nl_layer': False,\n",
       "  'seasonality': [24],\n",
       "  'max_epochs': 10,\n",
       "  'max_steps': None,\n",
       "  'early_stop_patience': 10,\n",
       "  'eval_freq': 10,\n",
       "  'batch_size': 32,\n",
       "  'eq_batch_size': False,\n",
       "  'learning_rate': 0.0005,\n",
       "  'lr_decay': 0.8,\n",
       "  'lr_decay_step_size': 100,\n",
       "  'per_series_lr_multip': 1.5,\n",
       "  'gradient_eps': 1e-08,\n",
       "  'gradient_clipping_threshold': 20,\n",
       "  'rnn_weight_decay': 0.0,\n",
       "  'noise_std': 0.0005,\n",
       "  'level_variability_penalty': 10,\n",
       "  'testing_percentile': 50,\n",
       "  'training_percentile': 50,\n",
       "  'random_seed': 1,\n",
       "  'loss_train': 'SMYL',\n",
       "  'loss_valid': 'MAE',\n",
       "  'len_sample_chunks': 672,\n",
       "  'window_sampling_limit': 500000,\n",
       "  'complete_inputs': True,\n",
       "  'idx_to_sample_freq': 24,\n",
       "  'val_idx_to_sample_freq': 24,\n",
       "  'n_series_per_batch': 1,\n",
       "  'normalizer_y': None,\n",
       "  'normalizer_x': None},\n",
       " 'y_true': array([[24.08, 22.52, 20.13, ..., 28.37, 27.24, 25.73],\n",
       "        [26.45, 26.26, 26.24, ..., 30.65, 30.02, 29.37],\n",
       "        [29.26, 28.72, 28.29, ..., 30.01, 29.44, 28.76],\n",
       "        ...,\n",
       "        [48.39, 47.72, 47.23, ..., 52.05, 51.09, 50.47],\n",
       "        [51.49, 50.83, 50.74, ..., 53.99, 53.86, 52.32],\n",
       "        [51.09, 50.19, 48.98, ..., 49.09, 49.02, 48.1 ]], dtype=float32),\n",
       " 'y_hat': array([[24.33769 , 22.102844, 21.10142 , ..., 27.454004, 27.137604,\n",
       "         26.435623],\n",
       "        [24.343973, 22.348608, 21.180744, ..., 27.49965 , 26.88523 ,\n",
       "         26.388895],\n",
       "        [27.938967, 25.281277, 24.288834, ..., 31.5685  , 30.135736,\n",
       "         30.171461],\n",
       "        ...,\n",
       "        [46.256874, 46.90347 , 46.982185, ..., 49.996956, 50.326725,\n",
       "         51.179863],\n",
       "        [48.246696, 47.63383 , 47.224636, ..., 52.28208 , 51.462975,\n",
       "         52.726986],\n",
       "        [51.020382, 50.916542, 50.6636  , ..., 52.560085, 52.79641 ,\n",
       "         53.634846]], dtype=float32),\n",
       " 'run_time': 5.3648741245269775,\n",
       " 'status': 'ok'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = evaluate_model(loss_function=mae, mc=mc, \n",
    "                        S_df=S_df, Y_df=Y_df, X_df=X_df, f_cols=[],\n",
    "                        ds_in_test=0, ds_in_val=728*24,\n",
    "                        n_uids=None, n_val_windows=None, freq=None,\n",
    "                        is_val_random=False, loss_kwargs={})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe707fccc10>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(result['y_hat'].flatten())\n",
    "plt.plot(Y_df['y'][-728*24:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.012679 seconds\n",
      "INFO:hyperopt.tpe:TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================      \n",
      "\n",
      "activation                                     SELU  \n",
      "batch_normalization                           False\n",
      "batch_size                                      256\n",
      "complete_inputs                               False\n",
      "complete_sample                               False\n",
      "device                                         cuda\n",
      "dropout_prob_exogenous                     0.293461\n",
      "dropout_prob_theta                         0.243891\n",
      "early_stop_patience                              16\n",
      "eval_freq                                        50\n",
      "frequency                                         H\n",
      "idx_to_sample_freq                               24\n",
      "initialization                        glorot_normal\n",
      "l1_theta                                          0\n",
      "learning_rate                              0.000737\n",
      "len_sample_chunks                              None\n",
      "loss_hypar                                      0.5\n",
      "loss_train                                      MAE\n",
      "loss_valid                                      MAE\n",
      "lr_decay                                   0.310092\n",
      "lr_decay_step_size                              100\n",
      "max_epochs                                       10\n",
      "max_steps                                      None\n",
      "mode                                         simple\n",
      "model                                        nbeats\n",
      "n_blocks                                     (1, 1)\n",
      "n_harmonics                                       1\n",
      "n_hidden                                        256\n",
      "n_layers                                     (2, 2)\n",
      "n_polynomials                                     2\n",
      "n_s_hidden                                        0\n",
      "n_series_per_batch                                1\n",
      "n_time_in                                       168\n",
      "n_time_out                                       24\n",
      "n_val_weeks                                     104\n",
      "n_x_hidden                                      9.0\n",
      "normalizer_x                                 median\n",
      "normalizer_y                                   None\n",
      "random_seed                                    17.0\n",
      "seasonality                                      24\n",
      "shared_weights                                False\n",
      "stack_types               (identity, exogenous_tcn)\n",
      "val_idx_to_sample_freq                           24\n",
      "weight_decay                               0.000063\n",
      "window_sampling_limit                        100000\n",
      "dtype: object\n",
      "===============================================      \n",
      "\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Validation splits\n",
      "\n",
      "INFO:root:                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0           2016-12-27 2018-12-24 23:00:00\n",
      "          1           2013-01-01 2016-12-26 23:00:00\n",
      "INFO:root:\n",
      "Total data \t\t\t52416 time stamps \n",
      "Available percentage=100.0, \t52416 time stamps \n",
      "Insample  percentage=66.67, \t34944 time stamps \n",
      "Outsample percentage=33.33, \t17472 time stamps \n",
      "\n",
      "INFO:root:Train Validation splits\n",
      "\n",
      "INFO:root:                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0           2013-01-01 2016-12-26 23:00:00\n",
      "          1           2016-12-27 2018-12-24 23:00:00\n",
      "INFO:root:\n",
      "Total data \t\t\t52416 time stamps \n",
      "Available percentage=100.0, \t52416 time stamps \n",
      "Insample  percentage=33.33, \t17472 time stamps \n",
      "Outsample percentage=66.67, \t34944 time stamps \n",
      "\n",
      "INFO:root:Train Validation splits\n",
      "\n",
      "INFO:root:                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0           2013-01-01 2018-12-24 23:00:00\n",
      "INFO:root:\n",
      "Total data \t\t\t52416 time stamps \n",
      "Available percentage=100.0, \t52416 time stamps \n",
      "Insample  percentage=0.0, \t0 time stamps \n",
      "Outsample percentage=100.0, \t52416 time stamps \n",
      "\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/ubuntu/anaconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | _NBEATS | 371 K \n",
      "----------------------------------\n",
      "371 K     Trainable params\n",
      "0         Non-trainable params\n",
      "371 K     Total params\n",
      "1.487     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172aae15390f4e55bbf61e91263bcae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "/home/ubuntu/anaconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8a3a1b90a941f4ab09d143f21f0956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6097e63d262d422e9dbb5344dc07c86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 28.825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81b11ae17de34fea8f45a4a73e5bddc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 13.843 >= min_delta = 0.0001. New best score: 14.981\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0627eedb598c46a497c711ea8c4b869d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 11.207 >= min_delta = 0.0001. New best score: 3.774\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c9861fd895460987bb352abce65ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb47a282b914ffda750ca3005d6413f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95471736fb2c46b894d5ea0638bd6632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.530 >= min_delta = 0.0001. New best score: 3.244\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91a76e50faa4f709b76cb830c1fecb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2269feac7b0450f96bf6ce006be20a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5ee89f5aab443da234d36560cf7cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188636ffd5cc47788105651108c7d87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, predict dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e7fcae187449338278714366fbb343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true.shape (#n_series, #n_fcds, #lt): (728,)       \n",
      "y_hat.shape (#n_series, #n_fcds, #lt): (728,)        \n",
      " 50%|     | 1/2 [00:02<00:02,  2.79s/trial, best loss: 2.1017706394195557]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.020423 seconds\n",
      "INFO:hyperopt.tpe:TPE using 1/1 trials with best loss 2.101771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================                                \n",
      "\n",
      "activation                                SELU                                 \n",
      "batch_normalization                      False\n",
      "batch_size                                 256\n",
      "complete_inputs                          False\n",
      "complete_sample                          False\n",
      "device                                    cuda\n",
      "dropout_prob_exogenous                0.302431\n",
      "dropout_prob_theta                    0.385168\n",
      "early_stop_patience                         16\n",
      "eval_freq                                   50\n",
      "frequency                                    H\n",
      "idx_to_sample_freq                          24\n",
      "initialization                   glorot_normal\n",
      "l1_theta                                     0\n",
      "learning_rate                         0.000729\n",
      "len_sample_chunks                         None\n",
      "loss_hypar                                 0.5\n",
      "loss_train                                 MAE\n",
      "loss_valid                                 MAE\n",
      "lr_decay                                0.3939\n",
      "lr_decay_step_size                         100\n",
      "max_epochs                                  10\n",
      "max_steps                                 None\n",
      "mode                                    simple\n",
      "model                                   nbeats\n",
      "n_blocks                                (1, 1)\n",
      "n_harmonics                                  1\n",
      "n_hidden                                   256\n",
      "n_layers                                (2, 2)\n",
      "n_polynomials                                2\n",
      "n_s_hidden                                   0\n",
      "n_series_per_batch                           1\n",
      "n_time_in                                  168\n",
      "n_time_out                                  24\n",
      "n_val_weeks                                104\n",
      "n_x_hidden                                 3.0\n",
      "normalizer_x                            median\n",
      "normalizer_y                              None\n",
      "random_seed                               16.0\n",
      "seasonality                                 24\n",
      "shared_weights                           False\n",
      "stack_types               (identity, identity)\n",
      "val_idx_to_sample_freq                      24\n",
      "weight_decay                          0.000083\n",
      "window_sampling_limit                   100000\n",
      "dtype: object\n",
      "===============================================                                \n",
      "\n",
      " 50%|     | 1/2 [00:02<00:02,  2.79s/trial, best loss: 2.1017706394195557]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Train Validation splits\n",
      "\n",
      "INFO:root:                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0           2016-12-27 2018-12-24 23:00:00\n",
      "          1           2013-01-01 2016-12-26 23:00:00\n",
      "INFO:root:\n",
      "Total data \t\t\t52416 time stamps \n",
      "Available percentage=100.0, \t52416 time stamps \n",
      "Insample  percentage=66.67, \t34944 time stamps \n",
      "Outsample percentage=33.33, \t17472 time stamps \n",
      "\n",
      "INFO:root:Train Validation splits\n",
      "\n",
      "INFO:root:                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0           2013-01-01 2016-12-26 23:00:00\n",
      "          1           2016-12-27 2018-12-24 23:00:00\n",
      "INFO:root:\n",
      "Total data \t\t\t52416 time stamps \n",
      "Available percentage=100.0, \t52416 time stamps \n",
      "Insample  percentage=33.33, \t17472 time stamps \n",
      "Outsample percentage=66.67, \t34944 time stamps \n",
      "\n",
      "INFO:root:Train Validation splits\n",
      "\n",
      "INFO:root:                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0           2013-01-01 2018-12-24 23:00:00\n",
      "INFO:root:\n",
      "Total data \t\t\t52416 time stamps \n",
      "Available percentage=100.0, \t52416 time stamps \n",
      "Insample  percentage=0.0, \t0 time stamps \n",
      "Outsample percentage=100.0, \t52416 time stamps \n",
      "\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/home/ubuntu/anaconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | _NBEATS | 415 K \n",
      "----------------------------------\n",
      "415 K     Trainable params\n",
      "0         Non-trainable params\n",
      "415 K     Total params\n",
      "1.660     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7337e0b771bf4ad99f92e93c3fbdc3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "/home/ubuntu/anaconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e8d5af5e714e2d8393f7782b449b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4b3d8460cd4461bba33cef1693728d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 3.649\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b918f11e214a06b27bc77232d966e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134361367ba1486eb81d998360f2d682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.299 >= min_delta = 0.0001. New best score: 3.350\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f68108d4b184785afa6aae0ebe7f402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.376 >= min_delta = 0.0001. New best score: 2.974\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5bed5711e04365bba0e265d3018940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.060 >= min_delta = 0.0001. New best score: 2.914\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af5b7a47819471aa00933ab11d60c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0001. New best score: 2.913\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563bf17409ea490db33bc354338de2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.029 >= min_delta = 0.0001. New best score: 2.884\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c3192123054304a70d36f5400478e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.041 >= min_delta = 0.0001. New best score: 2.843\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0700b8fc4e864dc8a8b767928ce4469e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.031 >= min_delta = 0.0001. New best score: 2.812\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af9b65049824c01a1aa1cd87eedcd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.019 >= min_delta = 0.0001. New best score: 2.793\n",
      "/home/ubuntu/anaconda3/envs/nixtla/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, predict dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bc8af098b44859bf014268a6e87c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true.shape (#n_series, #n_fcds, #lt): (728,)                                 \n",
      "y_hat.shape (#n_series, #n_fcds, #lt): (728,)                                  \n",
      "100%|| 2/2 [00:04<00:00,  2.41s/trial, best loss: 1.9828330278396606]\n"
     ]
    }
   ],
   "source": [
    "trials = hyperopt_tunning(space=nbeats_space, hyperopt_max_evals=2, loss_function=mae,\n",
    "                          S_df=S_df, Y_df=Y_df, X_df=X_df, f_cols=[],\n",
    "                          ds_in_val=728*24, n_uids=None, n_val_windows=None, freq=None,\n",
    "                          is_val_random=False, loss_kwargs={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'state': 2,\n",
       "  'tid': 0,\n",
       "  'spec': None,\n",
       "  'result': {'loss': 2.1017706394195557,\n",
       "   'mc': {'activation': 'SELU',\n",
       "    'batch_normalization': False,\n",
       "    'batch_size': 256,\n",
       "    'complete_inputs': False,\n",
       "    'complete_sample': False,\n",
       "    'device': 'cuda',\n",
       "    'dropout_prob_exogenous': 0.2934610359635618,\n",
       "    'dropout_prob_theta': 0.24389096640506186,\n",
       "    'early_stop_patience': 16,\n",
       "    'eval_freq': 50,\n",
       "    'frequency': 'H',\n",
       "    'idx_to_sample_freq': 24,\n",
       "    'initialization': 'glorot_normal',\n",
       "    'l1_theta': 0,\n",
       "    'learning_rate': 0.0007367406100039542,\n",
       "    'len_sample_chunks': None,\n",
       "    'loss_hypar': 0.5,\n",
       "    'loss_train': 'MAE',\n",
       "    'loss_valid': 'MAE',\n",
       "    'lr_decay': 0.31009178056304154,\n",
       "    'lr_decay_step_size': 100,\n",
       "    'max_epochs': 10,\n",
       "    'max_steps': None,\n",
       "    'mode': 'simple',\n",
       "    'model': 'nbeats',\n",
       "    'n_blocks': (1, 1),\n",
       "    'n_harmonics': 1,\n",
       "    'n_hidden': 256,\n",
       "    'n_layers': (2, 2),\n",
       "    'n_polynomials': 2,\n",
       "    'n_s_hidden': 0,\n",
       "    'n_series_per_batch': 1,\n",
       "    'n_time_in': 168,\n",
       "    'n_time_out': 24,\n",
       "    'n_val_weeks': 104,\n",
       "    'n_x_hidden': 9.0,\n",
       "    'normalizer_x': 'median',\n",
       "    'normalizer_y': None,\n",
       "    'random_seed': 17.0,\n",
       "    'seasonality': 24,\n",
       "    'shared_weights': False,\n",
       "    'stack_types': ('identity', 'exogenous_tcn'),\n",
       "    'val_idx_to_sample_freq': 24,\n",
       "    'weight_decay': 6.317818377567524e-05,\n",
       "    'window_sampling_limit': 100000,\n",
       "    'n_x': 1,\n",
       "    'n_s': 1,\n",
       "    'n_theta_hidden': [[256, 256], [256, 256]]},\n",
       "   'y_true': array([25.73, 29.37, 28.76, 25.95, 26.71, 29.36, 30.93, 28.3 , 30.58,\n",
       "          33.32, 28.86, 30.5 , 29.72, 28.69, 28.  , 25.04, 28.72, 29.79,\n",
       "          29.41, 30.89, 30.99, 29.56, 27.84, 28.19, 27.36, 27.84, 28.13,\n",
       "          28.42, 28.4 , 27.41, 28.66, 28.67, 28.51, 27.96, 29.31, 29.99,\n",
       "          28.97, 29.96, 30.59, 30.8 , 30.62, 31.01, 32.  , 33.14, 32.63,\n",
       "          32.11, 31.77, 31.04, 31.35, 31.96, 31.01, 29.98, 30.36, 28.15,\n",
       "          28.87, 27.66, 29.85, 26.38, 27.82, 30.46, 28.49, 28.67, 27.58,\n",
       "          29.55, 29.93, 29.03, 30.83, 29.08, 30.54, 30.97, 32.54, 30.1 ,\n",
       "          29.72, 31.56, 29.66, 29.13, 29.94, 25.2 , 28.56, 27.86, 25.65,\n",
       "          29.17, 27.05, 27.23, 28.04, 28.94, 29.22, 28.55, 28.05, 28.15,\n",
       "          28.5 , 28.9 , 29.68, 27.87, 28.14, 27.49, 27.38, 28.06, 27.12,\n",
       "          24.5 , 26.57, 27.03, 27.59, 25.54, 22.99, 25.42, 24.72, 27.11,\n",
       "          28.73, 27.15, 29.23, 28.95, 29.76, 29.91, 27.27, 24.44, 25.9 ,\n",
       "          29.06, 28.89, 31.36, 31.24, 31.39, 30.1 , 30.12, 27.03, 27.1 ,\n",
       "          28.  , 27.99, 27.48, 29.84, 30.25, 27.39, 30.99, 31.73, 32.4 ,\n",
       "          28.76, 30.05, 30.05, 30.26, 30.21, 26.95, 26.68, 26.74, 25.06,\n",
       "          25.17, 24.04, 25.8 , 25.6 , 25.65, 25.42, 26.33, 24.14, 24.06,\n",
       "          26.78, 26.11, 25.61, 26.57, 26.97, 26.21, 26.29, 26.2 , 13.97,\n",
       "          19.62, 26.43, 24.68, 24.5 , 24.28, 20.64, 25.43, 24.76, 24.89,\n",
       "          22.06, 23.07, 24.79, 24.81, 24.03, 26.5 , 26.34, 24.42, 23.49,\n",
       "          21.8 , 23.48, 24.23, 23.69, 23.57, 22.99, 24.14, 24.19, 24.33,\n",
       "          25.6 , 26.23, 26.55, 27.41, 26.73, 27.4 , 27.12, 27.44, 26.51,\n",
       "          26.96, 26.51, 26.33, 25.51, 25.02, 25.63, 25.47, 26.65, 27.45,\n",
       "          26.47, 26.65, 26.77, 27.02, 26.89, 27.46, 26.35, 26.75, 26.36,\n",
       "          26.42, 26.7 , 27.04, 25.04, 23.65, 24.86, 25.4 , 26.11, 24.57,\n",
       "          25.86, 25.87, 25.57, 21.97, 26.01, 26.3 , 26.17, 26.85, 25.74,\n",
       "          25.99, 23.77, 25.79, 27.04, 27.77, 27.7 , 28.65, 29.16, 29.65,\n",
       "          30.36, 29.78, 30.32, 30.15, 31.4 , 32.27, 31.37, 31.55, 31.47,\n",
       "          31.56, 29.66, 30.83, 29.27, 29.87, 27.35, 27.67, 28.47, 26.5 ,\n",
       "          28.19, 30.22, 31.05, 31.52, 31.57, 31.55, 31.55, 30.51, 30.65,\n",
       "          30.42, 29.68, 29.51, 29.8 , 29.38, 29.81, 27.96, 27.85, 24.06,\n",
       "          20.41, 24.3 , 17.11, 26.12, 26.91, 26.6 , 28.79, 30.26, 28.56,\n",
       "          27.11, 27.63, 26.63, 26.03, 21.72, 26.06, 25.26, 28.37, 27.81,\n",
       "          27.91, 26.  , 28.97, 29.57, 27.19, 27.1 , 27.64, 20.1 , 20.06,\n",
       "          20.03, 28.5 , 28.95, 23.95, 28.85, 27.1 , 24.96, 28.03, 28.25,\n",
       "          28.3 , 28.57, 26.03, 26.01, 28.29, 29.71, 30.37, 29.74, 29.66,\n",
       "          27.57, 27.58, 27.88, 28.67, 31.55, 29.76, 27.01, 26.05, 29.13,\n",
       "          28.24, 28.01, 28.62, 30.82, 32.18, 30.92, 30.97, 27.9 , 28.24,\n",
       "          29.83, 27.07, 27.94, 24.64, 26.06, 26.79, 27.52, 28.21, 27.96,\n",
       "          26.49, 28.26, 29.03, 29.02, 28.59, 30.43, 29.06, 28.  , 27.3 ,\n",
       "          26.94, 20.08, 25.65, 25.22, 24.51, 28.22, 26.82, 26.68, 25.59,\n",
       "          25.43, 25.02, 27.55, 27.31, 28.07, 29.66, 29.03, 27.75, 28.11,\n",
       "          28.6 , 30.37, 30.05, 29.53, 28.79, 28.82, 25.69, 28.05, 29.31,\n",
       "          30.45, 32.79, 31.64, 30.52, 33.06, 28.08, 25.5 , 28.98, 30.08,\n",
       "          28.01, 27.57, 28.33, 30.14, 27.7 , 29.53, 31.9 , 32.12, 32.78,\n",
       "          34.9 , 33.7 , 32.74, 30.91, 31.17, 29.96, 28.87, 31.02, 31.14,\n",
       "          29.74, 32.22, 32.97, 34.89, 33.77, 35.77, 37.41, 37.34, 38.21,\n",
       "          36.05, 36.93, 36.48, 38.98, 37.72, 37.73, 39.09, 39.81, 38.41,\n",
       "          38.17, 40.4 , 38.6 , 37.29, 35.57, 37.9 , 36.03, 35.68, 36.62,\n",
       "          37.64, 37.75, 37.68, 37.43, 36.79, 37.14, 37.48, 39.6 , 37.88,\n",
       "          41.43, 39.59, 38.68, 39.54, 42.1 , 39.38, 39.26, 40.87, 39.52,\n",
       "          39.56, 39.22, 39.22, 39.13, 38.39, 38.09, 37.42, 38.62, 38.68,\n",
       "          38.01, 37.64, 38.96, 38.5 , 37.96, 40.01, 39.18, 41.55, 39.83,\n",
       "          38.04, 34.93, 32.64, 35.34, 33.97, 34.21, 34.77, 34.35, 35.93,\n",
       "          36.02, 35.91, 33.77, 32.13, 31.09, 36.03, 35.26, 34.15, 28.06,\n",
       "          27.2 , 24.88, 12.42,  4.44,  9.48, 30.11, 19.5 , 20.07, 32.98,\n",
       "          32.97, 24.98, 29.06, 33.81, 31.77, 15.27, 28.05, 36.81, 36.07,\n",
       "          36.34, 39.04, 39.12, 37.69, 39.17, 38.85, 42.26, 41.36, 44.16,\n",
       "          42.2 , 40.66, 43.07, 44.91, 45.17, 46.5 , 47.28, 45.29, 46.73,\n",
       "          45.1 , 46.11, 46.91, 41.1 , 45.56, 44.46, 44.48, 41.49, 42.22,\n",
       "          41.97, 38.05, 37.47, 41.01, 43.27, 43.92, 44.45, 45.29, 42.82,\n",
       "          44.73, 45.48, 46.78, 48.94, 50.24, 50.84, 50.19, 47.56, 48.25,\n",
       "          49.76, 49.68, 50.8 , 51.54, 51.2 , 51.94, 52.4 , 53.18, 51.73,\n",
       "          51.33, 50.51, 51.9 , 52.56, 52.44, 53.29, 53.92, 54.39, 54.33,\n",
       "          51.99, 50.87, 50.53, 53.  , 52.67, 52.72, 53.6 , 53.33, 53.44,\n",
       "          49.6 , 51.51, 53.6 , 51.78, 50.74, 47.48, 49.08, 49.32, 49.43,\n",
       "          49.87, 50.53, 50.59, 48.72, 48.83, 43.64, 48.23, 48.17, 49.92,\n",
       "          48.26, 50.62, 49.63, 49.77, 50.14, 50.15, 55.8 , 52.37, 54.05,\n",
       "          56.58, 55.2 , 53.87, 53.8 , 56.61, 56.84, 54.61, 53.44, 53.65,\n",
       "          53.05, 54.19, 50.99, 49.92, 53.13, 50.19, 49.35, 48.58, 48.91,\n",
       "          44.41, 39.04, 43.01,  3.27, 21.04, 30.61, 39.25, 34.23, 20.99,\n",
       "          30.48, 41.79, 19.92, 42.05, 42.76, 42.51, 44.67, 43.34, 45.61,\n",
       "          45.34, 47.03, 44.08, 41.38, 41.88, 42.4 , 39.36, 19.55,  4.91,\n",
       "          40.59, 41.44, 41.01, 39.89, 41.37, 40.77, 35.08, 34.58, 30.02,\n",
       "          41.19, 44.3 , 42.5 , 44.23, 40.99, 39.09, 39.04, 40.23, 41.93,\n",
       "          42.54, 41.44, 42.1 , 42.99, 43.91, 43.49, 43.8 , 42.69, 39.58,\n",
       "          38.47, 41.95, 43.68, 45.17, 44.97, 43.78, 45.38, 44.16, 43.48,\n",
       "          44.65, 47.6 , 49.43, 47.59, 48.16, 47.88, 49.28, 49.5 , 42.4 ,\n",
       "          42.66, 43.21, 43.23, 42.89, 44.65, 45.06, 46.69, 46.56, 43.81,\n",
       "          44.25, 43.8 , 44.43, 48.58, 49.21, 49.65, 51.36, 46.47, 49.86,\n",
       "          52.49, 48.69, 50.12, 48.12, 49.01, 50.47, 52.32, 48.1 ],\n",
       "         dtype=float32),\n",
       "   'y_hat': array([24.274979 , 24.151375 , 27.62336  , 27.231997 , 25.00191  ,\n",
       "          26.329071 , 28.709578 , 30.082626 , 26.985762 , 29.325583 ,\n",
       "          32.78441  , 27.769854 , 30.630558 , 28.886063 , 27.736332 ,\n",
       "          26.78309  , 23.714008 , 27.3941   , 28.75585  , 28.508244 ,\n",
       "          30.063381 , 30.707876 , 27.902287 , 27.707556 , 27.12242  ,\n",
       "          26.356369 , 26.811134 , 27.187178 , 27.148323 , 27.238522 ,\n",
       "          26.103241 , 27.651236 , 27.76525  , 27.773495 , 27.093254 ,\n",
       "          28.37559  , 28.825264 , 27.68026  , 28.978832 , 29.768927 ,\n",
       "          30.237543 , 29.873684 , 30.234442 , 31.003107 , 32.38931  ,\n",
       "          32.293568 , 31.792    , 32.105244 , 30.64681  , 30.267504 ,\n",
       "          30.67257  , 29.61596  , 28.909952 , 29.630047 , 27.7068   ,\n",
       "          28.00737  , 26.519136 , 28.464472 , 24.94335  , 26.585766 ,\n",
       "          29.3663   , 27.784622 , 27.884521 , 26.677294 , 28.429745 ,\n",
       "          28.780151 , 27.777325 , 29.862125 , 28.40974  , 29.857147 ,\n",
       "          30.120184 , 31.823153 , 28.682964 , 29.227987 , 30.92515  ,\n",
       "          29.00268  , 28.247536 , 28.932703 , 23.770943 , 27.362219 ,\n",
       "          26.557596 , 24.510551 , 28.521505 , 25.977915 , 26.213808 ,\n",
       "          26.900204 , 27.594507 , 28.094723 , 27.600344 , 27.374956 ,\n",
       "          27.292204 , 27.61785  , 27.680994 , 28.263897 , 26.630545 ,\n",
       "          27.272078 , 26.784348 , 26.37994  , 27.04722  , 25.686737 ,\n",
       "          23.092642 , 25.494154 , 25.886713 , 26.814165 , 24.478006 ,\n",
       "          21.898348 , 24.181335 , 23.21179  , 25.733816 , 27.503056 ,\n",
       "          26.230324 , 28.450047 , 28.014227 , 28.837992 , 28.744743 ,\n",
       "          26.134441 , 23.80624  , 25.405027 , 28.07377  , 27.380642 ,\n",
       "          30.098505 , 30.157328 , 30.620106 , 29.950987 , 29.839226 ,\n",
       "          25.939856 , 26.23904  , 26.601175 , 26.379705 , 25.993803 ,\n",
       "          28.929214 , 29.504868 , 26.543722 , 30.083288 , 30.550014 ,\n",
       "          31.273657 , 27.617188 , 29.35489  , 29.767118 , 29.548052 ,\n",
       "          28.855413 , 25.46436  , 25.26842  , 25.496456 , 23.832712 ,\n",
       "          24.282753 , 23.141321 , 24.55333  , 23.753923 , 24.289665 ,\n",
       "          23.975307 , 25.374357 , 23.590536 , 22.965937 , 25.820562 ,\n",
       "          24.58418  , 24.238613 , 25.53779  , 25.977158 , 25.66049  ,\n",
       "          25.392864 , 24.960669 , 12.296654 , 18.35784  , 25.100418 ,\n",
       "          22.745836 , 23.422836 , 23.124437 , 19.666288 , 24.485817 ,\n",
       "          23.08405  , 23.27156  , 20.998053 , 22.356167 , 23.696114 ,\n",
       "          23.844835 , 22.471884 , 25.06696  , 25.050526 , 23.484108 ,\n",
       "          22.658344 , 20.722057 , 22.334675 , 22.33002  , 21.944422 ,\n",
       "          22.227428 , 21.93957  , 23.449463 , 23.136076 , 23.174168 ,\n",
       "          24.20129  , 24.852013 , 25.391117 , 26.40194  , 26.124254 ,\n",
       "          26.661762 , 26.180788 , 26.161285 , 25.209972 , 25.670446 ,\n",
       "          25.368677 , 25.506063 , 24.477448 , 23.949297 , 24.21766  ,\n",
       "          24.03661  , 25.255653 , 26.20058  , 25.571434 , 25.765282 ,\n",
       "          25.807896 , 25.69998  , 25.558922 , 26.103098 , 25.103502 ,\n",
       "          26.030695 , 25.214296 , 24.885553 , 25.228767 , 25.544487 ,\n",
       "          23.737814 , 22.759508 , 24.065638 , 24.222881 , 24.8203   ,\n",
       "          22.806025 , 24.409908 , 24.577751 , 24.61347  , 21.433132 ,\n",
       "          25.040352 , 25.034485 , 24.562162 , 25.354275 , 24.373697 ,\n",
       "          25.22633  , 23.19918  , 24.86637  , 25.872313 , 26.35388  ,\n",
       "          26.429806 , 27.478098 , 28.343151 , 29.337826 , 29.604403 ,\n",
       "          29.08069  , 29.043783 , 29.124756 , 30.528587 , 31.42987  ,\n",
       "          30.84937  , 30.65875  , 30.744358 , 30.432648 , 28.414162 ,\n",
       "          29.867844 , 28.218534 , 29.292938 , 26.405739 , 26.724478 ,\n",
       "          27.001707 , 25.043705 , 26.954588 , 29.09992  , 30.357775 ,\n",
       "          30.820604 , 30.83753  , 30.465559 , 30.546125 , 29.483923 ,\n",
       "          29.800129 , 29.913927 , 28.853573 , 28.517807 , 28.648684 ,\n",
       "          28.051435 , 28.663448 , 27.036308 , 27.27805  , 23.14023  ,\n",
       "          19.419209 , 22.910667 , 15.666532 , 24.701668 , 25.605722 ,\n",
       "          25.90124  , 27.921314 , 29.45159  , 27.461905 , 26.27825  ,\n",
       "          26.605997 , 25.877676 , 25.472223 , 20.675728 , 25.077793 ,\n",
       "          23.725903 , 27.069338 , 26.402685 , 26.949566 , 25.617775 ,\n",
       "          28.328047 , 28.784925 , 26.07539  , 25.935104 , 26.482718 ,\n",
       "          18.957785 , 19.462414 , 19.115147 , 27.192125 , 27.138672 ,\n",
       "          22.445704 , 27.87192  , 26.220161 , 24.64076  , 27.353558 ,\n",
       "          27.015154 , 27.035896 , 27.499275 , 24.785042 , 25.37394  ,\n",
       "          27.731283 , 28.789951 , 29.469065 , 28.36414  , 28.797054 ,\n",
       "          26.566332 , 26.80316  , 27.122353 , 27.726164 , 30.948673 ,\n",
       "          28.475277 , 26.136011 , 25.659744 , 28.588472 , 27.349361 ,\n",
       "          27.06799  , 27.472652 , 29.795668 , 31.749004 , 30.171562 ,\n",
       "          32.248634 , 27.329533 , 28.168154 , 28.50998  , 24.752846 ,\n",
       "          26.331558 , 23.271944 , 25.032495 , 25.85082  , 26.513365 ,\n",
       "          27.468914 , 26.620802 , 25.538994 , 27.841085 , 28.090399 ,\n",
       "          28.461964 , 27.698467 , 30.041615 , 27.79973  , 27.23816  ,\n",
       "          26.1297   , 26.418127 , 19.30274  , 24.76327  , 23.560438 ,\n",
       "          22.748066 , 26.897594 , 25.224812 , 25.973627 , 25.126383 ,\n",
       "          24.678543 , 23.866898 , 26.601555 , 25.516    , 27.469719 ,\n",
       "          28.81172  , 28.606178 , 26.98822  , 27.447857 , 27.32585  ,\n",
       "          29.640114 , 29.061127 , 28.882586 , 28.88016  , 28.296692 ,\n",
       "          24.7521   , 26.733528 , 27.403772 , 29.495329 , 32.289867 ,\n",
       "          31.28648  , 30.52792  , 32.823425 , 26.222988 , 24.347008 ,\n",
       "          27.986612 , 29.593613 , 27.346851 , 26.633923 , 27.243177 ,\n",
       "          28.986797 , 26.18184  , 28.779312 , 31.246065 , 31.613092 ,\n",
       "          32.28903  , 35.1399   , 33.256237 , 32.65898  , 31.347315 ,\n",
       "          31.082333 , 30.0033   , 28.060162 , 29.724709 , 29.515564 ,\n",
       "          28.501434 , 31.609402 , 32.621387 , 34.78152  , 33.03356  ,\n",
       "          35.804974 , 37.034332 , 36.963604 , 39.015263 , 36.18129  ,\n",
       "          37.96429  , 36.42786  , 38.104424 , 36.338253 , 37.093544 ,\n",
       "          39.945816 , 41.585228 , 39.710506 , 40.54038  , 39.302265 ,\n",
       "          37.057457 , 37.535515 , 35.746304 , 38.074207 , 35.70967  ,\n",
       "          35.43531  , 35.882576 , 36.692913 , 37.05887  , 37.18769  ,\n",
       "          37.352528 , 37.022575 , 36.647392 , 36.742886 , 38.869072 ,\n",
       "          36.8174   , 41.316082 , 39.27426  , 39.02798  , 38.977955 ,\n",
       "          42.470024 , 38.482887 , 38.48348  , 40.184883 , 39.28535  ,\n",
       "          39.536476 , 38.85411  , 38.56031  , 38.401722 , 37.466957 ,\n",
       "          37.527256 , 37.09081  , 38.66069  , 38.309532 , 37.496693 ,\n",
       "          36.74172  , 38.022903 , 37.814304 , 37.401108 , 39.83977  ,\n",
       "          38.75593  , 41.228672 , 38.92672  , 37.271526 , 34.45977  ,\n",
       "          32.263268 , 35.138527 , 33.183765 , 32.961357 , 33.508904 ,\n",
       "          32.987484 , 34.736023 , 35.3529   , 35.465984 , 33.227238 ,\n",
       "          31.445452 , 29.979563 , 34.60697  , 33.51411  , 33.394756 ,\n",
       "          27.48575  , 26.777409 , 24.466917 , 10.688176 ,  3.0001388,\n",
       "           8.662841 , 29.499388 , 18.443686 , 18.000277 , 32.886776 ,\n",
       "          31.777882 , 25.187227 , 28.739923 , 33.19229  , 31.657385 ,\n",
       "          14.504236 , 27.71342  , 35.067085 , 34.92782  , 35.588337 ,\n",
       "          37.898148 , 39.390175 , 37.828823 , 38.66836  , 37.78954  ,\n",
       "          41.334007 , 40.4862   , 43.64151  , 42.124756 , 40.458637 ,\n",
       "          42.764885 , 44.078556 , 44.244164 , 45.806732 , 46.993446 ,\n",
       "          45.48609  , 46.867256 , 44.887997 , 45.524452 , 46.130886 ,\n",
       "          40.276268 , 45.254826 , 44.408367 , 44.147545 , 41.12059  ,\n",
       "          41.239643 , 40.936375 , 37.194508 , 36.906967 , 40.94553  ,\n",
       "          42.763367 , 43.296753 , 43.621094 , 44.627388 , 42.40095  ,\n",
       "          44.56606  , 45.582287 , 46.59435  , 48.639282 , 49.66051  ,\n",
       "          50.27722  , 49.83715  , 47.555386 , 48.67779  , 49.74229  ,\n",
       "          49.42842  , 50.444084 , 50.925465 , 50.71973  , 51.98799  ,\n",
       "          52.87847  , 53.431225 , 51.699234 , 51.006878 , 50.118435 ,\n",
       "          51.45215  , 52.43405  , 52.777214 , 53.425617 , 53.91119  ,\n",
       "          54.052254 , 53.880005 , 51.71592  , 50.937805 , 50.956272 ,\n",
       "          53.16315  , 52.45288  , 52.185963 , 53.04005  , 52.807903 ,\n",
       "          53.473328 , 50.160187 , 51.718536 , 53.587357 , 51.26681  ,\n",
       "          50.268948 , 47.08365  , 48.806118 , 49.720894 , 49.136154 ,\n",
       "          49.48593  , 49.800896 , 49.828156 , 48.30773  , 48.883785 ,\n",
       "          44.157265 , 48.36637  , 47.896477 , 49.342163 , 47.677387 ,\n",
       "          50.284645 , 49.36867  , 50.613262 , 50.388077 , 50.23631  ,\n",
       "          55.647873 , 51.861374 , 54.03837  , 57.10276  , 56.167538 ,\n",
       "          54.6243   , 54.11317  , 56.471893 , 56.860374 , 54.598686 ,\n",
       "          53.828773 , 54.653194 , 53.49362  , 54.224224 , 50.485504 ,\n",
       "          49.42242  , 52.72676  , 50.194237 , 49.99766  , 48.701073 ,\n",
       "          48.73677  , 43.887745 , 38.5052   , 42.356293 ,  3.034913 ,\n",
       "          21.50947  , 30.435131 , 37.99098  , 32.806175 , 19.179497 ,\n",
       "          29.978582 , 41.616604 , 19.514305 , 42.182228 , 41.87714  ,\n",
       "          41.90414  , 44.721016 , 42.670147 , 45.471348 , 46.45409  ,\n",
       "          47.035778 , 43.69287  , 40.969944 , 41.039433 , 41.701286 ,\n",
       "          38.986603 , 19.403566 ,  5.1350737, 40.52299  , 39.24665  ,\n",
       "          40.126575 , 38.888515 , 40.3755   , 42.319897 , 35.32634  ,\n",
       "          34.412773 , 29.079887 , 40.148098 , 43.23322  , 41.889507 ,\n",
       "          43.779392 , 41.08276  , 39.26788  , 38.56762  , 39.423714 ,\n",
       "          41.04775  , 42.07396  , 41.464153 , 41.828587 , 42.712788 ,\n",
       "          43.4067   , 42.869583 , 43.455486 , 42.503803 , 39.876564 ,\n",
       "          38.332375 , 41.497257 , 42.64832  , 44.554012 , 44.280907 ,\n",
       "          43.73163  , 45.962032 , 44.1377   , 43.32402  , 44.10712  ,\n",
       "          47.0243   , 49.19918  , 47.208725 , 49.311043 , 48.080334 ,\n",
       "          49.475697 , 49.15904  , 41.81566  , 42.730614 , 43.27764  ,\n",
       "          43.24905  , 42.644596 , 44.190956 , 44.136227 , 46.165054 ,\n",
       "          46.12344  , 43.748993 , 44.7247   , 43.656147 , 44.223953 ,\n",
       "          47.96081  , 48.645035 , 49.40003  , 52.21454  , 47.333664 ,\n",
       "          50.418636 , 52.840508 , 48.045765 , 49.655754 , 47.882545 ,\n",
       "          48.996212 , 51.196068 , 52.382473 ], dtype=float32),\n",
       "   'run_time': 2.7481112480163574,\n",
       "   'status': 'ok'},\n",
       "  'misc': {'tid': 0,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'activation': [0],\n",
       "    'batch_normalization': [0],\n",
       "    'batch_size': [0],\n",
       "    'complete_inputs': [0],\n",
       "    'complete_sample': [0],\n",
       "    'device': [0],\n",
       "    'dropout_prob_exogenous': [0],\n",
       "    'dropout_prob_theta': [0],\n",
       "    'early_stop_patience': [0],\n",
       "    'eval_freq': [0],\n",
       "    'frequency': [0],\n",
       "    'idx_to_sample_freq': [0],\n",
       "    'initialization': [0],\n",
       "    'l1_theta': [0],\n",
       "    'learning_rate': [0],\n",
       "    'len_sample_chunks': [0],\n",
       "    'loss': [0],\n",
       "    'loss_hypar': [0],\n",
       "    'loss_valid': [0],\n",
       "    'lr_decay': [0],\n",
       "    'lr_decay_step_size': [0],\n",
       "    'max_epochs': [0],\n",
       "    'max_steps': [0],\n",
       "    'n_blocks': [0],\n",
       "    'n_harmonics': [0],\n",
       "    'n_hidden': [0],\n",
       "    'n_layers': [0],\n",
       "    'n_polynomials': [0],\n",
       "    'n_s_hidden': [0],\n",
       "    'n_series_per_batch': [0],\n",
       "    'n_time_in': [0],\n",
       "    'n_time_out': [0],\n",
       "    'n_val_weeks': [0],\n",
       "    'n_x_hidden': [0],\n",
       "    'normalizer_x': [0],\n",
       "    'normalizer_y': [0],\n",
       "    'random_seed': [0],\n",
       "    'seasonality': [0],\n",
       "    'shared_weights': [0],\n",
       "    'stack_types': [0],\n",
       "    'val_idx_to_sample_freq': [0],\n",
       "    'weight_decay': [0],\n",
       "    'window_sampling_limit': [0]},\n",
       "   'vals': {'activation': [0],\n",
       "    'batch_normalization': [0],\n",
       "    'batch_size': [0],\n",
       "    'complete_inputs': [0],\n",
       "    'complete_sample': [0],\n",
       "    'device': [0],\n",
       "    'dropout_prob_exogenous': [0.2934610359635618],\n",
       "    'dropout_prob_theta': [0.24389096640506186],\n",
       "    'early_stop_patience': [0],\n",
       "    'eval_freq': [0],\n",
       "    'frequency': [0],\n",
       "    'idx_to_sample_freq': [0],\n",
       "    'initialization': [0],\n",
       "    'l1_theta': [0],\n",
       "    'learning_rate': [0.0007367406100039542],\n",
       "    'len_sample_chunks': [0],\n",
       "    'loss': [0],\n",
       "    'loss_hypar': [0],\n",
       "    'loss_valid': [0],\n",
       "    'lr_decay': [0.31009178056304154],\n",
       "    'lr_decay_step_size': [0],\n",
       "    'max_epochs': [0],\n",
       "    'max_steps': [0],\n",
       "    'n_blocks': [0],\n",
       "    'n_harmonics': [0],\n",
       "    'n_hidden': [0],\n",
       "    'n_layers': [0],\n",
       "    'n_polynomials': [0],\n",
       "    'n_s_hidden': [0],\n",
       "    'n_series_per_batch': [0],\n",
       "    'n_time_in': [0],\n",
       "    'n_time_out': [0],\n",
       "    'n_val_weeks': [0],\n",
       "    'n_x_hidden': [9.0],\n",
       "    'normalizer_x': [0],\n",
       "    'normalizer_y': [0],\n",
       "    'random_seed': [17.0],\n",
       "    'seasonality': [0],\n",
       "    'shared_weights': [0],\n",
       "    'stack_types': [1],\n",
       "    'val_idx_to_sample_freq': [0],\n",
       "    'weight_decay': [6.317818377567524e-05],\n",
       "    'window_sampling_limit': [0]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2021, 6, 6, 19, 34, 50, 389000),\n",
       "  'refresh_time': datetime.datetime(2021, 6, 6, 19, 34, 53, 156000)},\n",
       " {'state': 2,\n",
       "  'tid': 1,\n",
       "  'spec': None,\n",
       "  'result': {'loss': 1.9828330278396606,\n",
       "   'mc': {'activation': 'SELU',\n",
       "    'batch_normalization': False,\n",
       "    'batch_size': 256,\n",
       "    'complete_inputs': False,\n",
       "    'complete_sample': False,\n",
       "    'device': 'cuda',\n",
       "    'dropout_prob_exogenous': 0.3024306449332244,\n",
       "    'dropout_prob_theta': 0.3851678624996854,\n",
       "    'early_stop_patience': 16,\n",
       "    'eval_freq': 50,\n",
       "    'frequency': 'H',\n",
       "    'idx_to_sample_freq': 24,\n",
       "    'initialization': 'glorot_normal',\n",
       "    'l1_theta': 0,\n",
       "    'learning_rate': 0.0007294826926374994,\n",
       "    'len_sample_chunks': None,\n",
       "    'loss_hypar': 0.5,\n",
       "    'loss_train': 'MAE',\n",
       "    'loss_valid': 'MAE',\n",
       "    'lr_decay': 0.3939003899063233,\n",
       "    'lr_decay_step_size': 100,\n",
       "    'max_epochs': 10,\n",
       "    'max_steps': None,\n",
       "    'mode': 'simple',\n",
       "    'model': 'nbeats',\n",
       "    'n_blocks': (1, 1),\n",
       "    'n_harmonics': 1,\n",
       "    'n_hidden': 256,\n",
       "    'n_layers': (2, 2),\n",
       "    'n_polynomials': 2,\n",
       "    'n_s_hidden': 0,\n",
       "    'n_series_per_batch': 1,\n",
       "    'n_time_in': 168,\n",
       "    'n_time_out': 24,\n",
       "    'n_val_weeks': 104,\n",
       "    'n_x_hidden': 3.0,\n",
       "    'normalizer_x': 'median',\n",
       "    'normalizer_y': None,\n",
       "    'random_seed': 16.0,\n",
       "    'seasonality': 24,\n",
       "    'shared_weights': False,\n",
       "    'stack_types': ('identity', 'identity'),\n",
       "    'val_idx_to_sample_freq': 24,\n",
       "    'weight_decay': 8.299088918068486e-05,\n",
       "    'window_sampling_limit': 100000,\n",
       "    'n_x': 1,\n",
       "    'n_s': 1,\n",
       "    'n_theta_hidden': [[256, 256], [256, 256]]},\n",
       "   'y_true': array([25.73, 29.37, 28.76, 25.95, 26.71, 29.36, 30.93, 28.3 , 30.58,\n",
       "          33.32, 28.86, 30.5 , 29.72, 28.69, 28.  , 25.04, 28.72, 29.79,\n",
       "          29.41, 30.89, 30.99, 29.56, 27.84, 28.19, 27.36, 27.84, 28.13,\n",
       "          28.42, 28.4 , 27.41, 28.66, 28.67, 28.51, 27.96, 29.31, 29.99,\n",
       "          28.97, 29.96, 30.59, 30.8 , 30.62, 31.01, 32.  , 33.14, 32.63,\n",
       "          32.11, 31.77, 31.04, 31.35, 31.96, 31.01, 29.98, 30.36, 28.15,\n",
       "          28.87, 27.66, 29.85, 26.38, 27.82, 30.46, 28.49, 28.67, 27.58,\n",
       "          29.55, 29.93, 29.03, 30.83, 29.08, 30.54, 30.97, 32.54, 30.1 ,\n",
       "          29.72, 31.56, 29.66, 29.13, 29.94, 25.2 , 28.56, 27.86, 25.65,\n",
       "          29.17, 27.05, 27.23, 28.04, 28.94, 29.22, 28.55, 28.05, 28.15,\n",
       "          28.5 , 28.9 , 29.68, 27.87, 28.14, 27.49, 27.38, 28.06, 27.12,\n",
       "          24.5 , 26.57, 27.03, 27.59, 25.54, 22.99, 25.42, 24.72, 27.11,\n",
       "          28.73, 27.15, 29.23, 28.95, 29.76, 29.91, 27.27, 24.44, 25.9 ,\n",
       "          29.06, 28.89, 31.36, 31.24, 31.39, 30.1 , 30.12, 27.03, 27.1 ,\n",
       "          28.  , 27.99, 27.48, 29.84, 30.25, 27.39, 30.99, 31.73, 32.4 ,\n",
       "          28.76, 30.05, 30.05, 30.26, 30.21, 26.95, 26.68, 26.74, 25.06,\n",
       "          25.17, 24.04, 25.8 , 25.6 , 25.65, 25.42, 26.33, 24.14, 24.06,\n",
       "          26.78, 26.11, 25.61, 26.57, 26.97, 26.21, 26.29, 26.2 , 13.97,\n",
       "          19.62, 26.43, 24.68, 24.5 , 24.28, 20.64, 25.43, 24.76, 24.89,\n",
       "          22.06, 23.07, 24.79, 24.81, 24.03, 26.5 , 26.34, 24.42, 23.49,\n",
       "          21.8 , 23.48, 24.23, 23.69, 23.57, 22.99, 24.14, 24.19, 24.33,\n",
       "          25.6 , 26.23, 26.55, 27.41, 26.73, 27.4 , 27.12, 27.44, 26.51,\n",
       "          26.96, 26.51, 26.33, 25.51, 25.02, 25.63, 25.47, 26.65, 27.45,\n",
       "          26.47, 26.65, 26.77, 27.02, 26.89, 27.46, 26.35, 26.75, 26.36,\n",
       "          26.42, 26.7 , 27.04, 25.04, 23.65, 24.86, 25.4 , 26.11, 24.57,\n",
       "          25.86, 25.87, 25.57, 21.97, 26.01, 26.3 , 26.17, 26.85, 25.74,\n",
       "          25.99, 23.77, 25.79, 27.04, 27.77, 27.7 , 28.65, 29.16, 29.65,\n",
       "          30.36, 29.78, 30.32, 30.15, 31.4 , 32.27, 31.37, 31.55, 31.47,\n",
       "          31.56, 29.66, 30.83, 29.27, 29.87, 27.35, 27.67, 28.47, 26.5 ,\n",
       "          28.19, 30.22, 31.05, 31.52, 31.57, 31.55, 31.55, 30.51, 30.65,\n",
       "          30.42, 29.68, 29.51, 29.8 , 29.38, 29.81, 27.96, 27.85, 24.06,\n",
       "          20.41, 24.3 , 17.11, 26.12, 26.91, 26.6 , 28.79, 30.26, 28.56,\n",
       "          27.11, 27.63, 26.63, 26.03, 21.72, 26.06, 25.26, 28.37, 27.81,\n",
       "          27.91, 26.  , 28.97, 29.57, 27.19, 27.1 , 27.64, 20.1 , 20.06,\n",
       "          20.03, 28.5 , 28.95, 23.95, 28.85, 27.1 , 24.96, 28.03, 28.25,\n",
       "          28.3 , 28.57, 26.03, 26.01, 28.29, 29.71, 30.37, 29.74, 29.66,\n",
       "          27.57, 27.58, 27.88, 28.67, 31.55, 29.76, 27.01, 26.05, 29.13,\n",
       "          28.24, 28.01, 28.62, 30.82, 32.18, 30.92, 30.97, 27.9 , 28.24,\n",
       "          29.83, 27.07, 27.94, 24.64, 26.06, 26.79, 27.52, 28.21, 27.96,\n",
       "          26.49, 28.26, 29.03, 29.02, 28.59, 30.43, 29.06, 28.  , 27.3 ,\n",
       "          26.94, 20.08, 25.65, 25.22, 24.51, 28.22, 26.82, 26.68, 25.59,\n",
       "          25.43, 25.02, 27.55, 27.31, 28.07, 29.66, 29.03, 27.75, 28.11,\n",
       "          28.6 , 30.37, 30.05, 29.53, 28.79, 28.82, 25.69, 28.05, 29.31,\n",
       "          30.45, 32.79, 31.64, 30.52, 33.06, 28.08, 25.5 , 28.98, 30.08,\n",
       "          28.01, 27.57, 28.33, 30.14, 27.7 , 29.53, 31.9 , 32.12, 32.78,\n",
       "          34.9 , 33.7 , 32.74, 30.91, 31.17, 29.96, 28.87, 31.02, 31.14,\n",
       "          29.74, 32.22, 32.97, 34.89, 33.77, 35.77, 37.41, 37.34, 38.21,\n",
       "          36.05, 36.93, 36.48, 38.98, 37.72, 37.73, 39.09, 39.81, 38.41,\n",
       "          38.17, 40.4 , 38.6 , 37.29, 35.57, 37.9 , 36.03, 35.68, 36.62,\n",
       "          37.64, 37.75, 37.68, 37.43, 36.79, 37.14, 37.48, 39.6 , 37.88,\n",
       "          41.43, 39.59, 38.68, 39.54, 42.1 , 39.38, 39.26, 40.87, 39.52,\n",
       "          39.56, 39.22, 39.22, 39.13, 38.39, 38.09, 37.42, 38.62, 38.68,\n",
       "          38.01, 37.64, 38.96, 38.5 , 37.96, 40.01, 39.18, 41.55, 39.83,\n",
       "          38.04, 34.93, 32.64, 35.34, 33.97, 34.21, 34.77, 34.35, 35.93,\n",
       "          36.02, 35.91, 33.77, 32.13, 31.09, 36.03, 35.26, 34.15, 28.06,\n",
       "          27.2 , 24.88, 12.42,  4.44,  9.48, 30.11, 19.5 , 20.07, 32.98,\n",
       "          32.97, 24.98, 29.06, 33.81, 31.77, 15.27, 28.05, 36.81, 36.07,\n",
       "          36.34, 39.04, 39.12, 37.69, 39.17, 38.85, 42.26, 41.36, 44.16,\n",
       "          42.2 , 40.66, 43.07, 44.91, 45.17, 46.5 , 47.28, 45.29, 46.73,\n",
       "          45.1 , 46.11, 46.91, 41.1 , 45.56, 44.46, 44.48, 41.49, 42.22,\n",
       "          41.97, 38.05, 37.47, 41.01, 43.27, 43.92, 44.45, 45.29, 42.82,\n",
       "          44.73, 45.48, 46.78, 48.94, 50.24, 50.84, 50.19, 47.56, 48.25,\n",
       "          49.76, 49.68, 50.8 , 51.54, 51.2 , 51.94, 52.4 , 53.18, 51.73,\n",
       "          51.33, 50.51, 51.9 , 52.56, 52.44, 53.29, 53.92, 54.39, 54.33,\n",
       "          51.99, 50.87, 50.53, 53.  , 52.67, 52.72, 53.6 , 53.33, 53.44,\n",
       "          49.6 , 51.51, 53.6 , 51.78, 50.74, 47.48, 49.08, 49.32, 49.43,\n",
       "          49.87, 50.53, 50.59, 48.72, 48.83, 43.64, 48.23, 48.17, 49.92,\n",
       "          48.26, 50.62, 49.63, 49.77, 50.14, 50.15, 55.8 , 52.37, 54.05,\n",
       "          56.58, 55.2 , 53.87, 53.8 , 56.61, 56.84, 54.61, 53.44, 53.65,\n",
       "          53.05, 54.19, 50.99, 49.92, 53.13, 50.19, 49.35, 48.58, 48.91,\n",
       "          44.41, 39.04, 43.01,  3.27, 21.04, 30.61, 39.25, 34.23, 20.99,\n",
       "          30.48, 41.79, 19.92, 42.05, 42.76, 42.51, 44.67, 43.34, 45.61,\n",
       "          45.34, 47.03, 44.08, 41.38, 41.88, 42.4 , 39.36, 19.55,  4.91,\n",
       "          40.59, 41.44, 41.01, 39.89, 41.37, 40.77, 35.08, 34.58, 30.02,\n",
       "          41.19, 44.3 , 42.5 , 44.23, 40.99, 39.09, 39.04, 40.23, 41.93,\n",
       "          42.54, 41.44, 42.1 , 42.99, 43.91, 43.49, 43.8 , 42.69, 39.58,\n",
       "          38.47, 41.95, 43.68, 45.17, 44.97, 43.78, 45.38, 44.16, 43.48,\n",
       "          44.65, 47.6 , 49.43, 47.59, 48.16, 47.88, 49.28, 49.5 , 42.4 ,\n",
       "          42.66, 43.21, 43.23, 42.89, 44.65, 45.06, 46.69, 46.56, 43.81,\n",
       "          44.25, 43.8 , 44.43, 48.58, 49.21, 49.65, 51.36, 46.47, 49.86,\n",
       "          52.49, 48.69, 50.12, 48.12, 49.01, 50.47, 52.32, 48.1 ],\n",
       "         dtype=float32),\n",
       "   'y_hat': array([25.41661  , 25.362526 , 28.65475  , 28.06419  , 25.29368  ,\n",
       "          26.086197 , 28.89031  , 30.366188 , 27.791208 , 29.853092 ,\n",
       "          32.351826 , 28.317966 , 29.856863 , 29.229723 , 28.352434 ,\n",
       "          27.72079  , 24.378376 , 28.183607 , 29.433    , 29.2034   ,\n",
       "          30.270527 , 30.226616 , 28.824968 , 26.602867 , 27.249332 ,\n",
       "          27.57016  , 28.087402 , 27.380291 , 27.882566 , 27.742237 ,\n",
       "          26.677439 , 27.84697  , 28.025068 , 28.179861 , 27.50523  ,\n",
       "          28.70795  , 29.431993 , 28.187832 , 29.14193  , 29.9163   ,\n",
       "          30.371782 , 30.14372  , 30.316507 , 31.350912 , 32.44853  ,\n",
       "          31.842918 , 31.303976 , 30.66082  , 30.520767 , 31.355097 ,\n",
       "          31.890177 , 29.992426 , 29.169876 , 29.520784 , 27.613762 ,\n",
       "          28.89928  , 27.321898 , 29.164005 , 25.747673 , 27.219221 ,\n",
       "          29.97592  , 28.097654 , 28.232317 , 26.869125 , 28.99985  ,\n",
       "          29.177443 , 28.437315 , 30.343084 , 28.602146 , 30.060677 ,\n",
       "          30.354956 , 31.963589 , 29.452343 , 28.562216 , 30.817894 ,\n",
       "          29.425291 , 29.15633  , 29.34681  , 24.681929 , 27.930264 ,\n",
       "          27.222837 , 25.351742 , 28.809998 , 26.694473 , 26.763945 ,\n",
       "          27.412798 , 28.085712 , 28.503677 , 28.072922 , 27.572243 ,\n",
       "          27.530596 , 27.966782 , 28.52918  , 28.973478 , 27.053394 ,\n",
       "          27.46535  , 27.05968  , 26.976376 , 27.62928  , 26.642979 ,\n",
       "          23.596098 , 25.75708  , 26.683878 , 27.198196 , 25.101093 ,\n",
       "          22.455273 , 24.938795 , 24.047499 , 26.607162 , 28.313858 ,\n",
       "          26.617908 , 28.650928 , 28.212223 , 29.009615 , 29.244574 ,\n",
       "          26.407375 , 23.541208 , 25.404324 , 28.972002 , 28.722761 ,\n",
       "          30.549055 , 30.518562 , 30.428955 , 29.036015 , 29.344503 ,\n",
       "          26.517332 , 26.760056 , 27.755133 , 27.487791 , 26.832731 ,\n",
       "          29.076563 , 29.748938 , 26.9476   , 30.353174 , 30.952034 ,\n",
       "          31.728981 , 27.982042 , 28.96253  , 29.208895 , 30.067701 ,\n",
       "          30.03844  , 26.488958 , 25.96102  , 26.101326 , 24.746199 ,\n",
       "          25.020163 , 23.806454 , 25.32413  , 25.383852 , 24.842157 ,\n",
       "          24.67257  , 25.5861   , 23.837929 , 23.76212  , 26.106667 ,\n",
       "          25.75076  , 25.062689 , 25.698368 , 26.212883 , 25.843622 ,\n",
       "          25.854507 , 25.654089 , 13.838339 , 19.26919  , 26.008585 ,\n",
       "          24.246696 , 24.35364  , 23.673676 , 19.784992 , 25.067299 ,\n",
       "          23.961267 , 24.254189 , 21.515343 , 22.520176 , 24.270018 ,\n",
       "          24.444834 , 23.64156  , 25.694836 , 25.702717 , 23.866346 ,\n",
       "          23.005333 , 21.494696 , 23.158371 , 23.783371 , 22.999102 ,\n",
       "          22.846483 , 22.350853 , 23.640795 , 23.766987 , 23.764082 ,\n",
       "          25.06338  , 25.522629 , 25.896692 , 26.762669 , 26.114805 ,\n",
       "          26.776403 , 26.46484  , 26.85195  , 25.753344 , 26.34628  ,\n",
       "          26.046455 , 25.989113 , 25.067327 , 24.486258 , 25.125744 ,\n",
       "          24.852137 , 26.0811   , 26.992306 , 26.022081 , 26.145105 ,\n",
       "          26.090176 , 26.43768  , 26.20353  , 26.843088 , 25.86148  ,\n",
       "          26.562094 , 26.016632 , 25.889532 , 26.144789 , 26.38907  ,\n",
       "          24.208479 , 23.061052 , 24.460987 , 25.252546 , 25.57384  ,\n",
       "          24.08729  , 25.135216 , 25.102814 , 24.932598 , 21.66578  ,\n",
       "          25.679092 , 25.671812 , 25.718721 , 26.09059  , 24.928106 ,\n",
       "          25.311045 , 23.340652 , 25.396933 , 26.511854 , 27.230978 ,\n",
       "          27.022627 , 27.918346 , 28.24601  , 28.816359 , 29.790756 ,\n",
       "          29.147406 , 29.75251  , 29.17994  , 30.633179 , 31.585651 ,\n",
       "          30.988302 , 30.986292 , 30.785019 , 31.008081 , 28.845978 ,\n",
       "          30.007729 , 28.703348 , 29.524035 , 27.047112 , 27.27489  ,\n",
       "          28.016224 , 25.852041 , 27.589344 , 29.735994 , 30.50382  ,\n",
       "          30.996056 , 30.840015 , 30.879679 , 30.718658 , 29.807081 ,\n",
       "          30.083406 , 29.96691  , 29.284029 , 29.091217 , 29.275925 ,\n",
       "          28.610643 , 29.13011  , 27.405283 , 27.509926 , 23.845757 ,\n",
       "          20.249811 , 24.029701 , 16.85141  , 25.609386 , 26.582325 ,\n",
       "          26.331724 , 28.174187 , 29.235594 , 28.057327 , 26.13892  ,\n",
       "          26.794338 , 26.041788 , 25.977001 , 21.434864 , 25.674797 ,\n",
       "          24.896008 , 27.851406 , 27.248234 , 27.467905 , 25.36056  ,\n",
       "          28.313213 , 29.09295  , 26.757511 , 26.304047 , 26.88176  ,\n",
       "          19.874664 , 19.966005 , 19.864897 , 28.248528 , 28.43006  ,\n",
       "          23.346973 , 27.988401 , 26.213963 , 24.708984 , 27.678366 ,\n",
       "          27.704075 , 27.753399 , 27.830973 , 25.152613 , 25.328667 ,\n",
       "          27.85526  , 29.503685 , 29.929497 , 28.921373 , 28.747734 ,\n",
       "          26.668062 , 27.264751 , 27.60403  , 28.404276 , 31.186258 ,\n",
       "          29.088205 , 25.91056  , 24.779919 , 28.874279 , 28.31563  ,\n",
       "          27.790146 , 27.783587 , 30.347786 , 31.165995 , 29.327497 ,\n",
       "          30.117485 , 27.076523 , 28.93543  , 30.122555 , 26.113546 ,\n",
       "          27.032402 , 23.601053 , 25.809748 , 26.660471 , 27.271805 ,\n",
       "          27.805748 , 27.351368 , 25.024128 , 27.146177 , 28.728436 ,\n",
       "          28.855135 , 27.269712 , 29.852549 , 28.486269 , 26.705875 ,\n",
       "          25.934566 , 26.457287 , 20.424408 , 25.447147 , 24.646578 ,\n",
       "          24.173613 , 27.622032 , 26.13592  , 26.062195 , 24.84364  ,\n",
       "          25.000662 , 24.705992 , 27.194592 , 26.757635 , 27.251184 ,\n",
       "          29.186628 , 28.531504 , 27.20889  , 27.471165 , 28.157984 ,\n",
       "          29.703428 , 29.586231 , 28.893261 , 27.583488 , 28.074524 ,\n",
       "          25.615677 , 27.874228 , 28.599905 , 29.936005 , 32.225086 ,\n",
       "          30.936163 , 29.736628 , 32.518406 , 28.398268 , 24.731842 ,\n",
       "          27.37051  , 29.722572 , 28.796026 , 27.122509 , 27.146317 ,\n",
       "          29.983316 , 27.188934 , 28.666985 , 31.227135 , 31.85434  ,\n",
       "          32.27162  , 33.93347  , 32.99524  , 31.913853 , 29.086285 ,\n",
       "          30.406107 , 30.291332 , 29.00909  , 31.312963 , 30.64465  ,\n",
       "          28.874569 , 31.286755 , 31.947662 , 34.761734 , 33.782654 ,\n",
       "          34.76106  , 36.90637  , 36.51266  , 37.08396  , 35.284016 ,\n",
       "          36.363495 , 36.029438 , 39.472034 , 38.120644 , 37.13321  ,\n",
       "          38.238415 , 39.333878 , 37.37009  , 36.680515 , 40.971775 ,\n",
       "          39.987133 , 36.862225 , 34.161045 , 37.24032  , 36.77732  ,\n",
       "          35.55052  , 36.303562 , 37.276127 , 37.188595 , 36.928642 ,\n",
       "          36.52015  , 36.21989  , 37.094433 , 37.42209  , 39.03246  ,\n",
       "          36.92252  , 40.431503 , 38.95448  , 38.33959  , 39.05319  ,\n",
       "          41.11738  , 39.350452 , 38.616917 , 39.250286 , 38.628815 ,\n",
       "          39.4674   , 38.766212 , 38.546703 , 38.421696 , 37.563416 ,\n",
       "          37.134296 , 36.507454 , 37.74684  , 38.294296 , 37.547855 ,\n",
       "          36.976254 , 37.78562  , 37.4585   , 37.528954 , 39.546337 ,\n",
       "          38.525444 , 40.785797 , 39.1792   , 37.031593 , 33.75205  ,\n",
       "          31.94137  , 35.310326 , 33.80366  , 34.269726 , 34.336502 ,\n",
       "          33.4627   , 35.263214 , 35.374363 , 35.3731   , 33.04885  ,\n",
       "          31.447403 , 30.806961 , 35.283264 , 34.84679  , 33.56989  ,\n",
       "          27.449963 , 26.416708 , 24.476103 , 12.330863 ,  4.1209407,\n",
       "           9.051605 , 29.365496 , 19.449871 , 19.995571 , 30.928047 ,\n",
       "          32.05147  , 23.665245 , 28.45046  , 32.696182 , 31.363104 ,\n",
       "          15.023143 , 27.328934 , 35.850662 , 35.1831   , 35.93944  ,\n",
       "          37.975    , 37.876446 , 37.08089  , 38.475056 , 38.144154 ,\n",
       "          41.33968  , 40.510094 , 43.418358 , 41.596855 , 39.963245 ,\n",
       "          42.365314 , 44.081745 , 44.30852  , 45.667717 , 46.484608 ,\n",
       "          44.497356 , 45.905205 , 44.31375  , 45.499588 , 46.017353 ,\n",
       "          40.37339  , 44.9212   , 43.76781  , 43.890938 , 40.933994 ,\n",
       "          41.642155 , 41.03614  , 37.344902 , 37.03114  , 40.556843 ,\n",
       "          42.787476 , 43.274426 , 43.544407 , 44.196194 , 41.86746  ,\n",
       "          43.82056  , 44.779575 , 46.184322 , 48.07845  , 49.378708 ,\n",
       "          49.795124 , 49.121067 , 46.67189  , 47.504036 , 49.06955  ,\n",
       "          48.955296 , 50.021515 , 50.52259  , 50.219456 , 51.091743 ,\n",
       "          51.58631  , 52.38862  , 50.819977 , 50.41538  , 49.545673 ,\n",
       "          51.021694 , 51.840294 , 51.826065 , 52.50453  , 52.99625  ,\n",
       "          53.444176 , 53.280357 , 51.04032  , 50.134396 , 49.952377 ,\n",
       "          52.39417  , 51.882816 , 51.975883 , 52.708694 , 52.315014 ,\n",
       "          52.575184 , 48.95003  , 50.874046 , 52.77778  , 50.93591  ,\n",
       "          49.896336 , 46.571663 , 48.35065  , 48.72455  , 49.077736 ,\n",
       "          49.117466 , 49.870434 , 49.62874  , 47.630196 , 47.900097 ,\n",
       "          42.961536 , 47.657795 , 47.479446 , 49.2175   , 47.26467  ,\n",
       "          49.627872 , 48.738544 , 48.944397 , 49.388924 , 49.312645 ,\n",
       "          54.839222 , 51.466644 , 53.010433 , 55.501152 , 54.283028 ,\n",
       "          53.230408 , 53.059643 , 55.759247 , 55.851772 , 53.660656 ,\n",
       "          52.54872  , 52.94801  , 52.607815 , 53.70941  , 50.485294 ,\n",
       "          49.0341   , 52.212032 , 49.57907  , 48.922745 , 47.938866 ,\n",
       "          48.29966  , 43.80809  , 38.32247  , 42.286427 ,  3.2506814,\n",
       "          21.534088 , 30.253403 , 39.816998 , 33.607258 , 21.392477 ,\n",
       "          28.7175   , 40.790447 , 19.364809 , 41.97953  , 41.1646   ,\n",
       "          42.043068 , 43.736687 , 42.38166  , 44.741215 , 44.627235 ,\n",
       "          46.401608 , 43.37106  , 40.775627 , 40.97582  , 41.871273 ,\n",
       "          38.758442 , 19.613943 ,  5.1480775, 39.92442  , 41.060925 ,\n",
       "          40.533623 , 39.132267 , 39.70695  , 39.698277 , 34.425804 ,\n",
       "          34.31247  , 29.53926  , 40.3494   , 43.868008 , 42.3161   ,\n",
       "          43.888165 , 39.595882 , 38.088852 , 38.475636 , 39.603607 ,\n",
       "          41.145184 , 42.077213 , 40.90716  , 41.50854  , 42.16462  ,\n",
       "          43.170803 , 42.5903   , 42.84438  , 41.777634 , 39.075123 ,\n",
       "          37.99275  , 41.478737 , 43.29306  , 44.33116  , 44.035793 ,\n",
       "          42.707157 , 44.848343 , 43.63185  , 43.012817 , 43.89084  ,\n",
       "          46.677776 , 48.83101  , 46.763916 , 47.205807 , 47.040287 ,\n",
       "          48.858963 , 49.15515  , 41.452824 , 41.16545  , 42.813118 ,\n",
       "          43.188705 , 43.08741  , 43.85893  , 44.349174 , 45.684616 ,\n",
       "          45.731953 , 42.950775 , 43.48398  , 43.15677  , 43.91449  ,\n",
       "          48.145008 , 48.309155 , 48.68672  , 50.259872 , 45.408623 ,\n",
       "          49.45479  , 51.9686   , 48.622566 , 48.939945 , 46.681744 ,\n",
       "          48.386078 , 50.437023 , 51.582397 ], dtype=float32),\n",
       "   'run_time': 1.9847700595855713,\n",
       "   'status': 'ok'},\n",
       "  'misc': {'tid': 1,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'activation': [1],\n",
       "    'batch_normalization': [1],\n",
       "    'batch_size': [1],\n",
       "    'complete_inputs': [1],\n",
       "    'complete_sample': [1],\n",
       "    'device': [1],\n",
       "    'dropout_prob_exogenous': [1],\n",
       "    'dropout_prob_theta': [1],\n",
       "    'early_stop_patience': [1],\n",
       "    'eval_freq': [1],\n",
       "    'frequency': [1],\n",
       "    'idx_to_sample_freq': [1],\n",
       "    'initialization': [1],\n",
       "    'l1_theta': [1],\n",
       "    'learning_rate': [1],\n",
       "    'len_sample_chunks': [1],\n",
       "    'loss': [1],\n",
       "    'loss_hypar': [1],\n",
       "    'loss_valid': [1],\n",
       "    'lr_decay': [1],\n",
       "    'lr_decay_step_size': [1],\n",
       "    'max_epochs': [1],\n",
       "    'max_steps': [1],\n",
       "    'n_blocks': [1],\n",
       "    'n_harmonics': [1],\n",
       "    'n_hidden': [1],\n",
       "    'n_layers': [1],\n",
       "    'n_polynomials': [1],\n",
       "    'n_s_hidden': [1],\n",
       "    'n_series_per_batch': [1],\n",
       "    'n_time_in': [1],\n",
       "    'n_time_out': [1],\n",
       "    'n_val_weeks': [1],\n",
       "    'n_x_hidden': [1],\n",
       "    'normalizer_x': [1],\n",
       "    'normalizer_y': [1],\n",
       "    'random_seed': [1],\n",
       "    'seasonality': [1],\n",
       "    'shared_weights': [1],\n",
       "    'stack_types': [1],\n",
       "    'val_idx_to_sample_freq': [1],\n",
       "    'weight_decay': [1],\n",
       "    'window_sampling_limit': [1]},\n",
       "   'vals': {'activation': [0],\n",
       "    'batch_normalization': [0],\n",
       "    'batch_size': [0],\n",
       "    'complete_inputs': [0],\n",
       "    'complete_sample': [0],\n",
       "    'device': [0],\n",
       "    'dropout_prob_exogenous': [0.3024306449332244],\n",
       "    'dropout_prob_theta': [0.3851678624996854],\n",
       "    'early_stop_patience': [0],\n",
       "    'eval_freq': [0],\n",
       "    'frequency': [0],\n",
       "    'idx_to_sample_freq': [0],\n",
       "    'initialization': [0],\n",
       "    'l1_theta': [0],\n",
       "    'learning_rate': [0.0007294826926374994],\n",
       "    'len_sample_chunks': [0],\n",
       "    'loss': [0],\n",
       "    'loss_hypar': [0],\n",
       "    'loss_valid': [0],\n",
       "    'lr_decay': [0.3939003899063233],\n",
       "    'lr_decay_step_size': [0],\n",
       "    'max_epochs': [0],\n",
       "    'max_steps': [0],\n",
       "    'n_blocks': [0],\n",
       "    'n_harmonics': [0],\n",
       "    'n_hidden': [0],\n",
       "    'n_layers': [0],\n",
       "    'n_polynomials': [0],\n",
       "    'n_s_hidden': [0],\n",
       "    'n_series_per_batch': [0],\n",
       "    'n_time_in': [0],\n",
       "    'n_time_out': [0],\n",
       "    'n_val_weeks': [0],\n",
       "    'n_x_hidden': [3.0],\n",
       "    'normalizer_x': [0],\n",
       "    'normalizer_y': [0],\n",
       "    'random_seed': [16.0],\n",
       "    'seasonality': [0],\n",
       "    'shared_weights': [0],\n",
       "    'stack_types': [0],\n",
       "    'val_idx_to_sample_freq': [0],\n",
       "    'weight_decay': [8.299088918068486e-05],\n",
       "    'window_sampling_limit': [0]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2021, 6, 6, 19, 34, 53, 186000),\n",
       "  'refresh_time': datetime.datetime(2021, 6, 6, 19, 34, 55, 191000)}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
