{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Long Short-Term Memory Recurrent Neural Network (`LSTM`), uses a multilayer `LSTM` encoder and an `MLP` decoder. It builds upon the LSTM-cell that improves the exploding and vanishing gradients of classic `RNN`'s. This network has been extensively used in sequential prediction tasks like language modeling, phonetic labeling, and forecasting. The predictions are obtained by transforming the hidden states into contexts $\\mathbf{c}_{[t+1:t+H]}$, that are decoded and adapted into $\\mathbf{\\hat{y}}_{[t+1:t+H],[q]}$ through MLPs.\n",
    "\n",
    "\\begin{align}\n",
    " \\mathbf{h}_{t} &= \\textrm{LSTM}([\\mathbf{y}_{t},\\mathbf{x}^{(h)}_{t},\\mathbf{x}^{(s)}], \\mathbf{h}_{t-1})\\\\\n",
    "\\mathbf{c}_{[t+1:t+H]}&=\\textrm{Linear}([\\mathbf{h}_{t}, \\mathbf{x}^{(f)}_{[:t+H]}]) \\\\ \n",
    "\\hat{y}_{\\tau,[q]}&=\\textrm{MLP}([\\mathbf{c}_{\\tau},\\mathbf{x}^{(f)}_{\\tau}])\n",
    "\\end{align}\n",
    "\n",
    "where $\\mathbf{h}_{t}$, is the hidden state for time $t$, $\\mathbf{y}_{t}$ is the input at time $t$ and $\\mathbf{h}_{t-1}$ is the hidden state of the previous layer at $t-1$, $\\mathbf{x}^{(s)}$ are static exogenous inputs, $\\mathbf{x}^{(h)}_{t}$ historic exogenous, $\\mathbf{x}^{(f)}_{[:t+H]}$ are future exogenous available at the time of the prediction.\n",
    "\n",
    "**References**<br>-[Jeffrey L. Elman (1990). \"Finding Structure in Time\".](https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog1402_1)<br>-[Haşim Sak, Andrew Senior, Françoise Beaufays (2014). \"Long Short-Term Memory Based Recurrent Neural Network Architectures for Large Vocabulary Speech Recognition.\"](https://arxiv.org/abs/1402.1128)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 1. Long Short-Term Memory Cell.](imgs_models/lstm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "from neuralforecast.common._base_model import BaseModel\n",
    "from neuralforecast.common._modules import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LSTM(BaseModel):\n",
    "    \"\"\" LSTM\n",
    "\n",
    "    LSTM encoder, with MLP decoder.\n",
    "    The network has `tanh` or `relu` non-linearities, it is trained using \n",
    "    ADAM stochastic gradient descent. The network accepts static, historic \n",
    "    and future exogenous data.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `h`: int, forecast horizon.<br>\n",
    "    `input_size`: int, maximum sequence length for truncated train backpropagation. Default -1 uses all history.<br>\n",
    "    `inference_input_size`: int, maximum sequence length for truncated inference. Default -1 uses all history.<br>\n",
    "    `encoder_n_layers`: int=2, number of layers for the LSTM.<br>\n",
    "    `encoder_hidden_size`: int=200, units for the LSTM's hidden state size.<br>\n",
    "    `encoder_bias`: bool=True, whether or not to use biases b_ih, b_hh within LSTM units.<br>\n",
    "    `encoder_dropout`: float=0., dropout regularization applied to LSTM outputs.<br>\n",
    "    `context_size`: int=10, size of context vector for each timestamp on the forecasting window.<br>\n",
    "    `decoder_hidden_size`: int=200, size of hidden layer for the MLP decoder.<br>\n",
    "    `decoder_layers`: int=2, number of layers for the MLP decoder.<br>\n",
    "    `futr_exog_list`: str list, future exogenous columns.<br>\n",
    "    `hist_exog_list`: str list, historic exogenous columns.<br>\n",
    "    `stat_exog_list`: str list, static exogenous columns.<br>\n",
    "    `loss`: PyTorch module, instantiated train loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
    "    `valid_loss`: PyTorch module=`loss`, instantiated valid loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
    "    `max_steps`: int=1000, maximum number of training steps.<br>\n",
    "    `learning_rate`: float=1e-3, Learning rate between (0, 1).<br>\n",
    "    `num_lr_decays`: int=-1, Number of learning rate decays, evenly distributed across max_steps.<br>\n",
    "    `early_stop_patience_steps`: int=-1, Number of validation iterations before early stopping.<br>\n",
    "    `val_check_steps`: int=100, Number of training steps between every validation loss check.<br>\n",
    "    `batch_size`: int=32, number of differentseries in each batch.<br>\n",
    "    `valid_batch_size`: int=None, number of different series in each validation and test batch.<br>\n",
    "    `scaler_type`: str='robust', type of scaler for temporal inputs normalization see [temporal scalers](https://nixtla.github.io/neuralforecast/common.scalers.html).<br>\n",
    "    `random_seed`: int=1, random_seed for pytorch initializer and numpy generators.<br>\n",
    "    `num_workers_loader`: int=os.cpu_count(), workers to be used by `TimeSeriesDataLoader`.<br>\n",
    "    `drop_last_loader`: bool=False, if True `TimeSeriesDataLoader` drops last non-full batch.<br>\n",
    "    `alias`: str, optional,  Custom name of the model.<br>\n",
    "    `optimizer`: Subclass of 'torch.optim.Optimizer', optional, user specified optimizer instead of the default choice (Adam).<br>\n",
    "    `optimizer_kwargs`: dict, optional, list of parameters used by the user specified `optimizer`.<br>\n",
    "    `lr_scheduler`: Subclass of 'torch.optim.lr_scheduler.LRScheduler', optional, user specified lr_scheduler instead of the default choice (StepLR).<br>\n",
    "    `lr_scheduler_kwargs`: dict, optional, list of parameters used by the user specified `lr_scheduler`.<br>    \n",
    "    `**trainer_kwargs`: int,  keyword trainer arguments inherited from [PyTorch Lighning's trainer](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).<br>    \n",
    "    \"\"\"\n",
    "    # Class attributes\n",
    "    SAMPLING_TYPE = 'recurrent'\n",
    "    EXOGENOUS_FUTR = True\n",
    "    EXOGENOUS_HIST = True\n",
    "    EXOGENOUS_STAT = True\n",
    "    MULTIVARIATE = False    # If the model produces multivariate forecasts (True) or univariate (False)\n",
    "    RECURRENT = True        # If the model produces forecasts recursively (True) or direct (False)\n",
    "\n",
    "    def __init__(self,\n",
    "                 h: int,\n",
    "                 input_size: int,\n",
    "                 encoder_n_layers: int = 2,\n",
    "                 encoder_hidden_size: int = 200,\n",
    "                 encoder_bias: bool = True,\n",
    "                 encoder_dropout: float = 0.,\n",
    "                 context_size: int = 10,\n",
    "                 decoder_hidden_size: int = 200,\n",
    "                 decoder_layers: int = 2,\n",
    "                 futr_exog_list = None,\n",
    "                 hist_exog_list = None,\n",
    "                 stat_exog_list = None,\n",
    "                 exclude_insample_y = False,\n",
    "                 loss = MAE(),\n",
    "                 valid_loss = None,\n",
    "                 max_steps: int = 1000,\n",
    "                 learning_rate: float = 1e-3,\n",
    "                 num_lr_decays: int = -1,\n",
    "                 early_stop_patience_steps: int =-1,\n",
    "                 val_check_steps: int = 100,\n",
    "                 batch_size = 32,\n",
    "                 valid_batch_size: Optional[int] = None,\n",
    "                 windows_batch_size = 1024,\n",
    "                 inference_windows_batch_size = 1024,\n",
    "                 start_padding_enabled = False,\n",
    "                 step_size: int = 1,\n",
    "                 scaler_type: str = 'robust',\n",
    "                 random_seed = 1,\n",
    "                 num_workers_loader = 0,\n",
    "                 drop_last_loader = False,\n",
    "                 optimizer = None,\n",
    "                 optimizer_kwargs = None,\n",
    "                 lr_scheduler = None,\n",
    "                 lr_scheduler_kwargs = None,\n",
    "                 **trainer_kwargs):\n",
    "        super(LSTM, self).__init__(\n",
    "            h=h,\n",
    "            input_size=input_size,\n",
    "            futr_exog_list=futr_exog_list,\n",
    "            hist_exog_list=hist_exog_list,\n",
    "            stat_exog_list=stat_exog_list,\n",
    "            exclude_insample_y = exclude_insample_y,\n",
    "            loss=loss,\n",
    "            valid_loss=valid_loss,\n",
    "            max_steps=max_steps,\n",
    "            learning_rate=learning_rate,\n",
    "            num_lr_decays=num_lr_decays,\n",
    "            early_stop_patience_steps=early_stop_patience_steps,\n",
    "            val_check_steps=val_check_steps,\n",
    "            batch_size=batch_size,\n",
    "            valid_batch_size=valid_batch_size,\n",
    "            windows_batch_size=windows_batch_size,\n",
    "            inference_windows_batch_size=inference_windows_batch_size,\n",
    "            start_padding_enabled=start_padding_enabled,\n",
    "            step_size=step_size,\n",
    "            scaler_type=scaler_type,\n",
    "            random_seed=random_seed,\n",
    "            num_workers_loader=num_workers_loader,\n",
    "            drop_last_loader=drop_last_loader,\n",
    "            optimizer=optimizer,\n",
    "            optimizer_kwargs=optimizer_kwargs,\n",
    "            lr_scheduler=lr_scheduler,\n",
    "            lr_scheduler_kwargs=lr_scheduler_kwargs,\n",
    "            **trainer_kwargs\n",
    "        )\n",
    "\n",
    "        # LSTM\n",
    "        self.encoder_n_layers = encoder_n_layers\n",
    "        self.encoder_hidden_size = encoder_hidden_size\n",
    "        self.encoder_bias = encoder_bias\n",
    "        self.encoder_dropout = encoder_dropout\n",
    "        \n",
    "        # Context adapter\n",
    "        self.context_size = context_size\n",
    "\n",
    "        # MLP decoder\n",
    "        self.decoder_hidden_size = decoder_hidden_size\n",
    "        self.decoder_layers = decoder_layers\n",
    "\n",
    "        # LSTM input size (1 for target variable y)\n",
    "        input_encoder = 1 + self.hist_exog_size + self.stat_exog_size + self.futr_exog_size\n",
    "\n",
    "        # Instantiate model\n",
    "        self.rnn_state = None\n",
    "        self.hist_encoder = nn.LSTM(input_size=input_encoder,\n",
    "                                    hidden_size=self.encoder_hidden_size,\n",
    "                                    num_layers=self.encoder_n_layers,\n",
    "                                    bias=self.encoder_bias,\n",
    "                                    dropout=self.encoder_dropout,\n",
    "                                    batch_first=True)\n",
    "\n",
    "        # Context adapter\n",
    "        self.context_adapter = nn.Linear(in_features=self.encoder_hidden_size,\n",
    "                                         out_features=self.context_size * h)\n",
    "\n",
    "        # Decoder MLP\n",
    "        self.mlp_decoder = MLP(in_features=self.context_size * h + self.futr_exog_size,\n",
    "                               out_features=self.loss.outputsize_multiplier,\n",
    "                               hidden_size=self.decoder_hidden_size,\n",
    "                               num_layers=self.decoder_layers,\n",
    "                               activation='ReLU',\n",
    "                               dropout=0.0)\n",
    "\n",
    "    def forward(self, windows_batch):\n",
    "        \n",
    "        # Parse windows_batch\n",
    "        encoder_input = windows_batch['insample_y']                         # [B, seq_len, 1]\n",
    "        futr_exog     = windows_batch['futr_exog']                          # [B, seq_len, F]\n",
    "        hist_exog     = windows_batch['hist_exog']                          # [B, seq_len, X]\n",
    "        stat_exog     = windows_batch['stat_exog']                          # [B, S]\n",
    "\n",
    "        # Concatenate y, historic and static inputs              \n",
    "        batch_size, seq_len = encoder_input.shape[:2]\n",
    "        if self.hist_exog_size > 0:\n",
    "            encoder_input = torch.cat((encoder_input, hist_exog), dim=2)    # [B, seq_len, 1] + [B, seq_len, X] -> [B, seq_len, 1 + X]\n",
    "\n",
    "        if self.stat_exog_size > 0:\n",
    "            # print(encoder_input.shape)\n",
    "            stat_exog = stat_exog.unsqueeze(1).repeat(1, seq_len, 1)        # [B, S] -> [B, seq_len, S]\n",
    "            encoder_input = torch.cat((encoder_input, stat_exog), dim=2)    # [B, seq_len, 1 + X] + [B, seq_len, S] -> [B, seq_len, 1 + X + S]\n",
    "\n",
    "        if self.futr_exog_size > 0:\n",
    "            encoder_input = torch.cat((encoder_input, futr_exog), dim=2)    # [B, seq_len, 1 + X + S] + [B, seq_len, F] -> [B, seq_len, 1 + X + S + F]\n",
    "\n",
    "        # RNN forward\n",
    "        if self.maintain_state:\n",
    "            rnn_state = self.rnn_state\n",
    "        else:\n",
    "            rnn_state = None\n",
    "        \n",
    "        hidden_state, rnn_state = self.hist_encoder(encoder_input, \n",
    "                                                         rnn_state)    # [B, seq_len, rnn_hidden_state]\n",
    "        if self.maintain_state:\n",
    "            self.rnn_state = rnn_state\n",
    "\n",
    "        # Context adapter\n",
    "        context = self.context_adapter(hidden_state)                        # [B, seq_len, rnn_hidden_state] -> [B, seq_len, context_size * h]\n",
    "\n",
    "        # Residual connection with futr_exog\n",
    "        if self.futr_exog_size > 0:\n",
    "            context = torch.cat((context, futr_exog), dim=-1)               # [B, seq_len, context_size * h] + [B, seq_len, F] = [B, seq_len, context_size * h + F]\n",
    "\n",
    "        # Final forecast\n",
    "        output = self.mlp_decoder(context)                                  # [B, seq_len, context_size * h + F] -> [B, seq_len, n_output]\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/models/lstm.py#L19){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LSTM\n",
       "\n",
       ">      LSTM (h:int, input_size:int, encoder_n_layers:int=2,\n",
       ">            encoder_hidden_size:int=200, encoder_bias:bool=True,\n",
       ">            encoder_dropout:float=0.0, context_size:int=10,\n",
       ">            decoder_hidden_size:int=200, decoder_layers:int=2,\n",
       ">            futr_exog_list=None, hist_exog_list=None, stat_exog_list=None,\n",
       ">            exclude_insample_y=False, loss=MAE(), valid_loss=None,\n",
       ">            max_steps:int=1000, learning_rate:float=0.001,\n",
       ">            num_lr_decays:int=-1, early_stop_patience_steps:int=-1,\n",
       ">            val_check_steps:int=100, batch_size=32,\n",
       ">            valid_batch_size:Optional[int]=None, windows_batch_size=1024,\n",
       ">            inference_windows_batch_size=1024, start_padding_enabled=False,\n",
       ">            step_size:int=1, scaler_type:str='robust', random_seed=1,\n",
       ">            num_workers_loader=0, drop_last_loader=False, optimizer=None,\n",
       ">            optimizer_kwargs=None, lr_scheduler=None, lr_scheduler_kwargs=None,\n",
       ">            **trainer_kwargs)\n",
       "\n",
       "*LSTM\n",
       "\n",
       "LSTM encoder, with MLP decoder.\n",
       "The network has `tanh` or `relu` non-linearities, it is trained using \n",
       "ADAM stochastic gradient descent. The network accepts static, historic \n",
       "and future exogenous data.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`h`: int, forecast horizon.<br>\n",
       "`input_size`: int, maximum sequence length for truncated train backpropagation. Default -1 uses all history.<br>\n",
       "`inference_input_size`: int, maximum sequence length for truncated inference. Default -1 uses all history.<br>\n",
       "`encoder_n_layers`: int=2, number of layers for the LSTM.<br>\n",
       "`encoder_hidden_size`: int=200, units for the LSTM's hidden state size.<br>\n",
       "`encoder_bias`: bool=True, whether or not to use biases b_ih, b_hh within LSTM units.<br>\n",
       "`encoder_dropout`: float=0., dropout regularization applied to LSTM outputs.<br>\n",
       "`context_size`: int=10, size of context vector for each timestamp on the forecasting window.<br>\n",
       "`decoder_hidden_size`: int=200, size of hidden layer for the MLP decoder.<br>\n",
       "`decoder_layers`: int=2, number of layers for the MLP decoder.<br>\n",
       "`futr_exog_list`: str list, future exogenous columns.<br>\n",
       "`hist_exog_list`: str list, historic exogenous columns.<br>\n",
       "`stat_exog_list`: str list, static exogenous columns.<br>\n",
       "`loss`: PyTorch module, instantiated train loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
       "`valid_loss`: PyTorch module=`loss`, instantiated valid loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
       "`max_steps`: int=1000, maximum number of training steps.<br>\n",
       "`learning_rate`: float=1e-3, Learning rate between (0, 1).<br>\n",
       "`num_lr_decays`: int=-1, Number of learning rate decays, evenly distributed across max_steps.<br>\n",
       "`early_stop_patience_steps`: int=-1, Number of validation iterations before early stopping.<br>\n",
       "`val_check_steps`: int=100, Number of training steps between every validation loss check.<br>\n",
       "`batch_size`: int=32, number of differentseries in each batch.<br>\n",
       "`valid_batch_size`: int=None, number of different series in each validation and test batch.<br>\n",
       "`scaler_type`: str='robust', type of scaler for temporal inputs normalization see [temporal scalers](https://nixtla.github.io/neuralforecast/common.scalers.html).<br>\n",
       "`random_seed`: int=1, random_seed for pytorch initializer and numpy generators.<br>\n",
       "`num_workers_loader`: int=os.cpu_count(), workers to be used by `TimeSeriesDataLoader`.<br>\n",
       "`drop_last_loader`: bool=False, if True `TimeSeriesDataLoader` drops last non-full batch.<br>\n",
       "`alias`: str, optional,  Custom name of the model.<br>\n",
       "`optimizer`: Subclass of 'torch.optim.Optimizer', optional, user specified optimizer instead of the default choice (Adam).<br>\n",
       "`optimizer_kwargs`: dict, optional, list of parameters used by the user specified `optimizer`.<br>\n",
       "`lr_scheduler`: Subclass of 'torch.optim.lr_scheduler.LRScheduler', optional, user specified lr_scheduler instead of the default choice (StepLR).<br>\n",
       "`lr_scheduler_kwargs`: dict, optional, list of parameters used by the user specified `lr_scheduler`.<br>    \n",
       "`**trainer_kwargs`: int,  keyword trainer arguments inherited from [PyTorch Lighning's trainer](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).<br>*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/models/lstm.py#L19){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LSTM\n",
       "\n",
       ">      LSTM (h:int, input_size:int, encoder_n_layers:int=2,\n",
       ">            encoder_hidden_size:int=200, encoder_bias:bool=True,\n",
       ">            encoder_dropout:float=0.0, context_size:int=10,\n",
       ">            decoder_hidden_size:int=200, decoder_layers:int=2,\n",
       ">            futr_exog_list=None, hist_exog_list=None, stat_exog_list=None,\n",
       ">            exclude_insample_y=False, loss=MAE(), valid_loss=None,\n",
       ">            max_steps:int=1000, learning_rate:float=0.001,\n",
       ">            num_lr_decays:int=-1, early_stop_patience_steps:int=-1,\n",
       ">            val_check_steps:int=100, batch_size=32,\n",
       ">            valid_batch_size:Optional[int]=None, windows_batch_size=1024,\n",
       ">            inference_windows_batch_size=1024, start_padding_enabled=False,\n",
       ">            step_size:int=1, scaler_type:str='robust', random_seed=1,\n",
       ">            num_workers_loader=0, drop_last_loader=False, optimizer=None,\n",
       ">            optimizer_kwargs=None, lr_scheduler=None, lr_scheduler_kwargs=None,\n",
       ">            **trainer_kwargs)\n",
       "\n",
       "*LSTM\n",
       "\n",
       "LSTM encoder, with MLP decoder.\n",
       "The network has `tanh` or `relu` non-linearities, it is trained using \n",
       "ADAM stochastic gradient descent. The network accepts static, historic \n",
       "and future exogenous data.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`h`: int, forecast horizon.<br>\n",
       "`input_size`: int, maximum sequence length for truncated train backpropagation. Default -1 uses all history.<br>\n",
       "`inference_input_size`: int, maximum sequence length for truncated inference. Default -1 uses all history.<br>\n",
       "`encoder_n_layers`: int=2, number of layers for the LSTM.<br>\n",
       "`encoder_hidden_size`: int=200, units for the LSTM's hidden state size.<br>\n",
       "`encoder_bias`: bool=True, whether or not to use biases b_ih, b_hh within LSTM units.<br>\n",
       "`encoder_dropout`: float=0., dropout regularization applied to LSTM outputs.<br>\n",
       "`context_size`: int=10, size of context vector for each timestamp on the forecasting window.<br>\n",
       "`decoder_hidden_size`: int=200, size of hidden layer for the MLP decoder.<br>\n",
       "`decoder_layers`: int=2, number of layers for the MLP decoder.<br>\n",
       "`futr_exog_list`: str list, future exogenous columns.<br>\n",
       "`hist_exog_list`: str list, historic exogenous columns.<br>\n",
       "`stat_exog_list`: str list, static exogenous columns.<br>\n",
       "`loss`: PyTorch module, instantiated train loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
       "`valid_loss`: PyTorch module=`loss`, instantiated valid loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
       "`max_steps`: int=1000, maximum number of training steps.<br>\n",
       "`learning_rate`: float=1e-3, Learning rate between (0, 1).<br>\n",
       "`num_lr_decays`: int=-1, Number of learning rate decays, evenly distributed across max_steps.<br>\n",
       "`early_stop_patience_steps`: int=-1, Number of validation iterations before early stopping.<br>\n",
       "`val_check_steps`: int=100, Number of training steps between every validation loss check.<br>\n",
       "`batch_size`: int=32, number of differentseries in each batch.<br>\n",
       "`valid_batch_size`: int=None, number of different series in each validation and test batch.<br>\n",
       "`scaler_type`: str='robust', type of scaler for temporal inputs normalization see [temporal scalers](https://nixtla.github.io/neuralforecast/common.scalers.html).<br>\n",
       "`random_seed`: int=1, random_seed for pytorch initializer and numpy generators.<br>\n",
       "`num_workers_loader`: int=os.cpu_count(), workers to be used by `TimeSeriesDataLoader`.<br>\n",
       "`drop_last_loader`: bool=False, if True `TimeSeriesDataLoader` drops last non-full batch.<br>\n",
       "`alias`: str, optional,  Custom name of the model.<br>\n",
       "`optimizer`: Subclass of 'torch.optim.Optimizer', optional, user specified optimizer instead of the default choice (Adam).<br>\n",
       "`optimizer_kwargs`: dict, optional, list of parameters used by the user specified `optimizer`.<br>\n",
       "`lr_scheduler`: Subclass of 'torch.optim.lr_scheduler.LRScheduler', optional, user specified lr_scheduler instead of the default choice (StepLR).<br>\n",
       "`lr_scheduler_kwargs`: dict, optional, list of parameters used by the user specified `lr_scheduler`.<br>    \n",
       "`**trainer_kwargs`: int,  keyword trainer arguments inherited from [PyTorch Lighning's trainer](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).<br>*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LSTM.fit\n",
       "\n",
       ">      LSTM.fit (dataset, val_size=0, test_size=0, random_seed=None,\n",
       ">                distributed_config=None)\n",
       "\n",
       "*Fit.\n",
       "\n",
       "The `fit` method, optimizes the neural network's weights using the\n",
       "initialization parameters (`learning_rate`, `windows_batch_size`, ...)\n",
       "and the `loss` function as defined during the initialization.\n",
       "Within `fit` we use a PyTorch Lightning `Trainer` that\n",
       "inherits the initialization's `self.trainer_kwargs`, to customize\n",
       "its inputs, see [PL's trainer arguments](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).\n",
       "\n",
       "The method is designed to be compatible with SKLearn-like classes\n",
       "and in particular to be compatible with the StatsForecast library.\n",
       "\n",
       "By default the `model` is not saving training checkpoints to protect\n",
       "disk memory, to get them change `enable_checkpointing=True` in `__init__`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`val_size`: int, validation size for temporal cross-validation.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`test_size`: int, test size for temporal cross-validation.<br>*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LSTM.fit\n",
       "\n",
       ">      LSTM.fit (dataset, val_size=0, test_size=0, random_seed=None,\n",
       ">                distributed_config=None)\n",
       "\n",
       "*Fit.\n",
       "\n",
       "The `fit` method, optimizes the neural network's weights using the\n",
       "initialization parameters (`learning_rate`, `windows_batch_size`, ...)\n",
       "and the `loss` function as defined during the initialization.\n",
       "Within `fit` we use a PyTorch Lightning `Trainer` that\n",
       "inherits the initialization's `self.trainer_kwargs`, to customize\n",
       "its inputs, see [PL's trainer arguments](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).\n",
       "\n",
       "The method is designed to be compatible with SKLearn-like classes\n",
       "and in particular to be compatible with the StatsForecast library.\n",
       "\n",
       "By default the `model` is not saving training checkpoints to protect\n",
       "disk memory, to get them change `enable_checkpointing=True` in `__init__`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`val_size`: int, validation size for temporal cross-validation.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`test_size`: int, test size for temporal cross-validation.<br>*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LSTM.fit, name='LSTM.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### LSTM.predict\n",
       "\n",
       ">      LSTM.predict (dataset, test_size=None, step_size=1, random_seed=None,\n",
       ">                    **data_module_kwargs)\n",
       "\n",
       "*Predict.\n",
       "\n",
       "Neural network prediction with PL's `Trainer` execution of `predict_step`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`test_size`: int=None, test size for temporal cross-validation.<br>\n",
       "`step_size`: int=1, Step size between each window.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`**data_module_kwargs`: PL's TimeSeriesDataModule args, see [documentation](https://pytorch-lightning.readthedocs.io/en/1.6.1/extensions/datamodules.html#using-a-datamodule).*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### LSTM.predict\n",
       "\n",
       ">      LSTM.predict (dataset, test_size=None, step_size=1, random_seed=None,\n",
       ">                    **data_module_kwargs)\n",
       "\n",
       "*Predict.\n",
       "\n",
       "Neural network prediction with PL's `Trainer` execution of `predict_step`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`test_size`: int=None, test size for temporal cross-validation.<br>\n",
       "`step_size`: int=1, Step size between each window.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`**data_module_kwargs`: PL's TimeSeriesDataModule args, see [documentation](https://pytorch-lightning.readthedocs.io/en/1.6.1/extensions/datamodules.html#using-a-datamodule).*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(LSTM.predict, name='LSTM.predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import LSTM\n",
    "from neuralforecast.losses.pytorch import DistributionLoss\n",
    "from neuralforecast.utils import AirPassengersPanel, AirPassengersStatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type             | Params\n",
      "-----------------------------------------------------\n",
      "0 | loss            | DistributionLoss | 5     \n",
      "1 | padder_train    | ConstantPad1d    | 0     \n",
      "2 | scaler          | TemporalNorm     | 0     \n",
      "3 | hist_encoder    | LSTM             | 200 K \n",
      "4 | context_adapter | Linear           | 15.5 K\n",
      "5 | mlp_decoder     | MLP              | 15.9 K\n",
      "-----------------------------------------------------\n",
      "231 K     Trainable params\n",
      "5         Non-trainable params\n",
      "231 K     Total params\n",
      "0.926     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 33.33it/s, v_num=3697, train_loss_step=3.670, train_loss_epoch=3.670]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199: 100%|██████████| 1/1 [00:00<00:00, 32.25it/s, v_num=3697, train_loss_step=3.670, train_loss_epoch=3.670]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ospra\\miniconda3\\envs\\neuralforecast\\lib\\site-packages\\utilsforecast\\processing.py:374: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(freq)\n",
      "c:\\Users\\ospra\\miniconda3\\envs\\neuralforecast\\lib\\site-packages\\utilsforecast\\processing.py:428: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(freq)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 29.56it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ospra\\OneDrive\\Phd\\Repositories\\neuralforecast\\neuralforecast\\core.py:196: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Y_train_df = AirPassengersPanel[AirPassengersPanel.ds<AirPassengersPanel['ds'].values[-12]] # 132 train\n",
    "Y_test_df = AirPassengersPanel[AirPassengersPanel.ds>=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n",
    "\n",
    "nf = NeuralForecast(\n",
    "    models=[LSTM(h=12, \n",
    "                 input_size=24,\n",
    "                 loss=DistributionLoss(distribution='Normal', level=[80, 90]),\n",
    "                #  loss=MAE(),\n",
    "                 scaler_type='robust',\n",
    "                 encoder_n_layers=2,\n",
    "                 encoder_hidden_size=128,\n",
    "                 context_size=10,\n",
    "                 decoder_hidden_size=128,\n",
    "                 decoder_layers=2,\n",
    "                 max_steps=200,\n",
    "                 futr_exog_list=['y_[lag12]'],\n",
    "                 #hist_exog_list=['y_[lag12]'],\n",
    "                 stat_exog_list=['airline1'],\n",
    "                 )\n",
    "    ],\n",
    "    freq='M'\n",
    ")\n",
    "nf.fit(df=Y_train_df, static_df=AirPassengersStatic)\n",
    "Y_hat_df = nf.predict(futr_df=Y_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plots\n",
    "Y_hat_df = Y_hat_df.reset_index(drop=False).drop(columns=['unique_id','ds'])\n",
    "plot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\n",
    "plot_df = pd.concat([Y_train_df, plot_df])\n",
    "\n",
    "plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n",
    "plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n",
    "# plt.plot(plot_df['ds'], plot_df['LSTM'], c='purple', label='mean')\n",
    "plt.plot(plot_df['ds'], plot_df['LSTM-median'], c='blue', label='median')\n",
    "plt.fill_between(x=plot_df['ds'][-12:], \n",
    "                 y1=plot_df['LSTM-lo-90'][-12:].values, \n",
    "                 y2=plot_df['LSTM-hi-90'][-12:].values,\n",
    "                 alpha=0.4, label='level 90')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
