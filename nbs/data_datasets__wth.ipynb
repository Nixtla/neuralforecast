{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.datasets.wth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather (WTH) dataset\n",
    "\n",
    "> Download the WTH dataset: https://www.ncei.noaa.gov/data/local-climatological-data/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import gdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nixtlats.data.datasets.utils import Info, time_features_from_frequency_str\n",
    "from nixtlats.data.datasets.ett import process_multiple_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WTH meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class WTH:\n",
    "    freq: str = 'H'\n",
    "    name: str = 'WTH'\n",
    "    n_ts: int = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "WTHInfo = Info(groups=('WTH',),\n",
    "              class_groups=(WTH,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class WTH:\n",
    "    \n",
    "    source_url: str = 'https://drive.google.com/uc?id=1UBRz-aM_57i_KCC-iaSWoKDPTGGv6EaG'\n",
    "\n",
    "    @staticmethod\n",
    "    def load(directory: str,\n",
    "             cache: bool = True) -> Tuple[pd.DataFrame, \n",
    "                                          Optional[pd.DataFrame], \n",
    "                                          Optional[pd.DataFrame]]:\n",
    "        \"\"\"Downloads and loads ETT data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        cache: bool\n",
    "            If `True` saves and loads \n",
    "            \n",
    "        Notes\n",
    "        -----\n",
    "        [1] Returns train+val+test sets.\n",
    "        \"\"\"\n",
    "        path = f'{directory}/wth/datasets'\n",
    "        file_cache = f'{path}/WTH.p'\n",
    "        \n",
    "        if os.path.exists(file_cache) and cache:\n",
    "            df, X_df, S_df = pd.read_pickle(file_cache)\n",
    "            \n",
    "            return df, X_df, S_df\n",
    "        \n",
    "        \n",
    "        WTH.download(directory)\n",
    "        path = f'{directory}/wth/datasets'\n",
    "        \n",
    "        y_df = pd.read_csv(f'{path}/WTH.csv')\n",
    "        y_df, X_df = process_multiple_ts(y_df)\n",
    "       \n",
    "        S_df = None\n",
    "        if cache:\n",
    "            pd.to_pickle((y_df, X_df, S_df), file_cache)\n",
    "            \n",
    "        return y_df, X_df, S_df\n",
    "\n",
    "    @staticmethod\n",
    "    def download(directory: str) -> None:\n",
    "        \"\"\"Download WTH Dataset.\"\"\"\n",
    "        path = f'{directory}/wth/datasets/'\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            gdown.download(WTH.source_url, f'{path}/WTH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: WTH n_series: 12 ex_vars: HourOfDay, DayOfWeek, DayOfMonth, DayOfYear\n"
     ]
    }
   ],
   "source": [
    "for group, meta in WTHInfo:\n",
    "    y_df, x_df, s_df = WTH.load(directory='data', cache=False)\n",
    "    n_series = len(np.unique(y_df.unique_id.values))\n",
    "    ex_vars = x_df.columns.to_list()\n",
    "    ex_vars.remove('unique_id')\n",
    "    ex_vars.remove('ds')\n",
    "\n",
    "    display_str  = f'Group: {group} '\n",
    "    display_str += f'n_series: {n_series} '\n",
    "    display_str += f'ex_vars: {\", \".join(ex_vars)}'\n",
    "\n",
    "    print(display_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_wth(expected_first_ds_y: np.ndarray,\n",
    "             expected_first_ds_x: np.ndarray) -> None:\n",
    "    y_df, x_df, _ = WTH.load(directory='data', cache=False)\n",
    "    first_ds_y = y_df.groupby('unique_id').head(1)['y'].values\n",
    "    first_ds_x = x_df.groupby('unique_id').head(1).drop(['unique_id', 'ds'], axis=1).values\n",
    "    expected_x = np.repeat(expected_first_ds_x.reshape(1, -1), first_ds_x.shape[0], axis=0)\n",
    "    \n",
    "    np.testing.assert_array_almost_equal(first_ds_y, expected_first_ds_y)\n",
    "    np.testing.assert_array_almost_equal(first_ds_x, expected_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wth(expected_first_ds_y=np.array([ 10.,  16.,  -9.,  13.,   7., -14.,  67.,   7.,  130.,  21.65,  30.35, -10.3]),\n",
    "         expected_first_ds_x=np.array([-0.5       ,  0.16666667, -0.5       , -0.5       ]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('nixtla': conda)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
