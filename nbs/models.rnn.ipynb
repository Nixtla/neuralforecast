{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models.rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elman proposed this classic recurrent neural network (`RNN`) in 1990, where each layer uses the following recurrent transformation:\n",
    "$$\\mathbf{h}^{l}_{t} = \\mathrm{Activation}([\\mathbf{y}_{t},\\mathbf{x}^{(h)}_{t},\\mathbf{x}^{(s)}] W^{\\intercal}_{ih} + b_{ih}  +  \\mathbf{h}^{l}_{t-1} W^{\\intercal}_{hh} + b_{hh})$$ \n",
    "\n",
    "where $\\mathbf{h}^{l}_{t}$, is the hidden state of RNN layer $l$ for time $t$, $\\mathbf{y}_{t}$ is the input at time $t$ and $\\mathbf{h}_{t-1}$ is the hidden state of the previous layer at $t-1$, $\\mathbf{x}^{(s)}$ are static exogenous inputs, $\\mathbf{x}^{(h)}_{t}$ historic exogenous, $\\mathbf{x}^{(f)}_{[:t+H]}$ are future exogenous available at the time of the prediction. The available activations are `tanh`, and `relu`. The predictions are obtained by transforming the hidden states into contexts $\\mathbf{c}_{[t+1:t+H]}$, that are decoded and adapted into $\\mathbf{\\hat{y}}_{[t+1:t+H],[q]}$ through MLPs.\n",
    "\n",
    "\\begin{align}\n",
    " \\mathbf{h}_{t} &= \\textrm{RNN}([\\mathbf{y}_{t},\\mathbf{x}^{(h)}_{t},\\mathbf{x}^{(s)}], \\mathbf{h}_{t-1})\\\\\n",
    "\\mathbf{c}_{[t+1:t+H]}&=\\textrm{Linear}([\\mathbf{h}_{t}, \\mathbf{x}^{(f)}_{[:t+H]}]) \\\\ \n",
    "\\hat{y}_{\\tau,[q]}&=\\textrm{MLP}([\\mathbf{c}_{\\tau},\\mathbf{x}^{(f)}_{\\tau}])\n",
    "\\end{align}\n",
    "\n",
    "**References**<br>\n",
    "-[Jeffrey L. Elman (1990). \"Finding Structure in Time\".](https://onlinelibrary.wiley.com/doiabs/10.1207/s15516709cog1402_1)<br>\n",
    "-[Cho, K., van Merrienboer, B., Gülcehre, C., Bougares, F., Schwenk, H., & Bengio, Y. (2014). Learning phrase representations using RNN encoder-decoder for statistical machine translation.](http://arxiv.org/abs/1406.1078)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Figure 1. Single Layer Elman RNN with MLP decoder.](imgs_models/rnn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ospra\\miniconda3\\envs\\neuralforecast\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import show_doc\n",
    "from neuralforecast.utils import generate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from neuralforecast.losses.pytorch import MAE\n",
    "from neuralforecast.common._base_model import BaseModel\n",
    "from neuralforecast.common._modules import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class RNN(BaseModel):\n",
    "    \"\"\" RNN\n",
    "\n",
    "    Multi Layer Elman RNN (RNN), with MLP decoder.\n",
    "    The network has `tanh` or `relu` non-linearities, it is trained using \n",
    "    ADAM stochastic gradient descent. The network accepts static, historic \n",
    "    and future exogenous data.\n",
    "\n",
    "    **Parameters:**<br>\n",
    "    `h`: int, forecast horizon.<br>\n",
    "    `input_size`: int, maximum sequence length for truncated train backpropagation. Default -1 uses all history.<br>\n",
    "    `inference_input_size`: int, maximum sequence length for truncated inference. Default -1 uses all history.<br>\n",
    "    `encoder_n_layers`: int=2, number of layers for the RNN.<br>\n",
    "    `encoder_hidden_size`: int=200, units for the RNN's hidden state size.<br>\n",
    "    `encoder_activation`: str=`tanh`, type of RNN activation from `tanh` or `relu`.<br>\n",
    "    `encoder_bias`: bool=True, whether or not to use biases b_ih, b_hh within RNN units.<br>\n",
    "    `encoder_dropout`: float=0., dropout regularization applied to RNN outputs.<br>\n",
    "    `context_size`: int=10, size of context vector for each timestamp on the forecasting window.<br>\n",
    "    `decoder_hidden_size`: int=200, size of hidden layer for the MLP decoder.<br>\n",
    "    `decoder_layers`: int=2, number of layers for the MLP decoder.<br>\n",
    "    `futr_exog_list`: str list, future exogenous columns.<br>\n",
    "    `hist_exog_list`: str list, historic exogenous columns.<br>\n",
    "    `stat_exog_list`: str list, static exogenous columns.<br>\n",
    "    `loss`: PyTorch module, instantiated train loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
    "    `valid_loss`: PyTorch module=`loss`, instantiated valid loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
    "    `max_steps`: int=1000, maximum number of training steps.<br>\n",
    "    `learning_rate`: float=1e-3, Learning rate between (0, 1).<br>\n",
    "    `num_lr_decays`: int=-1, Number of learning rate decays, evenly distributed across max_steps.<br>\n",
    "    `early_stop_patience_steps`: int=-1, Number of validation iterations before early stopping.<br>\n",
    "    `val_check_steps`: int=100, Number of training steps between every validation loss check.<br>\n",
    "    `batch_size`: int=32, number of differentseries in each batch.<br>\n",
    "    `valid_batch_size`: int=None, number of different series in each validation and test batch.<br>\n",
    "    `scaler_type`: str='robust', type of scaler for temporal inputs normalization see [temporal scalers](https://nixtla.github.io/neuralforecast/common.scalers.html).<br>\n",
    "    `random_seed`: int=1, random_seed for pytorch initializer and numpy generators.<br>\n",
    "    `num_workers_loader`: int=os.cpu_count(), workers to be used by `TimeSeriesDataLoader`.<br>\n",
    "    `drop_last_loader`: bool=False, if True `TimeSeriesDataLoader` drops last non-full batch.<br>\n",
    "    `optimizer`: Subclass of 'torch.optim.Optimizer', optional, user specified optimizer instead of the default choice (Adam).<br>\n",
    "    `optimizer_kwargs`: dict, optional, list of parameters used by the user specified `optimizer`.<br>\n",
    "    `lr_scheduler`: Subclass of 'torch.optim.lr_scheduler.LRScheduler', optional, user specified lr_scheduler instead of the default choice (StepLR).<br>\n",
    "    `lr_scheduler_kwargs`: dict, optional, list of parameters used by the user specified `lr_scheduler`.<br>    \n",
    "    `alias`: str, optional,  Custom name of the model.<br>\n",
    "\n",
    "    `**trainer_kwargs`: int,  keyword trainer arguments inherited from [PyTorch Lighning's trainer](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).<br>    \n",
    "    \"\"\"\n",
    "    # Class attributes\n",
    "    EXOGENOUS_FUTR = True\n",
    "    EXOGENOUS_HIST = True\n",
    "    EXOGENOUS_STAT = True\n",
    "    MULTIVARIATE = False    # If the model produces multivariate forecasts (True) or univariate (False)\n",
    "    RECURRENT = True        # If the model produces forecasts recursively (True) or direct (False)\n",
    "\n",
    "    def __init__(self,\n",
    "                 h: int,\n",
    "                 input_size: int = -1,\n",
    "                 inference_input_size: int = -1,\n",
    "                 encoder_n_layers: int = 2,\n",
    "                 encoder_hidden_size: int = 200,\n",
    "                 encoder_activation: str = 'tanh',\n",
    "                 encoder_bias: bool = True,\n",
    "                 encoder_dropout: float = 0.,\n",
    "                 context_size: int = 10,\n",
    "                 decoder_hidden_size: int = 200,\n",
    "                 decoder_layers: int = 2,\n",
    "                 futr_exog_list = None,\n",
    "                 hist_exog_list = None,\n",
    "                 stat_exog_list = None,\n",
    "                 exclude_insample_y = False,\n",
    "                 loss = MAE(),\n",
    "                 valid_loss = None,\n",
    "                 max_steps: int = 1000,\n",
    "                 learning_rate: float = 1e-3,\n",
    "                 num_lr_decays: int = -1,\n",
    "                 early_stop_patience_steps: int =-1,\n",
    "                 val_check_steps: int = 100,\n",
    "                 batch_size=32,\n",
    "                 valid_batch_size: Optional[int] = None,\n",
    "                 windows_batch_size = 1024,\n",
    "                 inference_windows_batch_size = 1024,\n",
    "                 start_padding_enabled = False,\n",
    "                 step_size: int = 1,\n",
    "                 scaler_type: str='robust',\n",
    "                 random_seed=1,\n",
    "                 num_workers_loader=0,\n",
    "                 drop_last_loader=False,\n",
    "                 optimizer=None,\n",
    "                 optimizer_kwargs=None,\n",
    "                 lr_scheduler = None,\n",
    "                 lr_scheduler_kwargs = None,                 \n",
    "                 **trainer_kwargs):\n",
    "        super(RNN, self).__init__(\n",
    "            h=h,\n",
    "            input_size=input_size,\n",
    "            inference_input_size=inference_input_size,\n",
    "            loss=loss,\n",
    "            valid_loss=valid_loss,\n",
    "            max_steps=max_steps,\n",
    "            learning_rate=learning_rate,\n",
    "            num_lr_decays=num_lr_decays,\n",
    "            early_stop_patience_steps=early_stop_patience_steps,\n",
    "            val_check_steps=val_check_steps,\n",
    "            batch_size=batch_size,\n",
    "            valid_batch_size=valid_batch_size,\n",
    "            windows_batch_size=windows_batch_size,\n",
    "            inference_windows_batch_size=inference_windows_batch_size,\n",
    "            start_padding_enabled=start_padding_enabled,\n",
    "            step_size=step_size,\n",
    "            scaler_type=scaler_type,\n",
    "            futr_exog_list=futr_exog_list,\n",
    "            hist_exog_list=hist_exog_list,\n",
    "            stat_exog_list=stat_exog_list,\n",
    "            exclude_insample_y = exclude_insample_y,\n",
    "            num_workers_loader=num_workers_loader,\n",
    "            drop_last_loader=drop_last_loader,\n",
    "            random_seed=random_seed,\n",
    "            optimizer=optimizer,\n",
    "            optimizer_kwargs=optimizer_kwargs,\n",
    "            lr_scheduler=lr_scheduler,\n",
    "            lr_scheduler_kwargs=lr_scheduler_kwargs,\n",
    "            **trainer_kwargs\n",
    "        )\n",
    "\n",
    "        # RNN\n",
    "        self.encoder_n_layers = encoder_n_layers\n",
    "        self.encoder_hidden_size = encoder_hidden_size\n",
    "        self.encoder_activation = encoder_activation\n",
    "        self.encoder_bias = encoder_bias\n",
    "        self.encoder_dropout = encoder_dropout\n",
    "        \n",
    "        # Context adapter\n",
    "        self.context_size = context_size\n",
    "\n",
    "        # MLP decoder\n",
    "        self.decoder_hidden_size = decoder_hidden_size\n",
    "        self.decoder_layers = decoder_layers\n",
    "\n",
    "        # RNN input size (1 for target variable y)\n",
    "        input_encoder = 1 + self.hist_exog_size + self.stat_exog_size + self.futr_exog_size\n",
    "\n",
    "        # Instantiate model\n",
    "        self.rnn_state = None\n",
    "        self.hist_encoder = nn.RNN(input_size=input_encoder,\n",
    "                                   hidden_size=self.encoder_hidden_size,\n",
    "                                   num_layers=self.encoder_n_layers,\n",
    "                                   nonlinearity=self.encoder_activation,\n",
    "                                   bias=self.encoder_bias,\n",
    "                                   dropout=self.encoder_dropout,\n",
    "                                   batch_first=True)\n",
    "\n",
    "        # Context adapter\n",
    "        self.context_adapter = nn.Linear(in_features=self.encoder_hidden_size,\n",
    "                                         out_features=self.context_size * h)\n",
    "\n",
    "        # Decoder MLP\n",
    "        self.mlp_decoder = MLP(in_features=self.context_size * h + self.futr_exog_size,\n",
    "                               out_features=self.loss.outputsize_multiplier,\n",
    "                               hidden_size=self.decoder_hidden_size,\n",
    "                               num_layers=self.decoder_layers,\n",
    "                               activation='ReLU',\n",
    "                               dropout=0.0)\n",
    "\n",
    "    def forward(self, windows_batch):\n",
    "        \n",
    "        # Parse windows_batch\n",
    "        encoder_input = windows_batch['insample_y']                         # [B, seq_len, 1]\n",
    "        futr_exog     = windows_batch['futr_exog']                          # [B, seq_len, F]\n",
    "        hist_exog     = windows_batch['hist_exog']                          # [B, seq_len, X]\n",
    "        stat_exog     = windows_batch['stat_exog']                          # [B, S]\n",
    "\n",
    "        # Concatenate y, historic and static inputs              \n",
    "        batch_size, seq_len = encoder_input.shape[:2]\n",
    "        if self.hist_exog_size > 0:\n",
    "            encoder_input = torch.cat((encoder_input, hist_exog), dim=2)    # [B, seq_len, 1] + [B, seq_len, X] -> [B, seq_len, 1 + X]\n",
    "\n",
    "        if self.stat_exog_size > 0:\n",
    "            # print(encoder_input.shape)\n",
    "            stat_exog = stat_exog.unsqueeze(1).repeat(1, seq_len, 1)        # [B, S] -> [B, seq_len, S]\n",
    "            encoder_input = torch.cat((encoder_input, stat_exog), dim=2)    # [B, seq_len, 1 + X] + [B, seq_len, S] -> [B, seq_len, 1 + X + S]\n",
    "\n",
    "        if self.futr_exog_size > 0:\n",
    "            encoder_input = torch.cat((encoder_input, futr_exog), dim=2)    # [B, seq_len, 1 + X + S] + [B, seq_len, F] -> [B, seq_len, 1 + X + S + F]\n",
    "\n",
    "        # RNN forward\n",
    "        if self.maintain_state:\n",
    "            rnn_state = self.rnn_state\n",
    "        else:\n",
    "            rnn_state = None\n",
    "        \n",
    "        hidden_state, rnn_state = self.hist_encoder(encoder_input, \n",
    "                                                         rnn_state)    # [B, seq_len, rnn_hidden_state]\n",
    "        if self.maintain_state:\n",
    "            self.rnn_state = rnn_state\n",
    "\n",
    "        # Context adapter\n",
    "        context = self.context_adapter(hidden_state)                        # [B, seq_len, rnn_hidden_state] -> [B, seq_len, context_size * h]\n",
    "\n",
    "        # Residual connection with futr_exog\n",
    "        if self.futr_exog_size > 0:\n",
    "            context = torch.cat((context, futr_exog), dim=-1)               # [B, seq_len, context_size * h] + [B, seq_len, F] = [B, seq_len, context_size * h + F]\n",
    "\n",
    "        # Final forecast\n",
    "        output = self.mlp_decoder(context)                                  # [B, seq_len, context_size * h + F] -> [B, seq_len, n_output]\n",
    "        \n",
    "        return output[:, -self.h:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/models/rnn.py#L17){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### RNN\n",
       "\n",
       ">      RNN (h:int, input_size:int=-1, inference_input_size:int=-1,\n",
       ">           encoder_n_layers:int=2, encoder_hidden_size:int=200,\n",
       ">           encoder_activation:str='tanh', encoder_bias:bool=True,\n",
       ">           encoder_dropout:float=0.0, context_size:int=10,\n",
       ">           decoder_hidden_size:int=200, decoder_layers:int=2,\n",
       ">           futr_exog_list=None, hist_exog_list=None, stat_exog_list=None,\n",
       ">           exclude_insample_y=False, loss=MAE(), valid_loss=None,\n",
       ">           max_steps:int=1000, learning_rate:float=0.001, num_lr_decays:int=-1,\n",
       ">           early_stop_patience_steps:int=-1, val_check_steps:int=100,\n",
       ">           batch_size=32, valid_batch_size:Optional[int]=None,\n",
       ">           windows_batch_size=1024, inference_windows_batch_size=1024,\n",
       ">           start_padding_enabled=False, step_size:int=1,\n",
       ">           scaler_type:str='robust', random_seed=1, num_workers_loader=0,\n",
       ">           drop_last_loader=False, optimizer=None, optimizer_kwargs=None,\n",
       ">           lr_scheduler=None, lr_scheduler_kwargs=None, **trainer_kwargs)\n",
       "\n",
       "*RNN\n",
       "\n",
       "Multi Layer Elman RNN (RNN), with MLP decoder.\n",
       "The network has `tanh` or `relu` non-linearities, it is trained using \n",
       "ADAM stochastic gradient descent. The network accepts static, historic \n",
       "and future exogenous data.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`h`: int, forecast horizon.<br>\n",
       "`input_size`: int, maximum sequence length for truncated train backpropagation. Default -1 uses all history.<br>\n",
       "`inference_input_size`: int, maximum sequence length for truncated inference. Default -1 uses all history.<br>\n",
       "`encoder_n_layers`: int=2, number of layers for the RNN.<br>\n",
       "`encoder_hidden_size`: int=200, units for the RNN's hidden state size.<br>\n",
       "`encoder_activation`: str=`tanh`, type of RNN activation from `tanh` or `relu`.<br>\n",
       "`encoder_bias`: bool=True, whether or not to use biases b_ih, b_hh within RNN units.<br>\n",
       "`encoder_dropout`: float=0., dropout regularization applied to RNN outputs.<br>\n",
       "`context_size`: int=10, size of context vector for each timestamp on the forecasting window.<br>\n",
       "`decoder_hidden_size`: int=200, size of hidden layer for the MLP decoder.<br>\n",
       "`decoder_layers`: int=2, number of layers for the MLP decoder.<br>\n",
       "`futr_exog_list`: str list, future exogenous columns.<br>\n",
       "`hist_exog_list`: str list, historic exogenous columns.<br>\n",
       "`stat_exog_list`: str list, static exogenous columns.<br>\n",
       "`loss`: PyTorch module, instantiated train loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
       "`valid_loss`: PyTorch module=`loss`, instantiated valid loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
       "`max_steps`: int=1000, maximum number of training steps.<br>\n",
       "`learning_rate`: float=1e-3, Learning rate between (0, 1).<br>\n",
       "`num_lr_decays`: int=-1, Number of learning rate decays, evenly distributed across max_steps.<br>\n",
       "`early_stop_patience_steps`: int=-1, Number of validation iterations before early stopping.<br>\n",
       "`val_check_steps`: int=100, Number of training steps between every validation loss check.<br>\n",
       "`batch_size`: int=32, number of differentseries in each batch.<br>\n",
       "`valid_batch_size`: int=None, number of different series in each validation and test batch.<br>\n",
       "`scaler_type`: str='robust', type of scaler for temporal inputs normalization see [temporal scalers](https://nixtla.github.io/neuralforecast/common.scalers.html).<br>\n",
       "`random_seed`: int=1, random_seed for pytorch initializer and numpy generators.<br>\n",
       "`num_workers_loader`: int=os.cpu_count(), workers to be used by `TimeSeriesDataLoader`.<br>\n",
       "`drop_last_loader`: bool=False, if True `TimeSeriesDataLoader` drops last non-full batch.<br>\n",
       "`optimizer`: Subclass of 'torch.optim.Optimizer', optional, user specified optimizer instead of the default choice (Adam).<br>\n",
       "`optimizer_kwargs`: dict, optional, list of parameters used by the user specified `optimizer`.<br>\n",
       "`lr_scheduler`: Subclass of 'torch.optim.lr_scheduler.LRScheduler', optional, user specified lr_scheduler instead of the default choice (StepLR).<br>\n",
       "`lr_scheduler_kwargs`: dict, optional, list of parameters used by the user specified `lr_scheduler`.<br>    \n",
       "`alias`: str, optional,  Custom name of the model.<br>\n",
       "\n",
       "`**trainer_kwargs`: int,  keyword trainer arguments inherited from [PyTorch Lighning's trainer](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).<br>*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/Nixtla/neuralforecast/blob/main/neuralforecast/models/rnn.py#L17){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### RNN\n",
       "\n",
       ">      RNN (h:int, input_size:int=-1, inference_input_size:int=-1,\n",
       ">           encoder_n_layers:int=2, encoder_hidden_size:int=200,\n",
       ">           encoder_activation:str='tanh', encoder_bias:bool=True,\n",
       ">           encoder_dropout:float=0.0, context_size:int=10,\n",
       ">           decoder_hidden_size:int=200, decoder_layers:int=2,\n",
       ">           futr_exog_list=None, hist_exog_list=None, stat_exog_list=None,\n",
       ">           exclude_insample_y=False, loss=MAE(), valid_loss=None,\n",
       ">           max_steps:int=1000, learning_rate:float=0.001, num_lr_decays:int=-1,\n",
       ">           early_stop_patience_steps:int=-1, val_check_steps:int=100,\n",
       ">           batch_size=32, valid_batch_size:Optional[int]=None,\n",
       ">           windows_batch_size=1024, inference_windows_batch_size=1024,\n",
       ">           start_padding_enabled=False, step_size:int=1,\n",
       ">           scaler_type:str='robust', random_seed=1, num_workers_loader=0,\n",
       ">           drop_last_loader=False, optimizer=None, optimizer_kwargs=None,\n",
       ">           lr_scheduler=None, lr_scheduler_kwargs=None, **trainer_kwargs)\n",
       "\n",
       "*RNN\n",
       "\n",
       "Multi Layer Elman RNN (RNN), with MLP decoder.\n",
       "The network has `tanh` or `relu` non-linearities, it is trained using \n",
       "ADAM stochastic gradient descent. The network accepts static, historic \n",
       "and future exogenous data.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`h`: int, forecast horizon.<br>\n",
       "`input_size`: int, maximum sequence length for truncated train backpropagation. Default -1 uses all history.<br>\n",
       "`inference_input_size`: int, maximum sequence length for truncated inference. Default -1 uses all history.<br>\n",
       "`encoder_n_layers`: int=2, number of layers for the RNN.<br>\n",
       "`encoder_hidden_size`: int=200, units for the RNN's hidden state size.<br>\n",
       "`encoder_activation`: str=`tanh`, type of RNN activation from `tanh` or `relu`.<br>\n",
       "`encoder_bias`: bool=True, whether or not to use biases b_ih, b_hh within RNN units.<br>\n",
       "`encoder_dropout`: float=0., dropout regularization applied to RNN outputs.<br>\n",
       "`context_size`: int=10, size of context vector for each timestamp on the forecasting window.<br>\n",
       "`decoder_hidden_size`: int=200, size of hidden layer for the MLP decoder.<br>\n",
       "`decoder_layers`: int=2, number of layers for the MLP decoder.<br>\n",
       "`futr_exog_list`: str list, future exogenous columns.<br>\n",
       "`hist_exog_list`: str list, historic exogenous columns.<br>\n",
       "`stat_exog_list`: str list, static exogenous columns.<br>\n",
       "`loss`: PyTorch module, instantiated train loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
       "`valid_loss`: PyTorch module=`loss`, instantiated valid loss class from [losses collection](https://nixtla.github.io/neuralforecast/losses.pytorch.html).<br>\n",
       "`max_steps`: int=1000, maximum number of training steps.<br>\n",
       "`learning_rate`: float=1e-3, Learning rate between (0, 1).<br>\n",
       "`num_lr_decays`: int=-1, Number of learning rate decays, evenly distributed across max_steps.<br>\n",
       "`early_stop_patience_steps`: int=-1, Number of validation iterations before early stopping.<br>\n",
       "`val_check_steps`: int=100, Number of training steps between every validation loss check.<br>\n",
       "`batch_size`: int=32, number of differentseries in each batch.<br>\n",
       "`valid_batch_size`: int=None, number of different series in each validation and test batch.<br>\n",
       "`scaler_type`: str='robust', type of scaler for temporal inputs normalization see [temporal scalers](https://nixtla.github.io/neuralforecast/common.scalers.html).<br>\n",
       "`random_seed`: int=1, random_seed for pytorch initializer and numpy generators.<br>\n",
       "`num_workers_loader`: int=os.cpu_count(), workers to be used by `TimeSeriesDataLoader`.<br>\n",
       "`drop_last_loader`: bool=False, if True `TimeSeriesDataLoader` drops last non-full batch.<br>\n",
       "`optimizer`: Subclass of 'torch.optim.Optimizer', optional, user specified optimizer instead of the default choice (Adam).<br>\n",
       "`optimizer_kwargs`: dict, optional, list of parameters used by the user specified `optimizer`.<br>\n",
       "`lr_scheduler`: Subclass of 'torch.optim.lr_scheduler.LRScheduler', optional, user specified lr_scheduler instead of the default choice (StepLR).<br>\n",
       "`lr_scheduler_kwargs`: dict, optional, list of parameters used by the user specified `lr_scheduler`.<br>    \n",
       "`alias`: str, optional,  Custom name of the model.<br>\n",
       "\n",
       "`**trainer_kwargs`: int,  keyword trainer arguments inherited from [PyTorch Lighning's trainer](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).<br>*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### RNN.fit\n",
       "\n",
       ">      RNN.fit (dataset, val_size=0, test_size=0, random_seed=None,\n",
       ">               distributed_config=None)\n",
       "\n",
       "*Fit.\n",
       "\n",
       "The `fit` method, optimizes the neural network's weights using the\n",
       "initialization parameters (`learning_rate`, `windows_batch_size`, ...)\n",
       "and the `loss` function as defined during the initialization.\n",
       "Within `fit` we use a PyTorch Lightning `Trainer` that\n",
       "inherits the initialization's `self.trainer_kwargs`, to customize\n",
       "its inputs, see [PL's trainer arguments](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).\n",
       "\n",
       "The method is designed to be compatible with SKLearn-like classes\n",
       "and in particular to be compatible with the StatsForecast library.\n",
       "\n",
       "By default the `model` is not saving training checkpoints to protect\n",
       "disk memory, to get them change `enable_checkpointing=True` in `__init__`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`val_size`: int, validation size for temporal cross-validation.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`test_size`: int, test size for temporal cross-validation.<br>*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### RNN.fit\n",
       "\n",
       ">      RNN.fit (dataset, val_size=0, test_size=0, random_seed=None,\n",
       ">               distributed_config=None)\n",
       "\n",
       "*Fit.\n",
       "\n",
       "The `fit` method, optimizes the neural network's weights using the\n",
       "initialization parameters (`learning_rate`, `windows_batch_size`, ...)\n",
       "and the `loss` function as defined during the initialization.\n",
       "Within `fit` we use a PyTorch Lightning `Trainer` that\n",
       "inherits the initialization's `self.trainer_kwargs`, to customize\n",
       "its inputs, see [PL's trainer arguments](https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.trainer.trainer.Trainer.html?highlight=trainer).\n",
       "\n",
       "The method is designed to be compatible with SKLearn-like classes\n",
       "and in particular to be compatible with the StatsForecast library.\n",
       "\n",
       "By default the `model` is not saving training checkpoints to protect\n",
       "disk memory, to get them change `enable_checkpointing=True` in `__init__`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`val_size`: int, validation size for temporal cross-validation.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`test_size`: int, test size for temporal cross-validation.<br>*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(RNN.fit, name='RNN.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### RNN.predict\n",
       "\n",
       ">      RNN.predict (dataset, test_size=None, step_size=1, random_seed=None,\n",
       ">                   **data_module_kwargs)\n",
       "\n",
       "*Predict.\n",
       "\n",
       "Neural network prediction with PL's `Trainer` execution of `predict_step`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`test_size`: int=None, test size for temporal cross-validation.<br>\n",
       "`step_size`: int=1, Step size between each window.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`**data_module_kwargs`: PL's TimeSeriesDataModule args, see [documentation](https://pytorch-lightning.readthedocs.io/en/1.6.1/extensions/datamodules.html#using-a-datamodule).*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### RNN.predict\n",
       "\n",
       ">      RNN.predict (dataset, test_size=None, step_size=1, random_seed=None,\n",
       ">                   **data_module_kwargs)\n",
       "\n",
       "*Predict.\n",
       "\n",
       "Neural network prediction with PL's `Trainer` execution of `predict_step`.\n",
       "\n",
       "**Parameters:**<br>\n",
       "`dataset`: NeuralForecast's `TimeSeriesDataset`, see [documentation](https://nixtla.github.io/neuralforecast/tsdataset.html).<br>\n",
       "`test_size`: int=None, test size for temporal cross-validation.<br>\n",
       "`step_size`: int=1, Step size between each window.<br>\n",
       "`random_seed`: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__'s.<br>\n",
       "`**data_module_kwargs`: PL's TimeSeriesDataModule args, see [documentation](https://pytorch-lightning.readthedocs.io/en/1.6.1/extensions/datamodules.html#using-a-datamodule).*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(RNN.predict, name='RNN.predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name            | Type             | Params\n",
      "-----------------------------------------------------\n",
      "0 | loss            | DistributionLoss | 5     \n",
      "1 | padder_train    | ConstantPad1d    | 0     \n",
      "2 | scaler          | TemporalNorm     | 0     \n",
      "3 | hist_encoder    | RNN              | 50.0 K\n",
      "4 | context_adapter | Linear           | 15.5 K\n",
      "5 | mlp_decoder     | MLP              | 15.9 K\n",
      "-----------------------------------------------------\n",
      "81.4 K    Trainable params\n",
      "5         Non-trainable params\n",
      "81.4 K    Total params\n",
      "0.326     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  7.22it/s, v_num=3672, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=11.60]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=300` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299: 100%|██████████| 1/1 [00:00<00:00,  7.07it/s, v_num=3672, train_loss_step=2.920, train_loss_epoch=2.920, valid_loss=11.60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ospra\\miniconda3\\envs\\neuralforecast\\lib\\site-packages\\utilsforecast\\processing.py:374: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(freq)\n",
      "c:\\Users\\ospra\\miniconda3\\envs\\neuralforecast\\lib\\site-packages\\utilsforecast\\processing.py:428: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  freq = pd.tseries.frequencies.to_offset(freq)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 66.66it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ospra\\OneDrive\\Phd\\Repositories\\neuralforecast\\neuralforecast\\core.py:196: FutureWarning: In a future version the predictions will have the id as a column. You can set the `NIXTLA_ID_AS_COL` environment variable to adopt the new behavior and to suppress this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| eval: false\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuralforecast import NeuralForecast\n",
    "# from neuralforecast.models import RNN\n",
    "from neuralforecast.losses.pytorch import MQLoss, DistributionLoss\n",
    "from neuralforecast.utils import AirPassengersPanel, AirPassengersStatic\n",
    "from neuralforecast.tsdataset import TimeSeriesDataset, TimeSeriesLoader\n",
    "\n",
    "Y_train_df = AirPassengersPanel[AirPassengersPanel.ds<AirPassengersPanel['ds'].values[-12]] # 132 train\n",
    "Y_test_df = AirPassengersPanel[AirPassengersPanel.ds>=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n",
    "\n",
    "fcst = NeuralForecast(\n",
    "    models=[RNN(h=12,\n",
    "                # input_size=-1,\n",
    "                input_size=24,\n",
    "                inference_input_size=24,\n",
    "                # loss=MQLoss(level=[80, 90]),\n",
    "                 loss=DistributionLoss(distribution='Normal', level=[80, 90], return_params=False),\n",
    "                # loss=MAE(),\n",
    "                #  valid_loss=MAE(),\n",
    "                scaler_type='standard',\n",
    "                encoder_n_layers=2,\n",
    "                encoder_hidden_size=128,\n",
    "                context_size=10,\n",
    "                decoder_hidden_size=128,\n",
    "                decoder_layers=2,\n",
    "                max_steps=300,\n",
    "                futr_exog_list=['y_[lag12]'],\n",
    "                #hist_exog_list=['y_[lag12]'],\n",
    "                stat_exog_list=['airline1'],\n",
    "                )\n",
    "    ],\n",
    "    freq='M'\n",
    ")\n",
    "fcst.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\n",
    "forecasts = fcst.predict(futr_df=Y_test_df)\n",
    "\n",
    "Y_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\n",
    "plot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\n",
    "plot_df = pd.concat([Y_train_df, plot_df])\n",
    "\n",
    "plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n",
    "plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n",
    "plt.plot(plot_df['ds'], plot_df['RNN-median'], c='blue', label='median')\n",
    "plt.fill_between(x=plot_df['ds'][-12:], \n",
    "                 y1=plot_df['RNN-lo-90'][-12:].values, \n",
    "                 y2=plot_df['RNN-hi-90'][-12:].values,\n",
    "                 alpha=0.4, label='level 90')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
