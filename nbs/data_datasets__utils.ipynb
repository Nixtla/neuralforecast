{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.datasets.utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils for datasets\n",
    "\n",
    "> API details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import logging\n",
    "import subprocess\n",
    "import zipfile\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils para descargar archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def download_file(directory: Union[str, Path], source_url: str, decompress: bool = False) -> None:\n",
    "    \"\"\"Download data from source_ulr inside directory.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    directory: str, Path\n",
    "        Custom directory where data will be downloaded.\n",
    "    source_url: str\n",
    "        URL where data is hosted.\n",
    "    decompress: bool\n",
    "        Wheter decompress downloaded file. Default False.\n",
    "    \"\"\"\n",
    "    if isinstance(directory, str):\n",
    "        directory = Path(directory)\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    filename = source_url.split('/')[-1]\n",
    "    filepath = directory / filename\n",
    "\n",
    "    # Streaming, so we can iterate over the response.\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    r = requests.get(source_url, stream=True, headers=headers)\n",
    "    # Total size in bytes.\n",
    "    total_size = int(r.headers.get('content-length', 0))\n",
    "    block_size = 1024 #1 Kibibyte\n",
    "\n",
    "    t = tqdm(total=total_size, unit='iB', unit_scale=True)\n",
    "    with open(filepath, 'wb') as f:\n",
    "        for data in r.iter_content(block_size):\n",
    "            t.update(len(data))\n",
    "            f.write(data)\n",
    "            f.flush()\n",
    "    t.close()\n",
    "\n",
    "    if total_size != 0 and t.n != total_size:\n",
    "        logger.error('ERROR, something went wrong downloading data')\n",
    "\n",
    "    size = filepath.stat().st_size\n",
    "    logger.info(f'Successfully downloaded {filename}, {size}, bytes.')\n",
    "\n",
    "    if decompress:\n",
    "        with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "            zip_ref.extractall(directory)\n",
    "\n",
    "        logger.info(f'Successfully decompressed {filepath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Info:\n",
    "    \"\"\"\n",
    "    Info Dataclass of datasets.\n",
    "    Args:\n",
    "        groups (Tuple): Tuple of str groups\n",
    "        class_groups (Tuple): Tuple of dataclasses.\n",
    "    \"\"\"\n",
    "    groups: Tuple[str]\n",
    "    class_groups: Tuple[dataclass]\n",
    "\n",
    "    def get_group(self, group: str):\n",
    "        \"\"\"Gets dataclass of group.\"\"\"\n",
    "        if group not in self.groups:\n",
    "            raise Exception(f'Unkown group {group}')\n",
    "\n",
    "        return self.class_groups[self.groups.index(group)]\n",
    "    \n",
    "    def __getitem__(self, group: str):\n",
    "        \"\"\"Gets dataclass of group.\"\"\"\n",
    "        if group not in self.groups:\n",
    "            raise Exception(f'Unkown group {group}')\n",
    "\n",
    "        return self.class_groups[self.groups.index(group)]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for group in self.groups:\n",
    "            yield group, self.get_group(group)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class TimeSeriesDataclass:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        S (pd.DataFrame): DataFrame of static features of shape\n",
    "            (n_time_series, n_features).\n",
    "        X (pd.DataFrame): DataFrame of exogenous variables of shape\n",
    "            (sum n_periods_i for i=1..n_time_series, n_exogenous).\n",
    "        Y (pd.DataFrame): DataFrame of target variable of shape\n",
    "            (sum n_periods_i for i=1..n_time_series, 1).\n",
    "        idx_categorical_static (list, optional): List of categorical indexes\n",
    "            of S.\n",
    "        group (str, optional): Group name if applies.\n",
    "            Example: 'Yearly'\n",
    "    \"\"\"\n",
    "    S: pd.DataFrame\n",
    "    X: pd.DataFrame\n",
    "    Y: pd.DataFrame\n",
    "    idx_categorical_static: Optional[List] = None\n",
    "    group: Union[str, List[str]] = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
