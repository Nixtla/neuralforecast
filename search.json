[
  {
    "objectID": "models.gru.html",
    "href": "models.gru.html",
    "title": "GRU",
    "section": "",
    "text": "Cho et. al proposed the Gated Recurrent Unit (GRU) to improve on LSTM and Elman cells. The predictions at each time are given by a MLP decoder. This architecture follows closely the original Multi Layer Elman RNN with the main difference being its use of the GRU cells. The predictions are obtained by transforming the hidden states into contexts \\(\\mathbf{c}_{[t+1:t+H]}\\), that are decoded and adapted into \\(\\mathbf{\\hat{y}}_{[t+1:t+H],[q]}\\) through MLPs.\n\\[\\begin{align}\n\\mathbf{h}_{t} &= \\textrm{GRU}([\\mathbf{y}_{t},\\mathbf{x}^{(h)}_{t},\\mathbf{x}^{(s)}], \\mathbf{h}_{t-1})\\\\\n\\mathbf{c}_{[t+1:t+H]}&=\\textrm{Linear}([\\mathbf{h}_{t}, \\mathbf{x}^{(f)}_{[:t+H]}]) \\\\\n\\hat{y}_{\\tau,[q]}&=\\textrm{MLP}([\\mathbf{c}_{\\tau},\\mathbf{x}^{(f)}_{\\tau}])\n\\end{align}\\]\nwhere \\(\\mathbf{h}_{t}\\), is the hidden state for time \\(t\\), \\(\\mathbf{y}_{t}\\) is the input at time \\(t\\) and \\(\\mathbf{h}_{t-1}\\) is the hidden state of the previous layer at \\(t-1\\), \\(\\mathbf{x}^{(s)}\\) are static exogenous inputs, \\(\\mathbf{x}^{(h)}_{t}\\) historic exogenous, \\(\\mathbf{x}^{(f)}_{[:t+H]}\\) are future exogenous available at the time of the prediction.\nReferences -Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, Yoshua Bengio (2014). “Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling”. -Kyunghyun Cho, Bart van Merrienboer, Dzmitry Bahdanau, Yoshua Bengio (2014). “On the Properties of Neural Machine Translation: Encoder-Decoder Approaches”.\nsource\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.gru.html#usage-example",
    "href": "models.gru.html#usage-example",
    "title": "GRU",
    "section": "Usage Example",
    "text": "Usage Example\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import GRU\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss\nfrom neuralforecast.utils import AirPassengersPanel, AirPassengersStatic\nfrom neuralforecast.tsdataset import TimeSeriesDataset, TimeSeriesLoader\n\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]] # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nfcst = NeuralForecast(\n    models=[GRU(h=12,input_size=-1,\n                loss=DistributionLoss(distribution='Normal', level=[80, 90]),\n                scaler_type='robust',\n                encoder_n_layers=2,\n                encoder_hidden_size=128,\n                context_size=10,\n                decoder_hidden_size=128,\n                decoder_layers=2,\n                max_steps=200,\n                futr_exog_list=None,\n                hist_exog_list=['y_[lag12]'],\n                stat_exog_list=['airline1'],\n                )\n    ],\n    freq='M'\n)\nfcst.fit(df=Y_train_df, static_df=AirPassengersStatic)\nforecasts = fcst.predict(futr_df=Y_test_df)\n\nY_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nplot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\nplt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\nplt.plot(plot_df['ds'], plot_df['GRU-median'], c='blue', label='median')\nplt.fill_between(x=plot_df['ds'][-12:], \n                 y1=plot_df['GRU-lo-90'][-12:].values, \n                 y2=plot_df['GRU-hi-90'][-12:].values,\n                 alpha=0.4, label='level 90')\nplt.legend()\nplt.grid()\nplt.plot()"
  },
  {
    "objectID": "models.tcn.html",
    "href": "models.tcn.html",
    "title": "TCN",
    "section": "",
    "text": "For long time in deep learning, sequence modelling was synonymous with recurrent networks, yet several papers have shown that simple convolutional architectures can outperform canonical recurrent networks like LSTMs by demonstrating longer effective memory. By skipping temporal connections the causal convolution filters can be applied to larger time spans while remaining computationally efficient.\nThe predictions are obtained by transforming the hidden states into contexts \\(\\mathbf{c}_{[t+1:t+H]}\\), that are decoded and adapted into \\(\\mathbf{\\hat{y}}_{[t+1:t+H],[q]}\\) through MLPs.\n\\[\\begin{align}\n\\mathbf{h}_{t} &= \\textrm{TCN}([\\mathbf{y}_{t},\\mathbf{x}^{(h)}_{t},\\mathbf{x}^{(s)}], \\mathbf{h}_{t-1})\\\\\n\\mathbf{c}_{[t+1:t+H]}&=\\textrm{Linear}([\\mathbf{h}_{t}, \\mathbf{x}^{(f)}_{[:t+H]}]) \\\\\n\\hat{y}_{\\tau,[q]}&=\\textrm{MLP}([\\mathbf{c}_{\\tau},\\mathbf{x}^{(f)}_{\\tau}])\n\\end{align}\\]\nwhere \\(\\mathbf{h}_{t}\\), is the hidden state for time \\(t\\), \\(\\mathbf{y}_{t}\\) is the input at time \\(t\\) and \\(\\mathbf{h}_{t-1}\\) is the hidden state of the previous layer at \\(t-1\\), \\(\\mathbf{x}^{(s)}\\) are static exogenous inputs, \\(\\mathbf{x}^{(h)}_{t}\\) historic exogenous, \\(\\mathbf{x}^{(f)}_{[:t+H]}\\) are future exogenous available at the time of the prediction.\nReferences -van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Senior, A. W., & Kavukcuoglu, K. (2016). Wavenet: A generative model for raw audio. Computing Research Repository, abs/1609.03499. URL: http://arxiv.org/abs/1609.03499. arXiv:1609.03499. -Shaojie Bai, Zico Kolter, Vladlen Koltun. (2018). An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling. Computing Research Repository, abs/1803.01271. URL: https://arxiv.org/abs/1803.01271.\nsource\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.tcn.html#usage-example",
    "href": "models.tcn.html#usage-example",
    "title": "TCN",
    "section": "Usage Example",
    "text": "Usage Example\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import TCN\nfrom neuralforecast.losses.pytorch import GMM, MQLoss, DistributionLoss\nfrom neuralforecast.utils import AirPassengersPanel, AirPassengersStatic\nfrom neuralforecast.tsdataset import TimeSeriesDataset, TimeSeriesLoader\n\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]] # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nfcst = NeuralForecast(\n    models=[TCN(h=12,\n                input_size=-1,\n                #loss=DistributionLoss(distribution='Normal', level=[80, 90]),\n                loss=GMM(n_components=7, return_params=True, level=[80,90]),\n                learning_rate=5e-4,\n                kernel_size=2,\n                dilations=[1,2,4,8,16],\n                encoder_hidden_size=128,\n                context_size=10,\n                decoder_hidden_size=128,\n                decoder_layers=2,\n                max_steps=500,\n                scaler_type='robust',\n                futr_exog_list=['y_[lag12]'],\n                hist_exog_list=None,\n                stat_exog_list=['airline1'],\n                )\n    ],\n    freq='M'\n)\nfcst.fit(df=Y_train_df, static_df=AirPassengersStatic)\nforecasts = fcst.predict(futr_df=Y_test_df)\n\n# Plot quantile predictions\nY_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nplot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\nplt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\nplt.plot(plot_df['ds'], plot_df['TCN-median'], c='blue', label='median')\nplt.fill_between(x=plot_df['ds'][-12:], \n                 y1=plot_df['TCN-lo-90'][-12:].values,\n                 y2=plot_df['TCN-hi-90'][-12:].values,\n                 alpha=0.4, label='level 90')\nplt.legend()\nplt.grid()\nplt.plot()"
  },
  {
    "objectID": "models.deepar.html",
    "href": "models.deepar.html",
    "title": "DeepAR",
    "section": "",
    "text": "The DeepAR model produces probabilistic forecasts based on an autoregressive recurrent neural network optimized on panel data using cross-learning. DeepAR obtains its forecast distribution uses a Markov Chain Monte Carlo sampler with the following conditional probability: \\[\\mathbb{P}(\\mathbf{y}_{[t+1:t+H]}|\\;\\mathbf{y}_{[:t]},\\; \\mathbf{x}^{(f)}_{[:t+H]},\\; \\mathbf{x}^{(s)})\\]\nwhere \\(\\mathbf{x}^{(s)}\\) are static exogenous inputs, \\(\\mathbf{x}^{(f)}_{[:t+H]}\\) are future exogenous available at the time of the prediction. The predictions are obtained by transforming the hidden states \\(\\mathbf{h}_{t}\\) into predictive distribution parameters \\(\\theta_{t}\\), and then generating samples \\(\\mathbf{\\hat{y}}_{[t+1:t+H]}\\) through Monte Carlo sampling trajectories.\n\\[\\begin{align}\n\\mathbf{h}_{t} &= \\textrm{RNN}([\\mathbf{y}_{t},\\mathbf{x}^{(f)}_{t+1},\\mathbf{x}^{(s)}], \\mathbf{h}_{t-1})\\\\\n\\mathbf{\\theta}_{t}&=\\textrm{Linear}(\\mathbf{h}_{t}) \\\\\n\\hat{y}_{t+1}&=\\textrm{sample}(\\;\\mathrm{P}(y_{t+1}\\;|\\;\\mathbf{\\theta}_{t})\\;)\n\\end{align}\\]\nReferences - David Salinas, Valentin Flunkert, Jan Gasthaus, Tim Januschowski (2020). “DeepAR: Probabilistic forecasting with autoregressive recurrent networks”. International Journal of Forecasting. - Alexander Alexandrov et. al (2020). “GluonTS: Probabilistic and Neural Time Series Modeling in Python”. Journal of Machine Learning Research.\nsource\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.deepar.html#usage-example",
    "href": "models.deepar.html#usage-example",
    "title": "DeepAR",
    "section": "Usage Example",
    "text": "Usage Example\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss, GMM, PMM\nfrom neuralforecast.tsdataset import TimeSeriesDataset\nfrom neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic\n\n\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\n#from neuralforecast.models import DeepAR\nfrom neuralforecast.losses.pytorch import DistributionLoss, HuberMQLoss\nfrom neuralforecast.tsdataset import TimeSeriesDataset\nfrom neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic\n\n#AirPassengersPanel['y'] = AirPassengersPanel['y'] + 10\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]] # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nnf = NeuralForecast(\n    models=[DeepAR(h=12,\n                   input_size=48,\n                   lstm_n_layers=3,\n                   trajectory_samples=100,\n                   loss=DistributionLoss(distribution='Normal', level=[80, 90], return_params=False),\n                   learning_rate=0.005,\n                   stat_exog_list=['airline1'],\n                   futr_exog_list=['trend'],\n                   max_steps=100,\n                   val_check_steps=10,\n                   early_stop_patience_steps=-1,\n                   scaler_type='standard',\n                   enable_progress_bar=True),\n    ],\n    freq='M'\n)\nnf.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\nY_hat_df = nf.predict(futr_df=Y_test_df)\n\n# Plot quantile predictions\nY_hat_df = Y_hat_df.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nplot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\nplt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n#plt.plot(plot_df['ds'], plot_df['DeepAR'], c='purple', label='mean')\nplt.plot(plot_df['ds'], plot_df['DeepAR-median'], c='blue', label='median')\nplt.fill_between(x=plot_df['ds'][-12:], \n                 y1=plot_df['DeepAR-lo-90'][-12:].values, \n                 y2=plot_df['DeepAR-hi-90'][-12:].values,\n                 alpha=0.4, label='level 90')\nplt.legend()\nplt.grid()\nplt.plot()"
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "Example Data",
    "section": "",
    "text": "1. Synthetic Panel Data \n\nsource\n\ngenerate_series\n\n generate_series (n_series:int, freq:str='D', min_length:int=50,\n                  max_length:int=500, n_temporal_features:int=0,\n                  n_static_features:int=0, equal_ends:bool=False,\n                  seed:int=0)\n\nGenerate Synthetic Panel Series.\nGenerates n_series of frequency freq of different lengths in the interval [min_length, max_length]. If n_temporal_features &gt; 0, then each serie gets temporal features with random values. If n_static_features &gt; 0, then a static dataframe is returned along the temporal dataframe. If equal_ends == True then all series end at the same date.\nParameters: n_series: int, number of series for synthetic panel. min_length: int, minimal length of synthetic panel’s series. max_length: int, minimal length of synthetic panel’s series. n_temporal_features: int, default=0, number of temporal exogenous variables for synthetic panel’s series. n_static_features: int, default=0, number of static exogenous variables for synthetic panel’s series. equal_ends: bool, if True, series finish in the same date stamp ds. freq: str, frequency of the data, panda’s available frequencies.\nReturns: freq: pandas.DataFrame, synthetic panel with columns [unique_id, ds, y] and exogenous.\n\nfrom neuralforecast.utils import generate_series\n\nsynthetic_panel = generate_series(n_series=2)\nsynthetic_panel.groupby('unique_id').head(4)\n\n\n\n\n\n\n\n\nds\ny\n\n\nunique_id\n\n\n\n\n\n\n0\n2000-01-01\n0.357595\n\n\n0\n2000-01-02\n1.301382\n\n\n0\n2000-01-03\n2.272442\n\n\n0\n2000-01-04\n3.211827\n\n\n1\n2000-01-01\n5.399023\n\n\n1\n2000-01-02\n6.092818\n\n\n1\n2000-01-03\n0.476396\n\n\n1\n2000-01-04\n1.343744\n\n\n\n\n\n\n\n\ntemporal_df, static_df = generate_series(n_series=1000, n_static_features=2,\n                                         n_temporal_features=4, equal_ends=False)\nstatic_df.head(2)\n\n\n\n\n2. AirPassengers Data \nThe classic Box & Jenkins airline data. Monthly totals of international airline passengers, 1949 to 1960.\nIt has been used as a reference on several forecasting libraries, since it is a series that shows clear trends and seasonalities it offers a nice opportunity to quickly showcase a model’s predictions performance.\n\nfrom neuralforecast.utils import AirPassengersDF\n\nAirPassengersDF.head(12)\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\n1.0\n1949-01-31\n112.0\n\n\n1\n1.0\n1949-02-28\n118.0\n\n\n2\n1.0\n1949-03-31\n132.0\n\n\n3\n1.0\n1949-04-30\n129.0\n\n\n4\n1.0\n1949-05-31\n121.0\n\n\n5\n1.0\n1949-06-30\n135.0\n\n\n6\n1.0\n1949-07-31\n148.0\n\n\n7\n1.0\n1949-08-31\n148.0\n\n\n8\n1.0\n1949-09-30\n136.0\n\n\n9\n1.0\n1949-10-31\n119.0\n\n\n10\n1.0\n1949-11-30\n104.0\n\n\n11\n1.0\n1949-12-31\n118.0\n\n\n\n\n\n\n\n\n#We are going to plot the ARIMA predictions, and the prediction intervals.\nfig, ax = plt.subplots(1, 1, figsize = (20, 7))\nplot_df = AirPassengersDF.set_index('ds')\n\nplot_df[['y']].plot(ax=ax, linewidth=2)\nax.set_title('AirPassengers Forecast', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp [t]', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\n\n\nimport numpy as np\nimport pandas as pd\n\nn_static_features = 3\nn_series = 5\n\nstatic_features = np.random.uniform(low=0.0, high=1.0, \n                        size=(n_series, n_static_features))\nstatic_df = pd.DataFrame.from_records(static_features, \n                   columns = [f'static_{i}'for i in  range(n_static_features)])\nstatic_df['unique_id'] = np.arange(n_series)\n\n\nstatic_df\n\n\n\n3. Panel AirPassengers Data \nExtension to classic Box & Jenkins airline data. Monthly totals of international airline passengers, 1949 to 1960.\nIt includes two series with static, temporal and future exogenous variables, that can help to explore the performance of models like NBEATSx and TFT.\n\nfig, ax = plt.subplots(1, 1, figsize = (20, 7))\nplot_df = AirPassengersPanel.set_index('ds')\n\nplot_df.groupby('unique_id')['y'].plot(legend=True)\nax.set_title('AirPassengers Panel Data', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp [t]', fontsize=20)\nax.legend(title='unique_id', prop={'size': 15})\nax.grid()\n\n\nfig, ax = plt.subplots(1, 1, figsize = (20, 7))\nplot_df = AirPassengersPanel[AirPassengersPanel.unique_id=='Airline1'].set_index('ds')\n\nplot_df[['y', 'trend', 'y_[lag12]']].plot(ax=ax, linewidth=2)\nax.set_title('Box-Cox AirPassengers Data', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp [t]', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\n\n\n\n4. Time Features\nWe have developed a utility that generates normalized calendar features for use as absolute positional embeddings in Transformer-based models. These embeddings capture seasonal patterns in time series data and can be easily incorporated into the model architecture. Additionally, the features can be used as exogenous variables in other models to inform them of calendar patterns in the data.\nReferences - Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, Wancai Zhang. “Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting”\n\nsource\n\naugment_calendar_df\n\n augment_calendar_df (df, freq='H')\n\n\n\nQ - [month]\nM - [month]\nW - [Day of month, week of year]\nD - [Day of week, day of month, day of year]\nB - [Day of week, day of month, day of year]\nH - [Hour of day, day of week, day of month, day of year]\nT - [Minute of hour*, hour of day, day of week, day of month, day of year]\nS - [Second of minute, minute of hour, hour of day, day of week, day of month, day of year] *minute returns a number from 0-3 corresponding to the 15 minute period it falls into.\n\n\n\nsource\n\n\ntime_features_from_frequency_str\n\n time_features_from_frequency_str (freq_str:str)\n\nReturns a list of time features that will be appropriate for the given frequency string. Parameters ———- freq_str Frequency string of the form [multiple][granularity] such as “12H”, “5min”, “1D” etc.\n\nsource\n\n\nWeekOfYear\n\n WeekOfYear ()\n\nWeek of year encoded as value between [-0.5, 0.5]\n\nsource\n\n\nMonthOfYear\n\n MonthOfYear ()\n\nMonth of year encoded as value between [-0.5, 0.5]\n\nsource\n\n\nDayOfYear\n\n DayOfYear ()\n\nDay of year encoded as value between [-0.5, 0.5]\n\nsource\n\n\nDayOfMonth\n\n DayOfMonth ()\n\nDay of month encoded as value between [-0.5, 0.5]\n\nsource\n\n\nDayOfWeek\n\n DayOfWeek ()\n\nHour of day encoded as value between [-0.5, 0.5]\n\nsource\n\n\nHourOfDay\n\n HourOfDay ()\n\nHour of day encoded as value between [-0.5, 0.5]\n\nsource\n\n\nMinuteOfHour\n\n MinuteOfHour ()\n\nMinute of hour encoded as value between [-0.5, 0.5]\n\nsource\n\n\nSecondOfMinute\n\n SecondOfMinute ()\n\nMinute of hour encoded as value between [-0.5, 0.5]\n\nsource\n\n\nTimeFeature\n\n TimeFeature ()\n\nInitialize self. See help(type(self)) for accurate signature.\n\nAirPassengerPanelCalendar, calendar_cols = augment_calendar_df(df=AirPassengersPanel, freq='M')\nAirPassengerPanelCalendar.head()\n\n\nplot_df = AirPassengerPanelCalendar[AirPassengerPanelCalendar.unique_id=='Airline1'].set_index('ds')\nplt.plot(plot_df['month'])\nplt.grid()\nplt.xlabel('Datestamp')\nplt.ylabel('Normalized Month')\nplt.show()\n\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.dilated_rnn.html",
    "href": "models.dilated_rnn.html",
    "title": "Dilated RNN",
    "section": "",
    "text": "The Dilated Recurrent Neural Network (DilatedRNN) addresses common challenges of modeling long sequences like vanishing gradients, computational efficiency, and improved model flexibility to model complex relationships while maintaining its parsimony. The DilatedRNN builds a deep stack of RNN layers using skip conditions on the temporal and the network’s depth dimensions. The temporal dilated recurrent skip connections offer the capability to focus on multi-resolution inputs.The predictions are obtained by transforming the hidden states into contexts \\(\\mathbf{c}_{[t+1:t+H]}\\), that are decoded and adapted into \\(\\mathbf{\\hat{y}}_{[t+1:t+H],[q]}\\) through MLPs.\n\\[\\begin{align}\n\\mathbf{h}_{t} &= \\textrm{DilatedRNN}([\\mathbf{y}_{t},\\mathbf{x}^{(h)}_{t},\\mathbf{x}^{(s)}], \\mathbf{h}_{t-1})\\\\\n\\mathbf{c}_{[t+1:t+H]}&=\\textrm{Linear}([\\mathbf{h}_{t}, \\mathbf{x}^{(f)}_{[:t+H]}]) \\\\\n\\hat{y}_{\\tau,[q]}&=\\textrm{MLP}([\\mathbf{c}_{\\tau},\\mathbf{x}^{(f)}_{\\tau}])\n\\end{align}\\]\nwhere \\(\\mathbf{h}_{t}\\), is the hidden state for time \\(t\\), \\(\\mathbf{y}_{t}\\) is the input at time \\(t\\) and \\(\\mathbf{h}_{t-1}\\) is the hidden state of the previous layer at \\(t-1\\), \\(\\mathbf{x}^{(s)}\\) are static exogenous inputs, \\(\\mathbf{x}^{(h)}_{t}\\) historic exogenous, \\(\\mathbf{x}^{(f)}_{[:t+H]}\\) are future exogenous available at the time of the prediction.\nReferences-Shiyu Chang, et al. “Dilated Recurrent Neural Networks”.-Yao Qin, et al. “A Dual-Stage Attention-Based recurrent neural network for time series prediction”.-Kashif Rasul, et al. “Zalando Research: PyTorch Dilated Recurrent Neural Networks”.\nsource\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.dilated_rnn.html#usage-example",
    "href": "models.dilated_rnn.html#usage-example",
    "title": "Dilated RNN",
    "section": "Usage Example",
    "text": "Usage Example\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import DilatedRNN\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss\nfrom neuralforecast.utils import AirPassengersPanel, AirPassengersStatic\nfrom neuralforecast.tsdataset import TimeSeriesDataset, TimeSeriesLoader\n\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]] # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nfcst = NeuralForecast(\n    models=[DilatedRNN(h=12,\n                       input_size=-1,\n                       loss=DistributionLoss(distribution='Normal', level=[80, 90]),\n                       scaler_type='robust',\n                       encoder_hidden_size=100,\n                       max_steps=200,\n                       futr_exog_list=['y_[lag12]'],\n                       hist_exog_list=None,\n                       stat_exog_list=['airline1'],\n    )\n    ],\n    freq='M'\n)\nfcst.fit(df=Y_train_df, static_df=AirPassengersStatic)\nforecasts = fcst.predict(futr_df=Y_test_df)\n\nY_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nplot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\nplt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\nplt.plot(plot_df['ds'], plot_df['DilatedRNN-median'], c='blue', label='median')\nplt.fill_between(x=plot_df['ds'][-12:], \n                 y1=plot_df['DilatedRNN-lo-90'][-12:].values, \n                 y2=plot_df['DilatedRNN-hi-90'][-12:].values,\n                 alpha=0.4, label='level 90')\nplt.legend()\nplt.grid()\nplt.plot()"
  },
  {
    "objectID": "models.lstm.html",
    "href": "models.lstm.html",
    "title": "LSTM",
    "section": "",
    "text": "The Long Short-Term Memory Recurrent Neural Network (LSTM), uses a multilayer LSTM encoder and an MLP decoder. It builds upon the LSTM-cell that improves the exploding and vanishing gradients of classic RNN’s. This network has been extensively used in sequential prediction tasks like language modeling, phonetic labeling, and forecasting. The predictions are obtained by transforming the hidden states into contexts \\(\\mathbf{c}_{[t+1:t+H]}\\), that are decoded and adapted into \\(\\mathbf{\\hat{y}}_{[t+1:t+H],[q]}\\) through MLPs.\n\\[\\begin{align}\n\\mathbf{h}_{t} &= \\textrm{LSTM}([\\mathbf{y}_{t},\\mathbf{x}^{(h)}_{t},\\mathbf{x}^{(s)}], \\mathbf{h}_{t-1})\\\\\n\\mathbf{c}_{[t+1:t+H]}&=\\textrm{Linear}([\\mathbf{h}_{t}, \\mathbf{x}^{(f)}_{[:t+H]}]) \\\\\n\\hat{y}_{\\tau,[q]}&=\\textrm{MLP}([\\mathbf{c}_{\\tau},\\mathbf{x}^{(f)}_{\\tau}])\n\\end{align}\\]\nwhere \\(\\mathbf{h}_{t}\\), is the hidden state for time \\(t\\), \\(\\mathbf{y}_{t}\\) is the input at time \\(t\\) and \\(\\mathbf{h}_{t-1}\\) is the hidden state of the previous layer at \\(t-1\\), \\(\\mathbf{x}^{(s)}\\) are static exogenous inputs, \\(\\mathbf{x}^{(h)}_{t}\\) historic exogenous, \\(\\mathbf{x}^{(f)}_{[:t+H]}\\) are future exogenous available at the time of the prediction.\nReferences-Jeffrey L. Elman (1990). “Finding Structure in Time”.-Haşim Sak, Andrew Senior, Françoise Beaufays (2014). “Long Short-Term Memory Based Recurrent Neural Network Architectures for Large Vocabulary Speech Recognition.”\nsource\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.lstm.html#usage-example",
    "href": "models.lstm.html#usage-example",
    "title": "LSTM",
    "section": "Usage Example",
    "text": "Usage Example\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import LSTM\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss\nfrom neuralforecast.utils import AirPassengersPanel, AirPassengersStatic\nfrom neuralforecast.tsdataset import TimeSeriesDataset, TimeSeriesLoader\n\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]] # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nnf = NeuralForecast(\n    models=[LSTM(h=12, input_size=-1,\n                 loss=DistributionLoss(distribution='Normal', level=[80, 90]),\n                 scaler_type='robust',\n                 encoder_n_layers=2,\n                 encoder_hidden_size=128,\n                 context_size=10,\n                 decoder_hidden_size=128,\n                 decoder_layers=2,\n                 max_steps=200,\n                 futr_exog_list=['y_[lag12]'],\n                 #hist_exog_list=['y_[lag12]'],\n                 stat_exog_list=['airline1'],\n                 )\n    ],\n    freq='M'\n)\nnf.fit(df=Y_train_df, static_df=AirPassengersStatic)\nY_hat_df = nf.predict(futr_df=Y_test_df)\n\nY_hat_df = Y_hat_df.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nplot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\nplt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\nplt.plot(plot_df['ds'], plot_df['LSTM'], c='purple', label='mean')\nplt.plot(plot_df['ds'], plot_df['LSTM-median'], c='blue', label='median')\nplt.fill_between(x=plot_df['ds'][-12:], \n                 y1=plot_df['LSTM-lo-90'][-12:].values, \n                 y2=plot_df['LSTM-hi-90'][-12:].values,\n                 alpha=0.4, label='level 90')\nplt.legend()\nplt.grid()\nplt.plot()"
  },
  {
    "objectID": "common.base_recurrent.html",
    "href": "common.base_recurrent.html",
    "title": "BaseRecurrent",
    "section": "",
    "text": "The BaseRecurrent class contains standard methods shared across recurrent neural networks; these models possess the ability to process variable-length sequences of inputs through their internal memory states. The class is represented by LSTM, GRU, and RNN, along with other more sophisticated architectures like MQCNN.\nThe standard methods include TemporalNorm preprocessing, optimization utilities like parameter initialization, training_step, validation_step, and shared fit and predict methods.These shared methods enable all the neuralforecast.models compatibility with the core.NeuralForecast wrapper class.\n\n\nBaseRecurrent\n\n BaseRecurrent (h, input_size, inference_input_size, loss, valid_loss,\n                learning_rate, max_steps, val_check_steps, batch_size,\n                valid_batch_size, scaler_type='robust', num_lr_decays=0,\n                early_stop_patience_steps=-1, futr_exog_list=None,\n                hist_exog_list=None, stat_exog_list=None,\n                num_workers_loader=0, drop_last_loader=False,\n                random_seed=1, alias=None, **trainer_kwargs)\n\nBase Recurrent\nBase class for all recurrent-based models. The forecasts are produced sequentially between windows.\nThis class implements the basic functionality for all windows-based models, including: - PyTorch Lightning’s methods training_step, validation_step, predict_step.  - fit and predict methods used by NeuralForecast.core class.  - sampling and wrangling methods to sequential windows. \n\n\n\nBaseRecurrent.fit\n\n BaseRecurrent.fit (dataset, val_size=0, test_size=0, random_seed=None)\n\nFit.\nThe fit method, optimizes the neural network’s weights using the initialization parameters (learning_rate, batch_size, …) and the loss function as defined during the initialization. Within fit we use a PyTorch Lightning Trainer that inherits the initialization’s self.trainer_kwargs, to customize its inputs, see PL’s trainer arguments.\nThe method is designed to be compatible with SKLearn-like classes and in particular to be compatible with the StatsForecast library.\nBy default the model is not saving training checkpoints to protect disk memory, to get them change enable_checkpointing=True in __init__.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset, see documentation. val_size: int, validation size for temporal cross-validation. test_size: int, test size for temporal cross-validation. random_seed: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__’s.\n\n\n\nBaseRecurrent.predict\n\n BaseRecurrent.predict (dataset, step_size=1, random_seed=None,\n                        **data_module_kwargs)\n\nPredict.\nNeural network prediction with PL’s Trainer execution of predict_step.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset, see documentation. step_size: int=1, Step size between each window. random_seed: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__’s. **data_module_kwargs: PL’s TimeSeriesDataModule args, see documentation.\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.hint.html",
    "href": "models.hint.html",
    "title": "HINT",
    "section": "",
    "text": "The Hierarchical Mixture Networks (HINT) are a highly modular framework that combines SoTA neural forecast architectures with task-specialized mixture probability and advanced hierarchical reconciliation strategies. This powerful combination allows HINT to produce accurate and coherent probabilistic forecasts.\nHINT’s incorporates a TemporalNorm module into any neural forecast architecture, the module normalizes inputs into the network’s non-linearities operating range and recomposes its output’s scales through a global skip connection, improving accuracy and training robustness. HINT ensures the forecast coherence via bootstrap sample reconciliation that restores the aggregation constraints into its base samples.\nReferences - Kin G. Olivares, David Luo, Cristian Challu, Stefania La Vattiata, Max Mergenthaler, Artur Dubrawski (2023). “HINT: Hierarchical Mixture Networks For Coherent Probabilistic Forecasting”. Neural Information Processing Systems, submitted. Working Paper version available at arxiv. - Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker (2022).”Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures”. International Journal Forecasting, accepted paper available at arxiv. - Kin G. Olivares, Federico Garza, David Luo, Cristian Challu, Max Mergenthaler, Souhaib Ben Taieb, Shanika Wickramasuriya, and Artur Dubrawski (2022). “HierarchicalForecast: A reference framework for hierarchical forecasting in python”. Journal of Machine Learning Research, submitted, abs/2207.03517, 2022b.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.hint.html#reconciliation-methods",
    "href": "models.hint.html#reconciliation-methods",
    "title": "HINT",
    "section": "Reconciliation Methods",
    "text": "Reconciliation Methods\n\nsource\n\nget_identity_P\n\n get_identity_P (S:numpy.ndarray)\n\n\nsource\n\n\nget_bottomup_P\n\n get_bottomup_P (S:numpy.ndarray)\n\nBottomUp Reconciliation Matrix.\nCreates BottomUp hierarchical “projection” matrix is defined as: \\[\\mathbf{P}_{\\text{BU}} = [\\mathbf{0}_{\\mathrm{[b],[a]}}\\;|\\;\\mathbf{I}_{\\mathrm{[b][b]}}]\\]\nParameters: S: Summing matrix of size (base, bottom).\nReturns: P: Reconciliation matrix of size (bottom, base).\nReferences: - Orcutt, G.H., Watts, H.W., & Edwards, J.B.(1968). “Data aggregation and information loss”. The American Economic Review, 58 , 773(787).\n\nsource\n\n\nget_mintrace_ols_P\n\n get_mintrace_ols_P (S:numpy.ndarray)\n\nMinTraceOLS Reconciliation Matrix.\nCreates MinTraceOLS reconciliation matrix as proposed by Wickramasuriya et al.\n\\[\\mathbf{P}_{\\text{MinTraceOLS}}=\\left(\\mathbf{S}^{\\intercal}\\mathbf{S}\\right)^{-1}\\mathbf{S}^{\\intercal}\\]\nParameters: S: Summing matrix of size (base, bottom).\nReturns: P: Reconciliation matrix of size (bottom, base).\nReferences: - Wickramasuriya, S.L., Turlach, B.A. & Hyndman, R.J. (2020). “Optimal non-negative forecast reconciliation”. Stat Comput 30, 1167–1182, https://doi.org/10.1007/s11222-020-09930-0.\n\nsource\n\n\nget_mintrace_wls_P\n\n get_mintrace_wls_P (S:numpy.ndarray)\n\nMinTraceOLS Reconciliation Matrix.\nCreates MinTraceOLS reconciliation matrix as proposed by Wickramasuriya et al. Depending on a weighted GLS estimator and an estimator of the covariance matrix of the coherency errors \\(\\mathbf{W}_{h}\\).\n\\[ \\mathbf{W}_{h} = \\mathrm{Diag}(\\mathbf{S} \\mathbb{1}_{[b]})\\]\n\\[\\mathbf{P}_{\\text{MinTraceWLS}}=\\left(\\mathbf{S}^{\\intercal}\\mathbf{W}_{h}\\mathbf{S}\\right)^{-1}\n\\mathbf{S}^{\\intercal}\\mathbf{W}^{-1}_{h}\\]\nParameters: S: Summing matrix of size (base, bottom).\nReturns: P: Reconciliation matrix of size (bottom, base).\nReferences: - Wickramasuriya, S.L., Turlach, B.A. & Hyndman, R.J. (2020). “Optimal non-negative forecast reconciliation”. Stat Comput 30, 1167–1182, https://doi.org/10.1007/s11222-020-09930-0."
  },
  {
    "objectID": "models.hint.html#hint",
    "href": "models.hint.html#hint",
    "title": "HINT",
    "section": "HINT",
    "text": "HINT\n\nsource\n\nHINT\n\n HINT (h:int, S:numpy.ndarray, model, reconciliation:str,\n       alias:Optional[str]=None)\n\nHINT\nThe Hierarchical Mixture Networks (HINT) are a highly modular framework that combines SoTA neural forecast architectures with a task-specialized mixture probability and advanced hierarchical reconciliation strategies. This powerful combination allows HINT to produce accurate and coherent probabilistic forecasts.\nHINT’s incorporates a TemporalNorm module into any neural forecast architecture, the module normalizes inputs into the network’s non-linearities operating range and recomposes its output’s scales through a global skip connection, improving accuracy and training robustness. HINT ensures the forecast coherence via bootstrap sample reconciliation that restores the aggregation constraints into its base samples.\nAvailable reconciliations: - BottomUp - MinTraceOLS - MinTraceWLS - Identity\nParameters: h: int, Forecast horizon.  model: NeuralForecast model, instantiated model class from architecture collection. S: np.ndarray, dumming matrix of size (base, bottom) see HierarchicalForecast’s aggregate method. reconciliation: str, HINT’s reconciliation method from [‘BottomUp’, ‘MinTraceOLS’, ‘MinTraceWLS’]. alias: str, optional, Custom name of the model.\n\nsource\n\n\nHINT.fit\n\n HINT.fit (dataset, val_size=0, test_size=0, random_seed=None)\n\nHINT.fit\nHINT trains on the entire hierarchical dataset, by minimizing a composite log likelihood objective. HINT framework integrates TemporalNorm into the neural forecast architecture for a scale-decoupled optimization that robustifies cross-learning the hierachy’s series scales.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset see details here val_size: int, size of the validation set, (default 0). test_size: int, size of the test set, (default 0). random_seed: int, random seed for the prediction.\nReturns: self: A fitted base NeuralForecast model.\n\nsource\n\n\nHINT.predict\n\n HINT.predict (dataset, step_size=1, random_seed=None,\n               **data_module_kwargs)\n\nHINT.predict\nAfter fitting a base model on the entire hierarchical dataset. HINT restores the hierarchical aggregation constraints using bootstrapped sample reconciliation.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset see details here step_size: int, steps between sequential predictions, (default 1). random_seed: int, random seed for the prediction. **data_kwarg: additional parameters for the dataset module.\nReturns: y_hat: numpy predictions of the NeuralForecast model."
  },
  {
    "objectID": "models.hint.html#usage-example",
    "href": "models.hint.html#usage-example",
    "title": "HINT",
    "section": "Usage Example",
    "text": "Usage Example\nIn this example we will use HINT for the hierarchical forecast task, a multivariate regression problem with aggregation constraints. The aggregation constraints can be compactcly represented by the summing matrix \\(\\mathbf{S}_{[i][b]}\\), the Figure belows shows an example.\nIn this example we will make coherent predictions for the TourismL dataset.\nOutline 1. Import packages 2. Load hierarchical dataset 3. Fit and Predict HINT 4. Forecast Plot\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast.losses.pytorch import GMM, sCRPS\nfrom datasetsforecast.hierarchical import HierarchicalData\n\n# Auxiliary sorting\ndef sort_df_hier(Y_df, S_df):\n    # NeuralForecast core, sorts unique_id lexicographically\n    # by default, this class matches S_df and Y_hat_df order.    \n    Y_df.unique_id = Y_df.unique_id.astype('category')\n    Y_df.unique_id = Y_df.unique_id.cat.set_categories(S_df.index)\n    Y_df = Y_df.sort_values(by=['unique_id', 'ds'])\n    return Y_df\n\n# Load TourismSmall dataset\nhorizon = 12\nY_df, S_df, tags = HierarchicalData.load('./data', 'TourismLarge')\nY_df['ds'] = pd.to_datetime(Y_df['ds'])\nY_df = sort_df_hier(Y_df, S_df)\nlevel = [80,90]\n\n# Instantiate HINT\n# BaseNetwork + Distribution + Reconciliation\nnhits = NHITS(h=horizon,\n              input_size=24,\n              loss=GMM(n_components=10, level=level),\n              hist_exog_list=['month'],\n              max_steps=2000,\n              early_stop_patience_steps=10,\n              val_check_steps=50,\n              scaler_type='robust',\n              learning_rate=1e-3,\n              valid_loss=sCRPS(level=level))\n\nmodel = HINT(h=horizon, S=S_df.values,\n             model=nhits,  reconciliation='BottomUp')\n\n# Fit and Predict\nnf = NeuralForecast(models=[model], freq='MS')\nY_hat_df = nf.cross_validation(df=Y_df, val_size=12, n_windows=1)\n\n\n# Plot coherent probabilistic forecast\nunique_id = 'TotalAll'\nY_plot_df = Y_df[Y_df.unique_id==unique_id]\nplot_df = Y_hat_df[Y_hat_df.unique_id==unique_id]\nplot_df = Y_plot_df.merge(plot_df, on=['ds', 'unique_id'], how='left')\nn_years = 5\n\nplt.plot(plot_df['ds'][-12*n_years:], plot_df['y_x'][-12*n_years:], c='black', label='True')\nplt.plot(plot_df['ds'][-12*n_years:], plot_df['HINT'][-12*n_years:], c='purple', label='mean')\nplt.plot(plot_df['ds'][-12*n_years:], plot_df['HINT-median'][-12*n_years:], c='blue', label='median')\nplt.fill_between(x=plot_df['ds'][-12*n_years:],\n                 y1=plot_df['HINT-lo-90'][-12*n_years:].values,\n                 y2=plot_df['HINT-hi-90'][-12*n_years:].values,\n                 alpha=0.4, label='level 90')\nplt.legend()\nplt.grid()\nplt.plot()"
  },
  {
    "objectID": "models.nbeatsx.html",
    "href": "models.nbeatsx.html",
    "title": "NBEATSx",
    "section": "",
    "text": "The Neural Basis Expansion Analysis (NBEATS) is an MLP-based deep neural architecture with backward and forward residual links. The network has two variants: (1) in its interpretable configuration, NBEATS sequentially projects the signal into polynomials and harmonic basis to learn trend and seasonality components; (2) in its generic configuration, it substitutes the polynomial and harmonic basis for identity basis and larger network’s depth. The Neural Basis Expansion Analysis with Exogenous (NBEATSx), incorporates projections to exogenous temporal variables available at the time of the prediction. This method proved state-of-the-art performance on the M3, M4, and Tourism Competition datasets, improving accuracy by 3% over the ESRNN M4 competition winner. For Electricity Price Forecasting tasks NBEATSx model improved accuracy by 20% and 5% over ESRNN and NBEATS, and 5% on task-specialized architectures.References-Boris N. Oreshkin, Dmitri Carpov, Nicolas Chapados, Yoshua Bengio (2019). “N-BEATS: Neural basis expansion analysis for interpretable time series forecasting”.-Kin G. Olivares, Cristian Challu, Grzegorz Marcjasz, Rafał Weron, Artur Dubrawski (2021). “Neural basis expansion analysis with exogenous variables: Forecasting electricity prices with NBEATSx”.\nsource\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.nbeatsx.html#usage-example",
    "href": "models.nbeatsx.html#usage-example",
    "title": "NBEATSx",
    "section": "Usage Example",
    "text": "Usage Example\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import NBEATSx\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss\nfrom neuralforecast.tsdataset import TimeSeriesDataset\nfrom neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic\n\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]] # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nmodel = NBEATSx(h=12, input_size=24,\n                #loss=MQLoss(level=[80, 90]),\n                loss=DistributionLoss(distribution='Normal', level=[80, 90]),\n                scaler_type='robust',\n                dropout_prob_theta=0.5,\n                stat_exog_list=['airline1'],\n                futr_exog_list=['trend'],\n                max_steps=200,\n                val_check_steps=10,\n                early_stop_patience_steps=2)\n\nnf = NeuralForecast(\n    models=[model],\n    freq='M'\n)\nnf.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\nY_hat_df = nf.predict(futr_df=Y_test_df)\n\n# Plot quantile predictions\nY_hat_df = Y_hat_df.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nplot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\nplt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\nplt.plot(plot_df['ds'], plot_df['NBEATSx'], c='purple', label='mean')\nplt.plot(plot_df['ds'], plot_df['NBEATSx-median'], c='blue', label='median')\nplt.fill_between(x=plot_df['ds'][-12:], \n                 y1=plot_df['NBEATSx-lo-90'][-12:].values, \n                 y2=plot_df['NBEATSx-hi-90'][-12:].values,\n                 alpha=0.4, label='level 90')\nplt.legend()\nplt.grid()\nplt.plot()"
  },
  {
    "objectID": "models.mlp.html",
    "href": "models.mlp.html",
    "title": "MLP",
    "section": "",
    "text": "Figure 1. Three layer MLP with autorregresive inputs.\nsource\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.mlp.html#usage-example",
    "href": "models.mlp.html#usage-example",
    "title": "MLP",
    "section": "Usage Example",
    "text": "Usage Example\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import MLP\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss\nfrom neuralforecast.tsdataset import TimeSeriesDataset\nfrom neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic\n\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]] # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nmodel = MLP(h=12, input_size=24,\n            loss=DistributionLoss(distribution='Normal', level=[80, 90]),\n            scaler_type='robust',\n            learning_rate=1e-3,\n            max_steps=200,\n            val_check_steps=10,\n            early_stop_patience_steps=2)\n\nfcst = NeuralForecast(\n    models=[model],\n    freq='M'\n)\nfcst.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\nforecasts = fcst.predict(futr_df=Y_test_df)\n\nY_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nplot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\nplt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\nplt.plot(plot_df['ds'], plot_df['MLP-median'], c='blue', label='median')\nplt.fill_between(x=plot_df['ds'][-12:], \n                 y1=plot_df['MLP-lo-90'][-12:].values, \n                 y2=plot_df['MLP-hi-90'][-12:].values,\n                 alpha=0.4, label='level 90')\nplt.grid()\nplt.legend()\nplt.plot()"
  },
  {
    "objectID": "losses.numpy.html",
    "href": "losses.numpy.html",
    "title": "NumPy Evaluation",
    "section": "",
    "text": "These metrics are on the same scale as the data.\n\n\n\nsource\n\n\n\n mae (y:numpy.ndarray, y_hat:numpy.ndarray,\n      weights:Optional[numpy.ndarray]=None, axis:Optional[int]=None)\n\nMean Absolute Error\nCalculates Mean Absolute Error between y and y_hat. MAE measures the relative prediction accuracy of a forecasting method by calculating the deviation of the prediction and the true value at a given time and averages these devations over the length of the series.\n\\[ \\mathrm{MAE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} |y_{\\tau} - \\hat{y}_{\\tau}| \\]\nParameters: y: numpy array, Actual values. y_hat: numpy array, Predicted values. mask: numpy array, Specifies date stamps per serie to consider in loss.\nReturns: mae: numpy array, (single value).\n\n\n\n\n\n\nsource\n\n\n\n mse (y:numpy.ndarray, y_hat:numpy.ndarray,\n      weights:Optional[numpy.ndarray]=None, axis:Optional[int]=None)\n\nMean Squared Error\nCalculates Mean Squared Error between y and y_hat. MSE measures the relative prediction accuracy of a forecasting method by calculating the squared deviation of the prediction and the true value at a given time, and averages these devations over the length of the series.\n\\[ \\mathrm{MSE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} (y_{\\tau} - \\hat{y}_{\\tau})^{2} \\]\nParameters: y: numpy array, Actual values. y_hat: numpy array, Predicted values. mask: numpy array, Specifies date stamps per serie to consider in loss.\nReturns: mse: numpy array, (single value).\n\n\n\n\n\n\nsource\n\n\n\n rmse (y:numpy.ndarray, y_hat:numpy.ndarray,\n       weights:Optional[numpy.ndarray]=None, axis:Optional[int]=None)\n\nRoot Mean Squared Error\nCalculates Root Mean Squared Error between y and y_hat. RMSE measures the relative prediction accuracy of a forecasting method by calculating the squared deviation of the prediction and the observed value at a given time and averages these devations over the length of the series. Finally the RMSE will be in the same scale as the original time series so its comparison with other series is possible only if they share a common scale. RMSE has a direct connection to the L2 norm.\n\\[ \\mathrm{RMSE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\sqrt{\\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} (y_{\\tau} - \\hat{y}_{\\tau})^{2}} \\]\nParameters: y: numpy array, Actual values. y_hat: numpy array, Predicted values. mask: numpy array, Specifies date stamps per serie to consider in loss.\nReturns: rmse: numpy array, (single value).\nGive us a ⭐ on Github"
  },
  {
    "objectID": "losses.numpy.html#mean-absolute-error",
    "href": "losses.numpy.html#mean-absolute-error",
    "title": "NumPy Evaluation",
    "section": "",
    "text": "source\n\n\n\n mae (y:numpy.ndarray, y_hat:numpy.ndarray,\n      weights:Optional[numpy.ndarray]=None, axis:Optional[int]=None)\n\nMean Absolute Error\nCalculates Mean Absolute Error between y and y_hat. MAE measures the relative prediction accuracy of a forecasting method by calculating the deviation of the prediction and the true value at a given time and averages these devations over the length of the series.\n\\[ \\mathrm{MAE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} |y_{\\tau} - \\hat{y}_{\\tau}| \\]\nParameters: y: numpy array, Actual values. y_hat: numpy array, Predicted values. mask: numpy array, Specifies date stamps per serie to consider in loss.\nReturns: mae: numpy array, (single value)."
  },
  {
    "objectID": "losses.numpy.html#mean-squared-error",
    "href": "losses.numpy.html#mean-squared-error",
    "title": "NumPy Evaluation",
    "section": "",
    "text": "source\n\n\n\n mse (y:numpy.ndarray, y_hat:numpy.ndarray,\n      weights:Optional[numpy.ndarray]=None, axis:Optional[int]=None)\n\nMean Squared Error\nCalculates Mean Squared Error between y and y_hat. MSE measures the relative prediction accuracy of a forecasting method by calculating the squared deviation of the prediction and the true value at a given time, and averages these devations over the length of the series.\n\\[ \\mathrm{MSE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} (y_{\\tau} - \\hat{y}_{\\tau})^{2} \\]\nParameters: y: numpy array, Actual values. y_hat: numpy array, Predicted values. mask: numpy array, Specifies date stamps per serie to consider in loss.\nReturns: mse: numpy array, (single value)."
  },
  {
    "objectID": "losses.numpy.html#root-mean-squared-error",
    "href": "losses.numpy.html#root-mean-squared-error",
    "title": "NumPy Evaluation",
    "section": "",
    "text": "source\n\n\n\n rmse (y:numpy.ndarray, y_hat:numpy.ndarray,\n       weights:Optional[numpy.ndarray]=None, axis:Optional[int]=None)\n\nRoot Mean Squared Error\nCalculates Root Mean Squared Error between y and y_hat. RMSE measures the relative prediction accuracy of a forecasting method by calculating the squared deviation of the prediction and the observed value at a given time and averages these devations over the length of the series. Finally the RMSE will be in the same scale as the original time series so its comparison with other series is possible only if they share a common scale. RMSE has a direct connection to the L2 norm.\n\\[ \\mathrm{RMSE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\sqrt{\\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} (y_{\\tau} - \\hat{y}_{\\tau})^{2}} \\]\nParameters: y: numpy array, Actual values. y_hat: numpy array, Predicted values. mask: numpy array, Specifies date stamps per serie to consider in loss.\nReturns: rmse: numpy array, (single value)."
  },
  {
    "objectID": "losses.numpy.html#mean-absolute-percentage-error",
    "href": "losses.numpy.html#mean-absolute-percentage-error",
    "title": "NumPy Evaluation",
    "section": "Mean Absolute Percentage Error",
    "text": "Mean Absolute Percentage Error\n\nsource\n\nmape\n\n mape (y:numpy.ndarray, y_hat:numpy.ndarray,\n       weights:Optional[numpy.ndarray]=None, axis:Optional[int]=None)\n\nMean Absolute Percentage Error\nCalculates Mean Absolute Percentage Error between y and y_hat. MAPE measures the relative prediction accuracy of a forecasting method by calculating the percentual deviation of the prediction and the observed value at a given time and averages these devations over the length of the series. The closer to zero an observed value is, the higher penalty MAPE loss assigns to the corresponding error.\n\\[ \\mathrm{MAPE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\frac{|y_{\\tau}-\\hat{y}_{\\tau}|}{|y_{\\tau}|} \\]\nParameters: y: numpy array, Actual values. y_hat: numpy array, Predicted values. mask: numpy array, Specifies date stamps per serie to consider in loss.\nReturns: mape: numpy array, (single value)."
  },
  {
    "objectID": "losses.numpy.html#smape",
    "href": "losses.numpy.html#smape",
    "title": "NumPy Evaluation",
    "section": "SMAPE",
    "text": "SMAPE\n\nsource\n\nsmape\n\n smape (y:numpy.ndarray, y_hat:numpy.ndarray,\n        weights:Optional[numpy.ndarray]=None, axis:Optional[int]=None)\n\nSymmetric Mean Absolute Percentage Error\nCalculates Symmetric Mean Absolute Percentage Error between y and y_hat. SMAPE measures the relative prediction accuracy of a forecasting method by calculating the relative deviation of the prediction and the observed value scaled by the sum of the absolute values for the prediction and observed value at a given time, then averages these devations over the length of the series. This allows the SMAPE to have bounds between 0% and 200% which is desirable compared to normal MAPE that may be undetermined when the target is zero.\n\\[ \\mathrm{sMAPE}_{2}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\frac{|y_{\\tau}-\\hat{y}_{\\tau}|}{|y_{\\tau}|+|\\hat{y}_{\\tau}|} \\]\nParameters: y: numpy array, Actual values. y_hat: numpy array, Predicted values. mask: numpy array, Specifies date stamps per serie to consider in loss.\nReturns: smape: numpy array, (single value).\nReferences: Makridakis S., “Accuracy measures: theoretical and practical concerns”."
  },
  {
    "objectID": "losses.numpy.html#mean-absolute-scaled-error",
    "href": "losses.numpy.html#mean-absolute-scaled-error",
    "title": "NumPy Evaluation",
    "section": "Mean Absolute Scaled Error",
    "text": "Mean Absolute Scaled Error\n\nsource\n\nmase\n\n mase (y:numpy.ndarray, y_hat:numpy.ndarray, y_train:numpy.ndarray,\n       seasonality:int, weights:Optional[numpy.ndarray]=None,\n       axis:Optional[int]=None)\n\nMean Absolute Scaled Error Calculates the Mean Absolute Scaled Error between y and y_hat. MASE measures the relative prediction accuracy of a forecasting method by comparinng the mean absolute errors of the prediction and the observed value against the mean absolute errors of the seasonal naive model. The MASE partially composed the Overall Weighted Average (OWA), used in the M4 Competition.\n\\[ \\mathrm{MASE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}, \\mathbf{\\hat{y}}^{season}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\frac{|y_{\\tau}-\\hat{y}_{\\tau}|}{\\mathrm{MAE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}^{season}_{\\tau})} \\]\nParameters: y: numpy array, (batch_size, output_size), Actual values. y_hat: numpy array, (batch_size, output_size)), Predicted values. y_insample: numpy array, (batch_size, input_size), Actual insample Seasonal Naive predictions. seasonality: int. Main frequency of the time series; Hourly 24, Daily 7, Weekly 52, Monthly 12, Quarterly 4, Yearly 1.\nmask: numpy array, Specifies date stamps per serie to consider in loss.\nReturns: mase: numpy array, (single value).\nReferences: Rob J. Hyndman, & Koehler, A. B. “Another look at measures of forecast accuracy”. Spyros Makridakis, Evangelos Spiliotis, Vassilios Assimakopoulos, “The M4 Competition: 100,000 time series and 61 forecasting methods”."
  },
  {
    "objectID": "losses.numpy.html#relative-mean-absolute-error",
    "href": "losses.numpy.html#relative-mean-absolute-error",
    "title": "NumPy Evaluation",
    "section": "Relative Mean Absolute Error",
    "text": "Relative Mean Absolute Error\n\nsource\n\nrmae\n\n rmae (y:numpy.ndarray, y_hat1:numpy.ndarray, y_hat2:numpy.ndarray,\n       weights:Optional[numpy.ndarray]=None, axis:Optional[int]=None)\n\nRMAE\nCalculates Relative Mean Absolute Error (RMAE) between two sets of forecasts (from two different forecasting methods). A number smaller than one implies that the forecast in the numerator is better than the forecast in the denominator.\n\\[ \\mathrm{rMAE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}, \\mathbf{\\hat{y}}^{base}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\frac{|y_{\\tau}-\\hat{y}_{\\tau}|}{\\mathrm{MAE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}^{base}_{\\tau})} \\]\nParameters: y: numpy array, observed values. y_hat1: numpy array. Predicted values of first model. y_hat2: numpy array. Predicted values of baseline model. weights: numpy array, optional. Weights for weighted average. axis: None or int, optional.Axis or axes along which to average a. The default, axis=None, will average over all of the elements of the input array.\nReturns: rmae: numpy array or double.\nReferences: Rob J. Hyndman, & Koehler, A. B. “Another look at measures of forecast accuracy”."
  },
  {
    "objectID": "losses.numpy.html#quantile-loss",
    "href": "losses.numpy.html#quantile-loss",
    "title": "NumPy Evaluation",
    "section": "Quantile Loss",
    "text": "Quantile Loss\n\nsource\n\nquantile_loss\n\n quantile_loss (y:numpy.ndarray, y_hat:numpy.ndarray, q:float=0.5,\n                weights:Optional[numpy.ndarray]=None,\n                axis:Optional[int]=None)\n\nQuantile Loss\nComputes the quantile loss between y and y_hat. QL measures the deviation of a quantile forecast. By weighting the absolute deviation in a non symmetric way, the loss pays more attention to under or over estimation. A common value for q is 0.5 for the deviation from the median (Pinball loss).\n\\[ \\mathrm{QL}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}^{(q)}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\Big( (1-q)\\,( \\hat{y}^{(q)}_{\\tau} - y_{\\tau} )_{+} + q\\,( y_{\\tau} - \\hat{y}^{(q)}_{\\tau} )_{+} \\Big) \\]\nParameters: y: numpy array, Actual values. y_hat: numpy array, Predicted values. q: float, between 0 and 1. The slope of the quantile loss, in the context of quantile regression, the q determines the conditional quantile level. mask: numpy array, Specifies date stamps per serie to consider in loss.\nReturns: quantile_loss: numpy array, (single value).\nReferences: Roger Koenker and Gilbert Bassett, Jr., “Regression Quantiles”."
  },
  {
    "objectID": "losses.numpy.html#multi-quantile-loss",
    "href": "losses.numpy.html#multi-quantile-loss",
    "title": "NumPy Evaluation",
    "section": "Multi-Quantile Loss",
    "text": "Multi-Quantile Loss\n\nsource\n\nmqloss\n\n mqloss (y:numpy.ndarray, y_hat:numpy.ndarray, quantiles:numpy.ndarray,\n         weights:Optional[numpy.ndarray]=None, axis:Optional[int]=None)\n\nMulti-Quantile loss\nCalculates the Multi-Quantile loss (MQL) between y and y_hat. MQL calculates the average multi-quantile Loss for a given set of quantiles, based on the absolute difference between predicted quantiles and observed values.\n\\[ \\mathrm{MQL}(\\mathbf{y}_{\\tau},[\\mathbf{\\hat{y}}^{(q_{1})}_{\\tau}, ... ,\\hat{y}^{(q_{n})}_{\\tau}]) = \\frac{1}{n} \\sum_{q_{i}} \\mathrm{QL}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}^{(q_{i})}_{\\tau}) \\]\nThe limit behavior of MQL allows to measure the accuracy of a full predictive distribution \\(\\mathbf{\\hat{F}}_{\\tau}\\) with the continuous ranked probability score (CRPS). This can be achieved through a numerical integration technique, that discretizes the quantiles and treats the CRPS integral with a left Riemann approximation, averaging over uniformly distanced quantiles.\n\\[ \\mathrm{CRPS}(y_{\\tau}, \\mathbf{\\hat{F}}_{\\tau}) = \\int^{1}_{0} \\mathrm{QL}(y_{\\tau}, \\hat{y}^{(q)}_{\\tau}) dq \\]\nParameters: y: numpy array, Actual values. y_hat: numpy array, Predicted values. quantiles: numpy array,(n_quantiles). Quantiles to estimate from the distribution of y. mask: numpy array, Specifies date stamps per serie to consider in loss.\nReturns: mqloss: numpy array, (single value).\nReferences: Roger Koenker and Gilbert Bassett, Jr., “Regression Quantiles”. James E. Matheson and Robert L. Winkler, “Scoring Rules for Continuous Probability Distributions”."
  },
  {
    "objectID": "models.autoformer.html",
    "href": "models.autoformer.html",
    "title": "Autoformer",
    "section": "",
    "text": "The Autoformer model tackles the challenge of finding reliable dependencies on intricate temporal patterns of long-horizon forecasting.\nThe architecture has the following distinctive features: - In-built progressive decomposition in trend and seasonal compontents based on a moving average filter. - Auto-Correlation mechanism that discovers the period-based dependencies by calculating the autocorrelation and aggregating similar sub-series based on the periodicity. - Classic encoder-decoder proposed by Vaswani et al. (2017) with a multi-head attention mechanism.\nThe Autoformer model utilizes a three-component approach to define its embedding: - It employs encoded autoregressive features obtained from a convolution network. - Absolute positional embeddings obtained from calendar features are utilized.\nReferences - Wu, Haixu, Jiehui Xu, Jianmin Wang, and Mingsheng Long. “Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting”\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.autoformer.html#auxiliary-functions",
    "href": "models.autoformer.html#auxiliary-functions",
    "title": "Autoformer",
    "section": "1. Auxiliary Functions",
    "text": "1. Auxiliary Functions\n\nsource\n\nDecoder\n\n Decoder (layers, norm_layer=None, projection=None)\n\nAutoformer decoder\n\nsource\n\n\nDecoderLayer\n\n DecoderLayer (self_attention, cross_attention, hidden_size, c_out,\n               conv_hidden_size=None, MovingAvg=25, dropout=0.1,\n               activation='relu')\n\nAutoformer decoder layer with the progressive decomposition architecture\n\nsource\n\n\nEncoder\n\n Encoder (attn_layers, conv_layers=None, norm_layer=None)\n\nAutoformer encoder\n\nsource\n\n\nEncoderLayer\n\n EncoderLayer (attention, hidden_size, conv_hidden_size=None,\n               MovingAvg=25, dropout=0.1, activation='relu')\n\nAutoformer encoder layer with the progressive decomposition architecture\n\nsource\n\n\nSeriesDecomp\n\n SeriesDecomp (kernel_size)\n\nSeries decomposition block\n\nsource\n\n\nMovingAvg\n\n MovingAvg (kernel_size, stride)\n\nMoving average block to highlight the trend of time series\n\nsource\n\n\nLayerNorm\n\n LayerNorm (channels)\n\nSpecial designed layernorm for the seasonal part\n\nsource\n\n\nAutoCorrelationLayer\n\n AutoCorrelationLayer (correlation, hidden_size, n_head, d_keys=None,\n                       d_values=None)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nsource\n\n\nAutoCorrelation\n\n AutoCorrelation (mask_flag=True, factor=1, scale=None,\n                  attention_dropout=0.1, output_attention=False)\n\nAutoCorrelation Mechanism with the following two phases: (1) period-based dependencies discovery (2) time delay aggregation This block can replace the self-attention family mechanism seamlessly."
  },
  {
    "objectID": "models.autoformer.html#autoformer",
    "href": "models.autoformer.html#autoformer",
    "title": "Autoformer",
    "section": "2. Autoformer",
    "text": "2. Autoformer\n\nsource\n\nAutoformer\n\n Autoformer (h:int, input_size:int, stat_exog_list=None,\n             hist_exog_list=None, futr_exog_list=None,\n             exclude_insample_y=False,\n             decoder_input_size_multiplier:float=0.5, hidden_size:int=128,\n             dropout:float=0.05, factor:int=3, n_head:int=4,\n             conv_hidden_size:int=32, activation:str='gelu',\n             encoder_layers:int=2, decoder_layers:int=1,\n             MovingAvg_window:int=25, loss=MAE(), valid_loss=None,\n             max_steps:int=5000, learning_rate:float=0.0001,\n             num_lr_decays:int=-1, early_stop_patience_steps:int=-1,\n             val_check_steps:int=100, batch_size:int=32,\n             valid_batch_size:Optional[int]=None, windows_batch_size=1024,\n             inference_windows_batch_size=1024,\n             start_padding_enabled=False, step_size:int=1,\n             scaler_type:str='identity', random_seed:int=1,\n             num_workers_loader:int=0, drop_last_loader:bool=False,\n             **trainer_kwargs)\n\nAutoformer\nThe Autoformer model tackles the challenge of finding reliable dependencies on intricate temporal patterns of long-horizon forecasting.\nThe architecture has the following distinctive features: - In-built progressive decomposition in trend and seasonal compontents based on a moving average filter. - Auto-Correlation mechanism that discovers the period-based dependencies by calculating the autocorrelation and aggregating similar sub-series based on the periodicity. - Classic encoder-decoder proposed by Vaswani et al. (2017) with a multi-head attention mechanism.\nThe Autoformer model utilizes a three-component approach to define its embedding: - It employs encoded autoregressive features obtained from a convolution network. - Absolute positional embeddings obtained from calendar features are utilized.\nParameters: h: int, forecast horizon. input_size: int, maximum sequence length for truncated train backpropagation. Default -1 uses all history. futr_exog_list: str list, future exogenous columns. hist_exog_list: str list, historic exogenous columns. stat_exog_list: str list, static exogenous columns. exclude_insample_y: bool=False, the model skips the autoregressive features y[t-input_size:t] if True. decoder_input_size_multiplier: float = 0.5, . hidden_size: int=128, units of embeddings and encoders. n_head: int=4, controls number of multi-head’s attention. dropout: float (0, 1), dropout throughout Autoformer architecture. factor: int=3, Probsparse attention factor. conv_hidden_size: int=32, channels of the convolutional encoder. activation: str=GELU, activation from [‘ReLU’, ‘Softplus’, ‘Tanh’, ‘SELU’, ‘LeakyReLU’, ‘PReLU’, ‘Sigmoid’, ‘GELU’]. encoder_layers: int=2, number of layers for the TCN encoder. decoder_layers: int=1, number of layers for the MLP decoder. distil: bool = True, wether the Autoformer decoder uses bottlenecks. loss: PyTorch module, instantiated train loss class from losses collection. max_steps: int=1000, maximum number of training steps. learning_rate: float=1e-3, Learning rate between (0, 1). num_lr_decays: int=-1, Number of learning rate decays, evenly distributed across max_steps. early_stop_patience_steps: int=-1, Number of validation iterations before early stopping. val_check_steps: int=100, Number of training steps between every validation loss check. batch_size: int=32, number of different series in each batch. valid_batch_size: int=None, number of different series in each validation and test batch, if None uses batch_size. windows_batch_size: int=1024, number of windows to sample in each training batch, default uses all. inference_windows_batch_size: int=1024, number of windows to sample in each inference batch. start_padding_enabled: bool=False, if True, the model will pad the time series with zeros at the beginning, by input size. scaler_type: str=‘robust’, type of scaler for temporal inputs normalization see temporal scalers. random_seed: int=1, random_seed for pytorch initializer and numpy generators. num_workers_loader: int=os.cpu_count(), workers to be used by TimeSeriesDataLoader. drop_last_loader: bool=False, if True TimeSeriesDataLoader drops last non-full batch. alias: str, optional, Custom name of the model. **trainer_kwargs: int, keyword trainer arguments inherited from PyTorch Lighning’s trainer.\n*References*&lt;br&gt;\n- [Wu, Haixu, Jiehui Xu, Jianmin Wang, and Mingsheng Long. \"Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting\"](https://proceedings.neurips.cc/paper/2021/hash/bcc0d400288793e8bdcd7c19a8ac0c2b-Abstract.html)&lt;br&gt;\n\n\n\nAutoformer.fit\n\n Autoformer.fit (dataset, val_size=0, test_size=0, random_seed=None)\n\nFit.\nThe fit method, optimizes the neural network’s weights using the initialization parameters (learning_rate, windows_batch_size, …) and the loss function as defined during the initialization. Within fit we use a PyTorch Lightning Trainer that inherits the initialization’s self.trainer_kwargs, to customize its inputs, see PL’s trainer arguments.\nThe method is designed to be compatible with SKLearn-like classes and in particular to be compatible with the StatsForecast library.\nBy default the model is not saving training checkpoints to protect disk memory, to get them change enable_checkpointing=True in __init__.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset, see documentation. val_size: int, validation size for temporal cross-validation. random_seed: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__’s. test_size: int, test size for temporal cross-validation.\n\n\n\nAutoformer.predict\n\n Autoformer.predict (dataset, test_size=None, step_size=1,\n                     random_seed=None, **data_module_kwargs)\n\nPredict.\nNeural network prediction with PL’s Trainer execution of predict_step.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset, see documentation. test_size: int=None, test size for temporal cross-validation. step_size: int=1, Step size between each window. random_seed: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__’s. **data_module_kwargs: PL’s TimeSeriesDataModule args, see documentation."
  },
  {
    "objectID": "models.autoformer.html#usage-example",
    "href": "models.autoformer.html#usage-example",
    "title": "Autoformer",
    "section": "Usage Example",
    "text": "Usage Example\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import MLP\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss\nfrom neuralforecast.tsdataset import TimeSeriesDataset\nfrom neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic, augment_calendar_df\n\nAirPassengersPanel, calendar_cols = augment_calendar_df(df=AirPassengersPanel, freq='M')\n\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]] # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nmodel = Autoformer(h=12,\n                 input_size=24,\n                 hidden_size = 16,\n                 conv_hidden_size = 32,\n                 n_head=2,\n                 loss=MAE(),\n                 futr_exog_list=calendar_cols,\n                 scaler_type='robust',\n                 learning_rate=1e-3,\n                 max_steps=300,\n                 val_check_steps=50,\n                 early_stop_patience_steps=2)\n\nnf = NeuralForecast(\n    models=[model],\n    freq='M'\n)\nnf.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\nforecasts = nf.predict(futr_df=Y_test_df)\n\nY_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nif model.loss.is_distribution_output:\n    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n    plt.plot(plot_df['ds'], plot_df['Autoformer-median'], c='blue', label='median')\n    plt.fill_between(x=plot_df['ds'][-12:], \n                    y1=plot_df['Autoformer-lo-90'][-12:].values, \n                    y2=plot_df['Autoformer-hi-90'][-12:].values,\n                    alpha=0.4, label='level 90')\n    plt.grid()\n    plt.legend()\n    plt.plot()\nelse:\n    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n    plt.plot(plot_df['ds'], plot_df['Autoformer'], c='blue', label='Forecast')\n    plt.legend()\n    plt.grid()"
  },
  {
    "objectID": "models.patchtst.html",
    "href": "models.patchtst.html",
    "title": "PatchTST",
    "section": "",
    "text": "The PatchTST model is an efficient Transformer-based model for multivariate time series forecasting.\nIt is based on two key components: - segmentation of time series into windows (patches) which are served as input tokens to Transformer - channel-independence. where each channel contains a single univariate time series.\nReferences - Nie, Y., Nguyen, N. H., Sinthong, P., & Kalagnanam, J. (2022). “A Time Series is Worth 64 Words: Long-term Forecasting with Transformers”\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.patchtst.html#backbone",
    "href": "models.patchtst.html#backbone",
    "title": "PatchTST",
    "section": "1. Backbone",
    "text": "1. Backbone\n\nAuxiliary Functions\n\nsource\n\n\nget_activation_fn\n\n get_activation_fn (activation)\n\n\nsource\n\n\nTranspose\n\n Transpose (*dims, contiguous=False)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\n\nPositional Encoding\n\nsource\n\n\npositional_encoding\n\n positional_encoding (pe, learn_pe, q_len, hidden_size)\n\n\nsource\n\n\nCoord1dPosEncoding\n\n Coord1dPosEncoding (q_len, exponential=False, normalize=True)\n\n\nsource\n\n\nCoord2dPosEncoding\n\n Coord2dPosEncoding (q_len, hidden_size, exponential=False,\n                     normalize=True, eps=0.001)\n\n\nsource\n\n\nPositionalEncoding\n\n PositionalEncoding (q_len, hidden_size, normalize=True)\n\n\n\nRevIN\n\nsource\n\n\nRevIN\n\n RevIN (num_features:int, eps=1e-05, affine=True, subtract_last=False)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\n\nEncoder\n\nsource\n\n\nTSTEncoderLayer\n\n TSTEncoderLayer (q_len, hidden_size, n_heads, d_k=None, d_v=None,\n                  linear_hidden_size=256, store_attn=False,\n                  norm='BatchNorm', attn_dropout=0, dropout=0.0,\n                  bias=True, activation='gelu', res_attention=False,\n                  pre_norm=False)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nsource\n\n\nTSTEncoder\n\n TSTEncoder (q_len, hidden_size, n_heads, d_k=None, d_v=None,\n             linear_hidden_size=None, norm='BatchNorm', attn_dropout=0.0,\n             dropout=0.0, activation='gelu', res_attention=False,\n             n_layers=1, pre_norm=False, store_attn=False)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nsource\n\n\nTSTiEncoder\n\n TSTiEncoder (c_in, patch_num, patch_len, max_seq_len=1024, n_layers=3,\n              hidden_size=128, n_heads=16, d_k=None, d_v=None,\n              linear_hidden_size=256, norm='BatchNorm', attn_dropout=0.0,\n              dropout=0.0, act='gelu', store_attn=False,\n              key_padding_mask='auto', padding_var=None, attn_mask=None,\n              res_attention=True, pre_norm=False, pe='zeros',\n              learn_pe=True)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nsource\n\n\nFlatten_Head\n\n Flatten_Head (individual, n_vars, nf, h, c_out, head_dropout=0)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nsource\n\n\nPatchTST_backbone\n\n PatchTST_backbone (c_in:int, c_out:int, input_size:int, h:int,\n                    patch_len:int, stride:int,\n                    max_seq_len:Optional[int]=1024, n_layers:int=3,\n                    hidden_size=128, n_heads=16, d_k:Optional[int]=None,\n                    d_v:Optional[int]=None, linear_hidden_size:int=256,\n                    norm:str='BatchNorm', attn_dropout:float=0.0,\n                    dropout:float=0.0, act:str='gelu',\n                    key_padding_mask:str='auto',\n                    padding_var:Optional[int]=None,\n                    attn_mask:Optional[torch.Tensor]=None,\n                    res_attention:bool=True, pre_norm:bool=False,\n                    store_attn:bool=False, pe:str='zeros',\n                    learn_pe:bool=True, fc_dropout:float=0.0,\n                    head_dropout=0, padding_patch=None,\n                    pretrain_head:bool=False, head_type='flatten',\n                    individual=False, revin=True, affine=True,\n                    subtract_last=False)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool"
  },
  {
    "objectID": "models.patchtst.html#model",
    "href": "models.patchtst.html#model",
    "title": "PatchTST",
    "section": "2. Model",
    "text": "2. Model\n\nsource\n\nPatchTST\n\n PatchTST (h, input_size, stat_exog_list=None, hist_exog_list=None,\n           futr_exog_list=None, exclude_insample_y=False,\n           encoder_layers:int=3, n_heads:int=16, hidden_size:int=128,\n           linear_hidden_size:int=256, dropout:float=0.2,\n           fc_dropout:float=0.2, head_dropout:float=0.0,\n           attn_dropout:float=0.0, patch_len:int=16, stride:int=8,\n           revin:bool=True, revin_affine:bool=False,\n           revin_subtract_last:bool=True, activation:str='gelu',\n           res_attention:bool=True, batch_normalization:bool=False,\n           learn_pos_embed:bool=True, loss=MAE(), valid_loss=None,\n           max_steps:int=5000, learning_rate:float=0.0001,\n           num_lr_decays:int=-1, early_stop_patience_steps:int=-1,\n           val_check_steps:int=100, batch_size:int=32,\n           valid_batch_size:Optional[int]=None, windows_batch_size=1024,\n           inference_windows_batch_size:int=1024,\n           start_padding_enabled=False, step_size:int=1,\n           scaler_type:str='identity', random_seed:int=1,\n           num_workers_loader:int=0, drop_last_loader:bool=False,\n           **trainer_kwargs)\n\nPatchTST\nThe PatchTST model is an efficient Transformer-based model for multivariate time series forecasting.\nIt is based on two key components: - segmentation of time series into windows (patches) which are served as input tokens to Transformer - channel-independence, where each channel contains a single univariate time series.\nParameters: h: int, Forecast horizon.  input_size: int, autorregresive inputs size, y=[1,2,3,4] input_size=2 -&gt; y_[t-2:t]=[1,2]. stat_exog_list: str list, static exogenous columns. hist_exog_list: str list, historic exogenous columns. futr_exog_list: str list, future exogenous columns. exclude_insample_y: bool=False, the model skips the autoregressive features y[t-input_size:t] if True. encoder_layers: int, number of layers for encoder. n_heads: int=16, number of multi-head’s attention. hidden_size: int=128, units of embeddings and encoders. linear_hidden_size: int=256, units of linear layer. dropout: float=0.1, dropout rate for residual connection. fc_dropout: float=0.1, dropout rate for linear layer. head_dropout: float=0.1, dropout rate for Flatten head layer. attn_dropout: float=0.1, dropout rate for attention layer. patch_len: int=32, length of patch. stride: int=16, stride of patch. revin: bool=True, bool to use RevIn. revin_affine: bool=False, bool to use affine in RevIn. revin_substract_last: bool=False, bool to use substract last in RevIn. activation: str=‘ReLU’, activation from [‘gelu’,‘relu’]. res_attention: bool=False, bool to use residual attention. batch_normalization: bool=False, bool to use batch normalization. learn_pos_embedding: bool=True, bool to learn positional embedding. loss: PyTorch module, instantiated train loss class from losses collection. valid_loss: PyTorch module=loss, instantiated valid loss class from losses collection. max_steps: int=1000, maximum number of training steps. learning_rate: float=1e-3, Learning rate between (0, 1). num_lr_decays: int=-1, Number of learning rate decays, evenly distributed across max_steps. early_stop_patience_steps: int=-1, Number of validation iterations before early stopping. val_check_steps: int=100, Number of training steps between every validation loss check. batch_size: int=32, number of different series in each batch. valid_batch_size: int=None, number of different series in each validation and test batch, if None uses batch_size. windows_batch_size: int=1024, number of windows to sample in each training batch, default uses all. inference_windows_batch_size: int=1024, number of windows to sample in each inference batch. start_padding_enabled: bool=False, if True, the model will pad the time series with zeros at the beginning, by input size. step_size: int=1, step size between each window of temporal data. scaler_type: str=‘identity’, type of scaler for temporal inputs normalization see temporal scalers. random_seed: int, random_seed for pytorch initializer and numpy generators. num_workers_loader: int=os.cpu_count(), workers to be used by TimeSeriesDataLoader. drop_last_loader: bool=False, if True TimeSeriesDataLoader drops last non-full batch. alias: str, optional, Custom name of the model. **trainer_kwargs: int, keyword trainer arguments inherited from PyTorch Lighning’s trainer.\nReferences: -Nie, Y., Nguyen, N. H., Sinthong, P., & Kalagnanam, J. (2022). “A Time Series is Worth 64 Words: Long-term Forecasting with Transformers”\n\n\n\nPatchTST.fit\n\n PatchTST.fit (dataset, val_size=0, test_size=0, random_seed=None)\n\nFit.\nThe fit method, optimizes the neural network’s weights using the initialization parameters (learning_rate, windows_batch_size, …) and the loss function as defined during the initialization. Within fit we use a PyTorch Lightning Trainer that inherits the initialization’s self.trainer_kwargs, to customize its inputs, see PL’s trainer arguments.\nThe method is designed to be compatible with SKLearn-like classes and in particular to be compatible with the StatsForecast library.\nBy default the model is not saving training checkpoints to protect disk memory, to get them change enable_checkpointing=True in __init__.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset, see documentation. val_size: int, validation size for temporal cross-validation. random_seed: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__’s. test_size: int, test size for temporal cross-validation.\n\n\n\nPatchTST.predict\n\n PatchTST.predict (dataset, test_size=None, step_size=1, random_seed=None,\n                   **data_module_kwargs)\n\nPredict.\nNeural network prediction with PL’s Trainer execution of predict_step.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset, see documentation. test_size: int=None, test size for temporal cross-validation. step_size: int=1, Step size between each window. random_seed: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__’s. **data_module_kwargs: PL’s TimeSeriesDataModule args, see documentation."
  },
  {
    "objectID": "models.patchtst.html#usage-example",
    "href": "models.patchtst.html#usage-example",
    "title": "PatchTST",
    "section": "Usage example",
    "text": "Usage example\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import MLP\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss\nfrom neuralforecast.tsdataset import TimeSeriesDataset\nfrom neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic, augment_calendar_df\n\nAirPassengersPanel, calendar_cols = augment_calendar_df(df=AirPassengersPanel, freq='M')\n\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]] # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nmodel = PatchTST(h=12,\n                 input_size=104,\n                 patch_len=24,\n                 stride=24,\n                 revin=False,\n                 hidden_size=16,\n                 n_heads=4,\n                 scaler_type='robust',\n                 loss=DistributionLoss(distribution='StudentT', level=[80, 90]),\n                 #loss=MAE(),\n                 learning_rate=1e-3,\n                 max_steps=500,\n                 val_check_steps=50,\n                 early_stop_patience_steps=2)\n\nnf = NeuralForecast(\n    models=[model],\n    freq='M'\n)\nnf.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\nforecasts = nf.predict(futr_df=Y_test_df)\n\n\nY_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nif model.loss.is_distribution_output:\n    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n    plt.plot(plot_df['ds'], plot_df['PatchTST-median'], c='blue', label='median')\n    plt.fill_between(x=plot_df['ds'][-12:], \n                    y1=plot_df['PatchTST-lo-90'][-12:].values, \n                    y2=plot_df['PatchTST-hi-90'][-12:].values,\n                    alpha=0.4, label='level 90')\n    plt.grid()\n    plt.legend()\n    plt.plot()\nelse:\n    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n    plt.plot(plot_df['ds'], plot_df['PatchTST'], c='blue', label='Forecast')\n    plt.legend()\n    plt.grid()\n\n\nY_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nif model.loss.is_distribution_output:\n    plot_df = plot_df[plot_df.unique_id=='Airline2'].drop('unique_id', axis=1)\n    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n    plt.plot(plot_df['ds'], plot_df['PatchTST-median'], c='blue', label='median')\n    plt.fill_between(x=plot_df['ds'][-12:], \n                    y1=plot_df['PatchTST-lo-90'][-12:].values, \n                    y2=plot_df['PatchTST-hi-90'][-12:].values,\n                    alpha=0.4, label='level 90')\n    plt.grid()\n    plt.legend()\n    plt.plot()\nelse:\n    plot_df = plot_df[plot_df.unique_id=='Airline2'].drop('unique_id', axis=1)\n    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n    plt.plot(plot_df['ds'], plot_df['PatchTST'], c='blue', label='Forecast')\n    plt.legend()\n    plt.grid()"
  },
  {
    "objectID": "examples/hierarchicalnetworks.html",
    "href": "examples/hierarchicalnetworks.html",
    "title": "Hierarchical Forecast",
    "section": "",
    "text": "This notebook offers a step by step guide to create a hierarchical forecasting pipeline.\nIn the pipeline we will use NeuralForecast and HINT class, to create fit, predict and reconcile forecasts.\nWe will use the TourismL dataset that summarizes large Australian national visitor survey.\nOutline 1. Installing packages 2. Load hierarchical dataset 3. Fit and Predict HINT 4. Forecast Evaluation\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/hierarchicalnetworks.html#installing-packages",
    "href": "examples/hierarchicalnetworks.html#installing-packages",
    "title": "Hierarchical Forecast",
    "section": "1. Installing packages",
    "text": "1. Installing packages\n\n!pip install datasetsforecast hierarchicalforecast\n!pip install git+https://github.com/Nixtla/neuralforecast.git"
  },
  {
    "objectID": "examples/hierarchicalnetworks.html#load-hierarchical-dataset",
    "href": "examples/hierarchicalnetworks.html#load-hierarchical-dataset",
    "title": "Hierarchical Forecast",
    "section": "2. Load hierarchical dataset",
    "text": "2. Load hierarchical dataset\nThis detailed Australian Tourism Dataset comes from the National Visitor Survey, managed by the Tourism Research Australia, it is composed of 555 monthly series from 1998 to 2016, it is organized geographically, and purpose of travel. The natural geographical hierarchy comprises seven states, divided further in 27 zones and 76 regions. The purpose of travel categories are holiday, visiting friends and relatives (VFR), business and other. The MinT (Wickramasuriya et al., 2019), among other hierarchical forecasting studies has used the dataset it in the past. The dataset can be accessed in the MinT reconciliation webpage, although other sources are available.\n\n\n\n\n\n\n\n\n\nGeographical Division\nNumber of series per division\nNumber of series per purpose\nTotal\n\n\n\n\nAustralia\n1\n4\n5\n\n\nStates\n7\n28\n35\n\n\nZones\n27\n108\n135\n\n\nRegions\n76\n304\n380\n\n\nTotal\n111\n444\n555\n\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom datasetsforecast.hierarchical import HierarchicalData\nfrom hierarchicalforecast.utils import aggregate, HierarchicalPlot\n\nfrom neuralforecast.utils import augment_calendar_df\n\ndef sort_df_hier(Y_df, S):\n    # NeuralForecast core, sorts unique_id lexicographically\n    # by default, this method matches S_df and Y_hat_df hierarchical order.\n    Y_df.unique_id = Y_df.unique_id.astype('category')\n    Y_df.unique_id = Y_df.unique_id.cat.set_categories(S.index)\n    Y_df = Y_df.sort_values(by=['unique_id', 'ds'])\n    return Y_df\n\n# Load hierarchical dataset\nY_df, S_df, tags = HierarchicalData.load('./data', 'TourismLarge')\nY_df['ds'] = pd.to_datetime(Y_df['ds'])\nY_df = sort_df_hier(Y_df, S_df)\n\nY_df, _ = augment_calendar_df(df=Y_df, freq='M')\n\nMathematically a hierarchical multivariate time series can be denoted by the vector \\(\\mathbf{y}_{[a,b],t}\\) defined by the following aggregation constraint:\n\\[\n\\mathbf{y}_{[a,b],t}  = \\mathbf{S}_{[a,b][b]} \\mathbf{y}_{[b],t} \\quad \\Leftrightarrow \\quad\n\\begin{bmatrix}\\mathbf{y}_{[a],t}\n\\\\ %\\hline\n\\mathbf{y}_{[b],t}\\end{bmatrix}\n= \\begin{bmatrix}\n\\mathbf{A}_{[a][b]}\\\\ %\\hline\n\\mathbf{I}_{[b][b]}\n\\end{bmatrix}\n\\mathbf{y}_{[b],t}\n\\]\nwhere \\(\\mathbf{y}_{[a],t}\\) are the aggregate series, \\(\\mathbf{y}_{[b],t}\\) are the bottom level series and \\(\\mathbf{S}_{[a,b][b]}\\) are the hierarchical aggregation constraints.\n\n# Here we plot the hierarchical constraints matrix\nhplot = HierarchicalPlot(S=S_df, tags=tags)\nhplot.plot_summing_matrix()\n\n\n\n\n\n# Here we plot the top most series from the dataset\n# that corresponds to the total tourist monthly visits to Australia\nplt.figure(figsize=(10,5))\nplt.plot(Y_df[Y_df['unique_id']=='TotalAll']['ds'], \n         Y_df[Y_df['unique_id']=='TotalAll']['y'], label='target')\nplt.plot(Y_df[Y_df['unique_id']=='TotalAll']['ds'], \n         Y_df[Y_df['unique_id']=='TotalAll']['month']*80000, label='month dummy')\nplt.xlabel('Date')\nplt.ylabel('Tourist Visits')\nplt.legend()\nplt.grid()\nplt.show()\nplt.close()"
  },
  {
    "objectID": "examples/hierarchicalnetworks.html#fit-and-predict-hint",
    "href": "examples/hierarchicalnetworks.html#fit-and-predict-hint",
    "title": "Hierarchical Forecast",
    "section": "3. Fit and Predict HINT",
    "text": "3. Fit and Predict HINT\nThe Hierarchical Forecast Network (HINT) combines into an easy to use model three components: 1. SoTA neural forecast model. 2. An efficient and flexible multivariate probability distribution. 3. Builtin reconciliation capabilities.\n\nimport numpy as np\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import NBEATSx, NHITS, HINT\nfrom neuralforecast.losses.pytorch import GMM, PMM, DistributionLoss, sCRPS\n\n\n# Train test splits\nhorizon = 12\nY_test_df  = Y_df.groupby('unique_id').tail(horizon)\nY_train_df = Y_df.drop(Y_test_df.index)\nY_test_df  = Y_test_df.set_index('unique_id')\nY_train_df = Y_train_df.set_index('unique_id')\n\n\n# Horizon and quantiles\nlevel = np.arange(0, 100, 2)\nqs = [[50-lv/2, 50+lv/2] if lv!=0 else [50] for lv in level]\nquantiles = np.sort(np.concatenate(qs)/100)\n\n# HINT := BaseNetwork + Distribution + Reconciliation\nnhits = NHITS(h=horizon,\n              input_size=24,\n              loss=GMM(n_components=10, quantiles=quantiles),\n              hist_exog_list=['month'],\n              max_steps=2000,\n              early_stop_patience_steps=10,\n              val_check_steps=50,\n              scaler_type='robust',\n              learning_rate=1e-3,\n              valid_loss=sCRPS(quantiles=quantiles))\n\nmodel = HINT(h=horizon, S=S_df.values,\n             model=nhits,  reconciliation='BottomUp')\n\nINFO:lightning_fabric.utilities.seed:Global seed set to 1\n\n\n\nY_df['y'] = Y_df['y'] * (Y_df['y'] &gt; 0)\nnf = NeuralForecast(models=[model], freq='MS')\n# Y_hat_df = nf.cross_validation(df=Y_df, val_size=12, n_windows=1)\nnf.fit(df=Y_train_df, val_size=12)\nY_hat_df = nf.predict()\n\n\nunique_id = 'TotalAll'\nY_plot_df = Y_df[Y_df.unique_id==unique_id].tail(12*5)\nY_hat_df = Y_hat_df.reset_index()\nplot_df = Y_hat_df[Y_hat_df.unique_id==unique_id]\nplot_df = Y_plot_df.merge(plot_df, on=['unique_id', 'ds'], how='left')\n\nplt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\nplt.plot(plot_df['ds'], plot_df['HINT-median'], c='blue', label='median')\nplt.fill_between(x=plot_df['ds'][-12:],\n                 y1=plot_df['HINT-lo-90.0'][-12:].values,\n                 y2=plot_df['HINT-hi-90.0'][-12:].values,\n                 alpha=0.4, label='level 90')\nplt.legend()\nplt.grid()\nplt.plot()\n\n[]"
  },
  {
    "objectID": "examples/hierarchicalnetworks.html#forecast-evaluation",
    "href": "examples/hierarchicalnetworks.html#forecast-evaluation",
    "title": "Hierarchical Forecast",
    "section": "4. Forecast Evaluation",
    "text": "4. Forecast Evaluation\nTo evaluate the coherent probabilistic predictions we use the scaled Continuous Ranked Probability Score (sCRPS), defined as follows:\n\\[\n\\mathrm{CRPS}(\\hat{F}_{[a,b],\\tau},\\mathbf{y}_{[a,b],\\tau}) =\n    \\frac{2}{N_{a}+N_{b}} \\sum_{i} \\int^{1}_{0} \\mathrm{QL}(\\hat{F}_{i,\\tau}, y_{i,\\tau})_{q} dq\n\\]\n\\[\n\\mathrm{sCRPS}(\\hat{F}_{[a,b\\,],\\tau},\\mathbf{y}_{[a,b\\,],\\tau}) =\n    \\frac{\\mathrm{CRPS}(\\hat{F}_{[a,b\\,],\\tau},\\mathbf{y}_{[a,b\\,],\\tau})}{\\sum_{i} | y_{i,\\tau} |}\n\\]\nAs you can see the HINT model efficiently achieves state of the art accuracy under minimal tuning.\n\nfrom hierarchicalforecast.evaluation import scaled_crps    \n    \ndef _get_hierarchical_scrps(hier_idxs, Y, Yq_hat, quantiles):\n    # We use the indexes obtained from the aggregation tags\n    # to compute scaled CRPS across the hierarchy levels \n    scrps_list = []\n    for idxs in hier_idxs:\n        y      = Y[idxs, :]\n        yq_hat = Yq_hat[idxs, :, :]\n        scrps  = scaled_crps(y, yq_hat, quantiles)\n        scrps_list.append(scrps)\n    return scrps_list\n\nhier_idxs = [np.arange(len(S_df))] +\\\n    [S_df.index.get_indexer(tags[level]) for level in list(tags.keys())]\n\n\nn_series = len(S_df)\nn_quantiles = len(quantiles)\n\n# Bootstrap predictions\nn_samples = 5\nY_hat_df_list = [nf.predict() for _ in range(n_samples)]\n\n# Parse y_test and y_rec\n# Keep only quantile columns from Y_hat_df\n# Removing mean and median default outputs\nmodel_name = type(model).__name__\nquantile_columns = [model_name + n for n in nhits.loss.output_names]\nquantile_columns.remove(model_name)\nYq_hat = []\nfor sample_idx in range(n_samples):\n    Y_hat = Y_hat_df_list[sample_idx][quantile_columns].values\n    Yq_hat.append(Y_hat.reshape(1, n_series, horizon, n_quantiles))\n\nYq_hat = np.concatenate(Yq_hat, axis=0)\nY_test = Y_test_df['y'].values.reshape(n_series, horizon)\n\n\nprint('Y_test.shape [n_series, horizon]', Y_test.shape)\nprint('Yq_hat.shape [n_samples, n_series, horizon, n_quantiles]', Yq_hat.shape)\n\n# Compute bootstraped sCRPS\nscrps_hint = [_get_hierarchical_scrps(hier_idxs, Y_test, Yq_hat[sample_idx], quantiles) \\\n              for sample_idx in range(n_samples)]\ncrps_mean = np.mean(np.array(scrps_hint), axis=0)\ncrps_std = np.std(np.array(scrps_hint), axis=0)\nscrps_hint = [f'{crps_mean[level_idx]:.4f}±{(1.96 * crps_std[level_idx]):.4f}' \\\n              for level_idx in range(len(crps_mean))]\n\n# Add reported baselines' performance\nlevels = ['Overall', 'Country', 'State', 'Zone', 'Region',\n          'Country/Purpose', 'State/Purpose', 'Zone/Purpose', 'Region/Purpose']\nscrps_dpmn = [\"0.1249±0.0020\",\"0.0431±0.0042\",\"0.0637±0.0032\",\"0.1084±0.0033\",\n              \"0.1554±0.0025\",\"0.0700±0.0038\",\"0.1070±0.0023\",\"0.1887±0.0032\",\"0.2629±0.0034\"]\nscrps_hiere2e = [\"0.1472±0.0029\",\"0.0842±0.0051\",\"0.1012±0.0029\",\"0.1317±0.0022\",\n              \"0.1705±0.0023\",\"0.0995±0.0061\",\"0.1336±0.0042\",\"0.1955±0.0025\",\"0.2615±0.0016\"]\nscrps_arima_mintrace = [\"0.1313±0.0009\",\"0.0471±0.0018\",\"0.0723±0.0011\",\"0.1143±0.0007\",\n              \"0.1591±0.0006\",\"0.0723±0.0014\",\"0.1243±0.0014\",\"0.1919±0.0008\",\"0.2694±0.0006\"]\nscrps_arima_bu = [\"0.1375±0.0013\",\"0.0622±0.0026\",\"0.0820±0.0019\",\"0.1207±0.0010\",\n              \"0.1646±0.0007\",\"0.0788±0.0018\",\"0.1268±0.0017\",\"0.1949±0.0010\",\"0.2698±0.0008\"]\nscrps_arima = [\"0.1416\",\"0.0263\",\"0.0904\",\"0.1389\",\"0.1878\",\"0.0770\",\"0.1270\",\"0.2022\",\"0.2834\"]\n\nscrps_results = dict(Levels=levels,\n                     HINT=scrps_hint, \n                     DPMN=scrps_dpmn,\n                     HierE2E=scrps_hiere2e, \n                     ARIMA_MinTrace_B=scrps_arima_mintrace,\n                     ARIMA_BottomUp_B=scrps_arima_bu,\n                     ARIMA=scrps_arima)\nscrps_results = pd.DataFrame(scrps_results)\nscrps_results\n\nY_test.shape [n_series, horizon] (555, 12)\nYq_hat.shape [n_samples, n_series, horizon, n_quantiles] (5, 555, 12, 99)\n\n\n\n  \n    \n      \n\n\n\n\n\n\nLevels\nHINT\nDPMN\nHierE2E\nARIMA_MinTrace_B\nARIMA_BottomUp_B\nARIMA\n\n\n\n\n0\nOverall\n0.1178±0.0002\n0.1249±0.0020\n0.1472±0.0029\n0.1313±0.0009\n0.1375±0.0013\n0.1416\n\n\n1\nCountry\n0.0288±0.0007\n0.0431±0.0042\n0.0842±0.0051\n0.0471±0.0018\n0.0622±0.0026\n0.0263\n\n\n2\nState\n0.0593±0.0004\n0.0637±0.0032\n0.1012±0.0029\n0.0723±0.0011\n0.0820±0.0019\n0.0904\n\n\n3\nZone\n0.1023±0.0003\n0.1084±0.0033\n0.1317±0.0022\n0.1143±0.0007\n0.1207±0.0010\n0.1389\n\n\n4\nRegion\n0.1451±0.0004\n0.1554±0.0025\n0.1705±0.0023\n0.1591±0.0006\n0.1646±0.0007\n0.1878\n\n\n5\nCountry/Purpose\n0.0752±0.0006\n0.0700±0.0038\n0.0995±0.0061\n0.0723±0.0014\n0.0788±0.0018\n0.0770\n\n\n6\nState/Purpose\n0.1109±0.0001\n0.1070±0.0023\n0.1336±0.0042\n0.1243±0.0014\n0.1268±0.0017\n0.1270\n\n\n7\nZone/Purpose\n0.1773±0.0003\n0.1887±0.0032\n0.1955±0.0025\n0.1919±0.0008\n0.1949±0.0010\n0.2022\n\n\n8\nRegion/Purpose\n0.2438±0.0002\n0.2629±0.0034\n0.2615±0.0016\n0.2694±0.0006\n0.2698±0.0008\n0.2834"
  },
  {
    "objectID": "examples/hierarchicalnetworks.html#references",
    "href": "examples/hierarchicalnetworks.html#references",
    "title": "Hierarchical Forecast",
    "section": "References",
    "text": "References\n\nKin G. Olivares, David Luo, Cristian Challu, Stefania La Vattiata, Max Mergenthaler, Artur Dubrawski (2023). “HINT: Hierarchical Mixture Networks For Coherent Probabilistic Forecasting”. International Conference on Machine Learning (ICML). Workshop on Structured Probabilistic Inference & Generative Modeling. Available at https://arxiv.org/abs/2305.07089.\nKin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker (2023).”Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures”. International Journal Forecasting, accepted paper. URL https://arxiv.org/pdf/2110.13179.pdf.\nKin G. Olivares, Federico Garza, David Luo, Cristian Challu, Max Mergenthaler, Souhaib Ben Taieb, Shanika Wickramasuriya, and Artur Dubrawski (2023). “HierarchicalForecast: A reference framework for hierarchical forecasting”. Journal of Machine Learning Research, submitted. URL https://arxiv.org/abs/2207.03517"
  },
  {
    "objectID": "examples/predictinsample.html",
    "href": "examples/predictinsample.html",
    "title": "Predict Insample",
    "section": "",
    "text": "This tutorial provides and example on how to use the predict_insample function of the core class to produce forecasts of the train and validation sets. In this example we will train the NHITS model on the AirPassengers data, and show how to recover the insample predictions after model is fitted.\nPredict Insample: The process of producing forecasts of the train and validation sets.\nUse Cases: * Debugging: producing insample predictions is useful for debugging purposes. For example, to check if the model is able to fit the train set. * Training convergence: check if the the model has converged. * Anomaly detection: insample predictions can be used to detect anomalous behavior in the train set (e.g. outliers). (Note: if a model is too flexible it might be able to perfectly forecast outliers)\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/predictinsample.html#installing-neuralforecast",
    "href": "examples/predictinsample.html#installing-neuralforecast",
    "title": "Predict Insample",
    "section": "1. Installing NeuralForecast",
    "text": "1. Installing NeuralForecast\n\n!pip install neuralforecast"
  },
  {
    "objectID": "examples/predictinsample.html#loading-airpassengers-data",
    "href": "examples/predictinsample.html#loading-airpassengers-data",
    "title": "Predict Insample",
    "section": "2. Loading AirPassengers Data",
    "text": "2. Loading AirPassengers Data\nThe core.NeuralForecast class contains shared, fit, predict and other methods that take as inputs pandas DataFrames with columns ['unique_id', 'ds', 'y'], where unique_id identifies individual time series from the dataset, ds is the date, and y is the target variable.\nIn this example dataset consists of a set of a single series, but you can easily fit your model to larger datasets in long format.\n\nfrom neuralforecast.utils import AirPassengersDF\n\n\nY_df = AirPassengersDF # Defined in neuralforecast.utils\nY_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\n1.0\n1949-01-31\n112.0\n\n\n1\n1.0\n1949-02-28\n118.0\n\n\n2\n1.0\n1949-03-31\n132.0\n\n\n3\n1.0\n1949-04-30\n129.0\n\n\n4\n1.0\n1949-05-31\n121.0"
  },
  {
    "objectID": "examples/predictinsample.html#model-training",
    "href": "examples/predictinsample.html#model-training",
    "title": "Predict Insample",
    "section": "3. Model Training",
    "text": "3. Model Training\nFirst, we train the NHITS models on the AirPassengers data. We will use the fit method of the core class to train the models.\n\nimport pandas as pd\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import NHITS\n\n\nhorizon = 12\n\n# Try different hyperparmeters to improve accuracy.\nmodels = [NHITS(h=horizon,                      # Forecast horizon\n                input_size=2 * horizon,         # Length of input sequence\n                max_steps=1000,                 # Number of steps to train\n                n_freq_downsample=[2, 1, 1],    # Downsampling factors for each stack output\n                mlp_units = 3 * [[1024, 1024]]) # Number of units in each block.\n          ]\nnf = NeuralForecast(models=models, freq='M')\nnf.fit(df=Y_df, val_size=horizon)"
  },
  {
    "objectID": "examples/predictinsample.html#predict-insample",
    "href": "examples/predictinsample.html#predict-insample",
    "title": "Predict Insample",
    "section": "4. Predict Insample",
    "text": "4. Predict Insample\nUsing the NeuralForecast.predict_insample method you can obtain the forecasts for the train and validation sets after the models are fitted. The function will always take the last dataset used for training in either the fit or cross_validation methods.\nWith the step_size parameter you can specify the step size between consecutive windows to produce the forecasts. In this example we will set step_size=horizon to produce non-overlapping forecasts.\nThe following diagram shows how the forecasts are produced based on the step_size parameter and h (horizon) of the model. In the diagram we set step_size=2 and h=4.\n\n\nY_hat_insample = nf.predict_insample(step_size=horizon)\n\nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00, 37.76it/s]\n\n\nThe predict_insample function returns a pandas DataFrame with the following columns: * unique_id: the unique identifier of the time series. * ds: the datestamp of the forecast for each row. * cutoff: the datestamp at which the forecast was made. * y: the actual value of the target variable. * model_name: the forecasted values for the models. In this case, NHITS.\n\nY_hat_insample.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ncutoff\nNHITS\ny\n\n\n\n\n0\n1.0\n1949-01-31\n1948-12-31\n0.204289\n112.0\n\n\n1\n1.0\n1949-02-28\n1948-12-31\n0.302111\n118.0\n\n\n2\n1.0\n1949-03-31\n1948-12-31\n0.399522\n132.0\n\n\n3\n1.0\n1949-04-30\n1948-12-31\n0.429369\n129.0\n\n\n4\n1.0\n1949-05-31\n1948-12-31\n0.518200\n121.0\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe function will produce forecasts from the first timestamp of the time series. For these initial timestamps, the forecasts might not be accurate given that models have very limited input information to produce forecasts."
  },
  {
    "objectID": "examples/predictinsample.html#plot-predictions",
    "href": "examples/predictinsample.html#plot-predictions",
    "title": "Predict Insample",
    "section": "5. Plot Predictions",
    "text": "5. Plot Predictions\nFinally, we plot the forecasts for the train and validation sets.\n\nimport matplotlib.pyplot as plt\n\n\nplt.figure(figsize=(10, 5))\nplt.plot(Y_hat_insample['ds'], Y_hat_insample['y'], label='True')\nplt.plot(Y_hat_insample['ds'], Y_hat_insample['NHITS'], label='Forecast')\nplt.axvline(Y_hat_insample['ds'].iloc[-12], color='black', linestyle='--', label='Train-Test Split')\nplt.xlabel('Timestamp [t]')\nplt.ylabel('Monthly Passengers')\nplt.grid()\nplt.legend()\n\n&lt;matplotlib.legend.Legend&gt;\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nNote how the forecasts for the train set are very accurate, while the forecast in the validation set (last 12 timetamps), are less precise. This is because the model was trained on the train set, and deep learning models such as the NHITS can easily overfit the train set."
  },
  {
    "objectID": "examples/predictinsample.html#references",
    "href": "examples/predictinsample.html#references",
    "title": "Predict Insample",
    "section": "References",
    "text": "References\n\nCristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2021). NHITS: Neural Hierarchical Interpolation for Time Series Forecasting. Accepted at AAAI 2023."
  },
  {
    "objectID": "examples/uncertaintyintervals.html",
    "href": "examples/uncertaintyintervals.html",
    "title": "Probabilistic Forecasts",
    "section": "",
    "text": "Probabilistic forecasting is a natural answer to quantify the uncertainty of target variable’s future. The task requires to model the following conditional predictive distribution:\n\\[\\mathbb{P}(\\mathbf{y}_{t+1:t+H} \\;|\\; \\mathbf{y}_{:t})\\]\nWe will show you how to tackle the task with NeuralForecast by combining a classic Long Short Term Memory Network (LSTM) and the Neural Hierarchical Interpolation (NHITS) with the multi quantile loss function (MQLoss).\n\\[ \\mathrm{MQLoss}(y_{\\tau}, [\\hat{y}^{(q1)}_{\\tau},\\hat{y}^{(q2)}_{\\tau},\\dots,\\hat{y}^{(Q)}_{\\tau}]) = \\frac{1}{H} \\sum_{q} \\mathrm{QL}(y_{\\tau}, \\hat{y}^{(q)}_{\\tau}) \\]\nIn this notebook we will: 1. Install NeuralForecast Library 2. Explore the M4-Hourly data. 3. Train the LSTM and NHITS 4. Visualize the LSTM/NHITS prediction intervals.\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/uncertaintyintervals.html#installing-neuralforecast",
    "href": "examples/uncertaintyintervals.html#installing-neuralforecast",
    "title": "Probabilistic Forecasts",
    "section": "1. Installing NeuralForecast",
    "text": "1. Installing NeuralForecast\n\n!pip install neuralforecast\n\n\nUseful functions\nThe plot_grid auxiliary function defined below will be useful to plot different time series, and different models’ forecasts.\n\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom itertools import product\nimport matplotlib.pyplot as plt\n\ndef plot_grid(df_train, df_test=None, plot_random=True, model=None, level=None):\n    fig, axes = plt.subplots(4, 2, figsize = (24, 14))\n\n    unique_ids = df_train['unique_id'].unique()\n\n    assert len(unique_ids) &gt;= 8, \"Must provide at least 8 ts\"\n    \n    if plot_random:\n        unique_ids = random.sample(list(unique_ids), k=8)\n    else:\n        unique_uids = unique_ids[:8]\n\n    for uid, (idx, idy) in zip(unique_ids, product(range(4), range(2))):\n        train_uid = df_train.query('unique_id == @uid')\n        axes[idx, idy].plot(train_uid['ds'], train_uid['y'], label = 'y_train')\n        if df_test is not None:\n            max_ds = train_uid['ds'].max()\n            test_uid = df_test.query('unique_id == @uid')\n            for col in ['y', f'{model}-median', 'y_test']:\n                if col in test_uid:\n                    axes[idx, idy].plot(test_uid['ds'], test_uid[col], label=col)\n            if level is not None:\n                for l, alpha in zip(sorted(level), [0.5, .4, .35, .2]):\n                    axes[idx, idy].fill_between(\n                        test_uid['ds'], \n                        test_uid[f'{model}-lo-{l}'], \n                        test_uid[f'{model}-hi-{l}'],\n                        alpha=alpha,\n                        color='orange',\n                        label=f'{model}_level_{l}',\n                    )\n        axes[idx, idy].set_title(f'M4 Hourly: {uid}')\n        axes[idx, idy].set_xlabel('Timestamp [t]')\n        axes[idx, idy].set_ylabel('Target')\n        axes[idx, idy].legend(loc='upper left')\n        axes[idx, idy].xaxis.set_major_locator(plt.MaxNLocator(20))\n        axes[idx, idy].grid()\n    fig.subplots_adjust(hspace=0.5)\n    plt.show()"
  },
  {
    "objectID": "examples/uncertaintyintervals.html#loading-m4-data",
    "href": "examples/uncertaintyintervals.html#loading-m4-data",
    "title": "Probabilistic Forecasts",
    "section": "2. Loading M4 Data",
    "text": "2. Loading M4 Data\nFor testing purposes, we will use the Hourly dataset from the M4 competition.\n\n!wget https://auto-arima-results.s3.amazonaws.com/M4-Hourly.csv\n!wget https://auto-arima-results.s3.amazonaws.com/M4-Hourly-test.csv\n\n\nimport pandas as pd\n\n\nY_train_df = pd.read_csv('M4-Hourly.csv')\nY_test_df = pd.read_csv('M4-Hourly-test.csv').rename(columns={'y': 'y_test'})\n\nIn this example we will use a subset of the data to avoid waiting too long. You can modify the number of series if you want.\n\nn_series = 8\nuids = Y_train_df['unique_id'].unique()[:n_series]\nY_train_df = Y_train_df.query('unique_id in @uids')\nY_test_df = Y_test_df.query('unique_id in @uids')\n\n\nplot_grid(Y_train_df, Y_test_df)"
  },
  {
    "objectID": "examples/uncertaintyintervals.html#model-training",
    "href": "examples/uncertaintyintervals.html#model-training",
    "title": "Probabilistic Forecasts",
    "section": "3. Model Training",
    "text": "3. Model Training\nThe core.NeuralForecast provides a high-level interface with our collection of PyTorch models. NeuralForecast is instantiated with a list of models=[LSTM(...), NHITS(...)], configured for the forecasting task.\n\nThe horizon parameter controls the number of steps ahead of the predictions, in this example 48 hours ahead (2 days).\nThe MQLoss with levels=[80,90] specializes the network’s output into the 80% and 90% prediction intervals.\nThe max_steps=2000, controls the duration of the network’s training.\n\nFor more network’s instantiation details check their documentation.\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.losses.pytorch import MQLoss\nfrom neuralforecast.models import LSTM, NHITS\n\n\nhorizon = 48\nlevels = [80, 90]\nmodels = [LSTM(input_size=3*horizon, h=horizon,\n               loss=MQLoss(level=levels), max_steps=1000),\n          NHITS(input_size=7*horizon, h=horizon,\n                n_freq_downsample=[24, 12, 1],\n                loss=MQLoss(level=levels), max_steps=2000),]\nnf = NeuralForecast(models=models, freq='H')\n\nGlobal seed set to 1\nGlobal seed set to 1\n\n\nAll the models of the library are global, meaning that all time series in Y_train_df is used during a shared optimization to train a single model with shared parameters. This is the most common practice in the forecasting literature for deep learning models, and it is known as “cross-learning”.\n\nnf.fit(df=Y_train_df)\n\n\nY_hat_df = nf.predict()\nY_hat_df = Y_hat_df.reset_index()\nY_hat_df.head()\n\nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00,  2.82it/s]\nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00, 136.22it/s]\n\n\n\n\n\n\n\n\n\nunique_id\nds\nLSTM-median\nLSTM-lo-90\nLSTM-lo-80\nLSTM-hi-80\nLSTM-hi-90\nNHITS-median\nNHITS-lo-90\nNHITS-lo-80\nNHITS-hi-80\nNHITS-hi-90\n\n\n\n\n0\nH1\n701\n603.491211\n526.534119\n544.686646\n650.893799\n673.805603\n611.634888\n575.999146\n582.778687\n677.277039\n674.705872\n\n\n1\nH1\n702\n548.415710\n438.868591\n472.805237\n608.017822\n639.063293\n569.997803\n513.014282\n518.707153\n598.849609\n616.793457\n\n\n2\nH1\n703\n502.010681\n382.608643\n411.710419\n570.315308\n608.669250\n510.787628\n454.184448\n465.425232\n538.964172\n554.563354\n\n\n3\nH1\n704\n460.870483\n339.368988\n370.636719\n544.232666\n579.824402\n478.482330\n429.657104\n452.395508\n500.892090\n502.507141\n\n\n4\nH1\n705\n436.451843\n313.868744\n343.514191\n520.812988\n559.734741\n463.763611\n432.906342\n427.853577\n486.854492\n487.539062\n\n\n\n\n\n\n\n\nY_test_df = Y_test_df.merge(Y_hat_df, how='left', on=['unique_id', 'ds'])"
  },
  {
    "objectID": "examples/uncertaintyintervals.html#plotting-predictions",
    "href": "examples/uncertaintyintervals.html#plotting-predictions",
    "title": "Probabilistic Forecasts",
    "section": "4. Plotting Predictions",
    "text": "4. Plotting Predictions\nHere we finalize our analysis by plotting the prediction intervals and verifying that both the LSTM and NHITS are giving excellent results.\nConsider the output [NHITS-lo-90.0, NHITS-hi-90.0], that represents the 80% prediction interval of the NHITS network; its lower limit gives the 5th percentile (or 0.05 quantile) while its upper limit gives the 95th percentile (or 0.95 quantile). For well-trained models we expect that the target values lie within the interval 90% of the time.\n\nLSTM\n\nplot_grid(Y_train_df, Y_test_df, level=levels, model='LSTM')\n\n\n\n\n\n\nNHITS\n\nplot_grid(Y_train_df, Y_test_df, level=levels, model='NHITS')"
  },
  {
    "objectID": "examples/uncertaintyintervals.html#references",
    "href": "examples/uncertaintyintervals.html#references",
    "title": "Probabilistic Forecasts",
    "section": "References",
    "text": "References\n\nRoger Koenker and Gilbert Basset (1978). Regression Quantiles, Econometrica.\nJeffrey L. Elman (1990). “Finding Structure in Time”.\nCristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2021). NHITS: Neural Hierarchical Interpolation for Time Series Forecasting. Accepted at AAAI 2023."
  },
  {
    "objectID": "examples/signal_decomposition.html",
    "href": "examples/signal_decomposition.html",
    "title": "Interpretable Decompositions",
    "section": "",
    "text": "Time series signal decomposition involves breaking down an original time series into its constituent components. By decomposing the time series, we can gain insights into underlying patterns, trends-cycles, and seasonal effects, enabling improved understanding and forecasting accuracy.\nThis notebook will show how to use the NHITS/NBEATSx to extract these series’ components. We will: - Installing NeuralForecast. - Simulate a Harmonic Signal. - NHITS’ forecast decomposition. - NBEATSx’ forecast decomposition.\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/signal_decomposition.html#installing-neuralforecast",
    "href": "examples/signal_decomposition.html#installing-neuralforecast",
    "title": "Interpretable Decompositions",
    "section": "1. Installing NeuralForecast",
    "text": "1. Installing NeuralForecast\n\n!pip install neuralforecast"
  },
  {
    "objectID": "examples/signal_decomposition.html#simulate-a-harmonic-signal",
    "href": "examples/signal_decomposition.html#simulate-a-harmonic-signal",
    "title": "Interpretable Decompositions",
    "section": "2. Simulate a Harmonic Signal",
    "text": "2. Simulate a Harmonic Signal\nIn this example, we will consider a Harmonic signal comprising two frequencies: one low-frequency and one high-frequency.\n\nimport numpy as np\nimport pandas as pd\n\n\nN = 10_000\nT = 1.0 / 800.0 # sample spacing\nx = np.linspace(0.0, N*T, N, endpoint=False)\n\ny1 = np.sin(10.0 * 2.0*np.pi*x) \ny2 = 0.5 * np.sin(100 * 2.0*np.pi*x)\ny = y1 + y2\n\n\nimport matplotlib.pyplot as plt\nplt.rcParams[\"axes.grid\"]=True\n\n\nfig, ax = plt.subplots(figsize=(6, 2.5))\nplt.plot(y[-80:], label='True')\nplt.plot(y1[-80:], label='Low Frequency', alpha=0.4)\nplt.plot(y2[-80:], label='High Frequency', alpha=0.4)\nplt.ylabel('Harmonic Signal')\nplt.xlabel('Time')\nplt.legend()\nplt.show()\nplt.close()\n\n\n\n\n\n# Split dataset into train/test\n# Last horizon observations for test\nhorizon = 96\nY_df = pd.DataFrame(dict(unique_id=1, ds=np.arange(len(x)), y=y))\nY_train_df = Y_df.groupby('unique_id').head(len(Y_df)-horizon).reset_index()\nY_test_df = Y_df.groupby('unique_id').tail(horizon).reset_index()\nY_test_df\n\n\n\n\n\n\n\n\nindex\nunique_id\nds\ny\n\n\n\n\n0\n9904\n1\n9904\n-0.951057\n\n\n1\n9905\n1\n9905\n-0.570326\n\n\n2\n9906\n1\n9906\n-0.391007\n\n\n3\n9907\n1\n9907\n-0.499087\n\n\n4\n9908\n1\n9908\n-0.809017\n\n\n...\n...\n...\n...\n...\n\n\n91\n9995\n1\n9995\n-0.029130\n\n\n92\n9996\n1\n9996\n-0.309017\n\n\n93\n9997\n1\n9997\n-0.586999\n\n\n94\n9998\n1\n9998\n-0.656434\n\n\n95\n9999\n1\n9999\n-0.432012\n\n\n\n\n96 rows × 4 columns"
  },
  {
    "objectID": "examples/signal_decomposition.html#nhits-decomposition",
    "href": "examples/signal_decomposition.html#nhits-decomposition",
    "title": "Interpretable Decompositions",
    "section": "3. NHITS decomposition",
    "text": "3. NHITS decomposition\nWe will employ NHITS stack-specialization to recover the latent harmonic functions.\nNHITS, a Wavelet-inspired algorithm, allows for breaking down a time series into various scales or resolutions, aiding in the identification of localized patterns or features. The expressivity ratios for each layer enable control over the model’s stack specialization.\n\nfrom neuralforecast.models import NHITS, NBEATSx\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.losses.pytorch import HuberLoss, MQLoss\n\n\nmodels = [NHITS(h=horizon,                           # Forecast horizon\n                input_size=2 * horizon,              # Length of input sequence\n                loss=HuberLoss(),                    # Robust Huber Loss\n                max_steps=1000,                      # Number of steps to train\n                dropout_prob_theta=0.5,\n                interpolation_mode='linear',\n                stack_types=['identity']*2,\n                n_blocks=[1, 1],\n                mlp_units=[[64, 64],[64, 64]],\n                n_freq_downsample=[10, 1],           # Inverse expressivity ratios for NHITS' stacks specialization\n                val_check_steps=10,                  # Frequency of validation signal (affects early stopping)\n              )\n          ]\nnf = NeuralForecast(models=models, freq='M')\nnf.fit(df=Y_train_df)\n\nGlobal seed set to 1\n\n\n\nfrom neuralforecast.tsdataset import TimeSeriesDataset\n\n# NHITS decomposition plot\nmodel = nf.models[0]\ndataset, *_ = TimeSeriesDataset.from_df(df = Y_train_df)\ny_hat = model.decompose(dataset=dataset)\n\nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00, 20.68it/s]\n\n\n\nfig, ax = plt.subplots(3, 1, figsize=(6, 7))\n\nax[0].plot(Y_test_df['y'].values, label='True', linewidth=4)\nax[0].plot(y_hat.sum(axis=1).flatten(), label='Forecast', color=\"#7B3841\")\nax[0].legend()\nax[0].set_ylabel('Harmonic Signal')\n\nax[1].plot(y_hat[0,1]+y_hat[0,0], label='stack1', color=\"green\")\nax[1].set_ylabel('NHITS Stack 1')\n\nax[2].plot(y_hat[0,2], label='stack2', color=\"orange\")\nax[2].set_ylabel('NHITS Stack 2')\nax[2].set_xlabel(r'Prediction $\\tau \\in \\{t+1,..., t+H\\}$')\nplt.show()"
  },
  {
    "objectID": "examples/signal_decomposition.html#nbeatsx-decomposition",
    "href": "examples/signal_decomposition.html#nbeatsx-decomposition",
    "title": "Interpretable Decompositions",
    "section": "4. NBEATSx decomposition",
    "text": "4. NBEATSx decomposition\nHere we will employ NBEATSx interpretable basis projection to recover the latent harmonic functions.\nNBEATSx, this network in its interpretable variant sequentially projects the signal into polynomials and harmonic basis to learn trend \\(T\\) and seasonality \\(S\\) components: \\[\\hat{y}_{[t+1:t+H]} = \\theta_{1} T + \\theta_{2} S\\]\nIn contrast to NHITS’ wavelet-like projections the basis heavily determine the behavior of the projections. And the Fourier projections are not capable of being immediately decomposed into individual frequencies.\n\nmodels = [NBEATSx(h=horizon,                           # Forecast horizon\n                  input_size=2 * horizon,              # Length of input sequence\n                  loss=HuberLoss(),                    # Robust Huber Loss\n                  max_steps=1000,                      # Number of steps to train\n                  dropout_prob_theta=0.5,\n                  stack_types=['trend', 'seasonality'], # Harmonic/Trend projection basis\n                  n_polynomials=0,                      # Lower frequencies can be captured by polynomials\n                  n_blocks=[1, 1],\n                  mlp_units=[[64, 64],[64, 64]],\n                  val_check_steps=10,                  # Frequency of validation signal (affects early stopping)\n              )\n          ]\nnf = NeuralForecast(models=models, freq='M')\nnf.fit(df=Y_train_df)\n\nGlobal seed set to 1\n\n\n\n# NBEATSx decomposition plot\nmodel = nf.models[0]\ndataset, *_ = TimeSeriesDataset.from_df(df = Y_train_df)\ny_hat = model.decompose(dataset=dataset)\n\nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00, 112.51it/s]\n\n\n\nfig, ax = plt.subplots(3, 1, figsize=(6, 7))\n\nax[0].plot(Y_test_df['y'].values, label='True', linewidth=4)\nax[0].plot(y_hat.sum(axis=1).flatten(), label='Forecast', color=\"#7B3841\")\nax[0].legend()\nax[0].set_ylabel('Harmonic Signal')\n\nax[1].plot(y_hat[0,1]+y_hat[0,0], label='stack1', color=\"green\")\nax[1].set_ylabel('NBEATSx Trend Stack')\n\nax[2].plot(y_hat[0,2], label='stack2', color=\"orange\")\nax[2].set_ylabel('NBEATSx Seasonality Stack')\nax[2].set_xlabel(r'Prediction $\\tau \\in \\{t+1,..., t+H\\}$')\nplt.show()"
  },
  {
    "objectID": "examples/signal_decomposition.html#references",
    "href": "examples/signal_decomposition.html#references",
    "title": "Interpretable Decompositions",
    "section": "References",
    "text": "References\n\nCristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2023). NHITS: Neural Hierarchical Interpolation for Time Series Forecasting.\nBoris N. Oreshkin, Dmitri Carpov, Nicolas Chapados, Yoshua Bengio (2019). “N-BEATS: Neural basis expansion analysis for interpretable time series forecasting”.\nKin G. Olivares, Cristian Challu, Grzegorz Marcjasz, Rafał Weron, Artur Dubrawski (2021). “Neural basis expansion analysis with exogenous variables: Forecasting electricity prices with NBEATSx”."
  },
  {
    "objectID": "examples/longhorizon_with_nhits.html",
    "href": "examples/longhorizon_with_nhits.html",
    "title": "Long-Horizon Forecast",
    "section": "",
    "text": "Long-horizon forecasting is challenging because of the volatility of the predictions and the computational complexity. To solve this problem we created the NHITS model and made the code available NeuralForecast library. NHITS specializes its partial outputs in the different frequencies of the time series through hierarchical interpolation and multi-rate input processing.\nIn this notebook we show how to use NHITS on the ETTm2 benchmark dataset. This data set includes data points for 2 Electricity Transformers at 2 stations, including load, oil temperature.\nWe will show you how to load data, train, and perform automatic hyperparameter tuning, to achieve SoTA performance, outperforming even the latest Transformer architectures for a fraction of their computational cost (50x faster).\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/longhorizon_with_nhits.html#installing-neuralforecast",
    "href": "examples/longhorizon_with_nhits.html#installing-neuralforecast",
    "title": "Long-Horizon Forecast",
    "section": "1. Installing NeuralForecast",
    "text": "1. Installing NeuralForecast\n\n!pip install neuralforecast datasetsforecast"
  },
  {
    "objectID": "examples/longhorizon_with_nhits.html#load-ettm2-data",
    "href": "examples/longhorizon_with_nhits.html#load-ettm2-data",
    "title": "Long-Horizon Forecast",
    "section": "2. Load ETTm2 Data",
    "text": "2. Load ETTm2 Data\nThe LongHorizon class will automatically download the complete ETTm2 dataset and process it.\nIt return three Dataframes: Y_df contains the values for the target variables, X_df contains exogenous calendar features and S_df contains static features for each time-series (none for ETTm2). For this example we will only use Y_df.\nIf you want to use your own data just replace Y_df. Be sure to use a long format and have a simmilar structure than our data set.\n\nimport pandas as pd\nfrom datasetsforecast.long_horizon import LongHorizon\n\n# Change this to your own data to try the model\nY_df, _, _ = LongHorizon.load(directory='./', group='ETTm2')\nY_df['ds'] = pd.to_datetime(Y_df['ds'])\n\n# For this excercise we are going to take 20% of the DataSet\nn_time = len(Y_df.ds.unique())\nval_size = int(.2 * n_time)\ntest_size = int(.2 * n_time)\n\nY_df.groupby('unique_id').head(2)\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\nHUFL\n2016-07-01 00:00:00\n-0.041413\n\n\n1\nHUFL\n2016-07-01 00:15:00\n-0.185467\n\n\n57600\nHULL\n2016-07-01 00:00:00\n0.040104\n\n\n57601\nHULL\n2016-07-01 00:15:00\n-0.214450\n\n\n115200\nLUFL\n2016-07-01 00:00:00\n0.695804\n\n\n115201\nLUFL\n2016-07-01 00:15:00\n0.434685\n\n\n172800\nLULL\n2016-07-01 00:00:00\n0.434430\n\n\n172801\nLULL\n2016-07-01 00:15:00\n0.428168\n\n\n230400\nMUFL\n2016-07-01 00:00:00\n-0.599211\n\n\n230401\nMUFL\n2016-07-01 00:15:00\n-0.658068\n\n\n288000\nMULL\n2016-07-01 00:00:00\n-0.393536\n\n\n288001\nMULL\n2016-07-01 00:15:00\n-0.659338\n\n\n345600\nOT\n2016-07-01 00:00:00\n1.018032\n\n\n345601\nOT\n2016-07-01 00:15:00\n0.980124\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# We are going to plot the temperature of the transformer \n# and marking the validation and train splits\nu_id = 'HUFL'\nx_plot = pd.to_datetime(Y_df[Y_df.unique_id==u_id].ds)\ny_plot = Y_df[Y_df.unique_id==u_id].y.values\n\nx_val = x_plot[n_time - val_size - test_size]\nx_test = x_plot[n_time - test_size]\n\nfig = plt.figure(figsize=(10, 5))\nfig.tight_layout()\n\nplt.plot(x_plot, y_plot)\nplt.xlabel('Date', fontsize=17)\nplt.ylabel('HUFL [15 min temperature]', fontsize=17)\n\nplt.axvline(x_val, color='black', linestyle='-.')\nplt.axvline(x_test, color='black', linestyle='-.')\nplt.text(x_val, 5, '  Validation', fontsize=12)\nplt.text(x_test, 5, '  Test', fontsize=12)\n\nplt.grid()"
  },
  {
    "objectID": "examples/longhorizon_with_nhits.html#hyperparameter-selection-and-forecasting",
    "href": "examples/longhorizon_with_nhits.html#hyperparameter-selection-and-forecasting",
    "title": "Long-Horizon Forecast",
    "section": "3. Hyperparameter selection and forecasting",
    "text": "3. Hyperparameter selection and forecasting\nThe AutoNHITS class will automatically perform hyperparamter tunning using Tune library, exploring a user-defined or default search space. Models are selected based on the error on a validation set and the best model is then stored and used during inference.\nThe AutoNHITS.default_config attribute contains a suggested hyperparameter space. Here, we specify a different search space following the paper’s hyperparameters. Notice that 1000 Stochastic Gradient Steps are enough to achieve SoTA performance. Feel free to play around with this space.\n\nfrom ray import tune\nfrom neuralforecast.auto import AutoNHITS\nfrom neuralforecast.core import NeuralForecast\n\n\nhorizon = 96 # 24hrs = 4 * 15 min.\n\n# Use your own config or AutoNHITS.default_config\nnhits_config = {\n       \"learning_rate\": tune.choice([1e-3]),                                     # Initial Learning rate\n       \"max_steps\": tune.choice([1000]),                                         # Number of SGD steps\n       \"input_size\": tune.choice([5 * horizon]),                                 # input_size = multiplier * horizon\n       \"batch_size\": tune.choice([7]),                                           # Number of series in windows\n       \"windows_batch_size\": tune.choice([256]),                                 # Number of windows in batch\n       \"n_pool_kernel_size\": tune.choice([[2, 2, 2], [16, 8, 1]]),               # MaxPool's Kernelsize\n       \"n_freq_downsample\": tune.choice([[168, 24, 1], [24, 12, 1], [1, 1, 1]]), # Interpolation expressivity ratios\n       \"activation\": tune.choice(['ReLU']),                                      # Type of non-linear activation\n       \"n_blocks\":  tune.choice([[1, 1, 1]]),                                    # Blocks per each 3 stacks\n       \"mlp_units\":  tune.choice([[[512, 512], [512, 512], [512, 512]]]),        # 2 512-Layers per block for each stack\n       \"interpolation_mode\": tune.choice(['linear']),                            # Type of multi-step interpolation\n       \"val_check_steps\": tune.choice([100]),                                    # Compute validation every 100 epochs\n       \"random_seed\": tune.randint(1, 10),\n    }\n\n\n\n\n\n\n\nTip\n\n\n\nRefer to https://docs.ray.io/en/latest/tune/index.html for more information on the different space options, such as lists and continous intervals.m\n\n\nTo instantiate AutoNHITS you need to define:\n\nh: forecasting horizon\nloss: training loss. Use the DistributionLoss to produce probabilistic forecasts.\nconfig: hyperparameter search space. If None, the AutoNHITS class will use a pre-defined suggested hyperparameter space.\nnum_samples: number of configurations explored.\n\n\nmodels = [AutoNHITS(h=horizon,\n                    config=nhits_config, \n                    num_samples=5)]\n\nINFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmp0ke5wzvj\nINFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmp0ke5wzvj/_remote_module_non_scriptable.py\n\n\nFit the model by instantiating a NeuralForecast object with the following required parameters:\n\nmodels: a list of models.\nfreq: a string indicating the frequency of the data. (See panda’s available frequencies.)\n\nThe cross_validation method allows you to simulate multiple historic forecasts, greatly simplifying pipelines by replacing for loops with fit and predict methods.\nWith time series data, cross validation is done by defining a sliding window across the historical data and predicting the period following it. This form of cross validation allows us to arrive at a better estimation of our model’s predictive abilities across a wider range of temporal instances while also keeping the data in the training set contiguous as is required by our models.\nThe cross_validation method will use the validation set for hyperparameter selection, and will then produce the forecasts for the test set.\n\nnf = NeuralForecast(\n    models=models,\n    freq='15min')\n\nY_hat_df = nf.cross_validation(df=Y_df, val_size=val_size,\n                               test_size=test_size, n_windows=None)\n\nINFO:ray.tune.tune:Initializing Ray automatically.For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run`."
  },
  {
    "objectID": "examples/longhorizon_with_nhits.html#evaluate-results",
    "href": "examples/longhorizon_with_nhits.html#evaluate-results",
    "title": "Long-Horizon Forecast",
    "section": "4. Evaluate Results",
    "text": "4. Evaluate Results\nThe AutoNHITS class contains a results tune attribute that stores information of each configuration explored. It contains the validation loss and best validation hyperparameter.\n\nnf.models[0].results.get_best_result().config\n\n{'learning_rate': 0.001,\n 'max_steps': 1000,\n 'input_size': 480,\n 'batch_size': 7,\n 'windows_batch_size': 256,\n 'n_pool_kernel_size': [2, 2, 2],\n 'n_freq_downsample': [24, 12, 1],\n 'activation': 'ReLU',\n 'n_blocks': [1, 1, 1],\n 'mlp_units': [[512, 512], [512, 512], [512, 512]],\n 'interpolation_mode': 'linear',\n 'check_val_every_n_epoch': 100,\n 'random_seed': 4,\n 'h': 96,\n 'loss': MAE()}\n\n\n\ny_true = Y_hat_df.y.values\ny_hat = Y_hat_df['AutoNHITS'].values\n\nn_series = len(Y_df.unique_id.unique())\n\ny_true = y_true.reshape(n_series, -1, horizon)\ny_hat = y_hat.reshape(n_series, -1, horizon)\n\nprint('Parsed results')\nprint('2. y_true.shape (n_series, n_windows, n_time_out):\\t', y_true.shape)\nprint('2. y_hat.shape  (n_series, n_windows, n_time_out):\\t', y_hat.shape)\n\nParsed results\n2. y_true.shape (n_series, n_windows, n_time_out):   (7, 11425, 96)\n2. y_hat.shape  (n_series, n_windows, n_time_out):   (7, 11425, 96)\n\n\n\nfig, axs = plt.subplots(nrows=3, ncols=1, figsize=(10, 11))\nfig.tight_layout()\n\nseries = ['HUFL','HULL','LUFL','LULL','MUFL','MULL','OT']\nseries_idx = 3\n\nfor idx, w_idx in enumerate([200, 300, 400]):\n  axs[idx].plot(y_true[series_idx, w_idx,:],label='True')\n  axs[idx].plot(y_hat[series_idx, w_idx,:],label='Forecast')\n  axs[idx].grid()\n  axs[idx].set_ylabel(series[series_idx]+f' window {w_idx}', \n                      fontsize=17)\n  if idx==2:\n    axs[idx].set_xlabel('Forecast Horizon', fontsize=17)\nplt.legend()\nplt.show()\nplt.close()\n\n\n\n\nFinally, we compute the test errors for the two metrics of interest:\n\\(\\qquad MAE = \\frac{1}{Windows * Horizon} \\sum_{\\tau} |y_{\\tau} - \\hat{y}_{\\tau}| \\qquad\\) and \\(\\qquad MSE = \\frac{1}{Windows * Horizon} \\sum_{\\tau} (y_{\\tau} - \\hat{y}_{\\tau})^{2} \\qquad\\)\n\nfrom neuralforecast.losses.numpy import mae, mse\n\nprint('MAE: ', mae(y_hat, y_true))\nprint('MSE: ', mse(y_hat, y_true))\n\nMAE:  0.26096806135482414\nMSE:  0.18279484416711375\n\n\nFor reference we can check the performance when compared to previous ‘state-of-the-art’ long-horizon Transformer-based forecasting methods from the NHITS paper. To recover or improve the paper results try setting hyperopt_max_evals=30 in Hyperparameter Tuning.\nMean Absolute Error (MAE):\n\n\n\nHorizon\nNHITS\nAutoFormer\nInFormer\nARIMA\n\n\n\n\n96\n0.255\n0.339\n0.453\n0.301\n\n\n192\n0.305\n0.340\n0.563\n0.345\n\n\n336\n0.346\n0.372\n0.887\n0.386\n\n\n720\n0.426\n0.419\n1.388\n0.445\n\n\n\nMean Squared Error (MSE):\n\n\n\nHorizon\nNHITS\nAutoFormer\nInFormer\nARIMA\n\n\n\n\n96\n0.176\n0.255\n0.365\n0.225\n\n\n192\n0.245\n0.281\n0.533\n0.298\n\n\n336\n0.295\n0.339\n1.363\n0.370\n\n\n720\n0.401\n0.422\n3.379\n0.478"
  },
  {
    "objectID": "examples/longhorizon_with_nhits.html#references",
    "href": "examples/longhorizon_with_nhits.html#references",
    "title": "Long-Horizon Forecast",
    "section": "References",
    "text": "References\nCristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2021). NHITS: Neural Hierarchical Interpolation for Time Series Forecasting. Accepted at AAAI 2023."
  },
  {
    "objectID": "examples/getting_started.html",
    "href": "examples/getting_started.html",
    "title": "Getting Started",
    "section": "",
    "text": "This notebook provides an example on how to start using the main functionalities of the NeuralForecast library. The NeuralForecast class allows users to easily interact with NeuralForecast.models PyTorch models. In this example we will forecast AirPassengers data with a classic LSTM and the recent NHITS models. The full list of available models is available here.\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/getting_started.html#installing-neuralforecast",
    "href": "examples/getting_started.html#installing-neuralforecast",
    "title": "Getting Started",
    "section": "1. Installing NeuralForecast",
    "text": "1. Installing NeuralForecast\n\n!pip install neuralforecast"
  },
  {
    "objectID": "examples/getting_started.html#loading-airpassengers-data",
    "href": "examples/getting_started.html#loading-airpassengers-data",
    "title": "Getting Started",
    "section": "2. Loading AirPassengers Data",
    "text": "2. Loading AirPassengers Data\nThe core.NeuralForecast class contains shared, fit, predict and other methods that take as inputs pandas DataFrames with columns ['unique_id', 'ds', 'y'], where unique_id identifies individual time series from the dataset, ds is the date, and y is the target variable.\nIn this example dataset consists of a set of a single series, but you can easily fit your model to larger datasets in long format.\n\nfrom neuralforecast.utils import AirPassengersDF\n\nY_df = AirPassengersDF # Defined in neuralforecast.utils\nY_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\n1.0\n1949-01-31\n112.0\n\n\n1\n1.0\n1949-02-28\n118.0\n\n\n2\n1.0\n1949-03-31\n132.0\n\n\n3\n1.0\n1949-04-30\n129.0\n\n\n4\n1.0\n1949-05-31\n121.0\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nDataFrames must include all ['unique_id', 'ds', 'y'] columns. Make sure y column does not have missing or non-numeric values."
  },
  {
    "objectID": "examples/getting_started.html#model-training",
    "href": "examples/getting_started.html#model-training",
    "title": "Getting Started",
    "section": "3. Model Training",
    "text": "3. Model Training\n\nFit the models\nUsing the NeuralForecast.fit method you can train a set of models to your dataset. You can define the forecasting horizon (12 in this example), and modify the hyperparameters of the model. For example, for the LSTM we changed the default hidden size for both encoder and decoders.\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import LSTM, NHITS, RNN\n\n\nhorizon = 12\n\n# Try different hyperparmeters to improve accuracy.\nmodels = [LSTM(h=horizon,                    # Forecast horizon\n               max_steps=500,                # Number of steps to train\n               scaler_type='standard',       # Type of scaler to normalize data\n               encoder_hidden_size=64,       # Defines the size of the hidden state of the LSTM\n               decoder_hidden_size=64,),     # Defines the number of hidden units of each layer of the MLP decoder\n          NHITS(h=horizon,                   # Forecast horizon\n                input_size=2 * horizon,      # Length of input sequence\n                max_steps=100,               # Number of steps to train\n                n_freq_downsample=[2, 1, 1]) # Downsampling factors for each stack output\n          ]\nnf = NeuralForecast(models=models, freq='M')\nnf.fit(df=Y_df)\n\n\n\n\n\n\n\nTip\n\n\n\nThe performance of Deep Learning models can be very sensitive to the choice of hyperparameters. Tuning the correct hyperparameters is an important step to obtain the best forecasts. The Auto version of these models, AutoLSTM and AutoNHITS, already perform hyperparameter selection automatically.\n\n\n\n\nPredict using the fitted models\nUsing the NeuralForecast.predict method you can obtain the h forecasts after the training data Y_df.\n\nY_hat_df = nf.predict()\n\nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00, 50.58it/s]\nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00, 126.52it/s]\n\n\nThe NeuralForecast.predict method returns a DataFrame with the forecasts for each unique_id, ds, and model.\n\nY_hat_df = Y_hat_df.reset_index()\nY_hat_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nLSTM\nNHITS\n\n\n\n\n0\n1.0\n1961-01-31\n424.380310\n453.039185\n\n\n1\n1.0\n1961-02-28\n442.092010\n429.609192\n\n\n2\n1.0\n1961-03-31\n448.555664\n498.796204\n\n\n3\n1.0\n1961-04-30\n473.586609\n509.536224\n\n\n4\n1.0\n1961-05-31\n512.466370\n524.131592"
  },
  {
    "objectID": "examples/getting_started.html#plot-predictions",
    "href": "examples/getting_started.html#plot-predictions",
    "title": "Getting Started",
    "section": "4. Plot Predictions",
    "text": "4. Plot Predictions\nFinally, we plot the forecasts of both models againts the real values.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nfig, ax = plt.subplots(1, 1, figsize = (20, 7))\nplot_df = pd.concat([Y_df, Y_hat_df]).set_index('ds') # Concatenate the train and forecast dataframes\nplot_df[['y', 'LSTM', 'NHITS']].plot(ax=ax, linewidth=2)\n\nax.set_title('AirPassengers Forecast', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp [t]', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor this guide we are using a simple LSTM model. More recent models, such as RNN, GRU, and DilatedRNN achieve better accuracy than LSTM in most settings. The full list of available models is available here."
  },
  {
    "objectID": "examples/getting_started.html#references",
    "href": "examples/getting_started.html#references",
    "title": "Getting Started",
    "section": "References",
    "text": "References\n\nBoris N. Oreshkin, Dmitri Carpov, Nicolas Chapados, Yoshua Bengio (2020). “N-BEATS: Neural basis expansion analysis for interpretable time series forecasting”. International Conference on Learning Representations.\nCristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2021). NHITS: Neural Hierarchical Interpolation for Time Series Forecasting. Accepted at AAAI 2023."
  },
  {
    "objectID": "examples/how_to_add_models.html",
    "href": "examples/how_to_add_models.html",
    "title": "How to add new Models to NeuralForecast",
    "section": "",
    "text": "Prerequisites\n\n\n\nThis Guide assumes advanced familiarity with NeuralForecast.\nWe highly recommend reading first the Getting Started and the NeuralForecast Map tutorials!\nAdditionally, refer to the CONTRIBUTING guide for the basics how to contribute to NeuralForecast.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/how_to_add_models.html#introduction",
    "href": "examples/how_to_add_models.html#introduction",
    "title": "How to add new Models to NeuralForecast",
    "section": "Introduction",
    "text": "Introduction\nThis tutorial is aimed at contributors who want to add a new model to the NeuralForecast library. The library’s existing modules handle optimization, training, selection, and evaluation of deep learning models. The core class simplifies building entire pipelines, both for industry and academia, on any dataset, with user-friendly methods such as fit and predict.\n\nAdding a new model to NeuralForecast is simpler than building a new PyTorch model from scratch. You only need to write the forward method.\n\nIt has the following additional advantages:\n\nExisting modules in NeuralForecast already implement the essential training and evaluating aspects for deep learning models.\nIntegrated with PyTorch-Lightning and Tune libraries for efficient optimization and distributed computation.\nThe BaseModel classes provide common optimization components, such as early stopping and learning rate schedulers.\nAutomatic performance tests are scheduled on Github to ensure quality standards.\nUsers can easily compare the performance and computation of the new model with existing models.\nOpportunity for exposure to a large community of users and contributors.\n\n\nExample: simplified MLP model\nWe will present the tutorial following an example on how to add a simplified version of the current MLP model, which does not include exogenous covariates.\nAt a given timestamp \\(t\\), the MLP model will forecast the next \\(h\\) values of the univariate target time, \\(Y_{t+1:t+h}\\), using as inputs the last \\(L\\) historical values, given by \\(Y_{t-L:t}\\). The following figure presents a diagram of the model.\n\n\n\nFigure 1. Three layer MLP with autorregresive inputs."
  },
  {
    "objectID": "examples/how_to_add_models.html#preliminaries",
    "href": "examples/how_to_add_models.html#preliminaries",
    "title": "How to add new Models to NeuralForecast",
    "section": "0. Preliminaries",
    "text": "0. Preliminaries\nFollow our tutorial on contributing here to set up your development environment.\nHere is a short list of the most important steps:\n\nCreate a fork of the neuralforecast library.\nClone the fork to your computer.\nSet an environment with the neuralforecast library, core dependencies, and nbdev package to code your model in an interactive notebook."
  },
  {
    "objectID": "examples/how_to_add_models.html#inherit-the-base-class-basewindows",
    "href": "examples/how_to_add_models.html#inherit-the-base-class-basewindows",
    "title": "How to add new Models to NeuralForecast",
    "section": "1. Inherit the Base Class (BaseWindows)",
    "text": "1. Inherit the Base Class (BaseWindows)\nThe library contains three types of base models: BaseWindows, BaseRecurrent, and BaseMultivariate. In this tutorial, we will focus on the BaseWindows class, which is the most common type of model in the library, with models such as NBEATS, NHITS, TFT, and PatchTST. The main difference between the three types is the sampling procedure and input batch for the forward method, which determines the type of model.\n\n\n\n\n\n\nImportant\n\n\n\nIf you want to add a BaseRecurrent or BaseMultivariate model, please add an issue in our github.\n\n\n\na. Sampling process\nDuring training, the base class receives a sample of time series of the dataset from the TimeSeriesLoader module. The BaseWindows models will sample individual windows of size input_size+h, starting from random timestamps.\n\n\nb. BaseWindows’ hyperparameters\nGet familiar with the hyperparameters specified in the base class, including h (horizon), input_size, and optimization hyperparameters such as learning_rate, max_steps, among others. The following list presents the hyperparameters related to the sampling of windows:\n\nh (h): number of future values to predict.\ninput_size (L): number of historic values to use as input for the model.\nbatch_size (bs): number of time series sampled by the loader during training.\nvalid_batch_size (v_bs): number of time series sampled by the loader during inference (validation and test).\nwindows_batch_size (w_bs): number of individual windows sampled during training (from the previous time series) to form the batch.\ninference_windows_batch_size (i_bs): number of individual windows sampled during inference to form each batch. Used to control the GPU memory.\n\n\n\nc. Input and Output batch shapes\nThe forward method receives a batch of data in a dictionary with the following keys:\n\ninsample_y: historic values of the time series.\ninsample_mask: mask indicating the available values of the time series (1 if available, 0 if missing).\nfutr_exog: future exogenous covariates (if any).\nhist_exog: historic exogenous covariates (if any).\nstat_exog: static exogenous covariates (if any).\n\nThe following table presents the shape for each tensor:\n\n\n\ntensor\nBaseWindows\n\n\n\n\ninsample_y\n(w_bs, L)\n\n\ninsample_mask\n(w_bs, L)\n\n\nfutr_exog\n(w_bs, L+h, n_f)\n\n\nhist_exog\n(w_bs, L, n_h)\n\n\nstat_exog\n(w_bs,n_s)\n\n\n\nThe forward function should return a single tensor with the forecasts of the next h timestamps for each window. Use the attributes of the loss class to automatically parse the output to the correct shape (see the example below).\n\n\n\n\n\n\nTip\n\n\n\nSince we are using nbdev, you can easily add prints to the code and see the shapes of the tensors during training.\n\n\n\n\nd. BaseWindows’ methods\nThe BaseWindows class contains several common methods for all windows-based models, simplifying the development of new models by preventing code duplication. The most important methods of the class are:\n\n_create_windows: parses the time series from the TimeSeriesLoader into individual windows of size input_size+h.\n_normalization: normalizes each window based on the scaler type.\n_inv_normalization: inverse normalization of the forecasts.\ntraining_step: training step of the model, called by PyTorch-Lightning’s Trainer class during training (fit method).\nvalidation_step: validation step of the model, called by PyTorch-Lightning’s Trainer class during validation.\npredict_step: prediction step of the model, called by PyTorch-Lightning’s Trainer class during inference (predict method)."
  },
  {
    "objectID": "examples/how_to_add_models.html#create-the-model-file-and-class",
    "href": "examples/how_to_add_models.html#create-the-model-file-and-class",
    "title": "How to add new Models to NeuralForecast",
    "section": "2. Create the model file and class",
    "text": "2. Create the model file and class\nOnce familiar with the basics of the BaseWindows class, the next step is creating your particular model.\nThe main steps are:\n\nCreate the file in the nbs folder (https://github.com/Nixtla/neuralforecast/tree/main/nbs). It should be named models.YOUR_MODEL_NAME.ipynb.\nAdd the header of the nbdev file.\nImport libraries in the file.\nDefine the __init__ method with the model’s inherited and particular hyperparameters and instantiate the architecture.\nDefine the forward method, which recieves the input batch dictionary and returns the forecast.\n\n\na. Model class\nFirst, add the following two cells on top of the nbdev file.\n#| default_exp models.mlp\n\n\n\n\n\n\nImportant\n\n\n\nChange mlp to your model’s name, using lowercase and underscores. When you later run nbdev_export, it will create a YOUR_MODEL.py script in the neuralforecast/models/ directory.\n\n\n#| hide\n%load_ext autoreload\n%autoreload 2\nNext, add the dependencies of the model.\n#| export\nfrom typing import Optional\n\nimport torch\nimport torch.nn as nn\n\nfrom neuralforecast.losses.pytorch import MAE\nfrom neuralforecast.common._base_windows import BaseWindows\n\n\n\n\n\n\nTip\n\n\n\nDon’t forget to add the #| export tag on this cell.\n\n\nNext, create the class with the init and forward methods. The following example shows the example for the simplified MLP model. We explain important details after the code.\n#| export\nclass MLP(BaseWindows): # &lt;&lt;---- Inherits from BaseWindows\n    def __init__(self,\n                 # Inhereted hyperparameters with no defaults\n                 h,\n                 input_size,\n                 # Model specific hyperparameters\n                 num_layers = 2,\n                 hidden_size = 1024,\n                 # Inhereted hyperparameters with defaults\n                 exclude_insample_y = False,\n                 loss = MAE(),\n                 valid_loss = None,\n                 max_steps: int = 1000,\n                 learning_rate: float = 1e-3,\n                 num_lr_decays: int = -1,\n                 early_stop_patience_steps: int =-1,\n                 val_check_steps: int = 100,\n                 batch_size: int = 32,\n                 valid_batch_size: Optional[int] = None,\n                 windows_batch_size = 1024,\n                 inference_windows_batch_size = -1,\n                 step_size: int = 1,\n                 scaler_type: str = 'identity',\n                 random_seed: int = 1,\n                 num_workers_loader: int = 0,\n                 drop_last_loader: bool = False,\n                 **trainer_kwargs):\n    # Inherit BaseWindows class\n    super(MLP, self).__init__(h=h,\n                              input_size=input_size,\n                              ..., # &lt;&lt;--- Add all inhereted hyperparameters\n                              random_seed=random_seed,\n                              **trainer_kwargs)\n\n    # Architecture\n    self.num_layers = num_layers\n    self.hidden_size = hidden_size\n\n    # MultiLayer Perceptron\n    layers = [nn.Linear(in_features=input_size, out_features=hidden_size)]\n    layers += [nn.ReLU()]\n    for i in range(num_layers - 1):\n        layers += [nn.Linear(in_features=hidden_size, out_features=hidden_size)]\n        layers += [nn.ReLU()]\n    self.mlp = nn.ModuleList(layers)\n\n    # Adapter with Loss dependent dimensions\n    self.out = nn.Linear(in_features=hidden_size, \n                         out_features=h * self.loss.outputsize_multiplier) ## &lt;&lt;--- Use outputsize_multiplier to adjust output size\n\n    def forward(self, windows_batch): # &lt;&lt;--- Receives windows_batch dictionary\n        # Parse windows_batch\n        insample_y = windows_batch['insample_y'].clone()\n        # MLP\n        y_pred = self.mlp(y_pred)\n        # Reshape and map to loss domain\n        y_pred = y_pred.reshape(batch_size, self.h, self.loss.outputsize_multiplier)\n        y_pred = self.loss.domain_map(y_pred)\n        return y_pred\n\n\n\n\n\n\nTip\n\n\n\n\nDon’t forget to add the #| export tag on each cell.\nLarger architectures, such as Transformers, might require splitting the forward by using intermediate functions.\n\n\n\n\nImportant notes\nThe base class has many hyperparameters, and models must have default values for all of them (except h and input_size). If you are unsure of what default value to use, we recommend copying the default values from existing models for most optimization and sampling hyperparameters. You can change the default values later at any time.\nThe reshape method at the end of the forward step is used to adjust the output shape. The loss class contains an outputsize_multiplier attribute to automatically adjust the output size of the forecast depending on the loss. For example, for the Multi-quantile loss (MQLoss), the model needs to output each quantile for each horizon.\nFinally, always include y_pred = self.loss.domain_map(y_pred) at the end of the forward. This is necessary to map the output to the domain (and shape) of the loss function. For example, if the loss function is the MAE, it maps the output of shape (batch_size, h, 1) to (batch_size, h).\n\n\n\nb. Tests and documentation\nnbdev allows for testing and documenting the model during the development process. It allows users to iterate the development within the notebook, testing the code in the same environment. Refer to existing models, such as the complete MLP model here. These files already contain the tests, documentation, and usage examples that were used during the development process.\n\n\nc. Export the new model to the library with nbdev\nFollowing the CONTRIBUTING guide, the next step is to export the new model from the development notebook to the neuralforecast folder with the actual scripts.\nTo export the model, run nbdev_export in your terminal. You should see a new file with your model in the neuralforecast/models/ folder."
  },
  {
    "objectID": "examples/how_to_add_models.html#core-class-and-additional-files",
    "href": "examples/how_to_add_models.html#core-class-and-additional-files",
    "title": "How to add new Models to NeuralForecast",
    "section": "3. Core class and additional files",
    "text": "3. Core class and additional files\nFinally, add the model to the core class and additional files:\n\nManually add the model in the following init file.\nAdd the model to the core class, using the nbdev file here:\n\nAdd the model to the initial model list:\n\nfrom neuralforecast.models import (\nGRU, LSTM, RNN, TCN, DilatedRNN,\nMLP, NHITS, NBEATS, NBEATSx,\nTFT, VanillaTransformer,\nInformer, Autoformer, FEDformer,\nStemGNN, PatchTST\n)\n\nAdd the model to the MODEL_FILENAME_DICT dictionary (used for the save and load functions)."
  },
  {
    "objectID": "examples/how_to_add_models.html#upload-to-github",
    "href": "examples/how_to_add_models.html#upload-to-github",
    "title": "How to add new Models to NeuralForecast",
    "section": "4. Upload to GitHub",
    "text": "4. Upload to GitHub\nCongratulations! The model is ready to be used in the library following the steps above.\nFollow our contributing guide’s final steps to upload the model to GitHub: here.\nOne of the maintainers will review the PR, request changes if necessary, and merge it into the library."
  },
  {
    "objectID": "examples/how_to_add_models.html#quick-checklist",
    "href": "examples/how_to_add_models.html#quick-checklist",
    "title": "How to add new Models to NeuralForecast",
    "section": "Quick Checklist",
    "text": "Quick Checklist\n\nGet familiar with the BaseWindows class hyperparameters and input/output shapes of the forward method.\nCreate the notebook with your model class in the nbs folder: models.YOUR_MODEL_NAME.ipynb\nAdd the header and import libraries.\nImplement init and forward methods.\nExport model with nbdev_export.\nAdd model to this init file.\nAdd the model to the core class here.\nFollow the CONTRIBUTING guide to create the PR to upload the model."
  },
  {
    "objectID": "examples/automatic_hyperparameter_tuning.html",
    "href": "examples/automatic_hyperparameter_tuning.html",
    "title": "Hyperparameter Optimization",
    "section": "",
    "text": "Deep-learning models are the state-of-the-art in time series forecasting. They have outperformed statistical and tree-based approaches in recent large-scale competitions, such as the M series, and are being increasingly adopted in industry. However, their performance is greatly affected by the choice of hyperparameters. Selecting the optimal configuration, a process called hyperparameter tuning, is essential to achieve the best performance.\nThe main steps of hyperparameter tuning are:\nWith Neuralforecast, we automatize and simplify the hyperparameter tuning process with the Auto models. Every model in the library has an Auto version (for example, AutoNHITS, AutoTFT) which can perform automatic hyperparameter selection on default or user-defined search space.\nThe Auto models can be used with two backends: Ray’s Tune library and Optuna, with a user-friendly and simplified API, with most of their capabilities.\nIn this tutorial, we show in detail how to instantiate and train an AutoNHITS model with a custom search space with both Tune and Optuna backends, install and use HYPEROPT search algorithm, and use the model with optimal hyperparameters to forecast.\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/automatic_hyperparameter_tuning.html#install-neuralforecast",
    "href": "examples/automatic_hyperparameter_tuning.html#install-neuralforecast",
    "title": "Hyperparameter Optimization",
    "section": "1. Install Neuralforecast",
    "text": "1. Install Neuralforecast\n\n# !pip install neuralforecast hyperopt"
  },
  {
    "objectID": "examples/automatic_hyperparameter_tuning.html#load-data",
    "href": "examples/automatic_hyperparameter_tuning.html#load-data",
    "title": "Hyperparameter Optimization",
    "section": "2. Load Data",
    "text": "2. Load Data\nIn this example we will use the AirPasengers, a popular dataset with monthly airline passengers in the US from 1949 to 1960. Load the data, available at our utils methods in the required format. See https://nixtla.github.io/neuralforecast/examples/data_format.html for more details on the data input format.\n\nfrom neuralforecast.utils import AirPassengersDF\n\nY_df = AirPassengersDF\nY_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\n1.0\n1949-01-31\n112.0\n\n\n1\n1.0\n1949-02-28\n118.0\n\n\n2\n1.0\n1949-03-31\n132.0\n\n\n3\n1.0\n1949-04-30\n129.0\n\n\n4\n1.0\n1949-05-31\n121.0"
  },
  {
    "objectID": "examples/automatic_hyperparameter_tuning.html#rays-tune-backend",
    "href": "examples/automatic_hyperparameter_tuning.html#rays-tune-backend",
    "title": "Hyperparameter Optimization",
    "section": "3. Ray’s Tune backend",
    "text": "3. Ray’s Tune backend\nFirst, we show how to use the Tune backend. This backend is based on Ray’s Tune library, which is a scalable framework for hyperparameter tuning. It is a popular library in the machine learning community, and it is used by many companies and research labs. If you plan to use the Optuna backend, you can skip this section.\n\n3.a Define hyperparameter grid\nEach Auto model contains a default search space that was extensively tested on multiple large-scale datasets. Additionally, users can define specific search spaces tailored for particular datasets and tasks.\nFirst, we create a custom search space for the AutoNHITS model. Search spaces are specified with dictionaries, where keys corresponds to the model’s hyperparameter and the value is a Tune function to specify how the hyperparameter will be sampled. For example, use randint to sample integers uniformly, and choice to sample values of a list.\nIn the following example we are optimizing the learning_rate and two NHITS specific hyperparameters: n_pool_kernel_size and n_freq_downsample. Additionaly, we use the search space to modify default hyperparameters, such as max_steps and val_check_steps.\n\nfrom ray import tune\n\n\nnhits_config = {\n       \"max_steps\": 100,                                                         # Number of SGD steps\n       \"input_size\": 24,                                                         # Size of input window\n       \"learning_rate\": tune.loguniform(1e-5, 1e-1),                             # Initial Learning rate\n       \"n_pool_kernel_size\": tune.choice([[2, 2, 2], [16, 8, 1]]),               # MaxPool's Kernelsize\n       \"n_freq_downsample\": tune.choice([[168, 24, 1], [24, 12, 1], [1, 1, 1]]), # Interpolation expressivity ratios\n       \"val_check_steps\": 50,                                                    # Compute validation every 50 steps\n       \"random_seed\": tune.randint(1, 10),                                       # Random seed\n    }\n\n\n\n\n\n\n\nImportant\n\n\n\nConfiguration dictionaries are not interchangeable between models since they have different hyperparameters. Refer to https://nixtla.github.io/neuralforecast/models.html for a complete list of each model’s hyperparameters.\n\n\n\n\n3.b Instantiate Auto model\nTo instantiate an Auto model you need to define:\n\nh: forecasting horizon.\nloss: training and validation loss from neuralforecast.losses.pytorch.\nconfig: hyperparameter search space. If None, the Auto class will use a pre-defined suggested hyperparameter space.\nsearch_alg: search algorithm (from tune.search), default is random search. Refer to https://docs.ray.io/en/latest/tune/api_docs/suggestion.html for more information on the different search algorithm options.\nbackend: backend to use, default is ray. If optuna, the Auto class will use the Optuna backend.\nnum_samples: number of configurations explored.\n\nIn this example we set horizon h as 12, use the MAE loss for training and validation, and use the HYPEROPT search algorithm.\n\nfrom ray.tune.search.hyperopt import HyperOptSearch\nfrom neuralforecast.losses.pytorch import MAE\nfrom neuralforecast.auto import AutoNHITS\n\n\nmodel = AutoNHITS(h=12,\n                  loss=MAE(),\n                  config=nhits_config,\n                  search_alg=HyperOptSearch(),\n                  backend='ray',\n                  num_samples=10)\n\n\n\n\n\n\n\nTip\n\n\n\nThe number of samples, num_samples, is a crucial parameter! Larger values will usually produce better results as we explore more configurations in the search space, but it will increase training times. Larger search spaces will usually require more samples. As a general rule, we recommend setting num_samples higher than 20. We set 10 in this example for demonstration purposes.\n\n\n\n\n3.c Train model and predict with Core class\nNext, we use the Neuralforecast class to train the Auto model. In this step, Auto models will automatically perform hyperparamter tuning training multiple models with different hyperparameters, producing the forecasts on the validation set, and evaluating them. The best configuration is selected based on the error on a validation set. Only the best model is stored and used during inference.\n\nfrom neuralforecast import NeuralForecast\n\nUse the val_size parameter of the fit method to control the length of the validation set. In this case we set the validation set as twice the forecasting horizon.\n\nnf = NeuralForecast(models=[model], freq='M')\nnf.fit(df=Y_df, val_size=24)\n\nGlobal seed set to 8\n\n\nThe results of the hyperparameter tuning are available in the results attribute of the Auto model. Use the get_dataframe method to get the results in a pandas dataframe.\n\nresults = nf.models[0].results.get_dataframe()\nresults.head()\n\n\n\n\n\n\n\n\nloss\ntime_this_iter_s\ndone\ntimesteps_total\nepisodes_total\ntraining_iteration\ntrial_id\nexperiment_id\ndate\ntimestamp\n...\nconfig/input_size\nconfig/learning_rate\nconfig/loss\nconfig/max_steps\nconfig/n_freq_downsample\nconfig/n_pool_kernel_size\nconfig/random_seed\nconfig/val_check_steps\nconfig/valid_loss\nlogdir\n\n\n\n\n0\n21.173204\n3.645993\nFalse\nNaN\nNaN\n2\ne20dbd9b\nf62650f116914e18889bb96963c6b202\n2023-10-03_11-19-14\n1696346354\n...\n24\n0.000415\nMAE()\n100\n[168, 24, 1]\n[16, 8, 1]\n7\n50\nMAE()\n/Users/cchallu/ray_results/_train_tune_2023-10...\n\n\n1\n33.843426\n3.756614\nFalse\nNaN\nNaN\n2\n75e09199\nf62650f116914e18889bb96963c6b202\n2023-10-03_11-19-22\n1696346362\n...\n24\n0.000068\nMAE()\n100\n[24, 12, 1]\n[16, 8, 1]\n4\n50\nMAE()\n/Users/cchallu/ray_results/_train_tune_2023-10...\n\n\n2\n17.750280\n8.573898\nFalse\nNaN\nNaN\n2\n0dc5925a\nf62650f116914e18889bb96963c6b202\n2023-10-03_11-19-36\n1696346376\n...\n24\n0.001615\nMAE()\n100\n[1, 1, 1]\n[2, 2, 2]\n8\n50\nMAE()\n/Users/cchallu/ray_results/_train_tune_2023-10...\n\n\n3\n24.573055\n6.987517\nFalse\nNaN\nNaN\n2\n352e03ff\nf62650f116914e18889bb96963c6b202\n2023-10-03_11-19-50\n1696346390\n...\n24\n0.003405\nMAE()\n100\n[1, 1, 1]\n[2, 2, 2]\n5\n50\nMAE()\n/Users/cchallu/ray_results/_train_tune_2023-10...\n\n\n4\n474221.937500\n4.912362\nFalse\nNaN\nNaN\n2\n289bdd5e\nf62650f116914e18889bb96963c6b202\n2023-10-03_11-20-00\n1696346400\n...\n24\n0.080117\nMAE()\n100\n[168, 24, 1]\n[16, 8, 1]\n5\n50\nMAE()\n/Users/cchallu/ray_results/_train_tune_2023-10...\n\n\n\n\n5 rows × 29 columns\n\n\n\nNext, we use the predict method to forecast the next 12 months using the optimal hyperparameters.\n\nY_hat_df = nf.predict()\nY_hat_df = Y_hat_df.reset_index()\nY_hat_df.head()\n\nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00, 113.97it/s]\n\n\n\n\n\n\n\n\n\nunique_id\nds\nAutoNHITS\n\n\n\n\n0\n1.0\n1961-01-31\n442.346680\n\n\n1\n1.0\n1961-02-28\n439.409821\n\n\n2\n1.0\n1961-03-31\n477.709930\n\n\n3\n1.0\n1961-04-30\n503.884064\n\n\n4\n1.0\n1961-05-31\n521.344421"
  },
  {
    "objectID": "examples/automatic_hyperparameter_tuning.html#optuna-backend",
    "href": "examples/automatic_hyperparameter_tuning.html#optuna-backend",
    "title": "Hyperparameter Optimization",
    "section": "4. Optuna backend",
    "text": "4. Optuna backend\nIn this section we show how to use the Optuna backend. Optuna is a lightweight and versatile platform for hyperparameter optimization. If you plan to use the Tune backend, you can skip this section.\n\n4.a Define hyperparameter grid\nEach Auto model contains a default search space that was extensively tested on multiple large-scale datasets. Additionally, users can define specific search spaces tailored for particular datasets and tasks.\nFirst, we create a custom search space for the AutoNHITS model. Search spaces are specified with a function that returns a dictionary, where keys corresponds to the model’s hyperparameter and the value is a suggest function to specify how the hyperparameter will be sampled. For example, use suggest_int to sample integers uniformly, and suggest_categorical to sample values of a list. See https://optuna.readthedocs.io/en/stable/reference/generated/optuna.trial.Trial.html for more details.\nIn the following example we are optimizing the learning_rate and two NHITS specific hyperparameters: n_pool_kernel_size and n_freq_downsample. Additionaly, we use the search space to modify default hyperparameters, such as max_steps and val_check_steps.\n\nimport optuna\noptuna.logging.set_verbosity(optuna.logging.WARNING) # Use this to disable training prints from optuna\n\n\ndef config_nhits(trial):\n    return {\n        \"max_steps\": 100,                                                                                               # Number of SGD steps\n        \"input_size\": 24,                                                                                               # Size of input window\n        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1),                                         # Initial Learning rate\n        \"n_pool_kernel_size\": trial.suggest_categorical(\"n_pool_kernel_size\", [[2, 2, 2], [16, 8, 1]]),                 # MaxPool's Kernelsize\n        \"n_freq_downsample\": trial.suggest_categorical(\"n_freq_downsample\", [[168, 24, 1], [24, 12, 1], [1, 1, 1]]),    # Interpolation expressivity ratios\n        \"val_check_steps\": 50,                                                                                          # Compute validation every 50 steps\n        \"random_seed\": trial.suggest_int(\"random_seed\", 1, 10),                                                         # Random seed\n    }\n\n\n\n4.b Instantiate Auto model\nTo instantiate an Auto model you need to define:\n\nh: forecasting horizon.\nloss: training and validation loss from neuralforecast.losses.pytorch.\nconfig: hyperparameter search space. If None, the Auto class will use a pre-defined suggested hyperparameter space.\nsearch_alg: search algorithm (from optuna.samplers), default is TPESampler (Tree-structured Parzen Estimator). Refer to https://optuna.readthedocs.io/en/stable/reference/samplers/index.html for more information on the different search algorithm options.\nbackend: backend to use, default is ray. If optuna, the Auto class will use the Optuna backend.\nnum_samples: number of configurations explored.\n\n\nmodel = AutoNHITS(h=12,\n                  loss=MAE(),\n                  config=config_nhits,\n                  search_alg=optuna.samplers.TPESampler(),\n                  backend='optuna',\n                  num_samples=10)\n\n\n\n\n\n\n\nImportant\n\n\n\nConfiguration dictionaries and search algorithms for Tune and Optuna are not interchangeable! Use the appropriate type of search algorithm and custom configuration dictionary for each backend.\n\n\n\n\n4.c Train model and predict with Core class\nUse the val_size parameter of the fit method to control the length of the validation set. In this case we set the validation set as twice the forecasting horizon.\n\nnf = NeuralForecast(models=[model], freq='M')\nnf.fit(df=Y_df, val_size=24)\n\nGlobal seed set to 6\nGlobal seed set to 6\nGlobal seed set to 1\nGlobal seed set to 1\nGlobal seed set to 7\nGlobal seed set to 4\nGlobal seed set to 9\nGlobal seed set to 8\nGlobal seed set to 7\nGlobal seed set to 7\nGlobal seed set to 6\n\n\nThe results of the hyperparameter tuning are available in the results attribute of the Auto model. Use the trials_dataframe method to get the results in a pandas dataframe.\n\nresults = nf.models[0].results.trials_dataframe()\nresults.drop(columns='user_attrs_ALL_PARAMS')\n\n\n\n\n\n\n\n\nnumber\nvalue\ndatetime_start\ndatetime_complete\nduration\nparams_learning_rate\nparams_n_freq_downsample\nparams_n_pool_kernel_size\nparams_random_seed\nstate\n\n\n\n\n0\n0\n2.964735e+01\n2023-10-23 19:13:30.251719\n2023-10-23 19:13:33.007086\n0 days 00:00:02.755367\n0.000074\n[24, 12, 1]\n[2, 2, 2]\n2\nCOMPLETE\n\n\n1\n1\n2.790444e+03\n2023-10-23 19:13:33.007483\n2023-10-23 19:13:35.823089\n0 days 00:00:02.815606\n0.026500\n[24, 12, 1]\n[2, 2, 2]\n10\nCOMPLETE\n\n\n2\n2\n2.193000e+01\n2023-10-23 19:13:35.823607\n2023-10-23 19:13:38.599414\n0 days 00:00:02.775807\n0.000337\n[168, 24, 1]\n[2, 2, 2]\n7\nCOMPLETE\n\n\n3\n3\n1.147799e+08\n2023-10-23 19:13:38.600149\n2023-10-23 19:13:41.440307\n0 days 00:00:02.840158\n0.059274\n[1, 1, 1]\n[16, 8, 1]\n5\nCOMPLETE\n\n\n4\n4\n2.140740e+01\n2023-10-23 19:13:41.440833\n2023-10-23 19:13:44.184860\n0 days 00:00:02.744027\n0.000840\n[168, 24, 1]\n[16, 8, 1]\n5\nCOMPLETE\n\n\n5\n5\n1.606544e+01\n2023-10-23 19:13:44.185291\n2023-10-23 19:13:46.945672\n0 days 00:00:02.760381\n0.005477\n[1, 1, 1]\n[16, 8, 1]\n8\nCOMPLETE\n\n\n6\n6\n1.301640e+04\n2023-10-23 19:13:46.946108\n2023-10-23 19:13:49.805633\n0 days 00:00:02.859525\n0.056746\n[1, 1, 1]\n[16, 8, 1]\n3\nCOMPLETE\n\n\n7\n7\n4.972713e+01\n2023-10-23 19:13:49.806278\n2023-10-23 19:13:52.577180\n0 days 00:00:02.770902\n0.000021\n[24, 12, 1]\n[2, 2, 2]\n9\nCOMPLETE\n\n\n8\n8\n2.138879e+01\n2023-10-23 19:13:52.577678\n2023-10-23 19:13:55.372792\n0 days 00:00:02.795114\n0.007136\n[1, 1, 1]\n[2, 2, 2]\n9\nCOMPLETE\n\n\n9\n9\n2.094145e+01\n2023-10-23 19:13:55.373149\n2023-10-23 19:13:58.125058\n0 days 00:00:02.751909\n0.004655\n[1, 1, 1]\n[2, 2, 2]\n6\nCOMPLETE\n\n\n\n\n\n\n\nNext, we use the predict method to forecast the next 12 months using the optimal hyperparameters.\n\nY_hat_df_optuna = nf.predict()\nY_hat_df_optuna = Y_hat_df_optuna.reset_index()\nY_hat_df_optuna.head()\n\nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00, 112.75it/s]\n\n\n\n\n\n\n\n\n\nunique_id\nds\nAutoNHITS\n\n\n\n\n0\n1.0\n1961-01-31\n445.272858\n\n\n1\n1.0\n1961-02-28\n469.633423\n\n\n2\n1.0\n1961-03-31\n475.265289\n\n\n3\n1.0\n1961-04-30\n483.228516\n\n\n4\n1.0\n1961-05-31\n516.583496"
  },
  {
    "objectID": "examples/automatic_hyperparameter_tuning.html#plots",
    "href": "examples/automatic_hyperparameter_tuning.html#plots",
    "title": "Hyperparameter Optimization",
    "section": "5. Plots",
    "text": "5. Plots\nFinally, we compare the forecasts produced by the AutoNHITS model with both backends.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nfig, ax = plt.subplots(1, 1, figsize = (20, 7))\nplot_df = pd.concat([Y_df, Y_hat_df]).reset_index()\n\nplt.plot(plot_df['ds'], plot_df['y'], label='y')\nplt.plot(plot_df['ds'], plot_df['AutoNHITS'], label='Ray')\nplt.plot(Y_hat_df_optuna['ds'], Y_hat_df_optuna['AutoNHITS'], label='Optuna')\n\nax.set_title('AirPassengers Forecast', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp [t]', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\n\n\n\n\n\nReferences\n\nCristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2021). NHITS: Neural Hierarchical Interpolation for Time Series Forecasting. Accepted at AAAI 2023.\nJames Bergstra, Remi Bardenet, Yoshua Bengio, and Balazs Kegl (2011). “Algorithms for Hyper-Parameter Optimization”. In: Advances in Neural Information Processing Systems. url: https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf\nKirthevasan Kandasamy, Karun Raju Vysyaraju, Willie Neiswanger, Biswajit Paria, Christopher R. Collins, Jeff Schneider, Barnabas Poczos, Eric P. Xing (2019). “Tuning Hyperparameters without Grad Students: Scalable and Robust Bayesian Optimisation with Dragonfly”. Journal of Machine Learning Research. url: https://arxiv.org/abs/1903.06694\nLisha Li, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, Ameet Talwalkar (2016). “Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization”. Journal of Machine Learning Research. url: https://arxiv.org/abs/1603.06560"
  },
  {
    "objectID": "examples/forecasting_tft.html",
    "href": "examples/forecasting_tft.html",
    "title": "TFT: Temporal Fusion Transformer",
    "section": "",
    "text": "Temporal Fusion Transformer (TFT) proposed by Lim et al. [1] is one of the most popular transformer-based model for time-series forecasting. In summary, TFT combines gating layers, an LSTM recurrent encoder, with multi-head attention layers for a multi-step forecasting strategy decoder. For more details on the Nixtla’s TFT implementation visit this link.\nIn this notebook we show how to train the TFT model on the Texas electricity market load data (ERCOT). Accurately forecasting electricity markets is of great interest, as it is useful for planning distribution and consumption.\nWe will show you how to load the data, train the TFT performing automatic hyperparameter tuning, and produce forecasts. Then, we will show you how to perform multiple historical forecasts for cross validation.\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/forecasting_tft.html#libraries",
    "href": "examples/forecasting_tft.html#libraries",
    "title": "TFT: Temporal Fusion Transformer",
    "section": "1. Libraries",
    "text": "1. Libraries\n\n!pip install neuralforecast\n\n\nimport torch\nimport numpy as np\nimport pandas as pd\n\n\ntorch.cuda.is_available()\n\nTrue"
  },
  {
    "objectID": "examples/forecasting_tft.html#load-ercot-data",
    "href": "examples/forecasting_tft.html#load-ercot-data",
    "title": "TFT: Temporal Fusion Transformer",
    "section": "2. Load ERCOT Data",
    "text": "2. Load ERCOT Data\nThe input to NeuralForecast is always a data frame in long format with three columns: unique_id, ds and y:\n\nThe unique_id (string, int or category) represents an identifier for the series.\nThe ds (datestamp or int) column should be either an integer indexing time or a datestamp ideally like YYYY-MM-DD for a date or YYYY-MM-DD HH:MM:SS for a timestamp.\nThe y (numeric) represents the measurement we wish to forecast. We will rename the\n\nFirst, read the 2022 historic total demand of the ERCOT market. We processed the original data (available here), by adding the missing hour due to daylight saving time, parsing the date to datetime format, and filtering columns of interest.\n\nY_df = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/ERCOT-clean.csv')\nY_df['ds'] = pd.to_datetime(Y_df['ds'])\nY_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\nERCOT\n2021-01-01 00:00:00\n43719.849616\n\n\n1\nERCOT\n2021-01-01 01:00:00\n43321.050347\n\n\n2\nERCOT\n2021-01-01 02:00:00\n43063.067063\n\n\n3\nERCOT\n2021-01-01 03:00:00\n43090.059203\n\n\n4\nERCOT\n2021-01-01 04:00:00\n43486.590073"
  },
  {
    "objectID": "examples/forecasting_tft.html#model-training-and-forecast",
    "href": "examples/forecasting_tft.html#model-training-and-forecast",
    "title": "TFT: Temporal Fusion Transformer",
    "section": "3. Model training and forecast",
    "text": "3. Model training and forecast\nFirst, instantiate the AutoTFT model. The AutoTFT class will automatically perform hyperparamter tunning using Tune library, exploring a user-defined or default search space. Models are selected based on the error on a validation set and the best model is then stored and used during inference.\nTo instantiate AutoTFT you need to define:\n\nh: forecasting horizon\nloss: training loss\nconfig: hyperparameter search space. If None, the AutoTFT class will use a pre-defined suggested hyperparameter space.\nnum_samples: number of configurations explored.\n\n\nfrom ray import tune\n\nfrom neuralforecast.auto import AutoTFT\nfrom neuralforecast.core import NeuralForecast\nfrom neuralforecast.losses.pytorch import MAE\n\nimport logging\nlogging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n\n\n\n\n\n\n\nTip\n\n\n\nIncrease the num_samples parameter to explore a wider set of configurations for the selected models. As a rule of thumb choose it to be bigger than 15.\nWith num_samples=3 this example should run in around 20 minutes.\n\n\n\nhorizon = 24\nmodels = [AutoTFT(h=horizon,\n                  loss=MAE(),\n                  config=None,\n                  num_samples=3)]\n\n\n\n\n\n\n\nTip\n\n\n\nAll our models can be used for both point and probabilistic forecasting. For producing probabilistic outputs, simply modify the loss to one of our DistributionLoss. The complete list of losses is available in this link\n\n\n\n\n\n\n\n\nImportant\n\n\n\n\n\nTFT is a very large model and can require a lot of memory! If you are running out of GPU memory, try declaring your config search space and decrease the hidden_size, n_heads, and windows_batch_size parameters.\nThis are all the parameters of the config:\nconfig = {\n      \"input_size\": tune.choice([horizon]),\n      \"hidden_size\": tune.choice([32]),\n      \"n_head\": tune.choice([2]),\n      \"learning_rate\": tune.loguniform(1e-4, 1e-1),\n      \"scaler_type\": tune.choice(['robust', 'standard']),\n      \"max_steps\": tune.choice([500, 1000]),\n      \"windows_batch_size\": tune.choice([32]),\n      \"check_val_every_n_epoch\": tune.choice([100]),\n      \"random_seed\": tune.randint(1, 20),\n}\n\n\n\nThe NeuralForecast class has built-in methods to simplify the forecasting pipelines, such as fit, predit, and cross_validation. Instantiate a NeuralForecast object with the following required parameters:\n\nmodels: a list of models.\nfreq: a string indicating the frequency of the data. (See panda’s available frequencies.)\n\nThen, use the fit method to train the AutoTFT model on the ERCOT data. The total training time will depend on the hardware and the explored configurations, it should take between 10 and 30 minutes.\n\nnf = NeuralForecast(\n    models=models,\n    freq='H')\n\nnf.fit(df=Y_df)\n\nFinally, use the predict method to forecast the next 24 hours after the training data and plot the forecasts.\n\nY_hat_df = nf.predict()\nY_hat_df.head()\n\n\n\n\n\n\n\n\n\n\n\nds\nAutoTFT\n\n\nunique_id\n\n\n\n\n\n\nERCOT\n2022-10-01 00:00:00\n38644.019531\n\n\nERCOT\n2022-10-01 01:00:00\n36833.121094\n\n\nERCOT\n2022-10-01 02:00:00\n35698.265625\n\n\nERCOT\n2022-10-01 03:00:00\n35065.148438\n\n\nERCOT\n2022-10-01 04:00:00\n34788.566406\n\n\n\n\n\n\n\nPlot the results with matplot lib\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 1, figsize = (10, 3))\nplot_df = pd.concat([Y_df.tail(24*5).reset_index(drop=True), Y_hat_df]).set_index('ds') # Concatenate the train and forecast dataframes\nplot_df[['y', 'AutoTFT']].plot(ax=ax, linewidth=2)\n\nax.set_title('Load [MW]', fontsize=12)\nax.set_ylabel('Monthly Passengers', fontsize=12)\nax.set_xlabel('Date', fontsize=12)\nax.legend(prop={'size': 10})\nax.grid()"
  },
  {
    "objectID": "examples/forecasting_tft.html#cross-validation-for-multiple-historic-forecasts",
    "href": "examples/forecasting_tft.html#cross-validation-for-multiple-historic-forecasts",
    "title": "TFT: Temporal Fusion Transformer",
    "section": "4. Cross validation for multiple historic forecasts",
    "text": "4. Cross validation for multiple historic forecasts\nThe cross_validation method allows you to simulate multiple historic forecasts, greatly simplifying pipelines by replacing for loops with fit and predict methods. See this tutorial for an animation of how the windows are defined.\nWith time series data, cross validation is done by defining a sliding window across the historical data and predicting the period following it. This form of cross validation allows us to arrive at a better estimation of our model’s predictive abilities across a wider range of temporal instances while also keeping the data in the training set contiguous as is required by our models. The cross_validation method will use the validation set for hyperparameter selection, and will then produce the forecasts for the test set.\nUse the cross_validation method to produce all the daily forecasts for September. Set the validation and test sizes. To produce daily forecasts set the forecasting set the step size between windows as 24, to only produce one forecast per day.\n\nval_size  = 90*24 # 90 days x 24 hours\ntest_size = 30*24 # 30 days x 24 hours\nfcst_df = nf.cross_validation(df=Y_df, val_size=val_size, test_size=test_size,\n                                n_windows=None, step_size=horizon)\n\nFinally, we merge the forecasts with the Y_df dataset and plot the forecasts.\n\nY_hat_df = fcst_df.reset_index(drop=True)\nY_hat_df = Y_hat_df.drop(columns=['y','cutoff'])\n\n\nplot_df = Y_df.merge(Y_hat_df, on=['unique_id','ds'], how='outer').tail(test_size+24*7)\n\nplt.figure(figsize=(20,5))\nplt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\nplt.plot(plot_df['ds'], plot_df['AutoTFT'], c='blue', label='Forecast')\nplt.axvline(pd.to_datetime('2022-09-01'), color='red', linestyle='-.')\nplt.legend()\nplt.grid()\nplt.plot()\n\n[]"
  },
  {
    "objectID": "examples/forecasting_tft.html#next-steps",
    "href": "examples/forecasting_tft.html#next-steps",
    "title": "TFT: Temporal Fusion Transformer",
    "section": "Next Steps",
    "text": "Next Steps\nIn Challu et al [2] we demonstrate that the N-HiTS model outperforms the latest transformers by more than 20% with 50 times less computation.\nLearn how to use the N-HiTS and the NeuralForecast library in this tutorial."
  },
  {
    "objectID": "examples/forecasting_tft.html#references",
    "href": "examples/forecasting_tft.html#references",
    "title": "TFT: Temporal Fusion Transformer",
    "section": "References",
    "text": "References\n[1] Lim, B., Arık, S. Ö., Loeff, N., & Pfister, T. (2021). Temporal fusion transformers for interpretable multi-horizon time series forecasting. International Journal of Forecasting, 37(4), 1748-1764..\n[2] Cristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2021). N-HiTS: Neural Hierarchical Interpolation for Time Series Forecasting. Accepted at AAAI 2023."
  },
  {
    "objectID": "examples/transfer_learning.html",
    "href": "examples/transfer_learning.html",
    "title": "Transfer Learning",
    "section": "",
    "text": "Transfer learning refers to the process of pre-training a flexible model on a large dataset and using it later on other data with little to no training. It is one of the most outstanding 🚀 achievements in Machine Learning 🧠 and has many practical applications.\nFor time series forecasting, the technique allows you to get lightning-fast predictions ⚡ bypassing the tradeoff between accuracy and speed (more than 30 times faster than our alreadsy fast autoARIMA for a similar accuracy).\nThis notebook shows how to generate a pre-trained model and store it in a checkpoint to make it available to forecast new time series never seen by the model.\nTable of Contents 1. Installing NeuralForecast/DatasetsForecast 2. Load M4 Data 3. Instantiate NeuralForecast core, Fit, and save 4. Load pre-trained model and predict on AirPassengers 5. Evaluate Results\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/transfer_learning.html#installing-libraries",
    "href": "examples/transfer_learning.html#installing-libraries",
    "title": "Transfer Learning",
    "section": "1. Installing Libraries",
    "text": "1. Installing Libraries\n\n# %%capture\n# !pip install git+https://github.com/Nixtla/datasetsforecast.git@main\n\n\n# %%capture\n# !pip install neuralforecast\n\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom IPython.display import display, Markdown\n\nimport matplotlib.pyplot as plt\n\nfrom datasetsforecast.m4 import M4\nfrom neuralforecast.core import NeuralForecast\nfrom neuralforecast.models import NHITS\nfrom neuralforecast.utils import AirPassengersDF\nfrom neuralforecast.losses.numpy import mae, mse\n\n\nimport logging\nlogging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n\nThis example will automatically run on GPUs if available. Make sure cuda is available. (If you need help to put this into production send us an email or join or community, we also offer a fully hosted solution)\n\ntorch.cuda.is_available()"
  },
  {
    "objectID": "examples/transfer_learning.html#load-m4-data",
    "href": "examples/transfer_learning.html#load-m4-data",
    "title": "Transfer Learning",
    "section": "2. Load M4 Data",
    "text": "2. Load M4 Data\nThe M4 class will automatically download the complete M4 dataset and process it.\nIt return three Dataframes: Y_df contains the values for the target variables, X_df contains exogenous calendar features and S_df contains static features for each time-series (none for M4). For this example we will only use Y_df.\nIf you want to use your own data just replace Y_df. Be sure to use a long format and have a simmilar structure than our data set.\n\nY_df, _, _ = M4.load(directory='./', group='Monthly', cache=True)\nY_df['ds'] = pd.to_datetime(Y_df['ds'])\nY_df"
  },
  {
    "objectID": "examples/transfer_learning.html#model-train-and-save",
    "href": "examples/transfer_learning.html#model-train-and-save",
    "title": "Transfer Learning",
    "section": "3. Model Train and Save",
    "text": "3. Model Train and Save\nUsing the NeuralForecast.fit method you can train a set of models to your dataset. You just have to define the input_size and horizon of your model. The input_size is the number of historic observations (lags) that the model will use to learn to predict h steps in the future. Also, you can modify the hyperparameters of the model to get a better accuracy.\n\nhorizon = 12\nstacks = 3\nmodels = [NHITS(input_size=5 * horizon,\n                h=horizon,\n                max_steps=100,\n                stack_types = stacks*['identity'],\n                n_blocks = stacks*[1],\n                mlp_units = [[256,256] for _ in range(stacks)],\n                n_pool_kernel_size = stacks*[1],\n                batch_size = 32,\n                scaler_type='standard',\n                n_freq_downsample=[12,4,1])]\nnf = NeuralForecast(models=models, freq='M')\nnf.fit(df=Y_df)\n\nSave model with core.NeuralForecast.save method. This method uses PytorchLightning save_checkpoint function. We set save_dataset=False to only save the model.\n\nnf.save(path='./results/transfer/', model_index=None, overwrite=True, save_dataset=False)"
  },
  {
    "objectID": "examples/transfer_learning.html#transfer-m4-to-airpassengers",
    "href": "examples/transfer_learning.html#transfer-m4-to-airpassengers",
    "title": "Transfer Learning",
    "section": "4. Transfer M4 to AirPassengers",
    "text": "4. Transfer M4 to AirPassengers\nWe load the stored model with the core.NeuralForecast.load method, and forecast AirPassenger with the core.NeuralForecast.predict function.\n\nfcst2 = NeuralForecast.load(path='./results/transfer/')\n\n\n# We define the train df. \nY_df = AirPassengersDF.copy()\nmean = Y_df[Y_df.ds&lt;='1959-12-31']['y'].mean()\nstd = Y_df[Y_df.ds&lt;='1959-12-31']['y'].std()\n\nY_train_df = Y_df[Y_df.ds&lt;='1959-12-31'] # 132 train\nY_test_df = Y_df[Y_df.ds&gt;'1959-12-31']   # 12 test\n\n\nY_hat_df = fcst2.predict(df=Y_train_df).reset_index()\nY_hat_df.head()\n\n\nfig, ax = plt.subplots(1, 1, figsize = (20, 7))\nY_hat_df = Y_test_df.merge(Y_hat_df, how='left', on=['unique_id', 'ds'])\nplot_df = pd.concat([Y_train_df, Y_hat_df]).set_index('ds')\n\nplot_df[['y', 'NHITS']].plot(ax=ax, linewidth=2)\n\nax.set_title('AirPassengers Forecast', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp [t]', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()"
  },
  {
    "objectID": "examples/transfer_learning.html#evaluate-results",
    "href": "examples/transfer_learning.html#evaluate-results",
    "title": "Transfer Learning",
    "section": "5. Evaluate Results",
    "text": "5. Evaluate Results\nWe evaluate the forecasts of the pre-trained model with the Mean Absolute Error (mae).\n\\[\n\\qquad MAE = \\frac{1}{Horizon} \\sum_{\\tau} |y_{\\tau} - \\hat{y}_{\\tau}|\\qquad\n\\]\n\ny_true = Y_test_df.y.values\ny_hat = Y_hat_df['NHITS'].values\n\n\nprint('NHITS     MAE: %0.3f' % mae(y_hat, y_true))\nprint('ETS       MAE: 16.222')\nprint('AutoARIMA MAE: 18.551')"
  },
  {
    "objectID": "examples/models_intro.html",
    "href": "examples/models_intro.html",
    "title": "NeuralForecast’s Contents",
    "section": "",
    "text": "Automatic forecasting tools optimize the hyperparameters of a given model class and select the best-performing model for a validation set. The optimization methods include grid search, random search, and Bayesian optimization.\n\n\n\n\n\n\n\n\n\n\nMLP-Based\nRNN-Based\nTransformers\nCNN-Based\nMultivariate\n\n\n\n\nAutoMLP\nAutoRNN\nAutoTFT\nAutoTimesNet\nAutoStemGNN\n\n\nAutoNBEATS\nAutoLSTM\nAutoInformer\n\nAutoHINT\n\n\nAutoNBEATSx\nAutoGRU\nAutoformer\n\n\n\n\nAutoNHITS\nAutoTCN\nAutoPatchTST\n\n\n\n\n\nAutoDeepAR\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/models_intro.html#automatic-forecasting-models",
    "href": "examples/models_intro.html#automatic-forecasting-models",
    "title": "NeuralForecast’s Contents",
    "section": "",
    "text": "Automatic forecasting tools optimize the hyperparameters of a given model class and select the best-performing model for a validation set. The optimization methods include grid search, random search, and Bayesian optimization.\n\n\n\n\n\n\n\n\n\n\nMLP-Based\nRNN-Based\nTransformers\nCNN-Based\nMultivariate\n\n\n\n\nAutoMLP\nAutoRNN\nAutoTFT\nAutoTimesNet\nAutoStemGNN\n\n\nAutoNBEATS\nAutoLSTM\nAutoInformer\n\nAutoHINT\n\n\nAutoNBEATSx\nAutoGRU\nAutoformer\n\n\n\n\nAutoNHITS\nAutoTCN\nAutoPatchTST\n\n\n\n\n\nAutoDeepAR"
  },
  {
    "objectID": "examples/models_intro.html#optimization-objectives",
    "href": "examples/models_intro.html#optimization-objectives",
    "title": "NeuralForecast’s Contents",
    "section": "Optimization Objectives",
    "text": "Optimization Objectives\nNeuralForecast is a highly modular framework capable of augmenting a wide variety of robust neural network architectures with different point or probability outputs as defined by their optimization objectives.\n\n\n\n\n\n\n\n\n\nScale-Dependent\nPercentage-Errors\nScale-Independent\nRobust\n\n\n\n\nMAE\nMAPE\nMASE\nHuber\n\n\nMSE\nsMAPE\n\nTukey\n\n\nRMSE\n\n\nHuberMQLoss\n\n\n\n\n\n\n\n\n\n\nParametric Probabilities\nNon-Parametric Probabilities\n\n\n\n\nNormal\nQuantileLoss\n\n\nStudenT\nMQLoss\n\n\nPoisson\nHuberQLoss\n\n\nNegative Binomial\nHuberMQLoss\n\n\nTweedie\n\n\n\nPMM /GMM"
  },
  {
    "objectID": "examples/models_intro.html#mlp-based-model-family",
    "href": "examples/models_intro.html#mlp-based-model-family",
    "title": "NeuralForecast’s Contents",
    "section": "MLP-Based Model Family",
    "text": "MLP-Based Model Family\nThe MLP-based family operates like a classic autoencoder. Its initial layers encode raw autoregressive window into a representation, and the decoder produces the desired output based on the horizon, probability output, or point objective. Recent architectures include modifications like residual learning techniques and task-specific changes.\n\n\n\n\n\n\n\n\n\n\nModel\nPoint Forecast\nProbabilistic Forecast\nInsample fitted values\nProbabilistic fitted values\n\n\n\n\nMLP\n✅\n✅\n✅\n✅\n\n\nNBEATS\n✅\n✅\n✅\n✅\n\n\nNBEATSx\n✅\n✅\n✅\n✅\n\n\nNHITS\n✅\n✅\n✅\n✅"
  },
  {
    "objectID": "examples/models_intro.html#rnn-based-model-family",
    "href": "examples/models_intro.html#rnn-based-model-family",
    "title": "NeuralForecast’s Contents",
    "section": "RNN-Based Model Family",
    "text": "RNN-Based Model Family\nThe RNN-based family attempts to leverage the data’s temporal structure while reducing MLPs over parametrization. Recurrent networks are dynamic and can handle sequences of varying lengths through a mechanism for updating internal states that considers the entire sequence history. Modern state modifications help diminish vanishing and exploding gradients.\n\n\n\n\n\n\n\n\n\n\nModel\nPoint Forecast\nProbabilistic Forecast\nInsample fitted values\nProbabilistic fitted values\n\n\n\n\nRNN\n✅\n✅\n✅\n✅\n\n\nGRU\n✅\n✅\n✅\n✅\n\n\nLSTM\n✅\n✅\n✅\n✅\n\n\nTCN\n✅\n✅\n✅\n✅\n\n\nDeepAR\n✅\n✅\n✅\n✅\n\n\nDilatedRNN\n✅\n✅\n✅\n✅"
  },
  {
    "objectID": "examples/models_intro.html#transformers-model-family",
    "href": "examples/models_intro.html#transformers-model-family",
    "title": "NeuralForecast’s Contents",
    "section": "Transformers Model Family",
    "text": "Transformers Model Family\nTransformer architectures are an alternative to recurrent networks. These networks build on the self-attention mechanism that directly allows modeling the relationship between different sequence parts without sequential processing. Attention makes Transformers more parallelizable than RNNs.\n\n\n\n\n\n\n\n\n\n\nModel\nPoint Forecast\nProbabilistic Forecast\nInsample fitted values\nProbabilistic fitted values\n\n\n\n\nTFT\n✅\n✅\n✅\n✅\n\n\nInformer\n✅\n✅\n✅\n✅\n\n\nAutoformer\n✅\n✅\n✅\n✅\n\n\nPatchTST\n✅\n✅\n✅\n✅\n\n\nVanillaTransformer\n✅\n✅\n✅\n✅"
  },
  {
    "objectID": "examples/models_intro.html#cnn-based-model-family",
    "href": "examples/models_intro.html#cnn-based-model-family",
    "title": "NeuralForecast’s Contents",
    "section": "CNN-Based Model Family",
    "text": "CNN-Based Model Family\nConvolutional Neural Networks (CNNs), originally celebrated for their accomplishments in image processing and computer vision, have also revealed substantial prowess in time series forecasting. Navigating through temporal data, CNNs utilize their convolutional layers to automatically and adaptively learn temporal patterns from the input data, offering an approach to uncovering subtle, underlying patterns embedded within a series of values.\n\n\n\nModel\nPoint Forecast\nProbabilistic Forecast\nInsample fitted values\nProbabilistic fitted values\n\n\n\n\nTimesNet\n✅\n✅\n✅\n✅"
  },
  {
    "objectID": "examples/predictive_maintenance.html",
    "href": "examples/predictive_maintenance.html",
    "title": "Predictive Maintenance",
    "section": "",
    "text": "Predictive maintenance (PdM) is a data-driven preventive maintanance program. It is a proactive maintenance strategy that uses sensors to monitor the performance and equipment conditions during operation. The PdM methods constantly analyze the data to predict when optimal maintenance schedules. It can reduce maintenance costs and prevent catastrophic equipment failure when used correctly.\nIn this notebook, we will apply NeuralForecast to perform a supervised Remaining Useful Life (RUL) estimation on the classic PHM2008 aircraft degradation dataset.\nOutline 1. Installing Packages 2. Load PHM2008 aircraft degradation dataset 3. Fit and Predict NeuralForecast 4. Evaluate Predictions\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/predictive_maintenance.html#installing-packages",
    "href": "examples/predictive_maintenance.html#installing-packages",
    "title": "Predictive Maintenance",
    "section": "1. Installing Packages",
    "text": "1. Installing Packages\n\n# %%capture\n# !pip install git+https://github.com/Nixtla/neuralforecast.git\n\n\n# %%capture\n# !pip install git+https://github.com/Nixtla/datasetsforecast.git\n\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nplt.rcParams['font.family'] = 'serif'\n\nfrom neuralforecast.models import NBEATSx, MLP\nfrom neuralforecast import NeuralForecast\n#from neuralforecast.losses.pytorch import DistributionLoss, HuberMQLoss, MQLoss\nfrom neuralforecast.losses.pytorch import HuberLoss, MAE\n\nfrom datasetsforecast.phm2008 import PHM2008"
  },
  {
    "objectID": "examples/predictive_maintenance.html#load-phm2008-aircraft-degradation-dataset",
    "href": "examples/predictive_maintenance.html#load-phm2008-aircraft-degradation-dataset",
    "title": "Predictive Maintenance",
    "section": "2. Load PHM2008 aircraft degradation dataset",
    "text": "2. Load PHM2008 aircraft degradation dataset\nHere we will load the Prognosis and Health Management 2008 challenge dataset. This dataset used the Commercial Modular Aero-Propulsion System Simulation to recreate the degradation process of turbofan engines for different aircraft with varying wear and manufacturing starting under normal conditions. The training dataset consists of complete run-to-failure simulations, while the test dataset comprises sequences before failure.\n\n\nY_train_df, Y_test_df = PHM2008.load(directory='./data', group='FD001', clip_rul=False)\nY_train_df\n\n\n\n\n\n\n\n\nunique_id\nds\ns_2\ns_3\ns_4\ns_7\ns_8\ns_9\ns_11\ns_12\ns_13\ns_14\ns_15\ns_17\ns_20\ns_21\ny\n\n\n\n\n0\n1\n1\n641.82\n1589.70\n1400.60\n554.36\n2388.06\n9046.19\n47.47\n521.66\n2388.02\n8138.62\n8.4195\n392\n39.06\n23.4190\n191\n\n\n1\n1\n2\n642.15\n1591.82\n1403.14\n553.75\n2388.04\n9044.07\n47.49\n522.28\n2388.07\n8131.49\n8.4318\n392\n39.00\n23.4236\n190\n\n\n2\n1\n3\n642.35\n1587.99\n1404.20\n554.26\n2388.08\n9052.94\n47.27\n522.42\n2388.03\n8133.23\n8.4178\n390\n38.95\n23.3442\n189\n\n\n3\n1\n4\n642.35\n1582.79\n1401.87\n554.45\n2388.11\n9049.48\n47.13\n522.86\n2388.08\n8133.83\n8.3682\n392\n38.88\n23.3739\n188\n\n\n4\n1\n5\n642.37\n1582.85\n1406.22\n554.00\n2388.06\n9055.15\n47.28\n522.19\n2388.04\n8133.80\n8.4294\n393\n38.90\n23.4044\n187\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n20626\n100\n196\n643.49\n1597.98\n1428.63\n551.43\n2388.19\n9065.52\n48.07\n519.49\n2388.26\n8137.60\n8.4956\n397\n38.49\n22.9735\n4\n\n\n20627\n100\n197\n643.54\n1604.50\n1433.58\n550.86\n2388.23\n9065.11\n48.04\n519.68\n2388.22\n8136.50\n8.5139\n395\n38.30\n23.1594\n3\n\n\n20628\n100\n198\n643.42\n1602.46\n1428.18\n550.94\n2388.24\n9065.90\n48.09\n520.01\n2388.24\n8141.05\n8.5646\n398\n38.44\n22.9333\n2\n\n\n20629\n100\n199\n643.23\n1605.26\n1426.53\n550.68\n2388.25\n9073.72\n48.39\n519.67\n2388.23\n8139.29\n8.5389\n395\n38.29\n23.0640\n1\n\n\n20630\n100\n200\n643.85\n1600.38\n1432.14\n550.79\n2388.26\n9061.48\n48.20\n519.30\n2388.26\n8137.33\n8.5036\n396\n38.37\n23.0522\n0\n\n\n\n\n20631 rows × 17 columns\n\n\n\n\nplot_df1 = Y_train_df[Y_train_df['unique_id']==1]\nplot_df2 = Y_train_df[Y_train_df['unique_id']==2]\nplot_df3 = Y_train_df[Y_train_df['unique_id']==3]\n\nplt.plot(plot_df1.ds, np.minimum(plot_df1.y, 125), color='#2D6B8F', linestyle='--')\nplt.plot(plot_df1.ds, plot_df1.y, color='#2D6B8F', label='Engine 1')\n\nplt.plot(plot_df2.ds, np.minimum(plot_df2.y, 125)+1.5, color='#CA6F6A', linestyle='--')\nplt.plot(plot_df2.ds, plot_df2.y+1.5, color='#CA6F6A', label='Engine 2')\n\nplt.plot(plot_df3.ds, np.minimum(plot_df3.y, 125)-1.5, color='#D5BC67', linestyle='--')\nplt.plot(plot_df3.ds, plot_df3.y-1.5, color='#D5BC67', label='Engine 3')\n\nplt.ylabel('Remaining Useful Life (RUL)', fontsize=15)\nplt.xlabel('Time Cycle', fontsize=15)\nplt.legend()\nplt.grid()\n\n\n\n\n\ndef smooth(s, b = 0.98):\n    v = np.zeros(len(s)+1) #v_0 is already 0.\n    bc = np.zeros(len(s)+1)\n    for i in range(1, len(v)): #v_t = 0.95\n        v[i] = (b * v[i-1] + (1-b) * s[i-1]) \n        bc[i] = 1 - b**i\n    sm = v[1:] / bc[1:]\n    return sm\n\nunique_id = 1\nplot_df = Y_train_df[Y_train_df.unique_id == unique_id].copy()\n\nfig, axes = plt.subplots(2,3, figsize = (8,5))\nfig.tight_layout()\n\nj = -1\n#, 's_11', 's_12', 's_13', 's_14', 's_15', 's_17', 's_20', 's_21'\nfor feature in ['s_2', 's_3', 's_4', 's_7', 's_8', 's_9']:\n    if ('s' in feature) and ('smoothed' not in feature):\n        j += 1\n        axes[j // 3, j % 3].plot(plot_df.ds, plot_df[feature], \n                                 c = '#2D6B8F', label = 'original')\n        axes[j // 3, j % 3].plot(plot_df.ds, smooth(plot_df[feature].values), \n                                 c = '#CA6F6A', label = 'smoothed')\n        #axes[j // 3, j % 3].plot([10,10],[0,1], c = 'black')\n        axes[j // 3, j % 3].set_title(feature)\n        axes[j // 3, j % 3].grid()\n        axes[j // 3, j % 3].legend()\n        \nplt.suptitle(f'Engine {unique_id} sensor records')\nplt.tight_layout()"
  },
  {
    "objectID": "examples/predictive_maintenance.html#fit-and-predict-neuralforecast",
    "href": "examples/predictive_maintenance.html#fit-and-predict-neuralforecast",
    "title": "Predictive Maintenance",
    "section": "3. Fit and Predict NeuralForecast",
    "text": "3. Fit and Predict NeuralForecast\nNeuralForecast methods are capable of addressing regression problems involving various variables. The regression problem involves predicting the target variable \\(y_{t+h}\\) based on its lags \\(y_{:t}\\), temporal exogenous features \\(x^{(h)}_{:t}\\), exogenous features available at the time of prediction \\(x^{(f)}_{:t+h}\\), and static features \\(x^{(s)}\\).\nThe task of estimating the remaining useful life (RUL) simplifies the problem to a single horizon prediction \\(h=1\\), where the objective is to predict \\(y_{t+1}\\) based on the exogenous features \\(x^{(f)}_{:t+1}\\) and static features \\(x^{(s)}\\). In the RUL estimation task, the exogenous features typically correspond to sensor monitoring information, while the target variable represents the RUL itself.\n\\[P(y_{t+1}\\;|\\;x^{(f)}_{:t+1},x^{(s)})\\]\n\nY_train_df, Y_test_df = PHM2008.load(directory='./data', group='FD001', clip_rul=True)\n\n\nfutr_exog_list =['s_2', 's_3', 's_4', 's_7', 's_8', 's_9', 's_11',\n                 's_12', 's_13', 's_14', 's_15', 's_17', 's_20', 's_21']\n\nmodel = NBEATSx(h=1, input_size=24,\n                loss=HuberLoss(),\n                scaler_type='robust',\n                stack_types=['identity', 'identity', 'identity'],\n                dropout_prob_theta=0.5,\n                futr_exog_list=futr_exog_list,\n                exclude_insample_y = True,\n                max_steps=1000)\nnf = NeuralForecast(models=[model], freq='M')\n\nnf.fit(df=Y_train_df)\nY_hat_df = nf.predict(futr_df=Y_test_df).reset_index() # By default last window?\n\nGlobal seed set to 1\n\n\n\nfilter_test_df = Y_test_df.groupby('unique_id').tail(31).reset_index()\nY_hat_df2 = nf.cross_validation(df=filter_test_df, n_windows=30, fit_models=False)"
  },
  {
    "objectID": "examples/predictive_maintenance.html#evaluate-predictions",
    "href": "examples/predictive_maintenance.html#evaluate-predictions",
    "title": "Predictive Maintenance",
    "section": "4. Evaluate Predictions",
    "text": "4. Evaluate Predictions\nIn the original PHM2008 dataset the true RUL values for the test set are only provided for the last time cycle of each enginge. We will filter the predictions to only evaluate the last time cycle.\n\\[RMSE(\\mathbf{y}_{T},\\hat{\\mathbf{y}}_{T}) = \\sqrt{\\frac{1}{|\\mathcal{D}_{test}|} \\sum_{i} (y_{i,T}-\\hat{y}_{i,T})^{2}}\\]\n\\[R2(\\mathbf{y}_{T},\\hat{\\mathbf{y}}_{T}) = 1- \\frac{\\sum_{i} (y_{i,T}-\\hat{y}_{i,T})^{2}}{\\sum_{i} (y_{i,T}-\\bar{y}_{i,T})^{2}}\\]\n\nfrom sklearn.metrics import r2_score\nfrom neuralforecast.losses.numpy import rmse\n\nmodel_name = repr(nf.models[0])\ny_last = Y_test_df[['unique_id', 'y']].groupby('unique_id').last().reset_index()\ny_hat_last = Y_hat_df[['unique_id', model_name]].groupby('unique_id').last().reset_index()\ny_last = y_last['y']\ny_hat_last = y_hat_last[model_name]\n\nrmse_eval = rmse(y=y_last, y_hat=y_hat_last)\nr2_eval = r2_score(y_true=y_last, y_pred=y_hat_last)\n\nprint(f'{model_name} Prognosis Evaluation')\nprint(f'RMSE:\\t {rmse_eval:.3f}')\nprint(f'R2:\\t {r2_eval:.3f}')\n\nNBEATSx Prognosis Evaluation\nRMSE:    4.119\nR2:  0.989\n\n\n\nplt.scatter(y_last, y_hat_last)\nplt.xlabel('True RUL', fontsize=15)\nplt.ylabel('RUL Prediction', fontsize=15)\nplt.grid()\n\n\n\n\n\nplot_df1 = Y_hat_df2[Y_hat_df2['unique_id']==1]\nplot_df2 = Y_hat_df2[Y_hat_df2['unique_id']==2]\nplot_df3 = Y_hat_df2[Y_hat_df2['unique_id']==3]\n\nplt.plot(plot_df1.ds, plot_df1['y'], c='#2D6B8F', label='E1 true RUL')\nplt.plot(plot_df1.ds, plot_df1[model_name]+1, c='#2D6B8F', linestyle='--', label='E1 predicted RUL')\n\nplt.plot(plot_df1.ds, plot_df2['y'], c='#CA6F6A', label='E2 true RUL')\nplt.plot(plot_df1.ds, plot_df2[model_name]+1, c='#CA6F6A', linestyle='--', label='E2 predicted RUL')\n\nplt.plot(plot_df1.ds, plot_df3['y'], c='#D5BC67', label='E3 true RUL')\nplt.plot(plot_df1.ds, plot_df3[model_name]+1, c='#D5BC67', linestyle='--', label='E3 predicted RUL')\n\nplt.legend()\nplt.grid()"
  },
  {
    "objectID": "examples/predictive_maintenance.html#references",
    "href": "examples/predictive_maintenance.html#references",
    "title": "Predictive Maintenance",
    "section": "References",
    "text": "References\n\nR. Keith Mobley (2002). “An Introduction to Predictive Maintenance”\nSaxena, A., Goebel, K., Simon, D.,&Eklund, N. (2008). “Damage propagation modeling for aircraft engine run-to-failure simulation”. International conference on prognostics and health management."
  },
  {
    "objectID": "examples/data_format.html",
    "href": "examples/data_format.html",
    "title": "Data Inputs",
    "section": "",
    "text": "In this example we will go through the dataset input requirements of the core.NeuralForecast class.\nThe core.NeuralForecast methods operate as global models that receive a set of time series rather than single series. The class uses cross-learning technique to fit flexible-shared models such as neural networks improving its generalization capabilities as shown by the M4 international forecasting competition (Smyl 2019, Semenoglou 2021).\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/data_format.html#long-format",
    "href": "examples/data_format.html#long-format",
    "title": "Data Inputs",
    "section": "Long format",
    "text": "Long format\n\nMultiple time series\nStore your time series in a pandas dataframe in long format, that is, each row represents an observation for a specific series and timestamp. Let’s see an example using the datasetsforecast library.\nY_df = pd.concat( [series1, series2, ...])\n\n!pip install datasetsforecast\n\n\nimport pandas as pd\nfrom datasetsforecast.m3 import M3\n\n\nY_df, *_ = M3.load('./data', group='Yearly')\n\n100%|██████████| 1.76M/1.76M [00:00&lt;00:00, 5.55MiB/s]\nINFO:datasetsforecast.utils:Successfully downloaded M3C.xls, 1757696, bytes.\n\n\n\nY_df.groupby('unique_id').head(2)\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\nY1\n1975-12-31\n940.66\n\n\n1\nY1\n1976-12-31\n1084.86\n\n\n20\nY10\n1975-12-31\n2160.04\n\n\n21\nY10\n1976-12-31\n2553.48\n\n\n40\nY100\n1975-12-31\n1424.70\n\n\n...\n...\n...\n...\n\n\n18260\nY97\n1976-12-31\n1618.91\n\n\n18279\nY98\n1975-12-31\n1164.97\n\n\n18280\nY98\n1976-12-31\n1277.87\n\n\n18299\nY99\n1975-12-31\n1870.00\n\n\n18300\nY99\n1976-12-31\n1307.20\n\n\n\n\n1290 rows × 3 columns\n\n\n\n\nY_df.groupby('unique_id').tail(2)\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n18\nY1\n1993-12-31\n8407.84\n\n\n19\nY1\n1994-12-31\n9156.01\n\n\n38\nY10\n1993-12-31\n3187.00\n\n\n39\nY10\n1994-12-31\n3058.00\n\n\n58\nY100\n1993-12-31\n3539.00\n\n\n...\n...\n...\n...\n\n\n18278\nY97\n1994-12-31\n4507.00\n\n\n18297\nY98\n1993-12-31\n1801.00\n\n\n18298\nY98\n1994-12-31\n1710.00\n\n\n18317\nY99\n1993-12-31\n2379.30\n\n\n18318\nY99\n1994-12-31\n2723.00\n\n\n\n\n1290 rows × 3 columns\n\n\n\nY_df is a dataframe with three columns: unique_id with a unique identifier for each time series, a column ds with the datestamp and a column y with the values of the series.\n\n\nSingle time series\nIf you have only one time series, you have to include the unique_id column. Consider, for example, the AirPassengers dataset.\n\nY_df = pd.read_csv('https://raw.githubusercontent.com/Nixtla/transfer-learning-time-series/main/datasets/air_passengers.csv')\n\nIn this example Y_df only contains two columns: timestamp, and value. To use NeuralForecast we have to include the unique_id column and rename the previuos ones.\n\nY_df['unique_id'] = 1. # We can add an integer as identifier\nY_df = Y_df.rename(columns={'timestamp': 'ds', 'value': 'y'})\nY_df = Y_df[['unique_id', 'ds', 'y']]\n\n\nY_df\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\n1.0\n1949-01-01\n112\n\n\n1\n1.0\n1949-02-01\n118\n\n\n2\n1.0\n1949-03-01\n132\n\n\n3\n1.0\n1949-04-01\n129\n\n\n4\n1.0\n1949-05-01\n121\n\n\n...\n...\n...\n...\n\n\n139\n1.0\n1960-08-01\n606\n\n\n140\n1.0\n1960-09-01\n508\n\n\n141\n1.0\n1960-10-01\n461\n\n\n142\n1.0\n1960-11-01\n390\n\n\n143\n1.0\n1960-12-01\n432\n\n\n\n\n144 rows × 3 columns"
  },
  {
    "objectID": "examples/data_format.html#references",
    "href": "examples/data_format.html#references",
    "title": "Data Inputs",
    "section": "References",
    "text": "References\n\nSlawek Smyl. (2019). “A hybrid method of exponential smoothing and recurrent networks for time series forecasting”. International Journal of Forecasting.\nArtemios-Anargyros Semenoglou, Evangelos Spiliotis, Spyros Makridakis, and Vassilios Assimakopoulos. (2021). Investigating the accuracy of cross-learning time series forecasting methods”. International Journal of Forecasting."
  },
  {
    "objectID": "common.scalers.html",
    "href": "common.scalers.html",
    "title": "TemporalNorm",
    "section": "",
    "text": "Figure 1. Illustration of temporal normalization (left), layer normalization (center) and batch normalization (right). The entries in green show the components used to compute the normalizing statistics.\n\n\n\n 1. Auxiliary Functions \n\n\nmasked_median\n\n masked_median (x, mask, dim=-1, keepdim=True)\n\nMasked Median\nCompute the median of tensor x along dim, ignoring values where mask is False. x and mask need to be broadcastable.\nParameters: x: torch.Tensor to compute median of along dim dimension. mask: torch Tensor bool with same shape as x, where x is valid and False where x should be masked. Mask should not be all False in any column of dimension dim to avoid NaNs from zero division. dim (int, optional): Dimension to take median of. Defaults to -1. keepdim (bool, optional): Keep dimension of x or not. Defaults to True.\nReturns: x_median: torch.Tensor with normalized values.\n\n\n\nmasked_mean\n\n masked_mean (x, mask, dim=-1, keepdim=True)\n\nMasked Mean\nCompute the mean of tensor x along dimension, ignoring values where mask is False. x and mask need to be broadcastable.\nParameters: x: torch.Tensor to compute mean of along dim dimension. mask: torch Tensor bool with same shape as x, where x is valid and False where x should be masked. Mask should not be all False in any column of dimension dim to avoid NaNs from zero division. dim (int, optional): Dimension to take mean of. Defaults to -1. keepdim (bool, optional): Keep dimension of x or not. Defaults to True.\nReturns: x_mean: torch.Tensor with normalized values.\n\n\n\n 2. Scalers \n\n\nminmax_statistics\n\n minmax_statistics (x, mask, eps=1e-06, dim=-1)\n\nMinMax Scaler\nStandardizes temporal features by ensuring its range dweels between [0,1] range. This transformation is often used as an alternative to the standard scaler. The scaled features are obtained as:\n\\[\\mathbf{z} = (\\mathbf{x}_{[B,T,C]}-\\mathrm{min}({\\mathbf{x}})_{[B,1,C]})/\n    (\\mathrm{max}({\\mathbf{x}})_{[B,1,C]}- \\mathrm{min}({\\mathbf{x}})_{[B,1,C]})\\]\nParameters: x: torch.Tensor input tensor. mask: torch Tensor bool, same dimension as x, indicates where x is valid and False where x should be masked. Mask should not be all False in any column of dimension dim to avoid NaNs from zero division. eps (float, optional): Small value to avoid division by zero. Defaults to 1e-6. dim (int, optional): Dimension over to compute min and max. Defaults to -1.\nReturns: z: torch.Tensor same shape as x, except scaled.\n\n\n\nminmax1_statistics\n\n minmax1_statistics (x, mask, eps=1e-06, dim=-1)\n\nMinMax1 Scaler\nStandardizes temporal features by ensuring its range dweels between [-1,1] range. This transformation is often used as an alternative to the standard scaler or classic Min Max Scaler. The scaled features are obtained as:\n\\[\\mathbf{z} = 2 (\\mathbf{x}_{[B,T,C]}-\\mathrm{min}({\\mathbf{x}})_{[B,1,C]})/ (\\mathrm{max}({\\mathbf{x}})_{[B,1,C]}- \\mathrm{min}({\\mathbf{x}})_{[B,1,C]})-1\\]\nParameters: x: torch.Tensor input tensor. mask: torch Tensor bool, same dimension as x, indicates where x is valid and False where x should be masked. Mask should not be all False in any column of dimension dim to avoid NaNs from zero division. eps (float, optional): Small value to avoid division by zero. Defaults to 1e-6. dim (int, optional): Dimension over to compute min and max. Defaults to -1.\nReturns: z: torch.Tensor same shape as x, except scaled.\n\n\n\nstd_statistics\n\n std_statistics (x, mask, dim=-1, eps=1e-06)\n\nStandard Scaler\nStandardizes features by removing the mean and scaling to unit variance along the dim dimension.\nFor example, for base_windows models, the scaled features are obtained as (with dim=1):\n\\[\\mathbf{z} = (\\mathbf{x}_{[B,T,C]}-\\bar{\\mathbf{x}}_{[B,1,C]})/\\hat{\\sigma}_{[B,1,C]}\\]\nParameters: x: torch.Tensor. mask: torch Tensor bool, same dimension as x, indicates where x is valid and False where x should be masked. Mask should not be all False in any column of dimension dim to avoid NaNs from zero division. eps (float, optional): Small value to avoid division by zero. Defaults to 1e-6. dim (int, optional): Dimension over to compute mean and std. Defaults to -1.\nReturns: z: torch.Tensor same shape as x, except scaled.\n\n\n\nrobust_statistics\n\n robust_statistics (x, mask, dim=-1, eps=1e-06)\n\nRobust Median Scaler\nStandardizes features by removing the median and scaling with the mean absolute deviation (mad) a robust estimator of variance. This scaler is particularly useful with noisy data where outliers can heavily influence the sample mean / variance in a negative way. In these scenarios the median and amd give better results.\nFor example, for base_windows models, the scaled features are obtained as (with dim=1):\n\\[\\mathbf{z} = (\\mathbf{x}_{[B,T,C]}-\\textrm{median}(\\mathbf{x})_{[B,1,C]})/\\textrm{mad}(\\mathbf{x})_{[B,1,C]}\\]\n\\[\\textrm{mad}(\\mathbf{x}) = \\frac{1}{N} \\sum_{}|\\mathbf{x} - \\mathrm{median}(x)|\\]\nParameters: x: torch.Tensor input tensor. mask: torch Tensor bool, same dimension as x, indicates where x is valid and False where x should be masked. Mask should not be all False in any column of dimension dim to avoid NaNs from zero division. eps (float, optional): Small value to avoid division by zero. Defaults to 1e-6. dim (int, optional): Dimension over to compute median and mad. Defaults to -1.\nReturns: z: torch.Tensor same shape as x, except scaled.\n\n\n\ninvariant_statistics\n\n invariant_statistics (x, mask, dim=-1, eps=1e-06)\n\nInvariant Median Scaler\nStandardizes features by removing the median and scaling with the mean absolute deviation (mad) a robust estimator of variance. Aditionally it complements the transformation with the arcsinh transformation.\nFor example, for base_windows models, the scaled features are obtained as (with dim=1):\n\\[\\mathbf{z} = (\\mathbf{x}_{[B,T,C]}-\\textrm{median}(\\mathbf{x})_{[B,1,C]})/\\textrm{mad}(\\mathbf{x})_{[B,1,C]}\\]\n\\[\\mathbf{z} = \\textrm{arcsinh}(\\mathbf{z})\\]\nParameters: x: torch.Tensor input tensor. mask: torch Tensor bool, same dimension as x, indicates where x is valid and False where x should be masked. Mask should not be all False in any column of dimension dim to avoid NaNs from zero division. eps (float, optional): Small value to avoid division by zero. Defaults to 1e-6. dim (int, optional): Dimension over to compute median and mad. Defaults to -1.\nReturns: z: torch.Tensor same shape as x, except scaled.\n\n\n\nidentity_statistics\n\n identity_statistics (x, mask, dim=-1, eps=1e-06)\n\nIdentity Scaler\nA placeholder identity scaler, that is argument insensitive.\nParameters: x: torch.Tensor input tensor. mask: torch Tensor bool, same dimension as x, indicates where x is valid and False where x should be masked. Mask should not be all False in any column of dimension dim to avoid NaNs from zero division. eps (float, optional): Small value to avoid division by zero. Defaults to 1e-6. dim (int, optional): Dimension over to compute median and mad. Defaults to -1.\nReturns: x: original torch.Tensor x.\n\n\n\n 3. TemporalNorm Module \n\n\nTemporalNorm\n\n TemporalNorm (scaler_type='robust', dim=-1, eps=1e-06, num_features=None)\n\nTemporal Normalization\nStandardization of the features is a common requirement for many machine learning estimators, and it is commonly achieved by removing the level and scaling its variance. The TemporalNorm module applies temporal normalization over the batch of inputs as defined by the type of scaler.\n\\[\\mathbf{z}_{[B,T,C]} = \\textrm{Scaler}(\\mathbf{x}_{[B,T,C]})\\]\nIf scaler_type is revin learnable normalization parameters are added on top of the usual normalization technique, the parameters are learned through scale decouple global skip connections. The technique is available for point and probabilistic outputs.\n\\[\\mathbf{\\hat{z}}_{[B,T,C]} = \\boldsymbol{\\hat{\\gamma}}_{[1,1,C]} \\mathbf{z}_{[B,T,C]} +\\boldsymbol{\\hat{\\beta}}_{[1,1,C]}\\]\nParameters: scaler_type: str, defines the type of scaler used by TemporalNorm. Available [identity, standard, robust, minmax, minmax1, invariant, revin]. dim (int, optional): Dimension over to compute scale and shift. Defaults to -1. eps (float, optional): Small value to avoid division by zero. Defaults to 1e-6. num_features: int=None, for RevIN-like learnable affine parameters initialization.\nReferences - Kin G. Olivares, David Luo, Cristian Challu, Stefania La Vattiata, Max Mergenthaler, Artur Dubrawski (2023). “HINT: Hierarchical Mixture Networks For Coherent Probabilistic Forecasting”. Neural Information Processing Systems, submitted. Working Paper version available at arxiv.\n\n\n\nTemporalNorm.transform\n\n TemporalNorm.transform (x, mask)\n\nCenter and scale the data.\nParameters: x: torch.Tensor shape [batch, time, channels]. mask: torch Tensor bool, shape [batch, time] where x is valid and False where x should be masked. Mask should not be all False in any column of dimension dim to avoid NaNs from zero division.\nReturns: z: torch.Tensor same shape as x, except scaled.\n\n\n\nTemporalNorm.inverse_transform\n\n TemporalNorm.inverse_transform (z, x_shift=None, x_scale=None)\n\nScale back the data to the original representation.\nParameters: z: torch.Tensor shape [batch, time, channels], scaled.\nReturns: x: torch.Tensor original data.\n\n\n\n Example \n\nimport numpy as np\n\n\n# Declare synthetic batch to normalize\nx1 = 10**0 * np.arange(36)[:, None]\nx2 = 10**1 * np.arange(36)[:, None]\n\nnp_x = np.concatenate([x1, x2], axis=1)\nnp_x = np.repeat(np_x[None, :,:], repeats=2, axis=0)\nnp_x[0,:,:] = np_x[0,:,:] + 100\n\nnp_mask = np.ones(np_x.shape)\nnp_mask[:, -12:, :] = 0\n\nprint(f'x.shape [batch, time, features]={np_x.shape}')\nprint(f'mask.shape [batch, time, features]={np_mask.shape}')\n\n\n# Validate scalers\nx = 1.0*torch.tensor(np_x)\nmask = torch.tensor(np_mask)\nscaler = TemporalNorm(scaler_type='standard', dim=1)\nx_scaled = scaler.transform(x=x, mask=mask)\nx_recovered = scaler.inverse_transform(x_scaled)\n\nplt.plot(x[0,:,0], label='x1', color='#78ACA8')\nplt.plot(x[0,:,1], label='x2',  color='#E3A39A')\nplt.title('Before TemporalNorm')\nplt.xlabel('Time')\nplt.legend()\nplt.show()\n\nplt.plot(x_scaled[0,:,0], label='x1', color='#78ACA8')\nplt.plot(x_scaled[0,:,1]+0.1, label='x2+0.1', color='#E3A39A')\nplt.title(f'TemporalNorm \\'{scaler.scaler_type}\\' ')\nplt.xlabel('Time')\nplt.legend()\nplt.show()\n\nplt.plot(x_recovered[0,:,0], label='x1', color='#78ACA8')\nplt.plot(x_recovered[0,:,1], label='x2', color='#E3A39A')\nplt.title('Recovered')\nplt.xlabel('Time')\nplt.legend()\nplt.show()\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": " Core ",
    "section": "",
    "text": "source\n\nNeuralForecast\n\n NeuralForecast (models:List[Any], freq:str,\n                 local_scaler_type:Optional[str]=None)\n\nThe core.StatsForecast class allows you to efficiently fit multiple NeuralForecast models for large sets of time series. It operates with pandas DataFrame df that identifies series and datestamps with the unique_id and ds columns. The y column denotes the target time series variable.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmodels\ntyping.List[typing.Any]\n\nInstantiated neuralforecast.models see collection here.\n\n\nfreq\nstr\n\nFrequency of the data, see panda’s available frequencies.\n\n\nlocal_scaler_type\ntyping.Optional[str]\nNone\nScaler to apply per-serie to all features before fitting, which is inverted after predicting.Can be ‘standard’, ‘robust’, ‘robust-iqr’, ‘minmax’ or ‘boxcox’\n\n\nReturns\nNeuralForecast\n\nReturns instantiated NeuralForecast class.\n\n\n\n\nsource\n\n\nNeuralForecast.fit\n\n NeuralForecast.fit (df:Optional[pandas.core.frame.DataFrame]=None,\n                     static_df:Optional[pandas.core.frame.DataFrame]=None,\n                     val_size:Optional[int]=0, sort_df:bool=True,\n                     use_init_models:bool=False, verbose:bool=False)\n\nFit the core.NeuralForecast.\nFit models to a large set of time series from DataFrame df. and store fitted models for later inspection.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\ntyping.Optional[pandas.core.frame.DataFrame]\nNone\nDataFrame with columns [unique_id, ds, y] and exogenous variables.If None, a previously stored dataset is required.\n\n\nstatic_df\ntyping.Optional[pandas.core.frame.DataFrame]\nNone\nDataFrame with columns [unique_id] and static exogenous.\n\n\nval_size\ntyping.Optional[int]\n0\nSize of validation set.\n\n\nsort_df\nbool\nTrue\nSort df before fitting.\n\n\nuse_init_models\nbool\nFalse\nUse initial model passed when NeuralForecast object was instantiated.\n\n\nverbose\nbool\nFalse\nPrint processing steps.\n\n\nReturns\nNeuralForecast\n\nReturns NeuralForecast class with fitted models.\n\n\n\n\nsource\n\n\nNeuralForecast.predict\n\n NeuralForecast.predict (df:Optional[pandas.core.frame.DataFrame]=None,\n                         static_df:Optional[pandas.core.frame.DataFrame]=N\n                         one, futr_df:Optional[pandas.core.frame.DataFrame\n                         ]=None, sort_df:bool=True, verbose:bool=False,\n                         **data_kwargs)\n\nPredict with core.NeuralForecast.\nUse stored fitted models to predict large set of time series from DataFrame df.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\ntyping.Optional[pandas.core.frame.DataFrame]\nNone\nDataFrame with columns [unique_id, ds, y] and exogenous variables.If a DataFrame is passed, it is used to generate forecasts.\n\n\nstatic_df\ntyping.Optional[pandas.core.frame.DataFrame]\nNone\nDataFrame with columns [unique_id] and static exogenous.\n\n\nfutr_df\ntyping.Optional[pandas.core.frame.DataFrame]\nNone\nDataFrame with [unique_id, ds] columns and df’s future exogenous.\n\n\nsort_df\nbool\nTrue\nSort df before fitting.\n\n\nverbose\nbool\nFalse\nPrint processing steps.\n\n\ndata_kwargs\nkwargs\n\nExtra arguments to be passed to the dataset within each model.\n\n\nReturns\npandas.DataFrame\n\nDataFrame with insample models columns for point predictions and probabilisticpredictions for all fitted models. \n\n\n\n\nsource\n\n\nNeuralForecast.cross_validation\n\n NeuralForecast.cross_validation\n                                  (df:Optional[pandas.core.frame.DataFrame\n                                  ]=None, static_df:Optional[pandas.core.f\n                                  rame.DataFrame]=None, n_windows:int=1,\n                                  step_size:int=1,\n                                  val_size:Optional[int]=0,\n                                  test_size:Optional[int]=None,\n                                  sort_df:bool=True,\n                                  use_init_models:bool=False,\n                                  verbose:bool=False, **data_kwargs)\n\nTemporal Cross-Validation with core.NeuralForecast.\ncore.NeuralForecast’s cross-validation efficiently fits a list of NeuralForecast models through multiple windows, in either chained or rolled manner.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\ntyping.Optional[pandas.core.frame.DataFrame]\nNone\nDataFrame with columns [unique_id, ds, y] and exogenous variables.If None, a previously stored dataset is required.\n\n\nstatic_df\ntyping.Optional[pandas.core.frame.DataFrame]\nNone\nDataFrame with columns [unique_id] and static exogenous.\n\n\nn_windows\nint\n1\nNumber of windows used for cross validation.\n\n\nstep_size\nint\n1\nStep size between each window.\n\n\nval_size\ntyping.Optional[int]\n0\nLength of validation size. If passed, set n_windows=None.\n\n\ntest_size\ntyping.Optional[int]\nNone\nLength of test size. If passed, set n_windows=None.\n\n\nsort_df\nbool\nTrue\nSort df before fitting.\n\n\nuse_init_models\nbool\nFalse\nUse initial model passed when object was instantiated.\n\n\nverbose\nbool\nFalse\nPrint processing steps.\n\n\ndata_kwargs\nkwargs\n\nExtra arguments to be passed to the dataset within each model.\n\n\nReturns\npandas.DataFrame\n\nDataFrame with insample models columns for point predictions and probabilisticpredictions for all fitted models. \n\n\n\n\nsource\n\n\nNeuralForecast.predict_insample\n\n NeuralForecast.predict_insample (step_size:int=1)\n\nPredict insample with core.NeuralForecast.\ncore.NeuralForecast’s predict_insample uses stored fitted models to predict historic values of a time series from the stored dataframe.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nstep_size\nint\n1\nStep size between each window.\n\n\nReturns\npandas.DataFrame\n\nDataFrame with insample predictions for all fitted models. \n\n\n\n\nsource\n\n\nNeuralForecast.save\n\n NeuralForecast.save (path:str, model_index:Optional[List]=None,\n                      save_dataset:bool=True, overwrite:bool=False)\n\nSave NeuralForecast core class.\ncore.NeuralForecast’s method to save current status of models, dataset, and configuration. Note that by default the models are not saving training checkpoints to save disk memory, to get them change the individual model **trainer_kwargs to include enable_checkpointing=True.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\n\nDirectory to save current status.\n\n\nmodel_index\ntyping.Optional[typing.List]\nNone\nList to specify which models from list of self.models to save.\n\n\nsave_dataset\nbool\nTrue\nWhether to save dataset or not.\n\n\noverwrite\nbool\nFalse\nWhether to overwrite files or not.\n\n\n\n\nsource\n\n\nNeuralForecast.load\n\n NeuralForecast.load (path, verbose=False, **kwargs)\n\nLoad NeuralForecast\ncore.NeuralForecast’s method to load checkpoint from path.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\n\nDirectory to save current status.\n\n\nverbose\nbool\nFalse\n\n\n\nkwargs\n\n\nAdditional keyword arguments to be passed to the functionload_from_checkpoint.\n\n\nReturns\nNeuralForecast\n\nInstantiated NeuralForecast class.\n\n\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.stemgnn.html",
    "href": "models.stemgnn.html",
    "title": "StemGNN",
    "section": "",
    "text": "The Spectral Temporal Graph Neural Network (StemGNN) is a Graph-based multivariate time-series forecasting model. StemGNN jointly learns temporal dependencies and inter-series correlations in the spectral domain, by combining Graph Fourier Transform (GFT) and Discrete Fourier Transform (DFT).\nThis method proved state-of-the-art performance on geo-temporal datasets such as Solar, METR-LA, and PEMS-BAY, and\nReferences -Defu Cao, Yujing Wang, Juanyong Duan, Ce Zhang, Xia Zhu, Congrui Huang, Yunhai Tong, Bixiong Xu, Jing Bai, Jie Tong, Qi Zhang (2020). “Spectral Temporal Graph Neural Network for Multivariate Time-series Forecasting”.\nsource\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.stemgnn.html#usage-examples",
    "href": "models.stemgnn.html#usage-examples",
    "title": "StemGNN",
    "section": "Usage Examples",
    "text": "Usage Examples\nTrain model and forecast future values with predict method.\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.utils import AirPassengersPanel, AirPassengersStatic\nfrom neuralforecast.losses.pytorch import MAE\n\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nmodel = StemGNN(h=12,\n                input_size=24,\n                n_series=2,\n                stat_exog_list=['airline1'],\n                futr_exog_list=['trend'],\n                scaler_type='robust',\n                max_steps=200,\n                early_stop_patience_steps=-1,\n                val_check_steps=10,\n                learning_rate=1e-3,\n                loss=MAE(),\n                valid_loss=None,\n                batch_size=32\n                )\n\nfcst = NeuralForecast(models=[model], freq='M')\nfcst.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\nforecasts = fcst.predict(futr_df=Y_test_df)\n\n\n# Plot quantile predictions\nY_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nplot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\nplt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\nplt.plot(plot_df['ds'], plot_df['StemGNN'], c='blue', label='Forecast')\nplt.legend()\nplt.grid()\n\nUsing cross_validation to forecast multiple historic values.\n\nfcst = NeuralForecast(models=[model], freq='M')\nforecasts = fcst.cross_validation(df=AirPassengersPanel, static_df=AirPassengersStatic, n_windows=2, step_size=12)\n\n\n# Plot quantile predictions\nY_hat_df = forecasts[forecasts['unique_id']=='Airline1']\nY_df = AirPassengersPanel[AirPassengersPanel['unique_id']=='Airline1']\n\nplt.plot(Y_df['ds'], Y_df['y'], c='black', label='True')\nplt.plot(Y_hat_df['ds'], Y_hat_df['StemGNN'], c='blue', label='Forecast')\nplt.legend()\nplt.grid()"
  },
  {
    "objectID": "common.modules.html",
    "href": "common.modules.html",
    "title": "NN Modules",
    "section": "",
    "text": "Multi-Layer Perceptron\n\nsource\n\n\n\n MLP (in_features, out_features, activation, hidden_size, num_layers,\n      dropout)\n\nMulti-Layer Perceptron Class\nParameters: in_features: int, dimension of input. out_features: int, dimension of output. activation: str, activation function to use. hidden_size: int, dimension of hidden layers. num_layers: int, number of hidden layers. dropout: float, dropout rate.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "common.modules.html#mlp",
    "href": "common.modules.html#mlp",
    "title": "NN Modules",
    "section": "",
    "text": "Multi-Layer Perceptron\n\nsource\n\n\n\n MLP (in_features, out_features, activation, hidden_size, num_layers,\n      dropout)\n\nMulti-Layer Perceptron Class\nParameters: in_features: int, dimension of input. out_features: int, dimension of output. activation: str, activation function to use. hidden_size: int, dimension of hidden layers. num_layers: int, number of hidden layers. dropout: float, dropout rate."
  },
  {
    "objectID": "common.modules.html#temporal-convolutions",
    "href": "common.modules.html#temporal-convolutions",
    "title": "NN Modules",
    "section": "2. Temporal Convolutions",
    "text": "2. Temporal Convolutions\nFor long time in deep learning, sequence modelling was synonymous with recurrent networks, yet several papers have shown that simple convolutional architectures can outperform canonical recurrent networks like LSTMs by demonstrating longer effective memory.\nReferences -van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Senior, A. W., & Kavukcuoglu, K. (2016). Wavenet: A generative model for raw audio. Computing Research Repository, abs/1609.03499. URL: http://arxiv.org/abs/1609.03499. arXiv:1609.03499. -Shaojie Bai, Zico Kolter, Vladlen Koltun. (2018). An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling. Computing Research Repository, abs/1803.01271. URL: https://arxiv.org/abs/1803.01271.\n\n\nChomp1d\n\n Chomp1d (horizon)\n\nChomp1d\nReceives x input of dim [N,C,T], and trims it so that only ‘time available’ information is used. Used by one dimensional causal convolutions CausalConv1d.\nParameters: horizon: int, length of outsample values to skip.\n\n\n\nCausalConv1d\n\n CausalConv1d (in_channels, out_channels, kernel_size, padding, dilation,\n               activation, stride:int=1)\n\nCausal Convolution 1d\nReceives x input of dim [N,C_in,T], and computes a causal convolution in the time dimension. Skipping the H steps of the forecast horizon, through its dilation. Consider a batch of one element, the dilated convolution operation on the \\(t\\) time step is defined:\n\\(\\mathrm{Conv1D}(\\mathbf{x},\\mathbf{w})(t) = (\\mathbf{x}_{[*d]} \\mathbf{w})(t) = \\sum^{K}_{k=1} w_{k} \\mathbf{x}_{t-dk}\\)\nwhere \\(d\\) is the dilation factor, \\(K\\) is the kernel size, \\(t-dk\\) is the index of the considered past observation. The dilation effectively applies a filter with skip connections. If \\(d=1\\) one recovers a normal convolution.\nParameters: in_channels: int, dimension of x input’s initial channels. out_channels: int, dimension of x outputs’s channels. activation: str, identifying activations from PyTorch activations. select from ‘ReLU’,‘Softplus’,‘Tanh’,‘SELU’, ‘LeakyReLU’,‘PReLU’,‘Sigmoid’. padding: int, number of zero padding used to the left. kernel_size: int, convolution’s kernel size. dilation: int, dilation skip connections.\nReturns: x: tensor, torch tensor of dim [N,C_out,T] activation(conv1d(inputs, kernel) + bias). \n\n\n\nTemporalConvolutionEncoder\n\n TemporalConvolutionEncoder (in_channels, out_channels, kernel_size,\n                             dilations, activation:str='ReLU')\n\nTemporal Convolution Encoder\nReceives x input of dim [N,T,C_in], permutes it to [N,C_in,T] applies a deep stack of exponentially dilated causal convolutions. The exponentially increasing dilations of the convolutions allow for the creation of weighted averages of exponentially large long-term memory.\nParameters: in_channels: int, dimension of x input’s initial channels. out_channels: int, dimension of x outputs’s channels. kernel_size: int, size of the convolving kernel. dilations: int list, controls the temporal spacing between the kernel points. activation: str, identifying activations from PyTorch activations. select from ‘ReLU’,‘Softplus’,‘Tanh’,‘SELU’, ‘LeakyReLU’,‘PReLU’,‘Sigmoid’.\nReturns: x: tensor, torch tensor of dim [N,T,C_out]."
  },
  {
    "objectID": "common.modules.html#transformers",
    "href": "common.modules.html#transformers",
    "title": "NN Modules",
    "section": "3. Transformers",
    "text": "3. Transformers\nReferences - Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, Wancai Zhang. “Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting” - Haixu Wu, Jiehui Xu, Jianmin Wang, Mingsheng Long.\n\n\nTransEncoder\n\n TransEncoder (attn_layers, conv_layers=None, norm_layer=None)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\n\n\nTransEncoderLayer\n\n TransEncoderLayer (attention, hidden_size, conv_hidden_size=None,\n                    dropout=0.1, activation='relu')\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\n\n\nTransDecoder\n\n TransDecoder (layers, norm_layer=None, projection=None)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\n\n\nTransDecoderLayer\n\n TransDecoderLayer (self_attention, cross_attention, hidden_size,\n                    conv_hidden_size=None, dropout=0.1, activation='relu')\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\n\n\nAttentionLayer\n\n AttentionLayer (attention, hidden_size, n_head, d_keys=None,\n                 d_values=None)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\n\n\nDataEmbedding\n\n DataEmbedding (c_in, exog_input_size, hidden_size, pos_embedding=True,\n                dropout=0.1)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\n\n\nTimeFeatureEmbedding\n\n TimeFeatureEmbedding (input_size, hidden_size)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\n\n\nTokenEmbedding\n\n TokenEmbedding (c_in, hidden_size)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\n\n\nPositionalEmbedding\n\n PositionalEmbedding (hidden_size, max_len=5000)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool"
  },
  {
    "objectID": "models.tft.html",
    "href": "models.tft.html",
    "title": "TFT",
    "section": "",
    "text": "In summary Temporal Fusion Transformer (TFT) combines gating layers, an LSTM recurrent encoder, with multi-head attention layers for a multi-step forecasting strategy decoder.TFT’s inputs are static exogenous \\(\\mathbf{x}^{(s)}\\), historic exogenous \\(\\mathbf{x}^{(h)}_{[:t]}\\), exogenous available at the time of the prediction \\(\\mathbf{x}^{(f)}_{[:t+H]}\\) and autorregresive features \\(\\mathbf{y}_{[:t]}\\), each of these inputs is further decomposed into categorical and continuous. The network uses a multi-quantile regression to model the following conditional probability:\\[\\mathbb{P}(\\mathbf{y}_{[t+1:t+H]}|\\;\\mathbf{y}_{[:t]},\\; \\mathbf{x}^{(h)}_{[:t]},\\; \\mathbf{x}^{(f)}_{[:t+H]},\\; \\mathbf{x}^{(s)})\\]\nReferences - Jan Golda, Krzysztof Kudrynski. “NVIDIA, Deep Learning Forecasting Examples” - Bryan Lim, Sercan O. Arik, Nicolas Loeff, Tomas Pfister, “Temporal Fusion Transformers for interpretable multi-horizon time series forecasting”\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.tft.html#auxiliary-functions",
    "href": "models.tft.html#auxiliary-functions",
    "title": "TFT",
    "section": "1. Auxiliary Functions",
    "text": "1. Auxiliary Functions\n\n1.1 Gating Mechanisms\nThe Gated Residual Network (GRN) provides adaptive depth and network complexity capable of accommodating different size datasets. As residual connections allow for the network to skip the non-linear transformation of input \\(\\mathbf{a}\\) and context \\(\\mathbf{c}\\).\n\\[\\begin{align}\n\\eta_{1} &= \\mathrm{ELU}(\\mathbf{W}_{1}\\mathbf{a}+\\mathbf{W}_{2}\\mathbf{c}+\\mathbf{b}_{1}) \\\\\n\\eta_{2} &= \\mathbf{W}_{2}\\eta_{1}+b_{2} \\\\\n\\mathrm{GRN}(\\mathbf{a}, \\mathbf{c}) &= \\mathrm{LayerNorm}(a + \\textrm{GLU}(\\eta_{2}))\n\\end{align}\\]\nThe Gated Linear Unit (GLU) provides the flexibility of supressing unnecesary parts of the GRN. Consider GRN’s output \\(\\gamma\\) then GLU transformation is defined by:\n\\[\\mathrm{GLU}(\\gamma) = \\sigma(\\mathbf{W}_{4}\\gamma +b_{4}) \\odot (\\mathbf{W}_{5}\\gamma +b_{5})\\]\n\n\n\nFigure 2. Gated Residual Network.\n\n\n\n\n1.2 Variable Selection Networks\nTFT includes automated variable selection capabilities, through its variable selection network (VSN) components. The VSN takes the original input \\(\\{\\mathbf{x}^{(s)}, \\mathbf{x}^{(h)}_{[:t]}, \\mathbf{x}^{(f)}_{[:t]}\\}\\) and transforms it through embeddings or linear transformations into a high dimensional space \\(\\{\\mathbf{E}^{(s)}, \\mathbf{E}^{(h)}_{[:t]}, \\mathbf{E}^{(f)}_{[:t+H]}\\}\\).\nFor the observed historic data, the embedding matrix \\(\\mathbf{E}^{(h)}_{t}\\) at time \\(t\\) is a concatenation of \\(j\\) variable \\(e^{(h)}_{t,j}\\) embeddings: \\[\\begin{align}\n\\mathbf{E}^{(h)}_{t} &= [e^{(h)}_{t,1},\\dots,e^{(h)}_{t,j},\\dots,e^{(h)}_{t,n_{h}}] \\\\\n\\mathbf{\\tilde{e}}^{(h)}_{t,j} &= \\mathrm{GRN}(e^{(h)}_{t,j})\n\\end{align}\\]\nThe variable selection weights are given by: \\[s^{(h)}_{t}=\\mathrm{SoftMax}(\\mathrm{GRN}(\\mathbf{E}^{(h)}_{t},\\mathbf{E}^{(s)}))\\]\nThe VSN processed features are then: \\[\\tilde{\\mathbf{E}}^{(h)}_{t}= \\sum_{j} s^{(h)}_{j} \\tilde{e}^{(h)}_{t,j}\\]\n\n\n\nFigure 3. Variable Selection Network.\n\n\n\n\n1.3. Multi-Head Attention\nTo avoid information bottlenecks from the classic Seq2Seq architecture, TFT incorporates a decoder-encoder attention mechanism inherited transformer architectures (Li et. al 2019, Vaswani et. al 2017). It transform the the outputs of the LSTM encoded temporal features, and helps the decoder better capture long-term relationships.\nThe original multihead attention for each component \\(H_{m}\\) and its query, key, and value representations are denoted by \\(Q_{m}, K_{m}, V_{m}\\), its transformation is given by:\n\\[\\begin{align}\nQ_{m} = Q W_{Q,m} \\quad K_{m} = K W_{K,h} \\quad V_{m} = V W_{V,m} \\\\\nH_{m}=\\mathrm{Attention}(Q_{m}, K_{m}, V_{m}) = \\mathrm{SoftMax}(Q_{m} K^{\\intercal}_{m}/\\mathrm{scale}) \\; V_{m} \\\\\n\\mathrm{MultiHead}(Q, K, V) = [H_{1},\\dots,H_{M}] W_{M}\n\\end{align}\\]\nTFT modifies the original multihead attention to improve its interpretability. To do it it uses shared values \\(\\tilde{V}\\) across heads and employs additive aggregation, \\(\\mathrm{InterpretableMultiHead}(Q,K,V) = \\tilde{H} W_{M}\\). The mechanism has a great resemblence to a single attention layer, but it allows for \\(M\\) multiple attention weights, and can be therefore be interpreted as the average ensemble of \\(M\\) single attention layers.\n\\[\\begin{align}\n\\tilde{H} &= \\left(\\frac{1}{M} \\sum_{m} \\mathrm{SoftMax}(Q_{m} K^{\\intercal}_{m}/\\mathrm{scale}) \\right) \\tilde{V}\n          = \\frac{1}{M} \\sum_{m} \\mathrm{Attention}(Q_{m}, K_{m}, \\tilde{V}) \\\\\n\\end{align}\\]"
  },
  {
    "objectID": "models.tft.html#tft-architecture",
    "href": "models.tft.html#tft-architecture",
    "title": "TFT",
    "section": "2. TFT Architecture",
    "text": "2. TFT Architecture\nThe first TFT’s step is embed the original input \\(\\{\\mathbf{x}^{(s)}, \\mathbf{x}^{(h)}, \\mathbf{x}^{(f)}\\}\\) into a high dimensional space \\(\\{\\mathbf{E}^{(s)}, \\mathbf{E}^{(h)}, \\mathbf{E}^{(f)}\\}\\), after which each embedding is gated by a variable selection network (VSN). The static embedding \\(\\mathbf{E}^{(s)}\\) is used as context for variable selection and as initial condition to the LSTM. Finally the encoded variables are fed into the multi-head attention decoder.\n\\[\\begin{align}\nc_{s}, c_{e}, (c_{h}, c_{c}) &=\\textrm{StaticCovariateEncoder}(\\mathbf{E}^{(s)}) \\\\\n      h_{[:t]}, h_{[t+1:t+H]}  &=\\textrm{TemporalCovariateEncoder}(\\mathbf{E}^{(h)}, \\mathbf{E}^{(f)}, c_{h}, c_{c}) \\\\\n\\hat{\\mathbf{y}}^{(q)}_{[t+1:t+H]} &=\\textrm{TemporalFusionDecoder}(h_{[t+1:t+H]}, c_{e})\n\\end{align}\\]\n\n2.1 Static Covariate Encoder\nThe static embedding \\(\\mathbf{E}^{(s)}\\) is transformed by the StaticCovariateEncoder into contexts \\(c_{s}, c_{e}, c_{h}, c_{c}\\). Where \\(c_{s}\\) are temporal variable selection contexts, \\(c_{e}\\) are TemporalFusionDecoder enriching contexts, and \\(c_{h}, c_{c}\\) are LSTM’s hidden/contexts for the TemporalCovariateEncoder.\n\\[\\begin{align}\nc_{s}, c_{e}, (c_{h}, c_{c}) & = \\textrm{GRN}(\\textrm{VSN}(\\mathbf{E}^{(s)}))\n\\end{align}\\]\n\n\n2.2 Temporal Covariate Encoder\nTemporalCovariateEncoder encodes the embeddings \\(\\mathbf{E}^{(h)}, \\mathbf{E}^{(f)}\\) and contexts \\((c_{h}, c_{c})\\) with an LSTM.\n\\[\\begin{align}\n\\tilde{\\mathbf{E}}^{(h)}_{[:t]} & = \\textrm{VSN}(\\mathbf{E}^{(h)}_{[:t]}, c_{s}) \\\\\n\\tilde{\\mathbf{E}}^{(h)}_{[:t]} &= \\mathrm{LSTM}(\\tilde{\\mathbf{E}}^{(h)}_{[:t]}, (c_{h}, c_{c})) \\\\\nh_{[:t]} &= \\mathrm{Gate}(\\mathrm{LayerNorm}(\\tilde{\\mathbf{E}}^{(h)}_{[:t]}))\n\\end{align}\\]\nAn analogous process is repeated for the future data, with the main difference that \\(\\mathbf{E}^{(f)}\\) contains the future available information.\n\\[\\begin{align}\n\\tilde{\\mathbf{E}}^{(f)}_{[t+1:t+h]} & = \\textrm{VSN}(\\mathbf{E}^{(h)}_{t+1:t+H}, \\mathbf{E}^{(f)}_{t+1:t+H}, c_{s}) \\\\\n\\tilde{\\mathbf{E}}^{(f)}_{[t+1:t+h]} &= \\mathrm{LSTM}(\\tilde{\\mathbf{E}}^{(h)}_{[t+1:t+h]}, (c_{h}, c_{c})) \\\\\nh_{[t+1:t+H]} &= \\mathrm{Gate}(\\mathrm{LayerNorm}(\\tilde{\\mathbf{E}}^{(f)}_{[t+1:t+h]}))\n\\end{align}\\]\n\n\n2.3 Temporal Fusion Decoder\nThe TemporalFusionDecoder enriches the LSTM’s outputs with \\(c_{e}\\) and then uses an attention layer, and multi-step adapter. \\[\\begin{align}\nh_{[t+1:t+H]} &= \\mathrm{MultiHeadAttention}(h_{[:t]}, h_{[t+1:t+H]}, c_{e}) \\\\\nh_{[t+1:t+H]} &= \\mathrm{Gate}(\\mathrm{LayerNorm}(h_{[t+1:t+H]}) \\\\\nh_{[t+1:t+H]} &= \\mathrm{Gate}(\\mathrm{LayerNorm}(\\mathrm{GRN}(h_{[t+1:t+H]})) \\\\\n\\hat{\\mathbf{y}}^{(q)}_{[t+1:t+H]} &= \\mathrm{MLP}(h_{[t+1:t+H]})\n\\end{align}\\]"
  },
  {
    "objectID": "models.tft.html#tft-methods",
    "href": "models.tft.html#tft-methods",
    "title": "TFT",
    "section": "3. TFT methods",
    "text": "3. TFT methods\n\nsource\n\nTFT\n\n TFT (h, input_size, tgt_size:int=1, stat_exog_list=None,\n      hist_exog_list=None, futr_exog_list=None, hidden_size:int=128,\n      n_head:int=4, attn_dropout:float=0.0, dropout:float=0.1, loss=MAE(),\n      valid_loss=None, max_steps:int=1000, learning_rate:float=0.001,\n      num_lr_decays:int=-1, early_stop_patience_steps:int=-1,\n      val_check_steps:int=100, batch_size:int=32,\n      valid_batch_size:Optional[int]=None, windows_batch_size:int=1024,\n      inference_windows_batch_size:int=1024, start_padding_enabled=False,\n      step_size:int=1, scaler_type:str='robust', num_workers_loader=0,\n      drop_last_loader=False, random_seed:int=1, **trainer_kwargs)\n\nTFT\nThe Temporal Fusion Transformer architecture (TFT) is an Sequence-to-Sequence model that combines static, historic and future available data to predict an univariate target. The method combines gating layers, an LSTM recurrent encoder, with and interpretable multi-head attention layer and a multi-step forecasting strategy decoder.\nParameters: h: int, Forecast horizon.  input_size: int, autorregresive inputs size, y=[1,2,3,4] input_size=2 -&gt; y_[t-2:t]=[1,2]. stat_exog_list: str list, static continuous columns. hist_exog_list: str list, historic continuous columns. futr_exog_list: str list, future continuous columns. hidden_size: int, units of embeddings and encoders. dropout: float (0, 1), dropout of inputs VSNs. n_head: int=4, number of attention heads in temporal fusion decoder. attn_dropout: float (0, 1), dropout of fusion decoder’s attention layer. shared_weights: bool, If True, all blocks within each stack will share parameters.  activation: str, activation from [‘ReLU’, ‘Softplus’, ‘Tanh’, ‘SELU’, ‘LeakyReLU’, ‘PReLU’, ‘Sigmoid’]. loss: PyTorch module, instantiated train loss class from losses collection. valid_loss: PyTorch module=loss, instantiated valid loss class from losses collection. max_steps: int=1000, maximum number of training steps. learning_rate: float=1e-3, Learning rate between (0, 1). num_lr_decays: int=-1, Number of learning rate decays, evenly distributed across max_steps. early_stop_patience_steps: int=-1, Number of validation iterations before early stopping. val_check_steps: int=100, Number of training steps between every validation loss check. batch_size: int, number of different series in each batch. windows_batch_size: int=None, windows sampled from rolled data, default uses all. inference_windows_batch_size: int=-1, number of windows to sample in each inference batch, -1 uses all. start_padding_enabled: bool=False, if True, the model will pad the time series with zeros at the beginning, by input size. valid_batch_size: int=None, number of different series in each validation and test batch. step_size: int=1, step size between each window of temporal data. scaler_type: str=‘robust’, type of scaler for temporal inputs normalization see temporal scalers. random_seed: int, random seed initialization for replicability. num_workers_loader: int=os.cpu_count(), workers to be used by TimeSeriesDataLoader. drop_last_loader: bool=False, if True TimeSeriesDataLoader drops last non-full batch. alias: str, optional, Custom name of the model. **trainer_kwargs: int, keyword trainer arguments inherited from PyTorch Lighning’s trainer.\nReferences: - Bryan Lim, Sercan O. Arik, Nicolas Loeff, Tomas Pfister, “Temporal Fusion Transformers for interpretable multi-horizon time series forecasting”\n\n\n\nTFT.fit\n\n TFT.fit (dataset, val_size=0, test_size=0, random_seed=None)\n\nFit.\nThe fit method, optimizes the neural network’s weights using the initialization parameters (learning_rate, windows_batch_size, …) and the loss function as defined during the initialization. Within fit we use a PyTorch Lightning Trainer that inherits the initialization’s self.trainer_kwargs, to customize its inputs, see PL’s trainer arguments.\nThe method is designed to be compatible with SKLearn-like classes and in particular to be compatible with the StatsForecast library.\nBy default the model is not saving training checkpoints to protect disk memory, to get them change enable_checkpointing=True in __init__.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset, see documentation. val_size: int, validation size for temporal cross-validation. random_seed: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__’s. test_size: int, test size for temporal cross-validation.\n\n\n\nTFT.predict\n\n TFT.predict (dataset, test_size=None, step_size=1, random_seed=None,\n              **data_module_kwargs)\n\nPredict.\nNeural network prediction with PL’s Trainer execution of predict_step.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset, see documentation. test_size: int=None, test size for temporal cross-validation. step_size: int=1, Step size between each window. random_seed: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__’s. **data_module_kwargs: PL’s TimeSeriesDataModule args, see documentation."
  },
  {
    "objectID": "models.tft.html#usage-example",
    "href": "models.tft.html#usage-example",
    "title": "TFT",
    "section": "Usage Example",
    "text": "Usage Example\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss, GMM, PMM\nfrom neuralforecast.tsdataset import TimeSeriesDataset\nfrom neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic\n\n\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\n#from neuralforecast.models import TFT\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss, GMM, PMM\nfrom neuralforecast.tsdataset import TimeSeriesDataset\nfrom neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic\n\n#AirPassengersPanel['y'] = AirPassengersPanel['y'] + 10\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]] # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nnf = NeuralForecast(\n    models=[TFT(h=12, input_size=48,\n                hidden_size=20,\n                #loss=DistributionLoss(distribution='Poisson', level=[80, 90]),\n                #loss=DistributionLoss(distribution='Normal', level=[80, 90]),\n                loss=DistributionLoss(distribution='StudentT', level=[80, 90]),\n                learning_rate=0.005,\n                stat_exog_list=['airline1'],\n                #futr_exog_list=['y_[lag12]'],\n                hist_exog_list=['trend'],\n                max_steps=500,\n                val_check_steps=10,\n                early_stop_patience_steps=10,\n                scaler_type='robust',\n                windows_batch_size=None,\n                enable_progress_bar=True),\n    ],\n    freq='M'\n)\nnf.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\nY_hat_df = nf.predict(futr_df=Y_test_df)\n\n# Plot quantile predictions\nY_hat_df = Y_hat_df.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nplot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\nplt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\nplt.plot(plot_df['ds'], plot_df['TFT'], c='purple', label='mean')\nplt.plot(plot_df['ds'], plot_df['TFT-median'], c='blue', label='median')\nplt.fill_between(x=plot_df['ds'][-12:], \n                 y1=plot_df['TFT-lo-90'][-12:].values, \n                 y2=plot_df['TFT-hi-90'][-12:].values,\n                 alpha=0.4, label='level 90')\nplt.legend()\nplt.grid()\nplt.plot()"
  },
  {
    "objectID": "models.html",
    "href": "models.html",
    "title": " Models ",
    "section": "",
    "text": "source\n\n\n\n AutoRNN (h, loss=MAE(), valid_loss=None, config=None,\n          search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerator\n          object at 0x7f739daa9c40&gt;, num_samples=10, refit_with_val=False,\n          cpus=4, gpus=0, verbose=False, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739daa9c40&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast.tsdataset import TimeSeriesDataset\nfrom neuralforecast.utils import AirPassengersDF as Y_df\n\n\n# Split train/test and declare time series dataset\nY_train_df = Y_df[Y_df.ds&lt;='1959-12-31'] # 132 train\nY_test_df = Y_df[Y_df.ds&gt;'1959-12-31']   # 12 test\ndataset, *_ = TimeSeriesDataset.from_df(Y_train_df)\n\n\n# Use your own config or AutoRNN.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=-1, encoder_hidden_size=8)\nmodel = AutoRNN(h=12, config=config, num_samples=1, cpus=1)\n\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\nmodel = AutoRNN(h=12, config=None, num_samples=1, cpus=1, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoLSTM (h, loss=MAE(), valid_loss=None, config=None,\n           search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerator\n           object at 0x7f739daa6f40&gt;, num_samples=10,\n           refit_with_val=False, cpus=4, gpus=0, verbose=False,\n           backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739daa6f40&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoLSTM.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=-1, encoder_hidden_size=8)\nmodel = AutoLSTM(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoLSTM(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoGRU (h, loss=MAE(), valid_loss=None, config=None,\n          search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerator\n          object at 0x7f739da9c250&gt;, num_samples=10, refit_with_val=False,\n          cpus=4, gpus=0, verbose=False, alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739da9c250&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoGRU.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=-1, encoder_hidden_size=8)\nmodel = AutoGRU(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoGRU(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoTCN (h, loss=MAE(), valid_loss=None, config=None,\n          search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerator\n          object at 0x7f739dac9d30&gt;, num_samples=10, refit_with_val=False,\n          cpus=4, gpus=0, verbose=False, alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739dac9d30&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoTCN.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=-1, encoder_hidden_size=8)\nmodel = AutoTCN(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoTCN(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoDeepAR (h, loss=DistributionLoss(), valid_loss=MQLoss(), config=None,\n             search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerat\n             or object at 0x7f739dad6f10&gt;, num_samples=10,\n             refit_with_val=False, cpus=4, gpus=0, verbose=False,\n             alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nDistributionLoss\nDistributionLoss()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nMQLoss\nMQLoss()\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739dad6f10&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=1, val_check_steps=1, input_size=12, lstm_hidden_size=8)\nmodel = AutoDeepAR(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoDeepAR(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoDilatedRNN (h, loss=MAE(), valid_loss=None, config=None,\n                 search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGen\n                 erator object at 0x7f739dae2490&gt;, num_samples=10,\n                 refit_with_val=False, cpus=4, gpus=0, verbose=False,\n                 alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739dae2490&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoDilatedRNN.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=-1, encoder_hidden_size=8)\nmodel = AutoDilatedRNN(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoDilatedRNN(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\n\n\n\n\nsource\n\n\n\n AutoMLP (h, loss=MAE(), valid_loss=None, config=None,\n          search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerator\n          object at 0x7f739daeba90&gt;, num_samples=10, refit_with_val=False,\n          cpus=4, gpus=0, verbose=False, alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739daeba90&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoMLP.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=12, hidden_size=8)\nmodel = AutoMLP(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoMLP(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoNBEATS (h, loss=MAE(), valid_loss=None, config=None,\n             search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerat\n             or object at 0x7f739ebde4f0&gt;, num_samples=10,\n             refit_with_val=False, cpus=4, gpus=0, verbose=False,\n             alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739ebde4f0&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNBEATS.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=12,\n              mlp_units=3*[[8, 8]])\nmodel = AutoNBEATS(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoNBEATS(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoNBEATSx (h, loss=MAE(), valid_loss=None, config=None,\n              search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenera\n              tor object at 0x7f739dad6100&gt;, num_samples=10,\n              refit_with_val=False, cpus=4, gpus=0, verbose=False,\n              alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739dad6100&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNBEATS.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=12,\n              mlp_units=3*[[8, 8]])\nmodel = AutoNBEATSx(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoNBEATSx(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoNHITS (h, loss=MAE(), valid_loss=None, config=None,\n            search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerato\n            r object at 0x7f739daccd30&gt;, num_samples=10,\n            refit_with_val=False, cpus=4, gpus=0, verbose=False,\n            alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739daccd30&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=12, \n              mlp_units=3 * [[8, 8]])\nmodel = AutoNHITS(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoNHITS(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\n\n\n\n\nsource\n\n\n\n AutoTFT (h, loss=MAE(), valid_loss=None, config=None,\n          search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerator\n          object at 0x7f739db3c0d0&gt;, num_samples=10, refit_with_val=False,\n          cpus=4, gpus=0, verbose=False, alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db3c0d0&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=1, val_check_steps=1, input_size=12, hidden_size=8)\nmodel = AutoTFT(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoTFT(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoVanillaTransformer (h, loss=MAE(), valid_loss=None, config=None,\n                         search_alg=&lt;ray.tune.search.basic_variant.BasicVa\n                         riantGenerator object at 0x7f739db1c970&gt;,\n                         num_samples=10, refit_with_val=False, cpus=4,\n                         gpus=0, verbose=False, alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db1c970&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=1, val_check_steps=1, input_size=12, hidden_size=8)\nmodel = AutoVanillaTransformer(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoVanillaTransformer(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoInformer (h, loss=MAE(), valid_loss=None, config=None,\n               search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGener\n               ator object at 0x7f739db279d0&gt;, num_samples=10,\n               refit_with_val=False, cpus=4, gpus=0, verbose=False,\n               alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db279d0&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=1, val_check_steps=1, input_size=12, hidden_size=8)\nmodel = AutoInformer(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoInformer(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoAutoformer (h, loss=MAE(), valid_loss=None, config=None,\n                 search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGen\n                 erator object at 0x7f739db06910&gt;, num_samples=10,\n                 refit_with_val=False, cpus=4, gpus=0, verbose=False,\n                 alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db06910&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=1, val_check_steps=1, input_size=12, hidden_size=8)\nmodel = AutoAutoformer(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoAutoformer(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoFEDformer (h, loss=MAE(), valid_loss=None, config=None,\n                search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGene\n                rator object at 0x7f739db17fd0&gt;, num_samples=10,\n                refit_with_val=False, cpus=4, gpus=0, verbose=False,\n                alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db17fd0&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=1, val_check_steps=1, input_size=12, hidden_size=64)\nmodel = AutoFEDformer(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoFEDformer(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoPatchTST (h, loss=MAE(), valid_loss=None, config=None,\n               search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGener\n               ator object at 0x7f739db094c0&gt;, num_samples=10,\n               refit_with_val=False, cpus=4, gpus=0, verbose=False,\n               alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db094c0&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=1, val_check_steps=1, input_size=12, hidden_size=16)\nmodel = AutoPatchTST(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoPatchTST(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\n\n\n\n\nsource\n\n\n\n AutoTimesNet (h, loss=MAE(), valid_loss=None, config=None,\n               search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGener\n               ator object at 0x7f739db4ca00&gt;, num_samples=10,\n               refit_with_val=False, cpus=4, gpus=0, verbose=False,\n               alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db4ca00&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# %%capture\n# # Use your own config or AutoTimesNet.default_config\n# config = dict(max_steps=1, val_check_steps=1, input_size=12, hidden_size=32)\n# model = AutoTimesNet(h=12, config=config, num_samples=1, cpus=1)\n\n# # Fit and predict\n# model.fit(dataset=dataset)\n# y_hat = model.predict(dataset=dataset)\n\n\n\n\n\n\nsource\n\n\n\n AutoStemGNN (h, n_series, loss=MAE(), valid_loss=None, config=None,\n              search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenera\n              tor object at 0x7f739db7f460&gt;, num_samples=10,\n              refit_with_val=False, cpus=4, gpus=0, verbose=False,\n              alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nn_series\n\n\n\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db7f460&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=1, val_check_steps=1, input_size=12)\nmodel = AutoStemGNN(h=12, n_series=1, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n\nsource\n\n\n\n\n AutoHINT (cls_model, h, loss, valid_loss, S, config,\n           search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerator\n           object at 0x7f739db750a0&gt;, num_samples=10, cpus=4, gpus=0,\n           refit_with_val=False, verbose=False, alias=None)\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncls_model\nPyTorch/PyTorchLightning model\n\nSee neuralforecast.models collection here.\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nPyTorch module\n\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nPyTorch module\n\nInstantiated valid loss class from losses collection.\n\n\nS\n\n\n\n\n\nconfig\ndict or callable\n\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db750a0&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\n\n\n# Perform a simple hyperparameter optimization with \n# NHITS and then reconcile with HINT\nfrom neuralforecast.losses.pytorch import GMM, sCRPS\n\nbase_config = dict(max_steps=1, val_check_steps=1, input_size=8)\nbase_model = AutoNHITS(h=4, loss=GMM(n_components=2, quantiles=quantiles), \n                       config=base_config, num_samples=1, cpus=1)\nmodel = HINT(h=4, S=S_df.values,\n             model=base_model,  reconciliation='MinTraceOLS')\n\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=hint_dataset)\n\n# Perform a conjunct hyperparameter optimization with \n# NHITS + HINT reconciliation configurations\nnhits_config = {\n       \"learning_rate\": tune.choice([1e-3]),                                     # Initial Learning rate\n       \"max_steps\": tune.choice([1]),                                            # Number of SGD steps\n       \"val_check_steps\": tune.choice([1]),                                      # Number of steps between validation\n       \"input_size\": tune.choice([5 * 12]),                                      # input_size = multiplier * horizon\n       \"batch_size\": tune.choice([7]),                                           # Number of series in windows\n       \"windows_batch_size\": tune.choice([256]),                                 # Number of windows in batch\n       \"n_pool_kernel_size\": tune.choice([[2, 2, 2], [16, 8, 1]]),               # MaxPool's Kernelsize\n       \"n_freq_downsample\": tune.choice([[168, 24, 1], [24, 12, 1], [1, 1, 1]]), # Interpolation expressivity ratios\n       \"activation\": tune.choice(['ReLU']),                                      # Type of non-linear activation\n       \"n_blocks\":  tune.choice([[1, 1, 1]]),                                    # Blocks per each 3 stacks\n       \"mlp_units\":  tune.choice([[[512, 512], [512, 512], [512, 512]]]),        # 2 512-Layers per block for each stack\n       \"interpolation_mode\": tune.choice(['linear']),                            # Type of multi-step interpolation\n       \"random_seed\": tune.randint(1, 10),\n       \"reconciliation\": tune.choice(['BottomUp', 'MinTraceOLS', 'MinTraceWLS'])\n    }\nmodel = AutoHINT(h=4, S=S_df.values,\n                 cls_model=NHITS,\n                 config=nhits_config,\n                 loss=GMM(n_components=2, level=[80, 90]),\n                 valid_loss=sCRPS(level=[80, 90]),\n                 num_samples=1, cpus=1)\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=hint_dataset)\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.html#a.-rnn-based",
    "href": "models.html#a.-rnn-based",
    "title": " Models ",
    "section": "",
    "text": "source\n\n\n\n AutoRNN (h, loss=MAE(), valid_loss=None, config=None,\n          search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerator\n          object at 0x7f739daa9c40&gt;, num_samples=10, refit_with_val=False,\n          cpus=4, gpus=0, verbose=False, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739daa9c40&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast.tsdataset import TimeSeriesDataset\nfrom neuralforecast.utils import AirPassengersDF as Y_df\n\n\n# Split train/test and declare time series dataset\nY_train_df = Y_df[Y_df.ds&lt;='1959-12-31'] # 132 train\nY_test_df = Y_df[Y_df.ds&gt;'1959-12-31']   # 12 test\ndataset, *_ = TimeSeriesDataset.from_df(Y_train_df)\n\n\n# Use your own config or AutoRNN.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=-1, encoder_hidden_size=8)\nmodel = AutoRNN(h=12, config=config, num_samples=1, cpus=1)\n\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\nmodel = AutoRNN(h=12, config=None, num_samples=1, cpus=1, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoLSTM (h, loss=MAE(), valid_loss=None, config=None,\n           search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerator\n           object at 0x7f739daa6f40&gt;, num_samples=10,\n           refit_with_val=False, cpus=4, gpus=0, verbose=False,\n           backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739daa6f40&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoLSTM.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=-1, encoder_hidden_size=8)\nmodel = AutoLSTM(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoLSTM(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoGRU (h, loss=MAE(), valid_loss=None, config=None,\n          search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerator\n          object at 0x7f739da9c250&gt;, num_samples=10, refit_with_val=False,\n          cpus=4, gpus=0, verbose=False, alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739da9c250&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoGRU.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=-1, encoder_hidden_size=8)\nmodel = AutoGRU(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoGRU(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoTCN (h, loss=MAE(), valid_loss=None, config=None,\n          search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerator\n          object at 0x7f739dac9d30&gt;, num_samples=10, refit_with_val=False,\n          cpus=4, gpus=0, verbose=False, alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739dac9d30&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoTCN.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=-1, encoder_hidden_size=8)\nmodel = AutoTCN(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoTCN(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoDeepAR (h, loss=DistributionLoss(), valid_loss=MQLoss(), config=None,\n             search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerat\n             or object at 0x7f739dad6f10&gt;, num_samples=10,\n             refit_with_val=False, cpus=4, gpus=0, verbose=False,\n             alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nDistributionLoss\nDistributionLoss()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nMQLoss\nMQLoss()\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739dad6f10&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=1, val_check_steps=1, input_size=12, lstm_hidden_size=8)\nmodel = AutoDeepAR(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoDeepAR(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoDilatedRNN (h, loss=MAE(), valid_loss=None, config=None,\n                 search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGen\n                 erator object at 0x7f739dae2490&gt;, num_samples=10,\n                 refit_with_val=False, cpus=4, gpus=0, verbose=False,\n                 alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739dae2490&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoDilatedRNN.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=-1, encoder_hidden_size=8)\nmodel = AutoDilatedRNN(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoDilatedRNN(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12"
  },
  {
    "objectID": "models.html#b.-mlp-based",
    "href": "models.html#b.-mlp-based",
    "title": " Models ",
    "section": "",
    "text": "source\n\n\n\n AutoMLP (h, loss=MAE(), valid_loss=None, config=None,\n          search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerator\n          object at 0x7f739daeba90&gt;, num_samples=10, refit_with_val=False,\n          cpus=4, gpus=0, verbose=False, alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739daeba90&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoMLP.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=12, hidden_size=8)\nmodel = AutoMLP(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoMLP(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoNBEATS (h, loss=MAE(), valid_loss=None, config=None,\n             search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerat\n             or object at 0x7f739ebde4f0&gt;, num_samples=10,\n             refit_with_val=False, cpus=4, gpus=0, verbose=False,\n             alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739ebde4f0&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNBEATS.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=12,\n              mlp_units=3*[[8, 8]])\nmodel = AutoNBEATS(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoNBEATS(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoNBEATSx (h, loss=MAE(), valid_loss=None, config=None,\n              search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenera\n              tor object at 0x7f739dad6100&gt;, num_samples=10,\n              refit_with_val=False, cpus=4, gpus=0, verbose=False,\n              alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739dad6100&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNBEATS.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=12,\n              mlp_units=3*[[8, 8]])\nmodel = AutoNBEATSx(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoNBEATSx(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoNHITS (h, loss=MAE(), valid_loss=None, config=None,\n            search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerato\n            r object at 0x7f739daccd30&gt;, num_samples=10,\n            refit_with_val=False, cpus=4, gpus=0, verbose=False,\n            alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739daccd30&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=2, val_check_steps=1, input_size=12, \n              mlp_units=3 * [[8, 8]])\nmodel = AutoNHITS(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoNHITS(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12"
  },
  {
    "objectID": "models.html#c.-transformer-based",
    "href": "models.html#c.-transformer-based",
    "title": " Models ",
    "section": "",
    "text": "source\n\n\n\n AutoTFT (h, loss=MAE(), valid_loss=None, config=None,\n          search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerator\n          object at 0x7f739db3c0d0&gt;, num_samples=10, refit_with_val=False,\n          cpus=4, gpus=0, verbose=False, alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db3c0d0&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=1, val_check_steps=1, input_size=12, hidden_size=8)\nmodel = AutoTFT(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoTFT(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoVanillaTransformer (h, loss=MAE(), valid_loss=None, config=None,\n                         search_alg=&lt;ray.tune.search.basic_variant.BasicVa\n                         riantGenerator object at 0x7f739db1c970&gt;,\n                         num_samples=10, refit_with_val=False, cpus=4,\n                         gpus=0, verbose=False, alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db1c970&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=1, val_check_steps=1, input_size=12, hidden_size=8)\nmodel = AutoVanillaTransformer(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoVanillaTransformer(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoInformer (h, loss=MAE(), valid_loss=None, config=None,\n               search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGener\n               ator object at 0x7f739db279d0&gt;, num_samples=10,\n               refit_with_val=False, cpus=4, gpus=0, verbose=False,\n               alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db279d0&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=1, val_check_steps=1, input_size=12, hidden_size=8)\nmodel = AutoInformer(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoInformer(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoAutoformer (h, loss=MAE(), valid_loss=None, config=None,\n                 search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGen\n                 erator object at 0x7f739db06910&gt;, num_samples=10,\n                 refit_with_val=False, cpus=4, gpus=0, verbose=False,\n                 alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db06910&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=1, val_check_steps=1, input_size=12, hidden_size=8)\nmodel = AutoAutoformer(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoAutoformer(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoFEDformer (h, loss=MAE(), valid_loss=None, config=None,\n                search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGene\n                rator object at 0x7f739db17fd0&gt;, num_samples=10,\n                refit_with_val=False, cpus=4, gpus=0, verbose=False,\n                alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db17fd0&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=1, val_check_steps=1, input_size=12, hidden_size=64)\nmodel = AutoFEDformer(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoFEDformer(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12\n\n\nsource\n\n\n\n\n AutoPatchTST (h, loss=MAE(), valid_loss=None, config=None,\n               search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGener\n               ator object at 0x7f739db094c0&gt;, num_samples=10,\n               refit_with_val=False, cpus=4, gpus=0, verbose=False,\n               alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db094c0&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=1, val_check_steps=1, input_size=12, hidden_size=16)\nmodel = AutoPatchTST(h=12, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n# Optuna\nmodel = AutoPatchTST(h=12, config=None, backend='optuna')\nassert model.config(MockTrial())['h'] == 12"
  },
  {
    "objectID": "models.html#d.-cnn-based",
    "href": "models.html#d.-cnn-based",
    "title": " Models ",
    "section": "",
    "text": "source\n\n\n\n AutoTimesNet (h, loss=MAE(), valid_loss=None, config=None,\n               search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGener\n               ator object at 0x7f739db4ca00&gt;, num_samples=10,\n               refit_with_val=False, cpus=4, gpus=0, verbose=False,\n               alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db4ca00&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# %%capture\n# # Use your own config or AutoTimesNet.default_config\n# config = dict(max_steps=1, val_check_steps=1, input_size=12, hidden_size=32)\n# model = AutoTimesNet(h=12, config=config, num_samples=1, cpus=1)\n\n# # Fit and predict\n# model.fit(dataset=dataset)\n# y_hat = model.predict(dataset=dataset)"
  },
  {
    "objectID": "models.html#e.-multivariate",
    "href": "models.html#e.-multivariate",
    "title": " Models ",
    "section": "",
    "text": "source\n\n\n\n AutoStemGNN (h, n_series, loss=MAE(), valid_loss=None, config=None,\n              search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenera\n              tor object at 0x7f739db7f460&gt;, num_samples=10,\n              refit_with_val=False, cpus=4, gpus=0, verbose=False,\n              alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon\n\n\nn_series\n\n\n\n\n\nloss\nMAE\nMAE()\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nNoneType\nNone\nInstantiated valid loss class from losses collection.\n\n\nconfig\nNoneType\nNone\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db7f460&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n# Use your own config or AutoNHITS.default_config\nconfig = dict(max_steps=1, val_check_steps=1, input_size=12)\nmodel = AutoStemGNN(h=12, n_series=1, config=config, num_samples=1, cpus=1)\n\n# Fit and predict\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=dataset)\n\n\nsource\n\n\n\n\n AutoHINT (cls_model, h, loss, valid_loss, S, config,\n           search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerator\n           object at 0x7f739db750a0&gt;, num_samples=10, cpus=4, gpus=0,\n           refit_with_val=False, verbose=False, alias=None)\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncls_model\nPyTorch/PyTorchLightning model\n\nSee neuralforecast.models collection here.\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nPyTorch module\n\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nPyTorch module\n\nInstantiated valid loss class from losses collection.\n\n\nS\n\n\n\n\n\nconfig\ndict or callable\n\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f739db750a0&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\n\n\n# Perform a simple hyperparameter optimization with \n# NHITS and then reconcile with HINT\nfrom neuralforecast.losses.pytorch import GMM, sCRPS\n\nbase_config = dict(max_steps=1, val_check_steps=1, input_size=8)\nbase_model = AutoNHITS(h=4, loss=GMM(n_components=2, quantiles=quantiles), \n                       config=base_config, num_samples=1, cpus=1)\nmodel = HINT(h=4, S=S_df.values,\n             model=base_model,  reconciliation='MinTraceOLS')\n\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=hint_dataset)\n\n# Perform a conjunct hyperparameter optimization with \n# NHITS + HINT reconciliation configurations\nnhits_config = {\n       \"learning_rate\": tune.choice([1e-3]),                                     # Initial Learning rate\n       \"max_steps\": tune.choice([1]),                                            # Number of SGD steps\n       \"val_check_steps\": tune.choice([1]),                                      # Number of steps between validation\n       \"input_size\": tune.choice([5 * 12]),                                      # input_size = multiplier * horizon\n       \"batch_size\": tune.choice([7]),                                           # Number of series in windows\n       \"windows_batch_size\": tune.choice([256]),                                 # Number of windows in batch\n       \"n_pool_kernel_size\": tune.choice([[2, 2, 2], [16, 8, 1]]),               # MaxPool's Kernelsize\n       \"n_freq_downsample\": tune.choice([[168, 24, 1], [24, 12, 1], [1, 1, 1]]), # Interpolation expressivity ratios\n       \"activation\": tune.choice(['ReLU']),                                      # Type of non-linear activation\n       \"n_blocks\":  tune.choice([[1, 1, 1]]),                                    # Blocks per each 3 stacks\n       \"mlp_units\":  tune.choice([[[512, 512], [512, 512], [512, 512]]]),        # 2 512-Layers per block for each stack\n       \"interpolation_mode\": tune.choice(['linear']),                            # Type of multi-step interpolation\n       \"random_seed\": tune.randint(1, 10),\n       \"reconciliation\": tune.choice(['BottomUp', 'MinTraceOLS', 'MinTraceWLS'])\n    }\nmodel = AutoHINT(h=4, S=S_df.values,\n                 cls_model=NHITS,\n                 config=nhits_config,\n                 loss=GMM(n_components=2, level=[80, 90]),\n                 valid_loss=sCRPS(level=[80, 90]),\n                 num_samples=1, cpus=1)\nmodel.fit(dataset=dataset)\ny_hat = model.predict(dataset=hint_dataset)"
  },
  {
    "objectID": "examples/save_load_models.html",
    "href": "examples/save_load_models.html",
    "title": "Save and Load Models",
    "section": "",
    "text": "Saving and loading trained Deep Learning models has multiple valuable uses. These models are often costly to train; storing a pre-trained model can help reduce costs as it can be loaded and reused to forecast multiple times. Moreover, it enables Transfer learning capabilities, consisting of pre-training a flexible model on a large dataset and using it later on other data with little to no training. It is one of the most outstanding 🚀 achievements in Machine Learning 🧠 and has many practical applications.\nIn this notebook we show an example on how to save and load NeuralForecast models.\nThe two methods to consider are: 1. NeuralForecast.save: Saves models into disk, allows save dataset and config. 2. NeuralForecast.load: Loads models from a given path.\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/save_load_models.html#installing-neuralforecast",
    "href": "examples/save_load_models.html#installing-neuralforecast",
    "title": "Save and Load Models",
    "section": "1. Installing NeuralForecast",
    "text": "1. Installing NeuralForecast\n\n!pip install neuralforecast"
  },
  {
    "objectID": "examples/save_load_models.html#loading-airpassengers-data",
    "href": "examples/save_load_models.html#loading-airpassengers-data",
    "title": "Save and Load Models",
    "section": "2. Loading AirPassengers Data",
    "text": "2. Loading AirPassengers Data\nFor this example we will use the classical AirPassenger Data set. Import the pre-processed AirPassenger from utils.\n\nfrom neuralforecast.utils import AirPassengersDF\n\nY_df = AirPassengersDF\nY_df = Y_df.reset_index(drop=True)\nY_df.head()\n\n/Users/cchallu/opt/anaconda3/envs/neuralforecast/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm"
  },
  {
    "objectID": "examples/save_load_models.html#model-training",
    "href": "examples/save_load_models.html#model-training",
    "title": "Save and Load Models",
    "section": "3. Model Training",
    "text": "3. Model Training\nNext, we instantiate and train three models: NBEATS, NHITS, and AutoMLP. The models with their hyperparameters are defined in the models list.\n\nfrom ray import tune\n\nfrom neuralforecast.core import NeuralForecast\nfrom neuralforecast.auto import AutoMLP\nfrom neuralforecast.models import NBEATS, NHITS\n\n\nhorizon = 12\nmodels = [NBEATS(input_size=2 * horizon, h=horizon, max_steps=50),\n          NHITS(input_size=2 * horizon, h=horizon, max_steps=50),\n          AutoMLP(# Ray tune explore config\n                  config=dict(max_steps=100, # Operates with steps not epochs\n                              input_size=tune.choice([3*horizon]),\n                              learning_rate=tune.choice([1e-3])),\n                  h=horizon,\n                  num_samples=1, cpus=1)]\n\n\nnf = NeuralForecast(models=models, freq='M')\nnf.fit(df=Y_df)\n\nProduce the forecasts with the predict method.\n\nY_hat_df = nf.predict().reset_index()\nY_hat_df.head()\n\nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00, 98.79it/s] \nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00, 123.41it/s]\nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00, 161.79it/s]\n\n\n\n\n\n\n\n\n\nunique_id\nds\nNBEATS\nNHITS\nAutoMLP\n\n\n\n\n0\n1.0\n1961-01-31\n428.410553\n445.268158\n452.550446\n\n\n1\n1.0\n1961-02-28\n425.958557\n469.293945\n442.683807\n\n\n2\n1.0\n1961-03-31\n477.748016\n462.920807\n474.043457\n\n\n3\n1.0\n1961-04-30\n477.548798\n489.986633\n503.836334\n\n\n4\n1.0\n1961-05-31\n495.973541\n518.612610\n531.347900\n\n\n\n\n\n\n\nWe plot the forecasts for each model. Note how the two NBEATS models are differentiated with a numerical suffix.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nplot_df = pd.concat([Y_df, Y_hat_df]).set_index('ds') # Concatenate the train and forecast dataframes\n\nplt.figure(figsize = (12, 3))\nplot_df[['y', 'NBEATS', 'NHITS', 'AutoMLP']].plot(linewidth=2)\n\nplt.title('AirPassengers Forecast', fontsize=10)\nplt.ylabel('Monthly Passengers', fontsize=10)\nplt.xlabel('Timestamp [t]', fontsize=10)\nplt.axvline(x=plot_df.index[-horizon], color='k', linestyle='--', linewidth=2)\nplt.legend(prop={'size': 10})\n\n&lt;matplotlib.legend.Legend&gt;\n\n\n&lt;Figure size 1200x300 with 0 Axes&gt;"
  },
  {
    "objectID": "examples/save_load_models.html#save-models",
    "href": "examples/save_load_models.html#save-models",
    "title": "Save and Load Models",
    "section": "4. Save models",
    "text": "4. Save models\nTo save all the trained models use the save method. This method will save both the hyperparameters and the learnable weights (parameters).\nThe save method has the following inputs:\n\npath: directory where models will be saved.\nmodel_index: optional list to specify which models to save. For example, to only save the NHITS model use model_index=[2].\noverwrite: boolean to overwrite existing files in path. When True, the method will only overwrite models with conflicting names.\nsave_dataset: boolean to save Dataset object with the dataset.\n\n\nnf.save(path='./checkpoints/test_run/',\n        model_index=None, \n        overwrite=True,\n        save_dataset=True)\n\nFor each model, two files are created and stored:\n\n[model_name]_[suffix].ckpt: Pytorch Lightning checkpoint file with the model parameters and hyperparameters.\n[model_name]_[suffix].pkl: Dictionary with configuration attributes.\n\nWhere model_name corresponds to the name of the model in lowercase (eg. nhits). We use a numerical suffix to distinguish multiple models of each class. In this example the names will be automlp_0, nbeats_0, and nhits_0.\n\n\n\n\n\n\nImportant\n\n\n\nThe Auto models will be stored as their base model. For example, the AutoMLP trained above is stored as an MLP model, with the best hyparparameters found during tuning."
  },
  {
    "objectID": "examples/save_load_models.html#load-models",
    "href": "examples/save_load_models.html#load-models",
    "title": "Save and Load Models",
    "section": "5. Load models",
    "text": "5. Load models\nLoad the saved models with the load method, specifying the path, and use the new nf2 object to produce forecasts.\n\nnf2 = NeuralForecast.load(path='./checkpoints/test_run/')\nY_hat_df = nf2.predict().reset_index()\nY_hat_df.head()\n\nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00, 153.75it/s]\nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00, 142.04it/s]\nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00, 105.82it/s]\n\n\n\n\n\n\n\n\n\nunique_id\nds\nMLP\nNHITS\nNBEATS\n\n\n\n\n0\n1.0\n1961-01-31\n452.550446\n445.268158\n428.410553\n\n\n1\n1.0\n1961-02-28\n442.683807\n469.293945\n425.958557\n\n\n2\n1.0\n1961-03-31\n474.043457\n462.920807\n477.748016\n\n\n3\n1.0\n1961-04-30\n503.836334\n489.986633\n477.548798\n\n\n4\n1.0\n1961-05-31\n531.347900\n518.612610\n495.973541\n\n\n\n\n\n\n\nFinally, plot the forecasts to confirm they are identical to the original forecasts.\n\nplot_df = pd.concat([Y_df, Y_hat_df]).set_index('ds') # Concatenate the train and forecast dataframes\n\nplt.figure(figsize = (12, 3))\nplot_df[['y', 'NBEATS', 'NHITS', 'MLP']].plot(linewidth=2)\n\nplt.title('AirPassengers Forecast', fontsize=10)\nplt.ylabel('Monthly Passengers', fontsize=10)\nplt.xlabel('Timestamp [t]', fontsize=10)\nplt.axvline(x=plot_df.index[-horizon], color='k', linestyle='--', linewidth=2)\nplt.legend(prop={'size': 10})\nplt.show()\n\n&lt;Figure size 1200x300 with 0 Axes&gt;"
  },
  {
    "objectID": "examples/save_load_models.html#references",
    "href": "examples/save_load_models.html#references",
    "title": "Save and Load Models",
    "section": "References",
    "text": "References\nhttps://pytorch-lightning.readthedocs.io/en/stable/common/checkpointing_basic.html\nOreshkin, B. N., Carpov, D., Chapados, N., & Bengio, Y. (2019). N-BEATS: Neural basis expansion analysis for interpretable time series forecasting. ICLR 2020\nCristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2021). N-HiTS: Neural Hierarchical Interpolation for Time Series Forecasting. Accepted at AAAI 2023."
  },
  {
    "objectID": "examples/neuralforecast_map.html",
    "href": "examples/neuralforecast_map.html",
    "title": "NeuralForecast map",
    "section": "",
    "text": "The neuralforecast library provides a comprehensive set of state-of-the-art deep learning models designed to power-up time series forecasting pipelines.\nThe library is constructed using a modular approach, where different responsibilities are isolated within specific modules. These modules include the user interface functions (core), data processing and loading (tsdataset), scalers, losses, and base classes for models.\nThis tutorial aims to explain the library’s structure and to describe how the different modules interact with each other.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/neuralforecast_map.html#i.-map",
    "href": "examples/neuralforecast_map.html#i.-map",
    "title": "NeuralForecast map",
    "section": "I. Map",
    "text": "I. Map\nThe following diagram presents the modules of the neuralforecast library and their relations.\n\n\n\nNeuralforecast map"
  },
  {
    "objectID": "examples/neuralforecast_map.html#ii.-modules",
    "href": "examples/neuralforecast_map.html#ii.-modules",
    "title": "NeuralForecast map",
    "section": "II. Modules",
    "text": "II. Modules\n\n1. Core (core.py)\nThe core module acts as the primary interaction point for users of the neuralforecast library. It houses the NeuralForecast class, which incorporates a range of key user interface functions designed to simplify the process of training and forecasting models. Functions include fit, predict, cross_validation, and predict_insample, each one constructed to be intuitive and user-friendly. The design of the NeuralForecast class is centered around enabling users to streamline their forecasting pipelines and to comfortably train and evaluate models.\n\n\n2. Dataset and Loader (tsdataset.py)\nThe TimeSeriesDataset class, located within the tsdataset module, is responsible for the storage and preprocessing of the input time series dataset. Once the TimeSeriesDataset class has prepared the data, it’s then consumed by the TimeSeriesLoader class, which samples batches (or subsets) of the time series during the training and inference stages.\n\n\n3. Base Model (common)\nThe common module contains three BaseModel classes, which serve as the foundation for all the model structures provided in the library. These base classes allow for a level of abstraction and code-reusability in the design of the models. We currently support three type of models:\n\nBaseWindows: designed for window-based models like NBEATS and Transformers.\nBaseRecurrent: designed for recurrent models like RNN and LSTM.\nBaseMultivariate: caters to multivariate models like StemGNN.\n\n\n\n4. Model (models)\nThe models module encompasses all the specific model classes available for use in the library. These include a variety of both simple and complex models such as RNN, NHITS, LSTM, StemGNN, and TFT. Each model in this module extends from one of the BaseModel classes in the common module.\n\n\n5. Losses (losses)\nThe losses module includes both numpy and pytorch losses, used for evalaution and training respectively. The module contains a wide range of losses, including MAE, MSE, MAPE, HuberLoss, among many others.\n\n\n6. Scalers (_scalers.py)\nThe _scalers.py module houses the TemporalNorm class. This class is responsible for the scaling (normalization) and de-scaling (reversing the normalization) of time series data. This step is crucial because it ensures all data fed to the model have a similar range, leading to more stable and efficient training processes."
  },
  {
    "objectID": "examples/neuralforecast_map.html#iii.-flow",
    "href": "examples/neuralforecast_map.html#iii.-flow",
    "title": "NeuralForecast map",
    "section": "III. Flow",
    "text": "III. Flow\nThe user first instantiates a model and the NeuralForecast core class. When they call the fit method, the following flow is executed:\n\nThe fit method instantiates a TimeSeriesDataset object to store and pre-process the input time series dataset, and the TimeSeriesLoader object to sample batches.\nThe fit method calls the model’s fit method (in the BaseModel class).\nThe model’s fit method instantiates a Pytorch-Lightning Trainer object, in charge of training the model.\nThe Trainer method samples a batch from the TimeSeriesLoader object, and calls the model’s training_step method (in the BaseModel class).\nThe model’s training_step:\n\nSamples windows from the original batch.\nNormalizes the windows with the scaler module.\nCalls the model’s forward method.\nComputes the loss using the losses module.\nReturns the loss.\n\nThe Trainer object repeats step 4 and 5 until max_steps iterations are completed.\nThe model is fitted, and can be used for forecasting future values (with the predict method) or recover insample predictions (using the predict_insample method)."
  },
  {
    "objectID": "examples/neuralforecast_map.html#iv.-next-steps-add-your-own-model",
    "href": "examples/neuralforecast_map.html#iv.-next-steps-add-your-own-model",
    "title": "NeuralForecast map",
    "section": "IV. Next Steps: add your own model",
    "text": "IV. Next Steps: add your own model\nCongratulations! You now know the internal details of the neuralforecast library.\nWith this knowledge you can easily add new models to the library, by just creating a model class which only requires the init and forward methods.\nCheck our detailed guide on how to add new models!"
  },
  {
    "objectID": "examples/robust_regression.html",
    "href": "examples/robust_regression.html",
    "title": "Outlier Robust Forecasting",
    "section": "",
    "text": "When outliers are present in a dataset, they can disrupt the calculated summary statistics, such as the mean and standard deviation, leading the model to favor the outlier values and deviate from most observations. Consequently, models need help in achieving a balance between accurately accommodating outliers and performing well on normal data, resulting in improved overall performance on both types of data. Robust regression algorithms tackle this issue, explicitly accounting for outliers in the dataset.\nIn this notebook we will show how to fit robust NeuralForecast methods. We will: - Installing NeuralForecast. - Loading Noisy AirPassengers. - Fit and predict robustified NeuralForecast. - Plot and evaluate predictions.\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/robust_regression.html#installing-neuralforecast",
    "href": "examples/robust_regression.html#installing-neuralforecast",
    "title": "Outlier Robust Forecasting",
    "section": "1. Installing NeuralForecast",
    "text": "1. Installing NeuralForecast\n\n!pip install git+https://github.com/Nixtla/neuralforecast.git\n\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import datasets\n\nimport matplotlib.pyplot as plt\nfrom random import random\nfrom random import randint\nfrom random import seed\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.utils import AirPassengersDF\n\nfrom neuralforecast.models import NHITS\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss, HuberMQLoss\n\nfrom neuralforecast.losses.numpy import mape, mqloss"
  },
  {
    "objectID": "examples/robust_regression.html#loading-noisy-airpassengers",
    "href": "examples/robust_regression.html#loading-noisy-airpassengers",
    "title": "Outlier Robust Forecasting",
    "section": "2. Loading Noisy AirPassengers",
    "text": "2. Loading Noisy AirPassengers\nFor this example we will use the classic Box-Cox AirPassengers dataset that we will augment it by introducing outliers.\nIn particular, we will focus on introducing outliers to the target variable altering it to deviate from its original observation by a specified factor, such as 2-to-4 times the standard deviation.\n\n# Original Box-Cox AirPassengers \n# as defined in neuralforecast.utils\nY_df = AirPassengersDF.copy() \nplt.plot(Y_df.y)\nplt.ylabel('Monthly Passengers')\nplt.xlabel('Timestamp [t]')\nplt.grid()\n\n\n\n\n\n# Here we add some artificial outliers to AirPassengers\nseed(1)\nfor i in range(len(Y_df)):\n    factor = randint(2, 4)\n    if random() &gt; 0.97:\n        Y_df.y[i] += factor * Y_df.y.std()\n\nplt.plot(Y_df.y)\nplt.ylabel('Monthly Passengers + Noise')\nplt.xlabel('Timestamp [t]')\nplt.grid()\n\n\n\n\n\n# Split datasets into train/test \n# Last 12 months for test\nY_train_df = Y_df.groupby('unique_id').head(-12).reset_index()\nY_test_df = Y_df.groupby('unique_id').tail(12).reset_index()\nY_test_df\n\n\n\n\n\n\n\n\nindex\nunique_id\nds\ny\n\n\n\n\n0\n132\n1.0\n1960-01-31\n417.0\n\n\n1\n133\n1.0\n1960-02-29\n391.0\n\n\n2\n134\n1.0\n1960-03-31\n419.0\n\n\n3\n135\n1.0\n1960-04-30\n461.0\n\n\n4\n136\n1.0\n1960-05-31\n472.0\n\n\n5\n137\n1.0\n1960-06-30\n535.0\n\n\n6\n138\n1.0\n1960-07-31\n622.0\n\n\n7\n139\n1.0\n1960-08-31\n606.0\n\n\n8\n140\n1.0\n1960-09-30\n508.0\n\n\n9\n141\n1.0\n1960-10-31\n461.0\n\n\n10\n142\n1.0\n1960-11-30\n390.0\n\n\n11\n143\n1.0\n1960-12-31\n432.0"
  },
  {
    "objectID": "examples/robust_regression.html#fit-and-predict-robustified-neuralforecast",
    "href": "examples/robust_regression.html#fit-and-predict-robustified-neuralforecast",
    "title": "Outlier Robust Forecasting",
    "section": "3. Fit and predict robustified NeuralForecast",
    "text": "3. Fit and predict robustified NeuralForecast\n\nHuber MQ Loss\nThe Huber loss, employed in robust regression, is a loss function that exhibits reduced sensitivity to outliers in data when compared to the squared error loss. The Huber loss function is quadratic for small errors and linear for large errors. Here we will use a slight modification for probabilistic predictions. Feel free to play with the \\(\\delta\\) parameter.\n\n\n\nDropout Regularization\nThe dropout technique is a regularization method used in neural networks to prevent overfitting. During training, dropout randomly sets a fraction of the input units or neurons in a layer to zero at each update, effectively “dropping out” those units. This means that the network cannot rely on any individual unit because it may be dropped out at any time. By doing so, dropout forces the network to learn more robust and generalizable representations by preventing units from co-adapting too much.\nThe dropout method, can help us to robustify the network to outliers in the auto-regressive features. You can explore it through the dropout_prob_theta parameter.\n\n\nFit NeuralForecast models\nUsing the NeuralForecast.fit method you can train a set of models to your dataset. You can define the forecasting horizon (12 in this example), and modify the hyperparameters of the model. For example, for the NHITS we changed the default hidden size for both encoder and decoders.\nSee the NHITS and MLP model documentation.\n\nhorizon = 12\nquantiles = [0.1, 0.25, 0.5, 0.75, 0.9]\n\n# Try different hyperparmeters to improve accuracy.\nmodels = [NHITS(h=horizon,                           # Forecast horizon\n                input_size=2 * horizon,              # Length of input sequence\n                loss=HuberMQLoss(quantiles=quantiles),    # Robust Huber Loss\n                valid_loss=MQLoss(quantiles=quantiles),   # Validation signal\n                max_steps=500,                       # Number of steps to train\n                dropout_prob_theta=0.6,              # Dropout to robustify vs outlier lag inputs\n                #early_stop_patience_steps=2,        # Early stopping regularization patience\n                val_check_steps=10,                  # Frequency of validation signal (affects early stopping)\n                alias='Huber',\n              ),\n          NHITS(h=horizon,\n                input_size=2 * horizon,\n                loss=DistributionLoss(distribution='Normal', \n                                      quantiles=quantiles), # Classic Normal distribution\n                valid_loss=MQLoss(quantiles=quantiles),\n                max_steps=500,\n                #early_stop_patience_steps=2,\n                dropout_prob_theta=0.6,\n                val_check_steps=10,\n                alias='Normal',\n              )\n          ]\nnf = NeuralForecast(models=models, freq='M')\nnf.fit(df=Y_train_df)\nY_hat_df = nf.predict()\n\nGlobal seed set to 1\nGlobal seed set to 1\n\n\n\n# By default NeuralForecast produces forecast intervals\n# In this case the lo-x and high-x levels represent the \n# low and high bounds of the prediction accumulating x% probability\nY_hat_df = Y_hat_df.reset_index(drop=True)\nY_hat_df\n\n\n\n\n\n\n\n\nds\nHuber-lo-80.0\nHuber-lo-50.0\nHuber-median\nHuber-hi-50.0\nHuber-hi-80.0\nNormal\nNormal-lo-80.0\nNormal-lo-50.0\nNormal-median\nNormal-hi-50.0\nNormal-hi-80.0\n\n\n\n\n0\n1960-01-31\n392.046448\n397.029694\n402.842377\n412.451111\n420.441254\n370.554321\n-1246.564331\n-466.951233\n374.260681\n1214.356934\n1953.910645\n\n\n1\n1960-02-29\n389.217041\n398.078979\n411.310669\n426.811432\n462.116272\n431.134827\n-1016.146179\n-376.702576\n469.389313\n1195.809082\n1874.808838\n\n\n2\n1960-03-31\n434.787323\n446.318176\n456.515533\n468.646667\n486.479950\n469.221069\n-965.224670\n-268.812164\n455.846985\n1197.529175\n1983.282349\n\n\n3\n1960-04-30\n435.589081\n443.395844\n451.102966\n458.542328\n469.953857\n544.345642\n-1038.976440\n-251.178711\n535.880615\n1403.179932\n2100.239990\n\n\n4\n1960-05-31\n442.144714\n448.320862\n455.896271\n466.212524\n477.713348\n400.593628\n-1188.452881\n-417.007935\n426.566284\n1202.106201\n2103.583008\n\n\n5\n1960-06-30\n505.597168\n513.204590\n522.992188\n535.911987\n547.264099\n482.142883\n-1210.700195\n-386.704407\n484.923767\n1400.397339\n2142.133789\n\n\n6\n1960-07-31\n566.634033\n576.086548\n588.730164\n602.847534\n613.312256\n548.551086\n-1049.558838\n-299.192017\n578.715820\n1399.025879\n2226.514404\n\n\n7\n1960-08-31\n554.081116\n568.410767\n580.600281\n594.198730\n605.851440\n542.382874\n-1056.719116\n-310.321533\n543.106689\n1420.388306\n2138.160889\n\n\n8\n1960-09-30\n503.825928\n511.493469\n520.782532\n530.070435\n551.331299\n656.870056\n-957.937927\n-157.202362\n644.464355\n1539.134644\n2261.052490\n\n\n9\n1960-10-31\n438.602539\n445.856720\n454.243591\n462.382782\n487.070221\n662.375427\n-926.544312\n-206.266907\n650.127808\n1537.292480\n2253.246094\n\n\n10\n1960-11-30\n395.615570\n402.616699\n417.529083\n430.389435\n452.758911\n499.940247\n-1233.157471\n-397.680908\n492.310120\n1396.803711\n2209.155273\n\n\n11\n1960-12-31\n433.402496\n439.153748\n448.741119\n456.206573\n471.018433\n458.918365\n-1393.779053\n-589.960815\n468.123871\n1448.744263\n2284.202637"
  },
  {
    "objectID": "examples/robust_regression.html#plot-and-evaluate-predictions",
    "href": "examples/robust_regression.html#plot-and-evaluate-predictions",
    "title": "Outlier Robust Forecasting",
    "section": "4. Plot and Evaluate Predictions",
    "text": "4. Plot and Evaluate Predictions\nFinally, we plot the forecasts of both models againts the real values.\nAnd evaluate the accuracy of the NHITS-Huber and NHITS-Normal forecasters.\n\nfig, ax = plt.subplots(1, 1, figsize = (20, 7))\nplot_df = pd.concat([Y_train_df, Y_hat_df]).set_index('ds') # Concatenate the train and forecast dataframes\nplot_df[['y', 'Huber-median', 'Normal-median']].plot(ax=ax, linewidth=2)\n\nax.set_title('Noisy AirPassengers Forecast', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp [t]', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\n\n\n\n\nTo evaluate the median predictions we use the mean average percentage error (MAPE), defined as follows:\n\\[\\mathrm{MAPE}(\\mathbf{y}_{\\tau}, \\hat{\\mathbf{y}}_{\\tau}) = \\mathrm{mean}\\left(\\frac{|\\mathbf{y}_{\\tau}-\\hat{\\mathbf{y}}_{\\tau}|}{|\\mathbf{y}_{\\tau}|}\\right)\\]\n\n#from neuralforecast.losses.numpy import mape, mqloss\n\nhuber_mae = mape(y=Y_test_df['y'], y_hat=Y_hat_df['Huber-median'])\nnormal_mae = mape(y=Y_test_df['y'], y_hat=Y_hat_df['Normal-median'])\n\nprint(f'Huber MAPE: {huber_mae:.1%}')\nprint(f'Normal MAPE: {normal_mae:.1%}')\n\nHuber MAPE: 4.2%\nNormal MAPE: 16.2%\n\n\nTo evaluate the coherent probabilistic predictions we use the Continuous Ranked Probability Score (CRPS), defined as follows:\n\\[\\mathrm{CRPS}(\\hat{F}_{\\tau},\\mathbf{y}_{\\tau}) = \\int^{1}_{0} \\mathrm{QL}(\\hat{F}_{\\tau}, y_{\\tau})_{q} dq\\]\nAs you can see robust regression improvements can reflect in the probabilistic forecasts too.\n\nhuber_qcols = ['Huber-lo-80.0', 'Huber-lo-50.0',    'Huber-median', 'Huber-hi-50.0', 'Huber-hi-80.0']\nnormal_qcols = ['Normal-lo-80.0', 'Normal-lo-50.0', 'Normal-median',    'Normal-hi-50.0', 'Normal-hi-80.0']\n\nhuber_crps = mqloss(y=Y_test_df['y'], y_hat=Y_hat_df[huber_qcols], \n                   quantiles=np.array(quantiles))\nnormal_crps = mqloss(y=Y_test_df['y'], y_hat=Y_hat_df[normal_qcols], \n                    quantiles=np.array(quantiles))\n\nprint(f'Huber CRPS: {huber_crps:.4}')\nprint(f'Normal CRPS: {normal_crps:.4}')\n\nHuber CRPS: 6.139\nNormal CRPS: 157.5"
  },
  {
    "objectID": "examples/robust_regression.html#references",
    "href": "examples/robust_regression.html#references",
    "title": "Outlier Robust Forecasting",
    "section": "References",
    "text": "References\n\nHuber Peter, J (1964). “Robust Estimation of a Location Parameter”. Annals of Statistics.\nNitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov (2014).”Dropout: A Simple Way to Prevent Neural Networks from Overfitting”. Journal of Machine Learning Research.\nCristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2023). NHITS: Neural Hierarchical Interpolation for Time Series Forecasting. Accepted at AAAI 2023."
  },
  {
    "objectID": "examples/electricitypeakforecasting.html",
    "href": "examples/electricitypeakforecasting.html",
    "title": "Detect Demand Peaks",
    "section": "",
    "text": "Predicting peaks in different markets is useful. In the electricity market, consuming electricity at peak demand is penalized with higher tarifs. When an individual or company consumes electricity when its most demanded, regulators calls that a coincident peak (CP).\nIn the Texas electricity market (ERCOT), the peak is the monthly 15-minute interval when the ERCOT Grid is at a point of highest capacity. The peak is caused by all consumers’ combined demand on the electrical grid. The coincident peak demand is an important factor used by ERCOT to determine final electricity consumption bills. ERCOT registers the CP demand of each client for 4 months, between June and September, and uses this to adjust electricity prices. Clients can therefore save on electricity bills by reducing the coincident peak demand.\nIn this example we will train an NHITS model on historic load data to forecast day-ahead peaks on September 2022. Multiple seasonality is traditionally present in low sampled electricity data. Demand exhibits daily and weekly seasonality, with clear patterns for specific hours of the day such as 6:00pm vs 3:00am or for specific days such as Sunday vs Friday.\nFirst, we will load ERCOT historic demand, then we will use the Neuralforecast.cross_validation method to fit the model and forecast daily load during September. Finally, we show how to use the forecasts to detect the coincident peak.\nOutline\n\nInstall libraries\nLoad and explore the data\nFit NHITS model and forecast\nPeak detection\n\n\n\n\n\n\n\nTip\n\n\n\nYou can use Colab to run this Notebook interactively\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/electricitypeakforecasting.html#introduction",
    "href": "examples/electricitypeakforecasting.html#introduction",
    "title": "Detect Demand Peaks",
    "section": "",
    "text": "Predicting peaks in different markets is useful. In the electricity market, consuming electricity at peak demand is penalized with higher tarifs. When an individual or company consumes electricity when its most demanded, regulators calls that a coincident peak (CP).\nIn the Texas electricity market (ERCOT), the peak is the monthly 15-minute interval when the ERCOT Grid is at a point of highest capacity. The peak is caused by all consumers’ combined demand on the electrical grid. The coincident peak demand is an important factor used by ERCOT to determine final electricity consumption bills. ERCOT registers the CP demand of each client for 4 months, between June and September, and uses this to adjust electricity prices. Clients can therefore save on electricity bills by reducing the coincident peak demand.\nIn this example we will train an NHITS model on historic load data to forecast day-ahead peaks on September 2022. Multiple seasonality is traditionally present in low sampled electricity data. Demand exhibits daily and weekly seasonality, with clear patterns for specific hours of the day such as 6:00pm vs 3:00am or for specific days such as Sunday vs Friday.\nFirst, we will load ERCOT historic demand, then we will use the Neuralforecast.cross_validation method to fit the model and forecast daily load during September. Finally, we show how to use the forecasts to detect the coincident peak.\nOutline\n\nInstall libraries\nLoad and explore the data\nFit NHITS model and forecast\nPeak detection\n\n\n\n\n\n\n\nTip\n\n\n\nYou can use Colab to run this Notebook interactively"
  },
  {
    "objectID": "examples/electricitypeakforecasting.html#libraries",
    "href": "examples/electricitypeakforecasting.html#libraries",
    "title": "Detect Demand Peaks",
    "section": "Libraries",
    "text": "Libraries\nWe assume you have NeuralForecast already installed. Check this guide for instructions on how to install NeuralForecast.\nInstall the necessary packages using pip install neuralforecast"
  },
  {
    "objectID": "examples/electricitypeakforecasting.html#load-data",
    "href": "examples/electricitypeakforecasting.html#load-data",
    "title": "Detect Demand Peaks",
    "section": "Load Data",
    "text": "Load Data\nThe input to NeuralForecast models is always a data frame in long format with three columns: unique_id, ds and y:\n\nThe unique_id (string, int or category) represents an identifier for the series.\nThe ds (datestamp or int) column should be either an integer indexing time or a datestamp ideally like YYYY-MM-DD for a date or YYYY-MM-DD HH:MM:SS for a timestamp.\nThe y (numeric) represents the measurement we wish to forecast. We will rename the\n\nFirst, download and read the 2022 historic total demand of the ERCOT market, available here. The data processing includes adding the missing hour due to daylight saving time, parsing the date to datetime format, and filtering columns of interest.\n\nimport numpy as np\nimport pandas as pd\n\n\n# Load data\nY_df = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/ERCOT-clean.csv', parse_dates=['ds'])\nY_df = Y_df.query(\"ds &gt;= '2022-01-01' & ds &lt;= '2022-10-01'\")\n\n\nY_df.plot(x='ds', y='y', figsize=(20, 7))\n\n&lt;AxesSubplot:xlabel='ds'&gt;"
  },
  {
    "objectID": "examples/electricitypeakforecasting.html#fit-and-forecast-with-nhits",
    "href": "examples/electricitypeakforecasting.html#fit-and-forecast-with-nhits",
    "title": "Detect Demand Peaks",
    "section": "Fit and Forecast with NHITS",
    "text": "Fit and Forecast with NHITS\nImport the NeuralForecast class and the models you need.\n\nfrom neuralforecast.core import NeuralForecast\nfrom neuralforecast.auto import AutoNHITS\n\n/Users/cchallu/opt/anaconda3/envs/neuralforecast/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n\nFirst, instantiate the model and define the parameters. To instantiate AutoNHITS you need to define:\n\nh: forecasting horizon\nloss: training loss. Use the DistributionLoss to produce probabilistic forecasts. Default: MAE.\nconfig: hyperparameter search space. If None, the AutoNHITS class will use a pre-defined suggested hyperparameter space.\nnum_samples: number of configurations explored.\n\n\nmodels = [AutoNHITS(h=24,\n                    config=None, # Uses default config\n                    num_samples=10\n                   )\n         ]\n\nWe fit the model by instantiating a NeuralForecast object with the following required parameters:\n\nmodels: a list of models. Select the models you want from models and import them.\nfreq: a string indicating the frequency of the data. (See panda’s available frequencies.)\n\n\n# Instantiate StatsForecast class as sf\nnf = NeuralForecast(\n    models=models,\n    freq='H', \n)\n\nThe cross_validation method allows the user to simulate multiple historic forecasts, greatly simplifying pipelines by replacing for loops with fit and predict methods. This method re-trains the model and forecast each window. See this tutorial for an animation of how the windows are defined.\nUse the cross_validation method to produce all the daily forecasts for September. To produce daily forecasts set the forecasting horizon h as 24. In this example we are simulating deploying the pipeline during September, so set the number of windows as 30 (one for each day). Finally, set the step size between windows as 24, to only produce one forecast per day.\n\ncrossvalidation_df = nf.cross_validation(\n    df=Y_df,\n    step_size=24,\n    n_windows=30\n  )\n\n\ncrossvalidation_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ncutoff\nAutoNHITS\ny\n\n\n\n\n0\nERCOT\n2022-09-01 00:00:00\n2022-08-31 23:00:00\n46184.621094\n45482.471757\n\n\n1\nERCOT\n2022-09-01 01:00:00\n2022-08-31 23:00:00\n44108.359375\n43602.658043\n\n\n2\nERCOT\n2022-09-01 02:00:00\n2022-08-31 23:00:00\n42990.058594\n42284.817342\n\n\n3\nERCOT\n2022-09-01 03:00:00\n2022-08-31 23:00:00\n42040.902344\n41663.156771\n\n\n4\nERCOT\n2022-09-01 04:00:00\n2022-08-31 23:00:00\n42007.972656\n41710.621904\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen using cross_validation make sure the forecasts are produced at the desired timestamps. Check the cutoff column which specifices the last timestamp before the forecasting window."
  },
  {
    "objectID": "examples/electricitypeakforecasting.html#peak-detection",
    "href": "examples/electricitypeakforecasting.html#peak-detection",
    "title": "Detect Demand Peaks",
    "section": "Peak Detection",
    "text": "Peak Detection\nFinally, we use the forecasts in crossvaldation_df to detect the daily hourly demand peaks. For each day, we set the detected peaks as the highest forecasts. In this case, we want to predict one peak (npeaks); depending on your setting and goals, this parameter might change. For example, the number of peaks can correspond to how many hours a battery can be discharged to reduce demand.\n\nnpeaks = 1 # Number of peaks\n\nFor the ERCOT 4CP detection task we are interested in correctly predicting the highest monthly load. Next, we filter the day in September with the highest hourly demand and predict the peak.\n\ncrossvalidation_df = crossvalidation_df.reset_index()[['ds','y','AutoNHITS']]\nmax_day = crossvalidation_df.iloc[crossvalidation_df['y'].argmax()].ds.day # Day with maximum load\ncv_df_day = crossvalidation_df.query('ds.dt.day == @max_day')\nmax_hour = cv_df_day['y'].argmax()\npeaks = cv_df_day['AutoNHITS'].argsort().iloc[-npeaks:].values # Predicted peaks\n\nIn the following plot we see how the model is able to correctly detect the coincident peak for September 2022.\n\nimport matplotlib.pyplot as plt\n\n\nplt.figure(figsize=(10, 5))\nplt.axvline(cv_df_day.iloc[max_hour]['ds'], color='black', label='True Peak')\nplt.scatter(cv_df_day.iloc[peaks]['ds'], cv_df_day.iloc[peaks]['AutoNHITS'], color='green', label=f'Predicted Top-{npeaks}')\nplt.plot(cv_df_day['ds'], cv_df_day['y'], label='y', color='blue')\nplt.plot(cv_df_day['ds'], cv_df_day['AutoNHITS'], label='Forecast', color='red')\nplt.xlabel('Time')\nplt.ylabel('Load (MW)')\nplt.grid()\nplt.legend()\n\n&lt;matplotlib.legend.Legend&gt;\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIn this example we only include September. However, NHITS can correctly predict the peaks for the 4 months of 2022. You can try this by increasing the nwindows parameter of cross_validation or filtering the Y_df dataset. The complete run for all months take only 10 minutes."
  },
  {
    "objectID": "examples/electricitypeakforecasting.html#references",
    "href": "examples/electricitypeakforecasting.html#references",
    "title": "Detect Demand Peaks",
    "section": "References",
    "text": "References\n\nCristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2021). “NHITS: Neural Hierarchical Interpolation for Time Series Forecasting”. Accepted at AAAI 2023."
  },
  {
    "objectID": "examples/intermittentdata.html",
    "href": "examples/intermittentdata.html",
    "title": "Intermittent/Sparse Series M5",
    "section": "",
    "text": "Intermittent or sparse data has very few non-zero observations. This type of data is hard to forecast because the zero values increase the uncertainty about the underlying patterns in the data. Furthermore, once a non-zero observation occurs, there can be considerable variation in its size. Intermittent time series are common in many industries, including finance, retail, transportation, and energy. Given the ubiquity of this type of series, special methods have been developed to forecast them. The first was from Croston (1972), followed by several variants and by different aggregation frameworks.\nThe models of NeuralForecast can be trained to model sparse or intermittent time series using a Poisson distribution loss. By the end of this tutorial, you’ll have a good understanding of these models and how to use them.\nOutline:\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/intermittentdata.html#install-libraries",
    "href": "examples/intermittentdata.html#install-libraries",
    "title": "Intermittent/Sparse Series M5",
    "section": "1. Install libraries",
    "text": "1. Install libraries\nWe assume that you have NeuralForecast already installed. If not, check this guide for instructions on how to install NeuralForecast\nInstall the necessary packages using pip install neuralforecast\n\n!pip install statsforecast s3fs fastparquet\n\n\n!pip install git+https://github.com/Nixtla/neuralforecast.git"
  },
  {
    "objectID": "examples/intermittentdata.html#load-and-explore-the-data",
    "href": "examples/intermittentdata.html#load-and-explore-the-data",
    "title": "Intermittent/Sparse Series M5",
    "section": "2. Load and explore the data",
    "text": "2. Load and explore the data\nFor this example, we’ll use a subset of the M5 Competition dataset. Each time series represents the unit sales of a particular product in a given Walmart store. At this level (product-store), most of the data is intermittent. We first need to import the data.\n\nimport pandas as pd\nfrom statsforecast import StatsForecast as sf\n\n/usr/local/lib/python3.8/dist-packages/statsforecast/core.py:21: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm\n\n\n\nY_df = pd.read_parquet('https://m5-benchmarks.s3.amazonaws.com/data/train/target.parquet')\nY_df = Y_df.rename(columns={\n    'item_id': 'unique_id', \n    'timestamp': 'ds', \n    'demand': 'y'\n})\nY_df['ds'] = pd.to_datetime(Y_df['ds'])\n\nFor simplicity sake we will keep just one category\n\nY_df = Y_df.query('unique_id.str.startswith(\"FOODS_3\")')\nY_df['unique_id'] = Y_df['unique_id'].astype(str)\nY_df = Y_df.reset_index(drop=True)\n\nPlot some series using the plot method from the StatsForecast class. This method prints 8 random series from the dataset and is useful for basic EDA.\n\nsf.plot(Y_df, engine='matplotlib')"
  },
  {
    "objectID": "examples/intermittentdata.html#train-models-for-intermittent-data",
    "href": "examples/intermittentdata.html#train-models-for-intermittent-data",
    "title": "Intermittent/Sparse Series M5",
    "section": "3. Train models for intermittent data",
    "text": "3. Train models for intermittent data\n\nfrom ray import tune\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.auto import AutoNHITS, AutoTFT\nfrom neuralforecast.losses.pytorch import DistributionLoss\n\nEach Auto model contains a default search space that was extensively tested on multiple large-scale datasets. Additionally, users can define specific search spaces tailored for particular datasets and tasks.\nFirst, we create a custom search space for the AutoNHITS and AutoTFT models. Search spaces are specified with dictionaries, where keys corresponds to the model’s hyperparameter and the value is a Tune function to specify how the hyperparameter will be sampled. For example, use randint to sample integers uniformly, and choice to sample values of a list.\n\nconfig_nhits = {\n    \"input_size\": tune.choice([28, 28*2, 28*3, 28*5]),              # Length of input window\n    \"n_blocks\": 5*[1],                                              # Length of input window\n    \"mlp_units\": 5 * [[512, 512]],                                  # Length of input window\n    \"n_pool_kernel_size\": tune.choice([5*[1], 5*[2], 5*[4],         \n                                      [8, 4, 2, 1, 1]]),            # MaxPooling Kernel size\n    \"n_freq_downsample\": tune.choice([[8, 4, 2, 1, 1],\n                                      [1, 1, 1, 1, 1]]),            # Interpolation expressivity ratios\n    \"learning_rate\": tune.loguniform(1e-4, 1e-2),                   # Initial Learning rate\n    \"scaler_type\": tune.choice([None]),                             # Scaler type\n    \"max_steps\": tune.choice([1000]),                               # Max number of training iterations\n    \"batch_size\": tune.choice([32, 64, 128, 256]),                  # Number of series in batch\n    \"windows_batch_size\": tune.choice([128, 256, 512, 1024]),       # Number of windows in batch\n    \"random_seed\": tune.randint(1, 20),                             # Random seed\n}\n\nconfig_tft = {\n        \"input_size\": tune.choice([28, 28*2, 28*3]),                # Length of input window\n        \"hidden_size\": tune.choice([64, 128, 256]),                 # Size of embeddings and encoders\n        \"learning_rate\": tune.loguniform(1e-4, 1e-2),               # Initial learning rate\n        \"scaler_type\": tune.choice([None]),                         # Scaler type\n        \"max_steps\": tune.choice([500, 1000]),                      # Max number of training iterations\n        \"batch_size\": tune.choice([32, 64, 128, 256]),              # Number of series in batch\n        \"windows_batch_size\": tune.choice([128, 256, 512, 1024]),   # Number of windows in batch\n        \"random_seed\": tune.randint(1, 20),                         # Random seed\n    }\n\nTo instantiate an Auto model you need to define:\n\nh: forecasting horizon.\nloss: training and validation loss from neuralforecast.losses.pytorch.\nconfig: hyperparameter search space. If None, the Auto class will use a pre-defined suggested hyperparameter space.\nsearch_alg: search algorithm (from tune.search), default is random search. Refer to https://docs.ray.io/en/latest/tune/api_docs/suggestion.html for more information on the different search algorithm options.\nnum_samples: number of configurations explored.\n\nIn this example we set horizon h as 28, use the Poisson distribution loss (ideal for count data) for training and validation, and use the default search algorithm.\n\nnf = NeuralForecast(\n    models=[\n        AutoNHITS(h=28, config=config_nhits, loss=DistributionLoss(distribution='Poisson', level=[80, 90], return_params=False), num_samples=5),\n        AutoTFT(h=28, config=config_tft, loss=DistributionLoss(distribution='Poisson', level=[80, 90], return_params=False), num_samples=2), \n    ],\n    freq='D'\n)\n\n\n\n\n\n\n\nTip\n\n\n\nThe number of samples, num_samples, is a crucial parameter! Larger values will usually produce better results as we explore more configurations in the search space, but it will increase training times. Larger search spaces will usually require more samples. As a general rule, we recommend setting num_samples higher than 20.\n\n\nNext, we use the Neuralforecast class to train the Auto model. In this step, Auto models will automatically perform hyperparamter tuning training multiple models with different hyperparameters, producing the forecasts on the validation set, and evaluating them. The best configuration is selected based on the error on a validation set. Only the best model is stored and used during inference.\n\nnf.fit(df=Y_df)\n\nNext, we use the predict method to forecast the next 28 days using the optimal hyperparameters.\n\nfcst_df = nf.predict()\n\n\n\n\n\n\n\n\nfcst_df.columns = fcst_df.columns.str.replace('-median', '')\n\n\nsf.plot(Y_df, fcst_df, engine='matplotlib', max_insample_length=28 * 3)"
  },
  {
    "objectID": "examples/intermittentdata.html#cross-validation",
    "href": "examples/intermittentdata.html#cross-validation",
    "title": "Intermittent/Sparse Series M5",
    "section": "4. Cross Validation",
    "text": "4. Cross Validation\nTime series cross-validation is a method for evaluating how a model would have performed in the past. It works by defining a sliding window across the historical data and predicting the period following it.\n\nNeuralForecast has an implementation of time series cross-validation that is fast and easy to use.\nThe cross_validation method from the NeuralForecast class takes the following arguments.\n\ndf: training data frame\nstep_size (int): step size between each window. In other words: how often do you want to run the forecasting processes.\nn_windows (int): number of windows used for cross validation. In other words: what number of forecasting processes in the past do you want to evaluate.\n\n\nnf = NeuralForecast(\n    models=[\n        AutoNHITS(h=28, config=config_nhits, loss=DistributionLoss(distribution='Poisson', level=[80, 90], return_params=False), num_samples=5),\n        AutoTFT(h=28, config=config_tft, loss=DistributionLoss(distribution='Poisson', level=[80, 90], return_params=False), num_samples=2), \n    ],\n    freq='D'\n)\n\n\ncv_df = nf.cross_validation(Y_df, n_windows=3, step_size=28)\n\nThe cv_df object is a new data frame that includes the following columns:\n\nunique_id index: (If you dont like working with index just run forecasts_cv_df.resetindex())\nds: datestamp or temporal index\ncutoff: the last datestamp or temporal index for the n_windows. If n_windows=1, then one unique cuttoff value, if n_windows=2 then two unique cutoff values.\ny: true value\n\"model\": columns with the model’s name and fitted value.\n\n\n# cv_df.columns = cv_df.columns.str.replace('-median', '')\n\n\ncv_df.head()\n\n\n  \n    \n      \n\n\n\n\n\n\nunique_id\nds\ncutoff\nAutoNHITS\nAutoNHITS-lo-90.0\nAutoNHITS-lo-80.0\nAutoNHITS-hi-80.0\nAutoNHITS-hi-90.0\nAutoTFT\nAutoTFT-lo-90.0\nAutoTFT-lo-80.0\nAutoTFT-hi-80.0\nAutoTFT-hi-90.0\ny\n\n\n\n\n0\nFOODS_3_001_CA_1\n2016-02-29\n2016-02-28\n0.0\n0.0\n0.0\n2.0\n2.0\n1.0\n0.0\n0.0\n2.0\n2.0\n0.0\n\n\n1\nFOODS_3_001_CA_1\n2016-03-01\n2016-02-28\n0.0\n0.0\n0.0\n2.0\n2.0\n1.0\n0.0\n0.0\n2.0\n2.0\n1.0\n\n\n2\nFOODS_3_001_CA_1\n2016-03-02\n2016-02-28\n0.0\n0.0\n0.0\n2.0\n2.0\n1.0\n0.0\n0.0\n2.0\n2.0\n1.0\n\n\n3\nFOODS_3_001_CA_1\n2016-03-03\n2016-02-28\n0.0\n0.0\n0.0\n2.0\n2.0\n1.0\n0.0\n0.0\n2.0\n2.0\n0.0\n\n\n4\nFOODS_3_001_CA_1\n2016-03-04\n2016-02-28\n0.0\n0.0\n0.0\n2.0\n2.0\n0.0\n0.0\n0.0\n2.0\n2.0\n0.0\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nfor cutoff in cv_df['cutoff'].unique():\n    sf.plot(Y_df, \n            cv_df.query('cutoff == @cutoff').drop(columns=['y', 'cutoff']), \n            max_insample_length=28 * 5, \n            unique_ids=['FOODS_3_001_CA_1'],\n            engine='matplotlib')\n\n\n\n\n\n\n\n\n\n\n\nEvaluate\nIn this section we will evaluate the performance of each model each cross validation window using the MSE metric.\n\nfrom neuralforecast.losses.numpy import mse, mae\n\n\ndef evaluate(df):\n    eval_ = {}\n    models = df.loc[:, ~df.columns.str.contains('unique_id|y|ds|cutoff|lo|hi')].columns\n    for model in models:\n        eval_[model] = {}\n        for metric in [mse, mae]:\n            eval_[model][metric.__name__] = metric(df['y'].values, df[model].values)\n    eval_df = pd.DataFrame(eval_).rename_axis('metric')\n    return eval_df\n\n\ncv_df.groupby('cutoff').apply(lambda df: evaluate(df))\n\n\n  \n    \n      \n\n\n\n\n\n\n\nAutoNHITS\nAutoTFT\n\n\ncutoff\nmetric\n\n\n\n\n\n\n2016-02-28\nmse\n10.274085\n15.240116\n\n\nmae\n1.445398\n1.511810\n\n\n2016-03-27\nmse\n9.533789\n14.307356\n\n\nmae\n1.445806\n1.520717\n\n\n2016-04-24\nmse\n9.561473\n14.719155\n\n\nmae\n1.455149\n1.534106"
  },
  {
    "objectID": "examples/intermittentdata.html#references",
    "href": "examples/intermittentdata.html#references",
    "title": "Intermittent/Sparse Series M5",
    "section": "References",
    "text": "References\n\nCroston, J. D. (1972). Forecasting and stock control for intermittent demands. Journal of the Operational Research Society, 23(3), 289-303.\nCristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2021). N-HiTS: Neural Hierarchical Interpolation for Time Series Forecasting. Accepted at AAAI 2023."
  },
  {
    "objectID": "examples/statsmlneuralmethods.html",
    "href": "examples/statsmlneuralmethods.html",
    "title": "Statistical, Machine Learning and Neural Forecasting methods",
    "section": "",
    "text": "Statistical, Machine Learning, and Neural Forecasting Methods In this tutorial, we will explore the process of forecasting on the M5 dataset by utilizing the most suitable model for each time series. We’ll accomplish this through an essential technique known as cross-validation. This approach helps us in estimating the predictive performance of our models, and in selecting the model that yields the best performance for each time series.\nThe M5 dataset comprises of hierarchical sales data, spanning five years, from Walmart. The aim is to forecast daily sales for the next 28 days. The dataset is broken down into the 50 states of America, with 10 stores in each state.\nIn the realm of time series forecasting and analysis, one of the more complex tasks is identifying the model that is optimally suited for a specific group of series. Quite often, this selection process leans heavily on intuition, which may not necessarily align with the empirical reality of our dataset.\nIn this tutorial, we aim to provide a more structured, data-driven approach to model selection for different groups of series within the M5 benchmark dataset. This dataset, well-known in the field of forecasting, allows us to showcase the versatility and power of our methodology.\nWe will train an assortment of models from various forecasting paradigms:\nStatsForecast\nMLForecast\nMachine Learning: Leveraging ML models like LightGBM, XGBoost, and LinearRegression can be advantageous due to their capacity to uncover intricate patterns in data. We’ll use the MLForecast library for this purpose.\nNeuralForecast\nDeep Learning: DL models, such as Transformers (AutoTFT) and Neural Networks (AutoNHITS), allow us to handle complex non-linear dependencies in time series data. We’ll utilize the NeuralForecast library for these models.\nUsing the Nixtla suite of libraries, we’ll be able to drive our model selection process with data, ensuring we utilize the most suitable models for specific groups of series in our dataset.\nOutline:\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/statsmlneuralmethods.html#installing-libraries",
    "href": "examples/statsmlneuralmethods.html#installing-libraries",
    "title": "Statistical, Machine Learning and Neural Forecasting methods",
    "section": "Installing Libraries",
    "text": "Installing Libraries\n\n!pip install statsforecast mlforecast neuralforecast datasetforecast s3fs pyarrow"
  },
  {
    "objectID": "examples/statsmlneuralmethods.html#download-and-prepare-data",
    "href": "examples/statsmlneuralmethods.html#download-and-prepare-data",
    "title": "Statistical, Machine Learning and Neural Forecasting methods",
    "section": "Download and prepare data",
    "text": "Download and prepare data\nThe example uses the M5 dataset. It consists of 30,490 bottom time series.\n\nimport pandas as pd\n\n\n# Load the training target dataset from the provided URL\nY_df = pd.read_parquet('https://m5-benchmarks.s3.amazonaws.com/data/train/target.parquet')\n\n# Rename columns to match the Nixtlaverse's expectations\n# The 'item_id' becomes 'unique_id' representing the unique identifier of the time series\n# The 'timestamp' becomes 'ds' representing the time stamp of the data points\n# The 'demand' becomes 'y' representing the target variable we want to forecast\nY_df = Y_df.rename(columns={\n    'item_id': 'unique_id', \n    'timestamp': 'ds', \n    'demand': 'y'\n})\n\n# Convert the 'ds' column to datetime format to ensure proper handling of date-related operations in subsequent steps\nY_df['ds'] = pd.to_datetime(Y_df['ds'])\n\nFor simplicity sake we will keep just one category\n\nY_df = Y_df.query('unique_id.str.startswith(\"FOODS_3\")').reset_index(drop=True)\n\nY_df['unique_id'] = Y_df['unique_id'].astype(str)"
  },
  {
    "objectID": "examples/statsmlneuralmethods.html#statsforecast",
    "href": "examples/statsmlneuralmethods.html#statsforecast",
    "title": "Statistical, Machine Learning and Neural Forecasting methods",
    "section": "StatsForecast",
    "text": "StatsForecast\nStatsForecast is a comprehensive library providing a suite of popular univariate time series forecasting models, all designed with a focus on high performance and scalability.\nHere’s what makes StatsForecast a powerful tool for time series forecasting:\n\nCollection of Local Models: StatsForecast provides a diverse collection of local models that can be applied to each time series individually, allowing us to capture unique patterns within each series.\nSimplicity: With StatsForecast, training, forecasting, and backtesting multiple models become a straightforward process, requiring only a few lines of code. This simplicity makes it a convenient tool for both beginners and experienced practitioners.\nOptimized for Speed: The implementation of the models in StatsForecast is optimized for speed, ensuring that large-scale computations are performed efficiently, thereby reducing the overall time for model training and prediction.\nHorizontal Scalability: One of the distinguishing features of StatsForecast is its ability to scale horizontally. It is compatible with distributed computing frameworks such as Spark, Dask, and Ray. This feature allows it to handle large datasets by distributing the computations across multiple nodes in a cluster, making it a go-to solution for large-scale time series forecasting tasks.\n\nStatsForecast receives a list of models to fit each time series. Since we are dealing with Daily data, it would be benefitial to use 7 as seasonality.\n\n# Import necessary models from the statsforecast library\nfrom statsforecast.models import (\n    # SeasonalNaive: A model that uses the previous season's data as the forecast\n    SeasonalNaive,\n    # Naive: A simple model that uses the last observed value as the forecast\n    Naive,\n    # HistoricAverage: This model uses the average of all historical data as the forecast\n    HistoricAverage,\n    # CrostonOptimized: A model specifically designed for intermittent demand forecasting\n    CrostonOptimized,\n    # ADIDA: Adaptive combination of Intermittent Demand Approaches, a model designed for intermittent demand\n    ADIDA,\n    # IMAPA: Intermittent Multiplicative AutoRegressive Average, a model for intermittent series that incorporates autocorrelation\n    IMAPA,\n    # AutoETS: Automated Exponential Smoothing model that automatically selects the best Exponential Smoothing model based on AIC\n    AutoETS\n)\n\nWe fit the models by instantiating a new StatsForecast object with the following parameters:\n\nmodels: a list of models. Select the models you want from models and import them.\nfreq: a string indicating the frequency of the data. (See panda’s available frequencies.)\nn_jobs: int, number of jobs used in the parallel processing, use -1 for all cores.\nfallback_model: a model to be used if a model fails. Any settings are passed into the constructor. Then you call its fit method and pass in the historical data frame.\n\n\nhorizon = 28\nmodels = [\n    SeasonalNaive(season_length=7),\n    Naive(),\n    HistoricAverage(),\n    CrostonOptimized(),\n    ADIDA(),\n    IMAPA(),\n    AutoETS(season_length=7)\n]\n\n\n# Instantiate the StatsForecast class\nsf = StatsForecast(\n    models=models,  # A list of models to be used for forecasting\n    freq='D',  # The frequency of the time series data (in this case, 'D' stands for daily frequency)\n    n_jobs=-1,  # The number of CPU cores to use for parallel execution (-1 means use all available cores)\n)\n\nThe forecast method takes two arguments: forecasts next h (horizon) and level.\n\nh (int): represents the forecast h steps into the future. In this case, 12 months ahead.\nlevel (list of floats): this optional parameter is used for probabilistic forecasting. Set the level (or confidence percentile) of your prediction interval. For example, level=[90] means that the model expects the real value to be inside that interval 90% of the times.\n\nThe forecast object here is a new data frame that includes a column with the name of the model and the y hat values, as well as columns for the uncertainty intervals.\nThis block of code times how long it takes to run the forecasting function of the StatsForecast class, which predicts the next 28 days (h=28). The level is set to [90], meaning it will compute the 90% prediction interval. The time is calculated in minutes and printed out at the end.\n\nfrom time import time\n\n# Get the current time before forecasting starts, this will be used to measure the execution time\ninit = time()\n\n# Call the forecast method of the StatsForecast instance to predict the next 28 days (h=28) \n# Level is set to [90], which means that it will compute the 90% prediction interval\nfcst_df = sf.forecast(df=Y_df, h=28, level=[90])\n\n# Get the current time after the forecasting ends\nend = time()\n\n# Calculate and print the total time taken for the forecasting in minutes\nprint(f'Forecast Minutes: {(end - init) / 60}')\n\nForecast Minutes: 2.270755163828532\n\n\n\nfcst_df.head()\n\n\n\n\n\n\n\n\nds\nSeasonalNaive\nSeasonalNaive-lo-90\nSeasonalNaive-hi-90\nNaive\nNaive-lo-90\nNaive-hi-90\nHistoricAverage\nHistoricAverage-lo-90\nHistoricAverage-hi-90\nCrostonOptimized\nADIDA\nIMAPA\nAutoETS\nAutoETS-lo-90\nAutoETS-hi-90\n\n\nunique_id\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFOODS_3_001_CA_1\n2016-05-23\n1.0\n-2.847174\n4.847174\n2.0\n0.098363\n3.901637\n0.448738\n-1.009579\n1.907055\n0.345192\n0.345477\n0.347249\n0.381414\n-1.028122\n1.790950\n\n\nFOODS_3_001_CA_1\n2016-05-24\n0.0\n-3.847174\n3.847174\n2.0\n-0.689321\n4.689321\n0.448738\n-1.009579\n1.907055\n0.345192\n0.345477\n0.347249\n0.286933\n-1.124136\n1.698003\n\n\nFOODS_3_001_CA_1\n2016-05-25\n0.0\n-3.847174\n3.847174\n2.0\n-1.293732\n5.293732\n0.448738\n-1.009579\n1.907055\n0.345192\n0.345477\n0.347249\n0.334987\n-1.077614\n1.747588\n\n\nFOODS_3_001_CA_1\n2016-05-26\n1.0\n-2.847174\n4.847174\n2.0\n-1.803274\n5.803274\n0.448738\n-1.009579\n1.907055\n0.345192\n0.345477\n0.347249\n0.186851\n-1.227280\n1.600982\n\n\nFOODS_3_001_CA_1\n2016-05-27\n0.0\n-3.847174\n3.847174\n2.0\n-2.252190\n6.252190\n0.448738\n-1.009579\n1.907055\n0.345192\n0.345477\n0.347249\n0.308112\n-1.107548\n1.723771"
  },
  {
    "objectID": "examples/statsmlneuralmethods.html#mlforecast",
    "href": "examples/statsmlneuralmethods.html#mlforecast",
    "title": "Statistical, Machine Learning and Neural Forecasting methods",
    "section": "MLForecast",
    "text": "MLForecast\nMLForecast is a powerful library that provides automated feature creation for time series forecasting, facilitating the use of global machine learning models. It is designed for high performance and scalability.\nKey features of MLForecast include:\n\nSupport for sklearn models: MLForecast is compatible with models that follow the scikit-learn API. This makes it highly flexible and allows it to seamlessly integrate with a wide variety of machine learning algorithms.\nSimplicity: With MLForecast, the tasks of training, forecasting, and backtesting models can be accomplished in just a few lines of code. This streamlined simplicity makes it user-friendly for practitioners at all levels of expertise.\nOptimized for speed: MLForecast is engineered to execute tasks rapidly, which is crucial when handling large datasets and complex models.\nHorizontal Scalability: MLForecast is capable of horizontal scaling using distributed computing frameworks such as Spark, Dask, and Ray. This feature enables it to efficiently process massive datasets by distributing the computations across multiple nodes in a cluster, making it ideal for large-scale time series forecasting tasks.\n\n\nfrom mlforecast import MLForecast\nfrom mlforecast.target_transforms import Differences\nfrom mlforecast.utils import PredictionIntervals\nfrom window_ops.expanding import expanding_mean\n\n\n!pip install lightgbm xgboost\n\n\n# Import the necessary models from various libraries\n\n# LGBMRegressor: A gradient boosting framework that uses tree-based learning algorithms from the LightGBM library\nfrom lightgbm import LGBMRegressor\n\n# XGBRegressor: A gradient boosting regressor model from the XGBoost library\nfrom xgboost import XGBRegressor\n\n# LinearRegression: A simple linear regression model from the scikit-learn library\nfrom sklearn.linear_model import LinearRegression\n\nTo use MLForecast for time series forecasting, we instantiate a new MLForecast object and provide it with various parameters to tailor the modeling process to our specific needs:\n\nmodels: This parameter accepts a list of machine learning models you wish to use for forecasting. You can import your preferred models from scikit-learn, lightgbm and xgboost.\nfreq: This is a string indicating the frequency of your data (hourly, daily, weekly, etc.). The specific format of this string should align with pandas’ recognized frequency strings.\ntarget_transforms: These are transformations applied to the target variable before model training and after model prediction. This can be useful when working with data that may benefit from transformations, such as log-transforms for highly skewed data.\nlags: This parameter accepts specific lag values to be used as regressors. Lags represent how many steps back in time you want to look when creating features for your model. For example, if you want to use the previous day’s data as a feature for predicting today’s value, you would specify a lag of 1.\nlags_transforms: These are specific transformations for each lag. This allows you to apply transformations to your lagged features.\ndate_features: This parameter specifies date-related features to be used as regressors. For instance, you might want to include the day of the week or the month as a feature in your model.\nnum_threads: This parameter controls the number of threads to use for parallelizing feature creation, helping to speed up this process when working with large datasets.\n\nAll these settings are passed to the MLForecast constructor. Once the MLForecast object is initialized with these settings, we call its fit method and pass the historical data frame as the argument. The fit method trains the models on the provided historical data, readying them for future forecasting tasks.\n\n# Instantiate the MLForecast object\nmlf = MLForecast(\n    models=[LGBMRegressor(), XGBRegressor(), LinearRegression()],  # List of models for forecasting: LightGBM, XGBoost and Linear Regression\n    freq='D',  # Frequency of the data - 'D' for daily frequency\n    lags=list(range(1, 7)),  # Specific lags to use as regressors: 1 to 6 days\n    lag_transforms = {\n        1:  [expanding_mean],  # Apply expanding mean transformation to the lag of 1 day\n    },\n    date_features=['year', 'month', 'day', 'dayofweek', 'quarter', 'week'],  # Date features to use as regressors\n)\n\nJust call the fit models to train the select models. In this case we are generating conformal prediction intervals.\n\n# Start the timer to calculate the time taken for fitting the models\ninit = time()\n\n# Fit the MLForecast models to the data, with prediction intervals set using a window size of 28 days\nmlf.fit(Y_df, prediction_intervals=PredictionIntervals(window_size=28))\n\n# Calculate the end time after fitting the models\nend = time()\n\n# Print the time taken to fit the MLForecast models, in minutes\nprint(f'MLForecast Minutes: {(end - init) / 60}')\n\nMLForecast Minutes: 2.2809854547182717\n\n\nAfter that, just call predict to generate forecasts.\n\nfcst_mlf_df = mlf.predict(28, level=[90])\n\n\nfcst_mlf_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nLGBMRegressor\nXGBRegressor\nLinearRegression\nLGBMRegressor-lo-90\nLGBMRegressor-hi-90\nXGBRegressor-lo-90\nXGBRegressor-hi-90\nLinearRegression-lo-90\nLinearRegression-hi-90\n\n\n\n\n0\nFOODS_3_001_CA_1\n2016-05-23\n0.549520\n0.598431\n0.359638\n-0.213915\n1.312955\n-0.020050\n1.216912\n0.030000\n0.689277\n\n\n1\nFOODS_3_001_CA_1\n2016-05-24\n0.553196\n0.337268\n0.100361\n-0.251383\n1.357775\n-0.201449\n0.875985\n-0.216195\n0.416917\n\n\n2\nFOODS_3_001_CA_1\n2016-05-25\n0.599668\n0.349604\n0.175840\n-0.203974\n1.403309\n-0.284416\n0.983624\n-0.150593\n0.502273\n\n\n3\nFOODS_3_001_CA_1\n2016-05-26\n0.638097\n0.322144\n0.156460\n0.118688\n1.157506\n-0.085872\n0.730160\n-0.273851\n0.586771\n\n\n4\nFOODS_3_001_CA_1\n2016-05-27\n0.763305\n0.300362\n0.328194\n-0.313091\n1.839701\n-0.296636\n0.897360\n-0.657089\n1.313476"
  },
  {
    "objectID": "examples/statsmlneuralmethods.html#neuralforecast",
    "href": "examples/statsmlneuralmethods.html#neuralforecast",
    "title": "Statistical, Machine Learning and Neural Forecasting methods",
    "section": "NeuralForecast",
    "text": "NeuralForecast\nNeuralForecast is a robust collection of neural forecasting models that focuses on usability and performance. It includes a variety of model architectures, from classic networks such as Multilayer Perceptrons (MLP) and Recurrent Neural Networks (RNN) to novel contributions like N-BEATS, N-HITS, Temporal Fusion Transformers (TFT), and more.\nKey features of NeuralForecast include:\n\nA broad collection of global models. Out of the box implementation of MLP, LSTM, RNN, TCN, DilatedRNN, NBEATS, NHITS, ESRNN, TFT, Informer, PatchTST and HINT.\nA simple and intuitive interface that allows training, forecasting, and backtesting of various models in a few lines of code.\nSupport for GPU acceleration to improve computational speed.\n\nThis machine doesn’t have GPU, but Google Colabs offers some for free.\nUsing Colab’s GPU to train NeuralForecast.\n\n# Read the results from Colab\nfcst_nf_df = pd.read_parquet('https://m5-benchmarks.s3.amazonaws.com/data/forecast-nf.parquet')\n\n\nfcst_nf_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nAutoNHITS\nAutoNHITS-lo-90\nAutoNHITS-hi-90\nAutoTFT\nAutoTFT-lo-90\nAutoTFT-hi-90\n\n\n\n\n0\nFOODS_3_001_CA_1\n2016-05-23\n0.0\n0.0\n2.0\n0.0\n0.0\n2.0\n\n\n1\nFOODS_3_001_CA_1\n2016-05-24\n0.0\n0.0\n2.0\n0.0\n0.0\n2.0\n\n\n2\nFOODS_3_001_CA_1\n2016-05-25\n0.0\n0.0\n2.0\n0.0\n0.0\n1.0\n\n\n3\nFOODS_3_001_CA_1\n2016-05-26\n0.0\n0.0\n2.0\n0.0\n0.0\n2.0\n\n\n4\nFOODS_3_001_CA_1\n2016-05-27\n0.0\n0.0\n2.0\n0.0\n0.0\n2.0\n\n\n\n\n\n\n\n\n# Merge the forecasts from StatsForecast and NeuralForecast\nfcst_df = fcst_df.merge(fcst_nf_df, how='left', on=['unique_id', 'ds'])\n\n# Merge the forecasts from MLForecast into the combined forecast dataframe\nfcst_df = fcst_df.merge(fcst_mlf_df, how='left', on=['unique_id', 'ds'])\n\n\nfcst_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\nSeasonalNaive\nSeasonalNaive-lo-90\nSeasonalNaive-hi-90\nNaive\nNaive-lo-90\nNaive-hi-90\nHistoricAverage\nHistoricAverage-lo-90\n...\nAutoTFT-hi-90\nLGBMRegressor\nXGBRegressor\nLinearRegression\nLGBMRegressor-lo-90\nLGBMRegressor-hi-90\nXGBRegressor-lo-90\nXGBRegressor-hi-90\nLinearRegression-lo-90\nLinearRegression-hi-90\n\n\n\n\n0\nFOODS_3_001_CA_1\n2016-05-23\n1.0\n-2.847174\n4.847174\n2.0\n0.098363\n3.901637\n0.448738\n-1.009579\n...\n2.0\n0.549520\n0.598431\n0.359638\n-0.213915\n1.312955\n-0.020050\n1.216912\n0.030000\n0.689277\n\n\n1\nFOODS_3_001_CA_1\n2016-05-24\n0.0\n-3.847174\n3.847174\n2.0\n-0.689321\n4.689321\n0.448738\n-1.009579\n...\n2.0\n0.553196\n0.337268\n0.100361\n-0.251383\n1.357775\n-0.201449\n0.875985\n-0.216195\n0.416917\n\n\n2\nFOODS_3_001_CA_1\n2016-05-25\n0.0\n-3.847174\n3.847174\n2.0\n-1.293732\n5.293732\n0.448738\n-1.009579\n...\n1.0\n0.599668\n0.349604\n0.175840\n-0.203974\n1.403309\n-0.284416\n0.983624\n-0.150593\n0.502273\n\n\n3\nFOODS_3_001_CA_1\n2016-05-26\n1.0\n-2.847174\n4.847174\n2.0\n-1.803274\n5.803274\n0.448738\n-1.009579\n...\n2.0\n0.638097\n0.322144\n0.156460\n0.118688\n1.157506\n-0.085872\n0.730160\n-0.273851\n0.586771\n\n\n4\nFOODS_3_001_CA_1\n2016-05-27\n0.0\n-3.847174\n3.847174\n2.0\n-2.252190\n6.252190\n0.448738\n-1.009579\n...\n2.0\n0.763305\n0.300362\n0.328194\n-0.313091\n1.839701\n-0.296636\n0.897360\n-0.657089\n1.313476\n\n\n\n\n5 rows × 32 columns"
  },
  {
    "objectID": "examples/statsmlneuralmethods.html#forecast-plots",
    "href": "examples/statsmlneuralmethods.html#forecast-plots",
    "title": "Statistical, Machine Learning and Neural Forecasting methods",
    "section": "Forecast plots",
    "text": "Forecast plots\n\nsf.plot(Y_df, fcst_df, max_insample_length=28 * 3)\n\n\n                                                \n\n\nUse the plot function to explore models and ID’s\n\nsf.plot(Y_df, fcst_df, max_insample_length=28 * 3, \n        models=['CrostonOptimized', 'AutoNHITS', 'SeasonalNaive', 'LGBMRegressor'])"
  },
  {
    "objectID": "examples/statsmlneuralmethods.html#cross-validation-in-statsforecast",
    "href": "examples/statsmlneuralmethods.html#cross-validation-in-statsforecast",
    "title": "Statistical, Machine Learning and Neural Forecasting methods",
    "section": "Cross Validation in StatsForecast",
    "text": "Cross Validation in StatsForecast\nThe cross_validation method from the StatsForecast class accepts the following arguments:\n\ndf: A DataFrame representing the training data.\nh (int): The forecast horizon, represented as the number of steps into the future that we wish to predict. For example, if we’re forecasting hourly data, h=24 would represent a 24-hour forecast.\nstep_size (int): The step size between each cross-validation window. This parameter determines how often we want to run the forecasting process.\nn_windows (int): The number of windows used for cross validation. This parameter defines how many past forecasting processes we want to evaluate.\n\nThese parameters allow us to control the extent and granularity of our cross-validation process. By tuning these settings, we can balance between computational cost and the thoroughness of the cross-validation.\n\ninit = time()\ncv_df = sf.cross_validation(df=Y_df, h=horizon, n_windows=3, step_size=horizon, level=[90])\nend = time()\nprint(f'CV Minutes: {(end - init) / 60}')\n\n/home/ubuntu/statsforecast/statsforecast/ets.py:1041: RuntimeWarning:\n\ndivide by zero encountered in double_scalars\n\n\n\nCV Minutes: 5.206169327100118\n\n\nThe crossvaldation_df object is a new data frame that includes the following columns:\n\nunique_id index: (If you dont like working with index just run forecasts_cv_df.resetindex())\nds: datestamp or temporal index\ncutoff: the last datestamp or temporal index for the n_windows. If n_windows=1, then one unique cuttoff value, if n_windows=2 then two unique cutoff values.\ny: true value\n\"model\": columns with the model’s name and fitted value.\n\n\ncv_df.head()\n\n\n\n\n\n\n\n\nds\ncutoff\ny\nSeasonalNaive\nSeasonalNaive-lo-90\nSeasonalNaive-hi-90\nNaive\nNaive-lo-90\nNaive-hi-90\nHistoricAverage\nHistoricAverage-lo-90\nHistoricAverage-hi-90\nCrostonOptimized\nADIDA\nIMAPA\nAutoETS\nAutoETS-lo-90\nAutoETS-hi-90\n\n\nunique_id\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFOODS_3_001_CA_1\n2016-02-29\n2016-02-28\n0.0\n2.0\n-1.878885\n5.878885\n0.0\n-1.917011\n1.917011\n0.449111\n-1.021813\n1.920036\n0.618472\n0.618375\n0.617998\n0.655286\n-0.765731\n2.076302\n\n\nFOODS_3_001_CA_1\n2016-03-01\n2016-02-28\n1.0\n0.0\n-3.878885\n3.878885\n0.0\n-2.711064\n2.711064\n0.449111\n-1.021813\n1.920036\n0.618472\n0.618375\n0.617998\n0.568595\n-0.853966\n1.991155\n\n\nFOODS_3_001_CA_1\n2016-03-02\n2016-02-28\n1.0\n0.0\n-3.878885\n3.878885\n0.0\n-3.320361\n3.320361\n0.449111\n-1.021813\n1.920036\n0.618472\n0.618375\n0.617998\n0.618805\n-0.805298\n2.042908\n\n\nFOODS_3_001_CA_1\n2016-03-03\n2016-02-28\n0.0\n1.0\n-2.878885\n4.878885\n0.0\n-3.834023\n3.834023\n0.449111\n-1.021813\n1.920036\n0.618472\n0.618375\n0.617998\n0.455891\n-0.969753\n1.881534\n\n\nFOODS_3_001_CA_1\n2016-03-04\n2016-02-28\n0.0\n1.0\n-2.878885\n4.878885\n0.0\n-4.286568\n4.286568\n0.449111\n-1.021813\n1.920036\n0.618472\n0.618375\n0.617998\n0.591197\n-0.835987\n2.018380"
  },
  {
    "objectID": "examples/statsmlneuralmethods.html#mlforecast-1",
    "href": "examples/statsmlneuralmethods.html#mlforecast-1",
    "title": "Statistical, Machine Learning and Neural Forecasting methods",
    "section": "MLForecast",
    "text": "MLForecast\nThe cross_validation method from the MLForecast class takes the following arguments.\n\ndata: training data frame\nwindow_size (int): represents h steps into the future that are being forecasted. In this case, 24 hours ahead.\nstep_size (int): step size between each window. In other words: how often do you want to run the forecasting processes.\nn_windows (int): number of windows used for cross-validation. In other words: what number of forecasting processes in the past do you want to evaluate.\nprediction_intervals: class to compute conformal intervals.\n\n\ninit = time()\ncv_mlf_df = mlf.cross_validation(\n    data=Y_df, \n    window_size=horizon, \n    n_windows=3, \n    step_size=horizon, \n    level=[90],\n)\nend = time()\nprint(f'CV Minutes: {(end - init) / 60}')\n\n/home/ubuntu/miniconda/envs/statsforecast/lib/python3.10/site-packages/mlforecast/forecast.py:576: UserWarning:\n\nExcuting `cross_validation` after `fit` can produce unexpected errors\n\n/home/ubuntu/miniconda/envs/statsforecast/lib/python3.10/site-packages/mlforecast/forecast.py:468: UserWarning:\n\nPlease rerun the `fit` method passing a proper value to prediction intervals to compute them.\n\n/home/ubuntu/miniconda/envs/statsforecast/lib/python3.10/site-packages/mlforecast/forecast.py:468: UserWarning:\n\nPlease rerun the `fit` method passing a proper value to prediction intervals to compute them.\n\n/home/ubuntu/miniconda/envs/statsforecast/lib/python3.10/site-packages/mlforecast/forecast.py:468: UserWarning:\n\nPlease rerun the `fit` method passing a proper value to prediction intervals to compute them.\n\n\n\nCV Minutes: 2.961174162228902\n\n\nThe crossvaldation_df object is a new data frame that includes the following columns:\n\nunique_id index: (If you dont like working with index just run forecasts_cv_df.resetindex())\nds: datestamp or temporal index\ncutoff: the last datestamp or temporal index for the n_windows. If n_windows=1, then one unique cuttoff value, if n_windows=2 then two unique cutoff values.\ny: true value\n\"model\": columns with the model’s name and fitted value.\n\n\ncv_mlf_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ncutoff\ny\nLGBMRegressor\nXGBRegressor\nLinearRegression\n\n\n\n\n0\nFOODS_3_001_CA_1\n2016-02-29\n2016-02-28\n0.0\n0.435674\n0.556261\n-0.312492\n\n\n1\nFOODS_3_001_CA_1\n2016-03-01\n2016-02-28\n1.0\n0.639676\n0.625806\n-0.041924\n\n\n2\nFOODS_3_001_CA_1\n2016-03-02\n2016-02-28\n1.0\n0.792989\n0.659650\n0.263699\n\n\n3\nFOODS_3_001_CA_1\n2016-03-03\n2016-02-28\n0.0\n0.806868\n0.535121\n0.482491\n\n\n4\nFOODS_3_001_CA_1\n2016-03-04\n2016-02-28\n0.0\n0.829106\n0.313353\n0.677326"
  },
  {
    "objectID": "examples/statsmlneuralmethods.html#neuralforecast-1",
    "href": "examples/statsmlneuralmethods.html#neuralforecast-1",
    "title": "Statistical, Machine Learning and Neural Forecasting methods",
    "section": "NeuralForecast",
    "text": "NeuralForecast\nThis machine doesn’t have GPU, but Google Colabs offers some for free.\nUsing Colab’s GPU to train NeuralForecast.\n\ncv_nf_df = pd.read_parquet('https://m5-benchmarks.s3.amazonaws.com/data/cross-validation-nf.parquet')\n\n\ncv_nf_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ncutoff\nAutoNHITS\nAutoNHITS-lo-90\nAutoNHITS-hi-90\nAutoTFT\nAutoTFT-lo-90\nAutoTFT-hi-90\ny\n\n\n\n\n0\nFOODS_3_001_CA_1\n2016-02-29\n2016-02-28\n0.0\n0.0\n2.0\n1.0\n0.0\n2.0\n0.0\n\n\n1\nFOODS_3_001_CA_1\n2016-03-01\n2016-02-28\n0.0\n0.0\n2.0\n1.0\n0.0\n2.0\n1.0\n\n\n2\nFOODS_3_001_CA_1\n2016-03-02\n2016-02-28\n0.0\n0.0\n2.0\n1.0\n0.0\n2.0\n1.0\n\n\n3\nFOODS_3_001_CA_1\n2016-03-03\n2016-02-28\n0.0\n0.0\n2.0\n1.0\n0.0\n2.0\n0.0\n\n\n4\nFOODS_3_001_CA_1\n2016-03-04\n2016-02-28\n0.0\n0.0\n2.0\n1.0\n0.0\n2.0\n0.0"
  },
  {
    "objectID": "examples/statsmlneuralmethods.html#merge-cross-validation-forecasts",
    "href": "examples/statsmlneuralmethods.html#merge-cross-validation-forecasts",
    "title": "Statistical, Machine Learning and Neural Forecasting methods",
    "section": "Merge cross validation forecasts",
    "text": "Merge cross validation forecasts\n\ncv_df = cv_df.merge(cv_nf_df.drop(columns=['y']), how='left', on=['unique_id', 'ds', 'cutoff'])\ncv_df = cv_df.merge(cv_mlf_df.drop(columns=['y']), how='left', on=['unique_id', 'ds', 'cutoff'])"
  },
  {
    "objectID": "examples/statsmlneuralmethods.html#plots-cv",
    "href": "examples/statsmlneuralmethods.html#plots-cv",
    "title": "Statistical, Machine Learning and Neural Forecasting methods",
    "section": "Plots CV",
    "text": "Plots CV\n\ncutoffs = cv_df['cutoff'].unique()\n\n\nfor cutoff in cutoffs:\n    img = sf.plot(\n        Y_df, \n        cv_df.query('cutoff == @cutoff').drop(columns=['y', 'cutoff']), \n        max_insample_length=28 * 5, \n        unique_ids=['FOODS_3_001_CA_1'],\n    )\n    img.show()\n\n\n                                                \n\n\n\n                                                \n\n\n\n                                                \n\n\n\nAggregate Demand\n\nagg_cv_df = cv_df.loc[:,~cv_df.columns.str.contains('hi|lo')].groupby(['ds', 'cutoff']).sum(numeric_only=True).reset_index()\nagg_cv_df.insert(0, 'unique_id', 'agg_demand')\n\n\nagg_Y_df = Y_df.groupby(['ds']).sum(numeric_only=True).reset_index()\nagg_Y_df.insert(0, 'unique_id', 'agg_demand')\n\n\nfor cutoff in cutoffs:\n    img = sf.plot(\n        agg_Y_df, \n        agg_cv_df.query('cutoff == @cutoff').drop(columns=['y', 'cutoff']),\n        max_insample_length=28 * 5,\n    )\n    img.show()"
  },
  {
    "objectID": "examples/statsmlneuralmethods.html#evaluation-per-series-and-cv-window",
    "href": "examples/statsmlneuralmethods.html#evaluation-per-series-and-cv-window",
    "title": "Statistical, Machine Learning and Neural Forecasting methods",
    "section": "Evaluation per series and CV window",
    "text": "Evaluation per series and CV window\nIn this section, we will evaluate the performance of each model for each time series and each cross validation window. Since we have many combinations, we will use dask to parallelize the evaluation. The parallelization will be done using fugue.\n\nfrom typing import List, Callable\n\nfrom distributed import Client\nfrom fugue import transform\nfrom fugue_dask import DaskExecutionEngine\nfrom datasetsforecast.losses import mse, mae, smape\n\nThe evaluate function receives a unique combination of a time series and a window, and calculates different metrics for each model in df.\n\ndef evaluate(df: pd.DataFrame, metrics: List[Callable]) -&gt; pd.DataFrame:\n    eval_ = {}\n    models = df.loc[:, ~df.columns.str.contains('unique_id|y|ds|cutoff|lo|hi')].columns\n    for model in models:\n        eval_[model] = {}\n        for metric in metrics:\n            eval_[model][metric.__name__] = metric(df['y'], df[model])\n    eval_df = pd.DataFrame(eval_).rename_axis('metric').reset_index()\n    eval_df.insert(0, 'cutoff', df['cutoff'].iloc[0])\n    eval_df.insert(0, 'unique_id', df['unique_id'].iloc[0])\n    return eval_df\n\n\nstr_models = cv_df.loc[:, ~cv_df.columns.str.contains('unique_id|y|ds|cutoff|lo|hi')].columns\nstr_models = ','.join([f\"{model}:float\" for model in str_models])\ncv_df['cutoff'] = cv_df['cutoff'].astype(str)\ncv_df['unique_id'] = cv_df['unique_id'].astype(str)\n\nLet’s cleate a dask client.\n\nclient = Client() # without this, dask is not in distributed mode\n# fugue.dask.dataframe.default.partitions determines the default partitions for a new DaskDataFrame\nengine = DaskExecutionEngine({\"fugue.dask.dataframe.default.partitions\": 96})\n\nThe transform function takes the evaluate functions and applies it to each combination of time series (unique_id) and cross validation window (cutoff) using the dask client we created before.\n\nevaluation_df = transform(\n    cv_df.loc[:, ~cv_df.columns.str.contains('lo|hi')], \n    evaluate, \n    engine=\"dask\",\n    params={'metrics': [mse, mae, smape]}, \n    schema=f\"unique_id:str,cutoff:str,metric:str, {str_models}\", \n    as_local=True,\n    partition={'by': ['unique_id', 'cutoff']}\n)\n\n/home/ubuntu/miniconda/envs/statsforecast/lib/python3.10/site-packages/distributed/client.py:3109: UserWarning:\n\nSending large graph of size 49.63 MiB.\nThis may cause some slowdown.\nConsider scattering data ahead of time and using futures.\n\n\n\n\nevaluation_df.head()\n\n\n\n\n\n\n\n\nunique_id\ncutoff\nmetric\nSeasonalNaive\nNaive\nHistoricAverage\nCrostonOptimized\nADIDA\nIMAPA\nAutoETS\nAutoNHITS\nAutoTFT\nLGBMRegressor\nXGBRegressor\nLinearRegression\n\n\n\n\n0\nFOODS_3_003_WI_3\n2016-02-28\nmse\n1.142857\n1.142857\n0.816646\n0.816471\n1.142857\n1.142857\n1.142857\n1.142857\n1.142857\n0.832010\n1.020361\n0.887121\n\n\n1\nFOODS_3_003_WI_3\n2016-02-28\nmae\n0.571429\n0.571429\n0.729592\n0.731261\n0.571429\n0.571429\n0.571429\n0.571429\n0.571429\n0.772788\n0.619949\n0.685413\n\n\n2\nFOODS_3_003_WI_3\n2016-02-28\nsmape\n71.428574\n71.428574\n158.813507\n158.516235\n200.000000\n200.000000\n200.000000\n71.428574\n71.428574\n145.901947\n188.159164\n178.883743\n\n\n3\nFOODS_3_013_CA_3\n2016-04-24\nmse\n4.000000\n6.214286\n2.406764\n3.561202\n2.267853\n2.267600\n2.268677\n2.750000\n2.125000\n2.160508\n2.370228\n2.289606\n\n\n4\nFOODS_3_013_CA_3\n2016-04-24\nmae\n1.500000\n2.142857\n1.214286\n1.340446\n1.214286\n1.214286\n1.214286\n1.107143\n1.142857\n1.140084\n1.157548\n1.148813\n\n\n\n\n\n\n\n\n# Calculate the mean metric for each cross validation window\nevaluation_df.groupby(['cutoff', 'metric']).mean(numeric_only=True)\n\n\n\n\n\n\n\n\n\nSeasonalNaive\nNaive\nHistoricAverage\nCrostonOptimized\nADIDA\nIMAPA\nAutoETS\nAutoNHITS\nAutoTFT\nLGBMRegressor\nXGBRegressor\nLinearRegression\n\n\ncutoff\nmetric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2016-02-28\nmae\n1.744289\n2.040496\n1.730704\n1.633017\n1.527965\n1.528772\n1.497553\n1.434938\n1.485419\n1.688403\n1.514102\n1.576320\n\n\nmse\n14.510710\n19.080585\n12.858994\n11.785032\n11.114497\n11.100909\n10.347847\n10.010982\n10.964664\n10.436206\n10.968788\n10.792831\n\n\nsmape\n85.202042\n87.719086\n125.418488\n124.749908\n127.591858\n127.704102\n127.790672\n79.132614\n80.983368\n118.489983\n140.420578\n127.043137\n\n\n2016-03-27\nmae\n1.795973\n2.106449\n1.754029\n1.662087\n1.570701\n1.572741\n1.535301\n1.432412\n1.502393\n1.712493\n1.600193\n1.601612\n\n\nmse\n14.810259\n26.044472\n12.804104\n12.020620\n12.083861\n12.120033\n11.315013\n9.445867\n10.762877\n10.723589\n12.924312\n10.943772\n\n\nsmape\n87.407471\n89.453247\n123.587196\n123.460030\n123.428459\n123.538521\n123.612991\n79.926781\n82.013168\n116.089699\n138.885941\n127.304871\n\n\n2016-04-24\nmae\n1.785983\n1.990774\n1.762506\n1.609268\n1.527627\n1.529721\n1.501820\n1.447401\n1.505127\n1.692946\n1.541845\n1.590985\n\n\nmse\n13.476350\n16.234917\n13.151311\n10.647048\n10.072225\n10.062395\n9.393439\n9.363891\n10.436214\n10.347073\n10.774202\n10.608137\n\n\nsmape\n89.238815\n90.685867\n121.124947\n119.721245\n120.325401\n120.345284\n120.649582\n81.402748\n83.614029\n113.334198\n136.755234\n124.618622\n\n\n\n\n\n\n\nResults showed in previous experiments.\n\n\n\nmodel\nMSE\n\n\n\n\nMQCNN\n10.09\n\n\nDeepAR-student_t\n10.11\n\n\nDeepAR-lognormal\n30.20\n\n\nDeepAR\n9.13\n\n\nNPTS\n11.53\n\n\n\nTop 3 models: DeepAR, AutoNHITS, AutoETS.\n\nDistribution of errors\n\n!pip install seaborn\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nevaluation_df_melted = pd.melt(evaluation_df, id_vars=['unique_id', 'cutoff', 'metric'], var_name='model', value_name='error')\n\n\nSMAPE\n\nsns.violinplot(evaluation_df_melted.query('metric==\"smape\"'), x='error', y='model')\n\n&lt;Axes: xlabel='error', ylabel='model'&gt;\n\n\n\n\n\n\n\n\nChoose models for groups of series\nFeature:\n\nA unified dataframe with forecasts for all different models\nEasy Ensamble\nE.g. Average predictions\nOr MinMax (Choosing is ensembling)\n\n\n# Choose the best model for each time series, metric, and cross validation window\nevaluation_df['best_model'] = evaluation_df.idxmin(axis=1, numeric_only=True)\n# count how many times a model wins per metric and cross validation window\ncount_best_model = evaluation_df.groupby(['cutoff', 'metric', 'best_model']).size().rename('n').to_frame().reset_index()\n# plot results\nsns.barplot(count_best_model, x='n', y='best_model', hue='metric')\n\n&lt;Axes: xlabel='n', ylabel='best_model'&gt;\n\n\n\n\n\n\n\nEt pluribus unum: an inclusive forecasting Pie.\n\n# For the mse, calculate how many times a model wins\neval_series_df = evaluation_df.query('metric == \"mse\"').groupby(['unique_id']).mean(numeric_only=True)\neval_series_df['best_model'] = eval_series_df.idxmin(axis=1)\ncounts_series = eval_series_df.value_counts('best_model')\nplt.pie(counts_series, labels=counts_series.index, autopct='%.0f%%')\nplt.show()\n\n\n\n\n\nsf.plot(Y_df, cv_df.drop(columns=['cutoff', 'y']), \n        max_insample_length=28 * 6, \n        models=['AutoNHITS'],\n        unique_ids=eval_series_df.query('best_model == \"AutoNHITS\"').index[:8])"
  },
  {
    "objectID": "examples/getting_started_complete.html",
    "href": "examples/getting_started_complete.html",
    "title": "End to End Walkthrough",
    "section": "",
    "text": "Prerequesites\n\n\n\n\n\nThis Guide assumes basic familiarity with NeuralForecast. For a minimal example visit the Quick Start\nFollow this article for a step to step guide on building a production-ready forecasting pipeline for multiple time series.\nDuring this guide you will gain familiary with the core NueralForecastclass and some relevant methods like NeuralForecast.fit, NeuralForecast.predict, and StatsForecast.cross_validation.\nWe will use a classical benchmarking dataset from the M4 competition. The dataset includes time series from different domains like finance, economy and sales. In this example, we will use a subset of the Hourly dataset.\nWe will model each time series globally Therefore, you will train a set of models for the whole dataset, and then select the best model for each individual time series. NeuralForecast focuses on speed, simplicity, and scalability, which makes it ideal for this task.\nOutline:\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/getting_started_complete.html#install-libraries",
    "href": "examples/getting_started_complete.html#install-libraries",
    "title": "End to End Walkthrough",
    "section": "1. Install libraries",
    "text": "1. Install libraries\nWe assume you have NeuralForecast already installed. Check this guide for instructions on how to install NeuralForecast.\nAdditionally, we will install s3fs to read from the S3 Filesystem of AWS, statsforecast for plotting, and datasetsforecast for common error metrics like MAE or MASE.\nInstall the necessary packages using pip install statsforecast s3fs datasetsforecast ``\n\n! pip install statsforecast s3fs datasetsforecast\n\n\n! pip install git+https://github.com/Nixtla/neuralforecast.git@main"
  },
  {
    "objectID": "examples/getting_started_complete.html#read-the-data",
    "href": "examples/getting_started_complete.html#read-the-data",
    "title": "End to End Walkthrough",
    "section": "2. Read the data",
    "text": "2. Read the data\nWe will use pandas to read the M4 Hourly data set stored in a parquet file for efficiency. You can use ordinary pandas operations to read your data in other formats likes .csv.\nThe input to NeuralForecast is always a data frame in long format with three columns: unique_id, ds and y:\n\nThe unique_id (string, int or category) represents an identifier for the series.\nThe ds (datestamp or int) column should be either an integer indexing time or a datestampe ideally like YYYY-MM-DD for a date or YYYY-MM-DD HH:MM:SS for a timestamp.\nThe y (numeric) represents the measurement we wish to forecast. We will rename the\n\nThis data set already satisfies the requirement.\nDepending on your internet connection, this step should take around 10 seconds.\n\nimport pandas as pd\n\nY_df = pd.read_parquet('https://datasets-nixtla.s3.amazonaws.com/m4-hourly.parquet')\n\nY_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\nH1\n1\n605.0\n\n\n1\nH1\n2\n586.0\n\n\n2\nH1\n3\n586.0\n\n\n3\nH1\n4\n559.0\n\n\n4\nH1\n5\n511.0\n\n\n\n\n\n\n\nThis dataset contains 414 unique series with 900 observations on average. For this example and reproducibility’s sake, we will select only 10 unique IDs. Depending on your processing infrastructure feel free to select more or less series.\n\n\n\n\n\n\nNote\n\n\n\nProcessing time is dependent on the available computing resources. Running this example with the complete dataset takes around 10 minutes in a c5d.24xlarge (96 cores) instance from AWS.\n\n\n\nuids = Y_df['unique_id'].unique()[:10] # Select 10 ids to make the example faster\nY_df = Y_df.query('unique_id in @uids').reset_index(drop=True)"
  },
  {
    "objectID": "examples/getting_started_complete.html#explore-data-with-the-plot-method-of-statsforecast",
    "href": "examples/getting_started_complete.html#explore-data-with-the-plot-method-of-statsforecast",
    "title": "End to End Walkthrough",
    "section": "3. Explore Data with the plot method of StatsForecast",
    "text": "3. Explore Data with the plot method of StatsForecast\nPlot some series using the plot method from the StatsForecast class. This method prints 8 random series from the dataset and is useful for basic EDA.\n\n\n\n\n\n\nNote\n\n\n\nThe StatsForecast.plot method uses Plotly as a defaul engine. You can change to MatPlotLib by setting engine=\"matplotlib\".\n\n\n\nfrom statsforecast import StatsForecast\n\nStatsForecast.plot(Y_df, engine='matplotlib')\n\n/Users/cchallu/opt/anaconda3/envs/neuralforecast/lib/python3.10/site-packages/statsforecast/core.py:25: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from tqdm.autonotebook import tqdm"
  },
  {
    "objectID": "examples/getting_started_complete.html#train-multiple-models-for-many-series",
    "href": "examples/getting_started_complete.html#train-multiple-models-for-many-series",
    "title": "End to End Walkthrough",
    "section": "4. Train multiple models for many series",
    "text": "4. Train multiple models for many series\nNeuralForecast can train many models on many time series globally and efficiently.\n\nfrom ray import tune\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.auto import AutoNHITS, AutoLSTM\nfrom neuralforecast.losses.pytorch import MQLoss\n\nEach Auto model contains a default search space that was extensively tested on multiple large-scale datasets. Additionally, users can define specific search spaces tailored for particular datasets and tasks.\nFirst, we create a custom search space for the AutoNHITS and AutoLSTM models. Search spaces are specified with dictionaries, where keys corresponds to the model’s hyperparameter and the value is a Tune function to specify how the hyperparameter will be sampled. For example, use randint to sample integers uniformly, and choice to sample values of a list.\n\nconfig_nhits = {\n    \"input_size\": tune.choice([48, 48*2, 48*3]),              # Length of input window\n    \"start_padding_enabled\": True,\n    \"n_blocks\": 5*[1],                                              # Length of input window\n    \"mlp_units\": 5 * [[64, 64]],                                  # Length of input window\n    \"n_pool_kernel_size\": tune.choice([5*[1], 5*[2], 5*[4],         \n                                      [8, 4, 2, 1, 1]]),            # MaxPooling Kernel size\n    \"n_freq_downsample\": tune.choice([[8, 4, 2, 1, 1],\n                                      [1, 1, 1, 1, 1]]),            # Interpolation expressivity ratios\n    \"learning_rate\": tune.loguniform(1e-4, 1e-2),                   # Initial Learning rate\n    \"scaler_type\": tune.choice([None]),                             # Scaler type\n    \"max_steps\": tune.choice([1000]),                               # Max number of training iterations\n    \"batch_size\": tune.choice([1, 4, 10]),                          # Number of series in batch\n    \"windows_batch_size\": tune.choice([128, 256, 512]),             # Number of windows in batch\n    \"random_seed\": tune.randint(1, 20),                             # Random seed\n}\n\nconfig_lstm = {\n    \"input_size\": tune.choice([48, 48*2, 48*3]),              # Length of input window\n    \"encoder_hidden_size\": tune.choice([64, 128]),            # Hidden size of LSTM cells\n    \"encoder_n_layers\": tune.choice([2,4]),                   # Number of layers in LSTM\n    \"learning_rate\": tune.loguniform(1e-4, 1e-2),             # Initial Learning rate\n    \"scaler_type\": tune.choice(['robust']),                   # Scaler type\n    \"max_steps\": tune.choice([500, 1000]),                    # Max number of training iterations\n    \"batch_size\": tune.choice([1, 4]),                        # Number of series in batch\n    \"random_seed\": tune.randint(1, 20),                       # Random seed\n}\n\nTo instantiate an Auto model you need to define:\n\nh: forecasting horizon.\nloss: training and validation loss from neuralforecast.losses.pytorch.\nconfig: hyperparameter search space. If None, the Auto class will use a pre-defined suggested hyperparameter space.\nsearch_alg: search algorithm (from tune.search), default is random search. Refer to https://docs.ray.io/en/latest/tune/api_docs/suggestion.html for more information on the different search algorithm options.\nnum_samples: number of configurations explored.\n\nIn this example we set horizon h as 48, use the MQLoss distribution loss for training and validation, and use the default search algorithm.\n\nnf = NeuralForecast(\n    models=[\n        AutoNHITS(h=48, config=config_nhits, loss=MQLoss(), num_samples=5),\n        AutoLSTM(h=48, config=config_lstm, loss=MQLoss(), num_samples=2),\n    ],\n    freq='H'\n)\n\n\n\n\n\n\n\nTip\n\n\n\nThe number of samples, num_samples, is a crucial parameter! Larger values will usually produce better results as we explore more configurations in the search space, but it will increase training times. Larger search spaces will usually require more samples. As a general rule, we recommend setting num_samples higher than 20.\n\n\nNext, we use the Neuralforecast class to train the Auto model. In this step, Auto models will automatically perform hyperparameter tuning training multiple models with different hyperparameters, producing the forecasts on the validation set, and evaluating them. The best configuration is selected based on the error on a validation set. Only the best model is stored and used during inference.\n\nnf.fit(df=Y_df)\n\nGlobal seed set to 15\nGlobal seed set to 4\n\n\nNext, we use the predict method to forecast the next 48 days using the optimal hyperparameters.\n\nfcst_df = nf.predict()\nfcst_df.columns = fcst_df.columns.str.replace('-median', '')\nfcst_df.head()\n\nPredicting DataLoader 0: 100%|██████████| 3/3 [00:00&lt;00:00, 164.16it/s]\nPredicting DataLoader 0: 100%|██████████| 3/3 [00:00&lt;00:00, 13.89it/s]\n\n\n\n\n\n\n\n\n\nds\nAutoNHITS\nAutoNHITS-lo-90\nAutoNHITS-lo-80\nAutoNHITS-hi-80\nAutoNHITS-hi-90\nAutoLSTM\nAutoLSTM-lo-90\nAutoLSTM-lo-80\nAutoLSTM-hi-80\nAutoLSTM-hi-90\n\n\nunique_id\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nH1\n749\n550.545288\n491.368347\n484.838226\n640.832520\n658.631592\n581.597534\n510.460632\n533.967041\n660.153076\n690.976379\n\n\nH1\n750\n549.216736\n491.054932\n484.474243\n639.552002\n657.615967\n530.324402\n440.821899\n472.254272\n622.214539\n653.435913\n\n\nH1\n751\n528.075989\n466.917053\n463.002289\n621.197205\n642.255005\n487.045593\n383.502045\n423.310974\n594.273071\n627.640320\n\n\nH1\n752\n486.842255\n418.012115\n419.017242\n585.653259\n611.903809\n457.408081\n347.901093\n390.807495\n569.789062\n604.200012\n\n\nH1\n753\n452.015930\n371.543884\n379.539215\n558.845154\n590.465942\n441.641418\n333.888611\n374.730621\n557.401978\n595.008484\n\n\n\n\n\n\n\n\nStatsForecast.plot(Y_df, fcst_df, engine='matplotlib', max_insample_length=48 * 3, level=[80, 90])\n\n\n\n\nThe StatsForecast.plot allows for further customization. For example, plot the results of the different models and unique ids.\n\n# Plot to unique_ids and some selected models\nStatsForecast.plot(Y_df, fcst_df, models=[\"AutoLSTM\"], unique_ids=[\"H107\", \"H104\"], level=[80, 90], engine='matplotlib')\n\n\n\n\n\n# Explore other models \nStatsForecast.plot(Y_df, fcst_df, models=[\"AutoNHITS\"], unique_ids=[\"H10\", \"H105\"], level=[80, 90], engine='matplotlib')"
  },
  {
    "objectID": "examples/getting_started_complete.html#evaluate-the-models-performance",
    "href": "examples/getting_started_complete.html#evaluate-the-models-performance",
    "title": "End to End Walkthrough",
    "section": "5. Evaluate the model’s performance",
    "text": "5. Evaluate the model’s performance\nIn previous steps, we’ve taken our historical data to predict the future. However, to asses its accuracy we would also like to know how the model would have performed in the past. To assess the accuracy and robustness of your models on your data perform Cross-Validation.\nWith time series data, Cross Validation is done by defining a sliding window across the historical data and predicting the period following it. This form of cross-validation allows us to arrive at a better estimation of our model’s predictive abilities across a wider range of temporal instances while also keeping the data in the training set contiguous as is required by our models.\nThe following graph depicts such a Cross Validation Strategy:\n\n\n\n\n\n\n\nTip\n\n\n\nSetting n_windows=1 mirrors a traditional train-test split with our historical data serving as the training set and the last 48 hours serving as the testing set.\n\n\nThe cross_validation method from the NeuralForecast class takes the following arguments.\n\ndf: training data frame\nstep_size (int): step size between each window. In other words: how often do you want to run the forecasting processes.\nn_windows (int): number of windows used for cross validation. In other words: what number of forecasting processes in the past do you want to evaluate.\n\n\nfrom neuralforecast.auto import AutoNHITS, AutoLSTM\nconfig_nhits = {\n    \"input_size\": tune.choice([48, 48*2, 48*3]),              # Length of input window\n    \"start_padding_enabled\": True,\n    \"n_blocks\": 5*[1],                                              # Length of input window\n    \"mlp_units\": 5 * [[64, 64]],                                  # Length of input window\n    \"n_pool_kernel_size\": tune.choice([5*[1], 5*[2], 5*[4],         \n                                      [8, 4, 2, 1, 1]]),            # MaxPooling Kernel size\n    \"n_freq_downsample\": tune.choice([[8, 4, 2, 1, 1],\n                                      [1, 1, 1, 1, 1]]),            # Interpolation expressivity ratios\n    \"learning_rate\": tune.loguniform(1e-4, 1e-2),                   # Initial Learning rate\n    \"scaler_type\": tune.choice([None]),                             # Scaler type\n    \"max_steps\": tune.choice([1000]),                               # Max number of training iterations\n    \"batch_size\": tune.choice([1, 4, 10]),                          # Number of series in batch\n    \"windows_batch_size\": tune.choice([128, 256, 512]),             # Number of windows in batch\n    \"random_seed\": tune.randint(1, 20),                             # Random seed\n}\n\nconfig_lstm = {\n    \"input_size\": tune.choice([48, 48*2, 48*3]),              # Length of input window\n    \"encoder_hidden_size\": tune.choice([64, 128]),            # Hidden size of LSTM cells\n    \"encoder_n_layers\": tune.choice([2,4]),                   # Number of layers in LSTM\n    \"learning_rate\": tune.loguniform(1e-4, 1e-2),             # Initial Learning rate\n    \"scaler_type\": tune.choice(['robust']),                   # Scaler type\n    \"max_steps\": tune.choice([500, 1000]),                    # Max number of training iterations\n    \"batch_size\": tune.choice([1, 4]),                        # Number of series in batch\n    \"random_seed\": tune.randint(1, 20),                       # Random seed\n}\nnf = NeuralForecast(\n    models=[\n        AutoNHITS(h=48, config=config_nhits, loss=MQLoss(), num_samples=5),\n        AutoLSTM(h=48, config=config_lstm, loss=MQLoss(), num_samples=2), \n    ],\n    freq='H'\n)\n\n\ncv_df = nf.cross_validation(Y_df, n_windows=2)\n\nGlobal seed set to 4\nGlobal seed set to 19\n\n\nThe cv_df object is a new data frame that includes the following columns:\n\nunique_id: identifies each time series\nds: datestamp or temporal index\ncutoff: the last datestamp or temporal index for the n_windows. If n_windows=1, then one unique cuttoff value, if n_windows=2 then two unique cutoff values.\ny: true value\n\"model\": columns with the model’s name and fitted value.\n\n\ncv_df.columns = cv_df.columns.str.replace('-median', '')\n\n\ncv_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ncutoff\nAutoNHITS\nAutoNHITS-lo-90\nAutoNHITS-lo-80\nAutoNHITS-hi-80\nAutoNHITS-hi-90\nAutoLSTM\nAutoLSTM-lo-90\nAutoLSTM-lo-80\nAutoLSTM-hi-80\nAutoLSTM-hi-90\ny\n\n\n\n\n0\nH1\n700\n699\n646.881714\n601.402893\n626.471008\n672.432617\n683.847778\n633.707031\n365.139832\n407.289246\n871.474976\n925.476196\n684.0\n\n\n1\nH1\n701\n699\n635.608643\n595.042908\n612.889771\n669.565979\n679.472900\n632.455017\n365.303131\n406.472992\n869.484985\n922.926514\n619.0\n\n\n2\nH1\n702\n699\n592.663940\n564.124390\n566.502319\n648.286072\n647.859253\n633.002502\n365.147522\n407.174866\n868.677979\n925.269409\n565.0\n\n\n3\nH1\n703\n699\n543.364563\n516.760742\n517.990234\n603.099182\n601.462280\n633.903503\n364.976746\n408.498779\n869.797180\n925.993164\n532.0\n\n\n4\nH1\n704\n699\n498.051178\n461.069489\n474.206360\n540.752563\n555.169739\n634.015991\n363.384155\n408.305298\n870.154297\n920.329224\n495.0\n\n\n\n\n\n\n\n\nfor cutoff in cv_df['cutoff'].unique():\n    StatsForecast.plot(\n        Y_df, \n        cv_df.query('cutoff == @cutoff').drop(columns=['y', 'cutoff']), \n        max_insample_length=48 * 4, \n        unique_ids=['H185'],\n        engine='matplotlib'\n    )\n\nNow, let’s evaluate the models’ performance.\n\nfrom datasetsforecast.losses import mse, mae, rmse\nfrom datasetsforecast.evaluation import accuracy\n\n\n\n\n\n\n\nWarning\n\n\n\nYou can also use Mean Average Percentage Error (MAPE), however for granular forecasts, MAPE values are extremely hard to judge and not useful to assess forecasting quality.\n\n\nCreate the data frame with the results of the evaluation of your cross-validation data frame using a Mean Squared Error metric.\n\nevaluation_df = accuracy(cv_df, [mse, mae, rmse], agg_by=['unique_id'])\nevaluation_df['best_model'] = evaluation_df.drop(columns=['metric', 'unique_id']).idxmin(axis=1)\nevaluation_df.head()\n\n\n\n\n\n\n\n\nmetric\nunique_id\nAutoNHITS\nAutoLSTM\nbest_model\n\n\n\n\n0\nmae\nH1\n38.259457\n131.158150\nAutoNHITS\n\n\n1\nmae\nH10\n14.044900\n32.972164\nAutoNHITS\n\n\n2\nmae\nH100\n254.464978\n281.836064\nAutoNHITS\n\n\n3\nmae\nH101\n257.810841\n148.341771\nAutoLSTM\n\n\n4\nmae\nH102\n176.114826\n472.413350\nAutoNHITS\n\n\n\n\n\n\n\nCreate a summary table with a model column and the number of series where that model performs best.\n\nsummary_df = evaluation_df.groupby(['metric', 'best_model']).size().sort_values().to_frame()\n\nsummary_df = summary_df.reset_index()\nsummary_df.columns = ['metric', 'model', 'nr. of unique_ids']\nsummary_df\n\n\n\n\n\n\n\n\nmetric\nmodel\nnr. of unique_ids\n\n\n\n\n0\nmae\nAutoLSTM\n1\n\n\n1\nmse\nAutoLSTM\n1\n\n\n2\nrmse\nAutoLSTM\n1\n\n\n3\nmae\nAutoNHITS\n9\n\n\n4\nmse\nAutoNHITS\n9\n\n\n5\nrmse\nAutoNHITS\n9\n\n\n\n\n\n\n\n\nsummary_df.query('metric == \"mse\"')\n\n\n\n\n\n\n\n\nmetric\nmodel\nnr. of unique_ids\n\n\n\n\n1\nmse\nAutoLSTM\n1\n\n\n4\nmse\nAutoNHITS\n9\n\n\n\n\n\n\n\nYou can further explore your results by plotting the unique_ids where a specific model wins.\n\nnhits_ids = evaluation_df.query('best_model == \"AutoNHITS\" and metric == \"mse\"')['unique_id'].unique()\n\nStatsForecast.plot(Y_df, fcst_df, unique_ids=nhits_ids, engine='matplotlib')"
  },
  {
    "objectID": "examples/getting_started_complete.html#select-the-best-model-for-every-unique-series",
    "href": "examples/getting_started_complete.html#select-the-best-model-for-every-unique-series",
    "title": "End to End Walkthrough",
    "section": "6. Select the best model for every unique series",
    "text": "6. Select the best model for every unique series\nDefine a utility function that takes your forecast’s data frame with the predictions and the evaluation data frame and returns a data frame with the best possible forecast for every unique_id.\n\ndef get_best_model_forecast(forecasts_df, evaluation_df, metric):\n    df = forecasts_df.set_index('ds', append=True).stack().to_frame().reset_index(level=2) # Wide to long \n    df.columns = ['model', 'best_model_forecast'] \n    df = df.join(evaluation_df.query('metric == @metric').set_index('unique_id')[['best_model']])\n    df = df.query('model.str.replace(\"-lo-90|-hi-90\", \"\", regex=True) == best_model').copy()\n    df.loc[:, 'model'] = [model.replace(bm, 'best_model') for model, bm in zip(df['model'], df['best_model'])]\n    df = df.drop(columns='best_model').set_index('model', append=True).unstack()\n    df.columns = df.columns.droplevel()\n    df = df.reset_index(level=1)\n    return df\n\nCreate your production-ready data frame with the best forecast for every unique_id.\n\nprod_forecasts_df = get_best_model_forecast(fcst_df, evaluation_df, metric='mse')\n\nprod_forecasts_df.head()\n\n\n\n\n\n\n\nmodel\nds\nbest_model\nbest_model-hi-90\nbest_model-lo-90\n\n\nunique_id\n\n\n\n\n\n\n\n\nH1\n749\n550.545288\n658.631592\n491.368347\n\n\nH1\n750\n549.216736\n657.615967\n491.054932\n\n\nH1\n751\n528.075989\n642.255005\n466.917053\n\n\nH1\n752\n486.842255\n611.903809\n418.012115\n\n\nH1\n753\n452.015930\n590.465942\n371.543884\n\n\n\n\n\n\n\nPlot the results.\n\nStatsForecast.plot(Y_df, prod_forecasts_df, level=[90], engine='matplotlib')"
  },
  {
    "objectID": "examples/time_series_scaling.html",
    "href": "examples/time_series_scaling.html",
    "title": "Time Series Scaling",
    "section": "",
    "text": "Scaling time series data is an important preprocessing step when using neural forecasting methods for several reasons:\nThe Neuralforecast library integrates two types of temporal scaling:\nIn this notebook, we will demonstrate how to scale the time series data with both methods on an Eletricity Price Forecasting (EPF) task.\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/time_series_scaling.html#install-neuralforecast",
    "href": "examples/time_series_scaling.html#install-neuralforecast",
    "title": "Time Series Scaling",
    "section": "1. Install Neuralforecast",
    "text": "1. Install Neuralforecast\n\n!pip install neuralforecast\n!pip install hyperopt"
  },
  {
    "objectID": "examples/time_series_scaling.html#load-data",
    "href": "examples/time_series_scaling.html#load-data",
    "title": "Time Series Scaling",
    "section": "2. Load Data",
    "text": "2. Load Data\nThe df dataframe contains the target and exogenous variables past information to train the model. The unique_id column identifies the markets, ds contains the datestamps, and y the electricity price. For future variables, we include a forecast of how much electricity will be produced (gen_forecast), system load (system_laod), and day of week (week_day). Both the electricity system demand and offer impact the price significantly, including these variables to the model greatly improve performance, as we demonstrate in Olivares et al. (2022).\nThe futr_df dataframe includes the information of the future exogenous variables for the period we want to forecast (in this case, 24 hours after the end of the train dataset df).\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\ndf = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/EPF_FR_BE.csv')\ndf['ds'] = pd.to_datetime(df['ds'])\n\nfutr_df = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/EPF_FR_BE_futr.csv')\nfutr_df['ds'] = pd.to_datetime(futr_df['ds'])\n\ndf.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\ngen_forecast\nsystem_load\nweek_day\n\n\n\n\n0\nFR\n2015-01-01 00:00:00\n53.48\n76905.0\n74812.0\n3\n\n\n1\nFR\n2015-01-01 01:00:00\n51.93\n75492.0\n71469.0\n3\n\n\n2\nFR\n2015-01-01 02:00:00\n48.76\n74394.0\n69642.0\n3\n\n\n3\nFR\n2015-01-01 03:00:00\n42.27\n72639.0\n66704.0\n3\n\n\n4\nFR\n2015-01-01 04:00:00\n38.41\n69347.0\n65051.0\n3\n\n\n\n\n\n\n\nWe can see that y and the exogenous variables are on largely different scales. Next, we show two methods to scale the data."
  },
  {
    "objectID": "examples/time_series_scaling.html#time-series-scaling-with-neuralforecast-class",
    "href": "examples/time_series_scaling.html#time-series-scaling-with-neuralforecast-class",
    "title": "Time Series Scaling",
    "section": "3. Time Series Scaling with Neuralforecast class",
    "text": "3. Time Series Scaling with Neuralforecast class\nOne of the most widely used approches for scaling time series is to treat it as a pre-processing step, where each time series and temporal exogenous variables are scaled based on their entire information in the train set. Models are then trained on the scaled data.\nTo simplify pipelines, we added a scaling functionality to the Neuralforecast class. Each time series will be scaled before training the model with either fit or cross_validation, and scaling statistics are stored. The class then uses the stored statistics to scale the forecasts back to the original scale before returning the forecasts.\n\n3.a. Instantiate model and Neuralforecast class\nIn this example we will use the TimesNet model, recently proposed in Wu, Haixu, et al. (2022). First instantiate the model with the desired parameters.\n\nfrom neuralforecast.models import TimesNet\nfrom neuralforecast.core import NeuralForecast\n\nimport logging\nlogging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n\n\nhorizon = 24 # day-ahead daily forecast\nmodel = TimesNet(h = horizon,                                                 # Horizon\n                 input_size = 5*horizon,                                      # Length of input window\n                 max_steps = 100,                                             # Training iterations\n                 top_k = 3,                                                   # Number of periods (for FFT).\n                 num_kernels = 3,                                             # Number of kernels for Inception module\n                 batch_size = 2,                                              # Number of time series per batch\n                 windows_batch_size = 32,                                     # Number of windows per batch\n                 learning_rate = 0.001,                                       # Learning rate\n                 futr_exog_list = ['gen_forecast', 'system_load','week_day'], # Future exogenous variables\n                 scaler_type = None)                                          # We use the Core scaling method\n\nGlobal seed set to 1\n\n\nFit the model by instantiating a NeuralForecast object and using the fit method. The local_scaler_type parameter is used to specify the type of scaling to be used. In this case, we will use standard, which scales the data to have zero mean and unit variance.Other supported scalers are minmax, robust, robust-iqr, minmax, and boxcox.\n\nnf = NeuralForecast(models=[model], freq='H', local_scaler_type='standard')\nnf.fit(df=df)\n\nEpoch 99: 100%|██████████| 1/1 [00:00&lt;00:00,  1.13it/s, v_num=181, train_loss_step=0.413, train_loss_epoch=0.413]\n\n\n\n\n3.b Forecast and plots\nFinally, use the predict method to forecast the day-ahead prices. The Neuralforecast class handles the inverse normalization, forecasts are returned in the original scale.\n\nY_hat_df = nf.predict(futr_df=futr_df)\nY_hat_df.head()\n\nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00, 26.56it/s]\n\n\n\n\n\n\n\n\n\nds\nTimesNet\n\n\nunique_id\n\n\n\n\n\n\nBE\n2016-11-01 00:00:00\n33.748502\n\n\nBE\n2016-11-01 01:00:00\n32.393269\n\n\nBE\n2016-11-01 02:00:00\n29.000997\n\n\nBE\n2016-11-01 03:00:00\n26.264737\n\n\nBE\n2016-11-01 04:00:00\n28.841827\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\nplot_df = df[df['unique_id']=='FR'].tail(24*5).reset_index(drop=True)\nY_hat_df = Y_hat_df.reset_index(drop=False)\nY_hat_df = Y_hat_df[Y_hat_df['unique_id']=='FR']\n\nplot_df = pd.concat([plot_df, Y_hat_df ]).set_index('ds') # Concatenate the train and forecast dataframes\n\nplot_df[['y', 'TimesNet']].plot(linewidth=2)\nplt.axvline('2016-11-01', color='red')\nplt.ylabel('Price [EUR/MWh]', fontsize=12)\nplt.xlabel('Date', fontsize=12)\nplt.grid()\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe inverse scaling is performed by the Neuralforecast class before returning the final forecasts. Therefore, the hyperparmater selection with Auto models and validation loss for early stopping or model selection are performed on the scaled data. Different types of scaling with the Neuralforecast class can’t be automatically compared with Auto models."
  },
  {
    "objectID": "examples/time_series_scaling.html#temporal-window-normalization-during-training",
    "href": "examples/time_series_scaling.html#temporal-window-normalization-during-training",
    "title": "Time Series Scaling",
    "section": "4. Temporal Window normalization during training",
    "text": "4. Temporal Window normalization during training\nTemporal normalization scales each instance of the batch separately at the window level. It is performed at each training iteration for each window of the batch, for both target variable and temporal exogenous covariates. For more details, see Olivares et al. (2023) and https://nixtla.github.io/neuralforecast/common.scalers.html.\n\n4.a. Instantiate model and Neuralforecast class\nTemporal normalization is specified by the scaler_type argument. Currently, it is only supported for Windows-based models (NHITS, NBEATS, MLP, TimesNet, and all Transformers). In this example, we use the TimesNet model and robust scaler, recently proposed by Wu, Haixu, et al. (2022). First instantiate the model with the desired parameters.\nVisit https://nixtla.github.io/neuralforecast/common.scalers.html for a complete list of supported scalers.\n\nhorizon = 24 # day-ahead daily forecast\nmodel = TimesNet(h = horizon,                                                 # Horizon\n                 input_size = 5*horizon,                                      # Length of input window\n                 max_steps = 100,                                             # Training iterations\n                 top_k = 3,                                                   # Number of periods (for FFT).\n                 num_kernels = 3,                                             # Number of kernels for Inception module\n                 batch_size = 2,                                              # Number of time series per batch\n                 windows_batch_size = 32,                                     # Number of windows per batch\n                 learning_rate = 0.001,                                       # Learning rate\n                 futr_exog_list = ['gen_forecast', 'system_load','week_day'], # Future exogenous variables\n                 scaler_type = 'robust')                                      # Robust scaling\n\nGlobal seed set to 1\n\n\nFit the model by instantiating a NeuralForecast object and using the fit method. Note that local_scaler_type has None as default to avoid scaling the data before training.\n\nnf = NeuralForecast(models=[model], freq='H')\nnf.fit(df=df)\n\nEpoch 99: 100%|██████████| 1/1 [00:00&lt;00:00,  1.73it/s, v_num=183, train_loss_step=0.977, train_loss_epoch=0.977]\n\n\n\n\n4.b Forecast and plots\nFinally, use the predict method to forecast the day-ahead prices. The forecasts are returned in the original scale.\n\nY_hat_df = nf.predict(futr_df=futr_df)\nY_hat_df.head()\n\nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00, 20.26it/s]\n\n\n\n\n\n\n\n\n\nds\nTimesNet\n\n\nunique_id\n\n\n\n\n\n\nBE\n2016-11-01 00:00:00\n40.024895\n\n\nBE\n2016-11-01 01:00:00\n35.253803\n\n\nBE\n2016-11-01 02:00:00\n33.185341\n\n\nBE\n2016-11-01 03:00:00\n33.572426\n\n\nBE\n2016-11-01 04:00:00\n37.039207\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\nplot_df = df[df['unique_id']=='FR'].tail(24*5).reset_index(drop=True)\nY_hat_df = Y_hat_df.reset_index(drop=False)\nY_hat_df = Y_hat_df[Y_hat_df['unique_id']=='FR']\n\nplot_df = pd.concat([plot_df, Y_hat_df ]).set_index('ds') # Concatenate the train and forecast dataframes\n\nplot_df[['y', 'TimesNet']].plot(linewidth=2)\nplt.axvline('2016-11-01', color='red')\nplt.ylabel('Price [EUR/MWh]', fontsize=12)\nplt.xlabel('Date', fontsize=12)\nplt.grid()\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nFor most applications, models with temporal normalization (section 4) produced more accurate forecasts than time series scaling (section 3). However, with temporal normalization models lose the information of the relative level between different windows. In some cases this global information within time series is crucial, for instance when an exogenous variables contains the dosage of a medication. In these cases, time series scaling (section 3) is preferred."
  },
  {
    "objectID": "examples/time_series_scaling.html#references",
    "href": "examples/time_series_scaling.html#references",
    "title": "Time Series Scaling",
    "section": "References",
    "text": "References\n\nKin G. Olivares, David Luo, Cristian Challu, Stefania La Vattiata, Max Mergenthaler, Artur Dubrawski (2023). “HINT: Hierarchical Mixture Networks For Coherent Probabilistic Forecasting”. International Conference on Machine Learning (ICML). Workshop on Structured Probabilistic Inference & Generative Modeling. Available at https://arxiv.org/abs/2305.07089.\nWu, Haixu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang, and Mingsheng Long. “Timesnet: Temporal 2d-variation modeling for general time series analysis.”, ICLR 2023"
  },
  {
    "objectID": "examples/longhorizon_probabilistic.html",
    "href": "examples/longhorizon_probabilistic.html",
    "title": "Probabilistic Long-Horizon",
    "section": "",
    "text": "Long-horizon forecasting is challenging because of the volatility of the predictions and the computational complexity. To solve this problem we created the NHITS model and made the code available NeuralForecast library. NHITS specializes its partial outputs in the different frequencies of the time series through hierarchical interpolation and multi-rate input processing. We model the target time-series with Student’s t-distribution. The NHITS will output the distribution parameters for each timestamp.\nIn this notebook we show how to use NHITS on the ETTm2 benchmark dataset for probabilistic forecasting. This data set includes data points for 2 Electricity Transformers at 2 stations, including load, oil temperature.\nWe will show you how to load data, train, and perform automatic hyperparameter tuning, to achieve SoTA performance, outperforming even the latest Transformer architectures for a fraction of their computational cost (50x faster).\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/longhorizon_probabilistic.html#libraries",
    "href": "examples/longhorizon_probabilistic.html#libraries",
    "title": "Probabilistic Long-Horizon",
    "section": "1. Libraries",
    "text": "1. Libraries\n\n!pip install neuralforecast datasetsforecast"
  },
  {
    "objectID": "examples/longhorizon_probabilistic.html#load-ettm2-data",
    "href": "examples/longhorizon_probabilistic.html#load-ettm2-data",
    "title": "Probabilistic Long-Horizon",
    "section": "2. Load ETTm2 Data",
    "text": "2. Load ETTm2 Data\nThe LongHorizon class will automatically download the complete ETTm2 dataset and process it.\nIt return three Dataframes: Y_df contains the values for the target variables, X_df contains exogenous calendar features and S_df contains static features for each time-series (none for ETTm2). For this example we will only use Y_df.\nIf you want to use your own data just replace Y_df. Be sure to use a long format and have a simmilar structure than our data set.\n\nimport pandas as pd\nfrom datasetsforecast.long_horizon import LongHorizon\n\n\n# Change this to your own data to try the model\nY_df, _, _ = LongHorizon.load(directory='./', group='ETTm2')\nY_df['ds'] = pd.to_datetime(Y_df['ds'])\n\n# For this excercise we are going to take 960 timestamps as validation and test\nn_time = len(Y_df.ds.unique())\nval_size = 96*10\ntest_size = 96*10\n\nY_df.groupby('unique_id').head(2)\n\n\n  \n    \n      \n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\nHUFL\n2016-07-01 00:00:00\n-0.041413\n\n\n1\nHUFL\n2016-07-01 00:15:00\n-0.185467\n\n\n57600\nHULL\n2016-07-01 00:00:00\n0.040104\n\n\n57601\nHULL\n2016-07-01 00:15:00\n-0.214450\n\n\n115200\nLUFL\n2016-07-01 00:00:00\n0.695804\n\n\n115201\nLUFL\n2016-07-01 00:15:00\n0.434685\n\n\n172800\nLULL\n2016-07-01 00:00:00\n0.434430\n\n\n172801\nLULL\n2016-07-01 00:15:00\n0.428168\n\n\n230400\nMUFL\n2016-07-01 00:00:00\n-0.599211\n\n\n230401\nMUFL\n2016-07-01 00:15:00\n-0.658068\n\n\n288000\nMULL\n2016-07-01 00:00:00\n-0.393536\n\n\n288001\nMULL\n2016-07-01 00:15:00\n-0.659338\n\n\n345600\nOT\n2016-07-01 00:00:00\n1.018032\n\n\n345601\nOT\n2016-07-01 00:15:00\n0.980124\n\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n\n\n\n\n\nImportant\n\n\n\nDataFrames must include all ['unique_id', 'ds', 'y'] columns. Make sure y column does not have missing or non-numeric values.\n\n\nNext, plot the HUFL variable marking the validation and train splits.\n\nimport matplotlib.pyplot as plt\n\n\n# We are going to plot the temperature of the transformer \n# and marking the validation and train splits\nu_id = 'HUFL'\nx_plot = pd.to_datetime(Y_df[Y_df.unique_id==u_id].ds)\ny_plot = Y_df[Y_df.unique_id==u_id].y.values\n\nx_val = x_plot[n_time - val_size - test_size]\nx_test = x_plot[n_time - test_size]\n\nfig = plt.figure(figsize=(10, 5))\nfig.tight_layout()\n\nplt.plot(x_plot, y_plot)\nplt.xlabel('Date', fontsize=17)\nplt.ylabel('OT [15 min temperature]', fontsize=17)\n\nplt.axvline(x_val, color='black', linestyle='-.')\nplt.axvline(x_test, color='black', linestyle='-.')\nplt.text(x_val, 5, '  Validation', fontsize=12)\nplt.text(x_test, 3, '  Test', fontsize=12)\n\nplt.grid()\nplt.show()\nplt.close()"
  },
  {
    "objectID": "examples/longhorizon_probabilistic.html#hyperparameter-selection-and-forecasting",
    "href": "examples/longhorizon_probabilistic.html#hyperparameter-selection-and-forecasting",
    "title": "Probabilistic Long-Horizon",
    "section": "3. Hyperparameter selection and forecasting",
    "text": "3. Hyperparameter selection and forecasting\nThe AutoNHITS class will automatically perform hyperparamter tunning using Tune library, exploring a user-defined or default search space. Models are selected based on the error on a validation set and the best model is then stored and used during inference.\nThe AutoNHITS.default_config attribute contains a suggested hyperparameter space. Here, we specify a different search space following the paper’s hyperparameters. Notice that 1000 Stochastic Gradient Steps are enough to achieve SoTA performance. Feel free to play around with this space.\n\nfrom ray import tune\n\nfrom neuralforecast.auto import AutoNHITS\nfrom neuralforecast.core import NeuralForecast\n\nfrom neuralforecast.losses.pytorch import DistributionLoss\n\nimport logging\nlogging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n\n\nhorizon = 96 # 24hrs = 4 * 15 min.\n\n# Use your own config or AutoNHITS.default_config\nnhits_config = {\n       \"learning_rate\": tune.choice([1e-3]),                                     # Initial Learning rate\n       \"max_steps\": tune.choice([1000]),                                         # Number of SGD steps\n       \"input_size\": tune.choice([5 * horizon]),                                 # input_size = multiplier * horizon\n       \"batch_size\": tune.choice([7]),                                           # Number of series in windows\n       \"windows_batch_size\": tune.choice([256]),                                 # Number of windows in batch\n       \"n_pool_kernel_size\": tune.choice([[2, 2, 2], [16, 8, 1]]),               # MaxPool's Kernelsize\n       \"n_freq_downsample\": tune.choice([[168, 24, 1], [24, 12, 1], [1, 1, 1]]), # Interpolation expressivity ratios\n       \"activation\": tune.choice(['ReLU']),                                      # Type of non-linear activation\n       \"n_blocks\":  tune.choice([[1, 1, 1]]),                                    # Blocks per each 3 stacks\n       \"mlp_units\":  tune.choice([[[512, 512], [512, 512], [512, 512]]]),        # 2 512-Layers per block for each stack\n       \"interpolation_mode\": tune.choice(['linear']),                            # Type of multi-step interpolation\n       \"random_seed\": tune.randint(1, 10),\n       \"scaler_type\": tune.choice(['robust']),\n       \"val_check_steps\": tune.choice([100])\n    }\n\n\n\n\n\n\n\nTip\n\n\n\nRefer to https://docs.ray.io/en/latest/tune/index.html for more information on the different space options, such as lists and continous intervals.m\n\n\nTo instantiate AutoNHITS you need to define:\n\nh: forecasting horizon\nloss: training loss. Use the DistributionLoss to produce probabilistic forecasts.\nconfig: hyperparameter search space. If None, the AutoNHITS class will use a pre-defined suggested hyperparameter space.\nnum_samples: number of configurations explored.\n\n\nmodels = [AutoNHITS(h=horizon,\n                    loss=DistributionLoss(distribution='StudentT', level=[80, 90]), \n                    config=nhits_config,\n                    num_samples=5)]\n\nFit the model by instantiating a NeuralForecast object with the following required parameters:\n\nmodels: a list of models.\nfreq: a string indicating the frequency of the data. (See panda’s available frequencies.)\n\n\n# Fit and predict\nnf = NeuralForecast(\n    models=models,\n    freq='15min')\n\nThe cross_validation method allows you to simulate multiple historic forecasts, greatly simplifying pipelines by replacing for loops with fit and predict methods.\nWith time series data, cross validation is done by defining a sliding window across the historical data and predicting the period following it. This form of cross validation allows us to arrive at a better estimation of our model’s predictive abilities across a wider range of temporal instances while also keeping the data in the training set contiguous as is required by our models.\nThe cross_validation method will use the validation set for hyperparameter selection, and will then produce the forecasts for the test set.\n\nY_hat_df = nf.cross_validation(df=Y_df, val_size=val_size,\n                               test_size=test_size, n_windows=None)"
  },
  {
    "objectID": "examples/longhorizon_probabilistic.html#visualization",
    "href": "examples/longhorizon_probabilistic.html#visualization",
    "title": "Probabilistic Long-Horizon",
    "section": "4. Visualization",
    "text": "4. Visualization\nFinally, we merge the forecasts with the Y_df dataset and plot the forecasts.\n\nY_hat_df = Y_hat_df.reset_index(drop=True)\nY_hat_df = Y_hat_df[(Y_hat_df['unique_id']=='OT') & (Y_hat_df['cutoff']=='2018-02-11 12:00:00')]\nY_hat_df = Y_hat_df.drop(columns=['y','cutoff'])\n\n\nplot_df = Y_df.merge(Y_hat_df, on=['unique_id','ds'], how='outer').tail(96*10+50+96*4).head(96*2+96*4)\n\nplt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\nplt.plot(plot_df['ds'], plot_df['AutoNHITS-median'], c='blue', label='median')\nplt.fill_between(x=plot_df['ds'], \n                    y1=plot_df['AutoNHITS-lo-90'], y2=plot_df['AutoNHITS-hi-90'],\n                    alpha=0.4, label='level 90')\nplt.legend()\nplt.grid()\nplt.plot()\n\n[]"
  },
  {
    "objectID": "examples/longhorizon_probabilistic.html#references",
    "href": "examples/longhorizon_probabilistic.html#references",
    "title": "Probabilistic Long-Horizon",
    "section": "References",
    "text": "References\nCristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2021). NHITS: Neural Hierarchical Interpolation for Time Series Forecasting. Accepted at AAAI 2023."
  },
  {
    "objectID": "examples/temporal_classifiers.html",
    "href": "examples/temporal_classifiers.html",
    "title": "Temporal Classification",
    "section": "",
    "text": "A logistic regression analyzes the relationship between a binary target variable and its predictor variables to estimate the probability of the dependent variable taking the value 1. In the presence of temporal data where observations along time aren’t independent, the errors of the model will be correlated through time and incorporating autoregressive features or lags can capture temporal dependencies and enhance the predictive power of logistic regression.\nNHITS’s inputs are static exogenous \\(\\mathbf{x}^{(s)}\\), historic exogenous \\(\\mathbf{x}^{(h)}_{[:t]}\\), exogenous available at the time of the prediction \\(\\mathbf{x}^{(f)}_{[:t+H]}\\) and autorregresive features \\(\\mathbf{y}_{[:t]}\\), each of these inputs is further decomposed into categorical and continuous. The network uses a multi-quantile regression to model the following conditional probability:\\[\\mathbb{P}(\\mathbf{y}_{[t+1:t+H]}|\\;\\mathbf{y}_{[:t]},\\; \\mathbf{x}^{(h)}_{[:t]},\\; \\mathbf{x}^{(f)}_{[:t+H]},\\; \\mathbf{x}^{(s)})\\]\nIn this notebook we show how to fit NeuralForecast methods for binary sequences regression. We will: - Installing NeuralForecast. - Loading binary sequence data. - Fit and predict temporal classifiers. - Plot and evaluate predictions.\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/temporal_classifiers.html#installing-neuralforecast",
    "href": "examples/temporal_classifiers.html#installing-neuralforecast",
    "title": "Temporal Classification",
    "section": "1. Installing NeuralForecast",
    "text": "1. Installing NeuralForecast\n\n#%%capture\n#!pip install neuralforecast\n\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import datasets\n\nimport matplotlib.pyplot as plt\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import MLP, NHITS, LSTM\nfrom neuralforecast.losses.pytorch import DistributionLoss, Accuracy"
  },
  {
    "objectID": "examples/temporal_classifiers.html#loading-binary-sequence-data",
    "href": "examples/temporal_classifiers.html#loading-binary-sequence-data",
    "title": "Temporal Classification",
    "section": "2. Loading Binary Sequence Data",
    "text": "2. Loading Binary Sequence Data\nThe core.NeuralForecast class contains shared, fit, predict and other methods that take as inputs pandas DataFrames with columns ['unique_id', 'ds', 'y'], where unique_id identifies individual time series from the dataset, ds is the date, and y is the target binary variable.\nIn this motivation example we convert 8x8 digits images into 64-length sequences and define a classification problem, to identify when the pixels surpass certain threshold. We declare a pandas dataframe in long format, to match NeuralForecast’s inputs.\n\ndigits = datasets.load_digits()\nimages = digits.images[:100]\n\nplt.imshow(images[0,:,:], cmap=plt.cm.gray, \n           vmax=16, interpolation=\"nearest\")\n\npixels = np.reshape(images, (len(images), 64))\nytarget = (pixels &gt; 10) * 1\n\nfig, ax1 = plt.subplots()\nax2 = ax1.twinx()\nax1.plot(pixels[10])\nax2.plot(ytarget[10], color='purple')\nax1.set_xlabel('Pixel index')\nax1.set_ylabel('Pixel value')\nax2.set_ylabel('Pixel threshold', color='purple')\nplt.grid()\nplt.show()\n\n\n\n\n\n\n\n\n# We flat the images and create an input dataframe\n# with 'unique_id' series identifier and 'ds' time stamp identifier.\nY_df = pd.DataFrame.from_dict({\n            'unique_id': np.repeat(np.arange(100), 64),\n            'ds': np.tile(np.arange(64)+1910, 100),\n            'y': ytarget.flatten(), 'pixels': pixels.flatten()})\nY_df\n\n\n\n\n\n\n\n\nunique_id\nds\ny\npixels\n\n\n\n\n0\n0\n1910\n0\n0.0\n\n\n1\n0\n1911\n0\n0.0\n\n\n2\n0\n1912\n0\n5.0\n\n\n3\n0\n1913\n1\n13.0\n\n\n4\n0\n1914\n0\n9.0\n\n\n...\n...\n...\n...\n...\n\n\n6395\n99\n1969\n1\n14.0\n\n\n6396\n99\n1970\n1\n16.0\n\n\n6397\n99\n1971\n0\n3.0\n\n\n6398\n99\n1972\n0\n0.0\n\n\n6399\n99\n1973\n0\n0.0\n\n\n\n\n6400 rows × 4 columns"
  },
  {
    "objectID": "examples/temporal_classifiers.html#fit-and-predict-temporal-classifiers",
    "href": "examples/temporal_classifiers.html#fit-and-predict-temporal-classifiers",
    "title": "Temporal Classification",
    "section": "3. Fit and predict temporal classifiers",
    "text": "3. Fit and predict temporal classifiers\n\nFit the models\nUsing the NeuralForecast.fit method you can train a set of models to your dataset. You can define the forecasting horizon (12 in this example), and modify the hyperparameters of the model. For example, for the NHITS we changed the default hidden size for both encoder and decoders.\nSee the NHITS and MLP model documentation.\n\n\n\n\n\n\nWarning\n\n\n\nFor the moment Recurrent-based model family is not available to operate with Bernoulli distribution output. This affects the following methods LSTM, GRU, DilatedRNN, and TCN. This feature is work in progress.\n\n\n\n# %%capture\nhorizon = 12\n\n# Try different hyperparmeters to improve accuracy.\nmodels = [MLP(h=horizon,                           # Forecast horizon\n              input_size=2 * horizon,              # Length of input sequence\n              loss=DistributionLoss('Bernoulli'),  # Binary classification loss\n              valid_loss=Accuracy(),               # Accuracy validation signal\n              max_steps=500,                       # Number of steps to train\n              scaler_type='standard',              # Type of scaler to normalize data\n              hidden_size=64,                      # Defines the size of the hidden state of the LSTM\n              #early_stop_patience_steps=2,         # Early stopping regularization patience\n              val_check_steps=10,                  # Frequency of validation signal (affects early stopping)\n              ),\n          NHITS(h=horizon,                          # Forecast horizon\n                input_size=2 * horizon,             # Length of input sequence\n                loss=DistributionLoss('Bernoulli'), # Binary classification loss\n                valid_loss=Accuracy(),              # Accuracy validation signal                \n                max_steps=500,                      # Number of steps to train\n                n_freq_downsample=[2, 1, 1],        # Downsampling factors for each stack output\n                #early_stop_patience_steps=2,        # Early stopping regularization patience\n                val_check_steps=10,                 # Frequency of validation signal (affects early stopping)\n                )             \n          ]\nnf = NeuralForecast(models=models, freq='Y')\nY_hat_df = nf.cross_validation(df=Y_df, n_windows=1)\n\nGlobal seed set to 1\nGlobal seed set to 1\n\n\nEpoch 124: 100%|██████████| 4/4 [00:00&lt;00:00, 50.22it/s, v_num=35, train_loss_step=0.260, train_loss_epoch=0.331]\nPredicting DataLoader 0: 100%|██████████| 4/4 [00:00&lt;00:00, 37.07it/s]\nEpoch 124: 100%|██████████| 4/4 [00:00&lt;00:00,  5.34it/s, v_num=37, train_loss_step=0.179, train_loss_epoch=0.180]\nPredicting DataLoader 0: 100%|██████████| 4/4 [00:00&lt;00:00, 49.74it/s]\n\n\n\n# By default NeuralForecast produces forecast intervals\n# In this case the lo-x and high-x levels represent the \n# low and high bounds of the prediction accumulating x% probability\nY_hat_df = Y_hat_df.reset_index(drop=True)\nY_hat_df\n\n\n\n\n\n\n\n\nunique_id\nds\ncutoff\nMLP\nMLP-median\nMLP-lo-90\nMLP-lo-80\nMLP-hi-80\nMLP-hi-90\nNHITS\nNHITS-median\nNHITS-lo-90\nNHITS-lo-80\nNHITS-hi-80\nNHITS-hi-90\ny\npixels\n\n\n\n\n0\n0\n1962\n1961\n0.190\n0.0\n0.0\n0.0\n1.0\n1.0\n0.422\n0.0\n0.0\n0.0\n1.0\n1.0\n0\n10.0\n\n\n1\n0\n1963\n1961\n0.754\n1.0\n0.0\n0.0\n1.0\n1.0\n0.955\n1.0\n1.0\n1.0\n1.0\n1.0\n1\n12.0\n\n\n2\n0\n1964\n1961\n0.035\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000\n0.0\n0.0\n0.0\n0.0\n0.0\n0\n0.0\n\n\n3\n0\n1965\n1961\n0.049\n0.0\n0.0\n0.0\n0.0\n0.0\n0.015\n0.0\n0.0\n0.0\n0.0\n0.0\n0\n0.0\n\n\n4\n0\n1966\n1961\n0.042\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000\n0.0\n0.0\n0.0\n0.0\n0.0\n0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1195\n99\n1969\n1961\n0.484\n0.0\n0.0\n0.0\n1.0\n1.0\n0.817\n1.0\n0.0\n0.0\n1.0\n1.0\n1\n14.0\n\n\n1196\n99\n1970\n1961\n0.587\n1.0\n0.0\n0.0\n1.0\n1.0\n0.495\n0.0\n0.0\n0.0\n1.0\n1.0\n1\n16.0\n\n\n1197\n99\n1971\n1961\n0.336\n0.0\n0.0\n0.0\n1.0\n1.0\n0.126\n0.0\n0.0\n0.0\n1.0\n1.0\n0\n3.0\n\n\n1198\n99\n1972\n1961\n0.046\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000\n0.0\n0.0\n0.0\n0.0\n0.0\n0\n0.0\n\n\n1199\n99\n1973\n1961\n0.001\n0.0\n0.0\n0.0\n0.0\n0.0\n0.000\n0.0\n0.0\n0.0\n0.0\n0.0\n0\n0.0\n\n\n\n\n1200 rows × 17 columns\n\n\n\n\n# Define classification threshold for final predictions\n# If (prob &gt; threshold) -&gt; 1\nY_hat_df['NHITS'] = (Y_hat_df['NHITS'] &gt; 0.5) * 1\nY_hat_df['MLP'] = (Y_hat_df['MLP'] &gt; 0.5) * 1\nY_hat_df\n\n\n\n\n\n\n\n\nunique_id\nds\ncutoff\nMLP\nMLP-median\nMLP-lo-90\nMLP-lo-80\nMLP-hi-80\nMLP-hi-90\nNHITS\nNHITS-median\nNHITS-lo-90\nNHITS-lo-80\nNHITS-hi-80\nNHITS-hi-90\ny\npixels\n\n\n\n\n0\n0\n1962\n1961\n0\n0.0\n0.0\n0.0\n1.0\n1.0\n0\n0.0\n0.0\n0.0\n1.0\n1.0\n0\n10.0\n\n\n1\n0\n1963\n1961\n1\n1.0\n0.0\n0.0\n1.0\n1.0\n1\n1.0\n1.0\n1.0\n1.0\n1.0\n1\n12.0\n\n\n2\n0\n1964\n1961\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0\n0.0\n\n\n3\n0\n1965\n1961\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0\n0.0\n\n\n4\n0\n1966\n1961\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0\n0.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1195\n99\n1969\n1961\n0\n0.0\n0.0\n0.0\n1.0\n1.0\n1\n1.0\n0.0\n0.0\n1.0\n1.0\n1\n14.0\n\n\n1196\n99\n1970\n1961\n1\n1.0\n0.0\n0.0\n1.0\n1.0\n0\n0.0\n0.0\n0.0\n1.0\n1.0\n1\n16.0\n\n\n1197\n99\n1971\n1961\n0\n0.0\n0.0\n0.0\n1.0\n1.0\n0\n0.0\n0.0\n0.0\n1.0\n1.0\n0\n3.0\n\n\n1198\n99\n1972\n1961\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0\n0.0\n\n\n1199\n99\n1973\n1961\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0\n0.0\n0.0\n0.0\n0.0\n0.0\n0\n0.0\n\n\n\n\n1200 rows × 17 columns"
  },
  {
    "objectID": "examples/temporal_classifiers.html#plot-and-evaluate-predictions",
    "href": "examples/temporal_classifiers.html#plot-and-evaluate-predictions",
    "title": "Temporal Classification",
    "section": "4. Plot and Evaluate Predictions",
    "text": "4. Plot and Evaluate Predictions\nFinally, we plot the forecasts of both models againts the real values. And evaluate the accuracy of the MLP and NHITS temporal classifiers.\n\nplot_df = Y_hat_df[Y_hat_df.unique_id==10]\n\nfig, ax = plt.subplots(1, 1, figsize = (20, 7))\nplt.plot(plot_df.ds, plot_df.y, label='target signal')\nplt.plot(plot_df.ds, plot_df['MLP'] * 1.1, label='MLP prediction')\nplt.plot(plot_df.ds, plot_df['NHITS'] * .9, label='NHITS prediction')\nax.set_title('Binary Sequence Forecast', fontsize=22)\nax.set_ylabel('Pixel Threshold and Prediction', fontsize=20)\nax.set_xlabel('Timestamp [t]', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()\n\n\n\n\n\ndef accuracy(y, y_hat):\n    return np.mean(y==y_hat)\n\nmlp_acc = accuracy(y=Y_hat_df['y'], y_hat=Y_hat_df['MLP'])\nnhits_acc = accuracy(y=Y_hat_df['y'], y_hat=Y_hat_df['NHITS'])\n\nprint(f'MLP Accuracy: {mlp_acc:.1%}')\nprint(f'NHITS Accuracy: {nhits_acc:.1%}')\n\nMLP Accuracy: 77.7%\nNHITS Accuracy: 78.1%"
  },
  {
    "objectID": "examples/temporal_classifiers.html#references",
    "href": "examples/temporal_classifiers.html#references",
    "title": "Temporal Classification",
    "section": "References",
    "text": "References\n\nCox D. R. (1958). “The Regression Analysis of Binary Sequences.” Journal of the Royal Statistical Society B, 20(2), 215–242.\nCristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2023). NHITS: Neural Hierarchical Interpolation for Time Series Forecasting. Accepted at AAAI 2023."
  },
  {
    "objectID": "examples/exogenous_variables.html",
    "href": "examples/exogenous_variables.html",
    "title": "Exogenous Variables",
    "section": "",
    "text": "Exogenous variables can provide additional information to greatly improve forecasting accuracy. Some examples include price or future promotions variables for demand forecasting, and weather data for electricity load forecast. In this notebook we show an example on how to add different types of exogenous variables to NeuralForecast models for making day-ahead hourly electricity price forecasts (EPF) for France and Belgium markets.\nAll NeuralForecast models are capable of incorporating exogenous variables to model the following conditional predictive distribution: \\[\\mathbb{P}(\\mathbf{y}_{t+1:t+H} \\;|\\; \\mathbf{y}_{[:t]},\\; \\mathbf{x}^{(h)}_{[:t]},\\; \\mathbf{x}^{(f)}_{[:t+H]},\\; \\mathbf{x}^{(s)} )\\]\nwhere the regressors are static exogenous \\(\\mathbf{x}^{(s)}\\), historic exogenous \\(\\mathbf{x}^{(h)}_{[:t]}\\), exogenous available at the time of the prediction \\(\\mathbf{x}^{(f)}_{[:t+H]}\\) and autorregresive features \\(\\mathbf{y}_{[:t]}\\). Depending on the train loss, the model outputs can be point forecasts (location estimators) or uncertainty intervals (quantiles).\nWe will show you how to include exogenous variables in the data, specify variables to a model, and produce forecasts using future exogenous variables.\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/exogenous_variables.html#libraries",
    "href": "examples/exogenous_variables.html#libraries",
    "title": "Exogenous Variables",
    "section": "1. Libraries",
    "text": "1. Libraries\n\n!pip install neuralforecast"
  },
  {
    "objectID": "examples/exogenous_variables.html#load-data",
    "href": "examples/exogenous_variables.html#load-data",
    "title": "Exogenous Variables",
    "section": "2. Load data",
    "text": "2. Load data\nThe df dataframe contains the target and exogenous variables past information to train the model. The unique_id column identifies the markets, ds contains the datestamps, and y the electricity price.\nInclude both historic and future temporal variables as columns. In this example, we are adding the system load (system_load) as historic data. For future variables, we include a forecast of how much electricity will be produced (gen_forecast) and day of week (week_day). Both the electricity system demand and offer impact the price significantly, including these variables to the model greatly improve performance, as we demonstrate in Olivares et al. (2022).\nThe distinction between historic and future variables will be made later as parameters of the model.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\ndf = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/EPF_FR_BE.csv')\ndf['ds'] = pd.to_datetime(df['ds'])\ndf.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ny\ngen_forecast\nsystem_load\nweek_day\n\n\n\n\n0\nFR\n2015-01-01 00:00:00\n53.48\n76905.0\n74812.0\n3\n\n\n1\nFR\n2015-01-01 01:00:00\n51.93\n75492.0\n71469.0\n3\n\n\n2\nFR\n2015-01-01 02:00:00\n48.76\n74394.0\n69642.0\n3\n\n\n3\nFR\n2015-01-01 03:00:00\n42.27\n72639.0\n66704.0\n3\n\n\n4\nFR\n2015-01-01 04:00:00\n38.41\n69347.0\n65051.0\n3\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nCalendar variables such as day of week, month, and year are very useful to capture long seasonalities.\n\n\n\nplt.figure(figsize=(15,5))\nplt.plot(df[df['unique_id']=='FR']['ds'], df[df['unique_id']=='FR']['y'])\nplt.xlabel('Date')\nplt.ylabel('Price [EUR/MWh]')\nplt.grid()\n\n\n\n\nAdd the static variables in a separate static_df dataframe. In this example, we are using one-hot encoding of the electricity market. The static_df must include one observation (row) for each unique_id of the df dataframe, with the different statics variables as columns.\n\nstatic_df = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/EPF_FR_BE_static.csv')\nstatic_df.head()\n\n\n\n\n\n\n\n\nunique_id\nmarket_0\nmarket_1\n\n\n\n\n0\nFR\n1\n0\n\n\n1\nBR\n0\n1"
  },
  {
    "objectID": "examples/exogenous_variables.html#training-with-exogenous-variables",
    "href": "examples/exogenous_variables.html#training-with-exogenous-variables",
    "title": "Exogenous Variables",
    "section": "3. Training with exogenous variables",
    "text": "3. Training with exogenous variables\nWe distinguish the exogenous variables by whether they reflect static or time-dependent aspects of the modeled data.\n\nStatic exogenous variables: The static exogenous variables carry time-invariant information for each time series. When the model is built with global parameters to forecast multiple time series, these variables allow sharing information within groups of time series with similar static variable levels. Examples of static variables include designators such as identifiers of regions, groups of products, etc.\nHistoric exogenous variables: This time-dependent exogenous variable is restricted to past observed values. Its predictive power depends on Granger-causality, as its past values can provide significant information about future values of the target variable \\(\\mathbf{y}\\).\nFuture exogenous variables: In contrast with historic exogenous variables, future values are available at the time of the prediction. Examples include calendar variables, weather forecasts, and known events that can cause large spikes and dips such as scheduled promotions.\n\nTo add exogenous variables to the model, first specify the name of each variable from the previous dataframes to the corresponding model hyperparameter during initialization: futr_exog_list, hist_exog_list, and stat_exog_list. We also set horizon as 24 to produce the next day hourly forecasts, and set input_size to use the last 5 days of data as input.\n\nfrom neuralforecast.auto import NHITS\nfrom neuralforecast.core import NeuralForecast\n\nimport logging\nlogging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n\n\nhorizon = 24 # day-ahead daily forecast\nmodels = [NHITS(h = horizon,\n                input_size = 5*horizon,\n                futr_exog_list = ['gen_forecast', 'week_day'], # &lt;- Future exogenous variables\n                hist_exog_list = ['system_load'], # &lt;- Historical exogenous variables\n                stat_exog_list = ['market_0', 'market_1'], # &lt;- Static exogenous variables\n                scaler_type = 'robust')]\n\n\n\n\n\n\n\nTip\n\n\n\nWhen including exogenous variables always use a scaler by setting the scaler_type hyperparameter. The scaler will scale all the temporal features: the target variable y, historic and future variables.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure future and historic variables are correctly placed. Defining historic variables as future variables will lead to data leakage.\n\n\nNext, pass the datasets to the df and static_df inputs of the fit method.\n\nnf = NeuralForecast(models=models, freq='H')\nnf.fit(df=df,\n       static_df=static_df)"
  },
  {
    "objectID": "examples/exogenous_variables.html#forecasting-with-exogenous-variables",
    "href": "examples/exogenous_variables.html#forecasting-with-exogenous-variables",
    "title": "Exogenous Variables",
    "section": "4. Forecasting with exogenous variables",
    "text": "4. Forecasting with exogenous variables\nBefore predicting the prices, we need to gather the future exogenous variables for the day we want to forecast. Define a new dataframe (futr_df) with the unique_id, ds, and future exogenous variables. There is no need to add the target variable y and historic variables as they won’t be used by the model.\n\nfutr_df = pd.read_csv('https://datasets-nixtla.s3.amazonaws.com/EPF_FR_BE_futr.csv')\nfutr_df['ds'] = pd.to_datetime(futr_df['ds'])\nfutr_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ngen_forecast\nweek_day\n\n\n\n\n0\nFR\n2016-11-01 00:00:00\n49118.0\n1\n\n\n1\nFR\n2016-11-01 01:00:00\n47890.0\n1\n\n\n2\nFR\n2016-11-01 02:00:00\n47158.0\n1\n\n\n3\nFR\n2016-11-01 03:00:00\n45991.0\n1\n\n\n4\nFR\n2016-11-01 04:00:00\n45378.0\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure futr_df has informations for the entire forecast horizon. In this example, we are forecasting 24 hours ahead, so futr_df must have 24 rows for each time series.\n\n\nFinally, use the predict method to forecast the day-ahead prices.\n\nY_hat_df = nf.predict(futr_df=futr_df)\nY_hat_df.head()\n\nPredicting DataLoader 0: 100%|██████████| 1/1 [00:00&lt;00:00, 95.56it/s] \n\n\n\n\n\n\n\n\n\nds\nNHITS\n\n\nunique_id\n\n\n\n\n\n\nBE\n2016-11-01 00:00:00\n36.936493\n\n\nBE\n2016-11-01 01:00:00\n33.701057\n\n\nBE\n2016-11-01 02:00:00\n30.956253\n\n\nBE\n2016-11-01 03:00:00\n28.285088\n\n\nBE\n2016-11-01 04:00:00\n27.118006\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\nplot_df = df[df['unique_id']=='FR'].tail(24*5).reset_index(drop=True)\nY_hat_df = Y_hat_df.reset_index(drop=False)\nY_hat_df = Y_hat_df[Y_hat_df['unique_id']=='FR']\n\nplot_df = pd.concat([plot_df, Y_hat_df ]).set_index('ds') # Concatenate the train and forecast dataframes\n\nplot_df[['y', 'NHITS']].plot(linewidth=2)\nplt.axvline('2016-11-01', color='red')\nplt.ylabel('Price [EUR/MWh]', fontsize=12)\nplt.xlabel('Date', fontsize=12)\nplt.grid()\n\n\n\n\nIn summary, to add exogenous variables to a model make sure to follow the next steps:\n\nAdd temporal exogenous variables as columns to the main dataframe (df).\nAdd static exogenous variables with the static_df dataframe.\nSpecify the name for each variable in the corresponding model hyperparameter.\nIf the model uses future exogenous variables, pass the future dataframe (futr_df) to the predict method."
  },
  {
    "objectID": "examples/exogenous_variables.html#references",
    "href": "examples/exogenous_variables.html#references",
    "title": "Exogenous Variables",
    "section": "References",
    "text": "References\n\nKin G. Olivares, Cristian Challu, Grzegorz Marcjasz, Rafał Weron, Artur Dubrawski, Neural basis expansion analysis with exogenous variables: Forecasting electricity prices with NBEATSx, International Journal of Forecasting\nCristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2021). NHITS: Neural Hierarchical Interpolation for Time Series Forecasting. Accepted at AAAI 2023."
  },
  {
    "objectID": "examples/longhorizon_with_transformers.html",
    "href": "examples/longhorizon_with_transformers.html",
    "title": "Transformer models",
    "section": "",
    "text": "Transformer models, originally proposed for applications in natural language processing, have seen increasing adoption in the field of time series forecasting. The transformative power of these models lies in their novel architecture that relies heavily on the self-attention mechanism, which helps the model to focus on different parts of the input sequence to make predictions, while capturing long-range dependencies within the data. In the context of time series forecasting, Transformer models leverage this self-attention mechanism to identify relevant information across different periods in the time series, making them exceptionally effective in predicting future values for complex and noisy sequences.\nLong horizon forecasting consists of predicting a large number of timestamps. It is a challenging task because of the volatility of the predictions and the computational complexity. To solve this problem, recent studies proposed a variety of Transformer-based models.\nThe Neuralforecast library includes implementations of the following popular recent models: Informer (Zhou, H. et al. 2021), Autoformer (Wu et al. 2021), FEDformer (Zhou, T. et al. 2022), and PatchTST (Nie et al. 2023).\nOur implementation of all these models are univariate, meaning that only autoregressive values of each feature are used for forecasting. We observed that these unvivariate models are more accurate and faster than their multivariate couterpart.\nIn this notebook we will show how to: * Load the ETTm2 benchmark dataset, used in the academic literature. * Train models * Forecast the test set\nThe results achieved in this notebook outperform the original self-reported results in the respective original paper, with a fraction of the computational cost. Additionally, all models are trained with the default recommended parameters, results can be further improved using our auto models with automatic hyperparameter selection.\nYou can run these experiments using GPU with Google Colab.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "examples/longhorizon_with_transformers.html#installing-libraries",
    "href": "examples/longhorizon_with_transformers.html#installing-libraries",
    "title": "Transformer models",
    "section": "1. Installing libraries",
    "text": "1. Installing libraries\n\n!pip install neuralforecast datasetsforecast"
  },
  {
    "objectID": "examples/longhorizon_with_transformers.html#load-ettm2-data",
    "href": "examples/longhorizon_with_transformers.html#load-ettm2-data",
    "title": "Transformer models",
    "section": "2. Load ETTm2 Data",
    "text": "2. Load ETTm2 Data\nThe LongHorizon class will automatically download the complete ETTm2 dataset and process it.\nIt return three Dataframes: Y_df contains the values for the target variables, X_df contains exogenous calendar features and S_df contains static features for each time-series (none for ETTm2). For this example we will only use Y_df.\nIf you want to use your own data just replace Y_df. Be sure to use a long format and have a simmilar structure than our data set.\n\nimport pandas as pd\n\nfrom datasetsforecast.long_horizon import LongHorizon\n\n\n# Change this to your own data to try the model\nY_df, _, _ = LongHorizon.load(directory='./', group='ETTm2')\nY_df['ds'] = pd.to_datetime(Y_df['ds'])\n\nn_time = len(Y_df.ds.unique())\nval_size = int(.2 * n_time)\ntest_size = int(.2 * n_time)\n\nY_df.groupby('unique_id').head(2)\n\n\n\n\n\n\n\n\nunique_id\nds\ny\n\n\n\n\n0\nHUFL\n2016-07-01 00:00:00\n-0.041413\n\n\n1\nHUFL\n2016-07-01 00:15:00\n-0.185467\n\n\n57600\nHULL\n2016-07-01 00:00:00\n0.040104\n\n\n57601\nHULL\n2016-07-01 00:15:00\n-0.214450\n\n\n115200\nLUFL\n2016-07-01 00:00:00\n0.695804\n\n\n115201\nLUFL\n2016-07-01 00:15:00\n0.434685\n\n\n172800\nLULL\n2016-07-01 00:00:00\n0.434430\n\n\n172801\nLULL\n2016-07-01 00:15:00\n0.428168\n\n\n230400\nMUFL\n2016-07-01 00:00:00\n-0.599211\n\n\n230401\nMUFL\n2016-07-01 00:15:00\n-0.658068\n\n\n288000\nMULL\n2016-07-01 00:00:00\n-0.393536\n\n\n288001\nMULL\n2016-07-01 00:15:00\n-0.659338\n\n\n345600\nOT\n2016-07-01 00:00:00\n1.018032\n\n\n345601\nOT\n2016-07-01 00:15:00\n0.980124"
  },
  {
    "objectID": "examples/longhorizon_with_transformers.html#train-models",
    "href": "examples/longhorizon_with_transformers.html#train-models",
    "title": "Transformer models",
    "section": "3. Train models",
    "text": "3. Train models\nWe will train models using the cross_validation method, which allows users to automatically simulate multiple historic forecasts (in the test set).\nThe cross_validation method will use the validation set for hyperparameter selection and early stopping, and will then produce the forecasts for the test set.\nFirst, instantiate each model in the models list, specifying the horizon, input_size, and training iterations.\n(NOTE: The FEDformer model was excluded due to extremely long training times.)\n\nfrom neuralforecast.core import NeuralForecast\nfrom neuralforecast.models import Informer, Autoformer, FEDformer, PatchTST\n\nINFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpopb2vyyt\nINFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpopb2vyyt/_remote_module_non_scriptable.py\n\n\n\nhorizon = 96 # 24hrs = 4 * 15 min.\nmodels = [Informer(h=horizon,                 # Forecasting horizon\n                input_size=horizon,           # Input size\n                max_steps=1000,               # Number of training iterations\n                val_check_steps=100,          # Compute validation loss every 100 steps\n                early_stop_patience_steps=3), # Stop training if validation loss does not improve\n          Autoformer(h=horizon,\n                input_size=horizon,\n                max_steps=1000,\n                val_check_steps=100,\n                early_stop_patience_steps=3),\n          PatchTST(h=horizon,\n                input_size=horizon,\n                max_steps=1000,\n                val_check_steps=100,\n                early_stop_patience_steps=3),\n         ]\n\nINFO:lightning_fabric.utilities.seed:Global seed set to 1\nINFO:lightning_fabric.utilities.seed:Global seed set to 1\nINFO:lightning_fabric.utilities.seed:Global seed set to 1\n\n\n\n\n\n\n\n\nTip\n\n\n\nCheck our auto models for automatic hyperparameter optimization.\n\n\nInstantiate a NeuralForecast object with the following required parameters:\n\nmodels: a list of models.\nfreq: a string indicating the frequency of the data. (See panda’s available frequencies.)\n\nSecond, use the cross_validation method, specifying the dataset (Y_df), validation size and test size.\n\nnf = NeuralForecast(\n    models=models,\n    freq='15min')\n\nY_hat_df = nf.cross_validation(df=Y_df,\n                               val_size=val_size,\n                               test_size=test_size,\n                               n_windows=None)\n\nThe cross_validation method will return the forecasts for each model on the test set.\n\nY_hat_df.head()\n\n\n\n\n\n\n\n\nunique_id\nds\ncutoff\nInformer\nAutoformer\nPatchTST\ny\n\n\n\n\n0\nHUFL\n2017-10-24 00:00:00\n2017-10-23 23:45:00\n-1.055062\n-0.861487\n-0.860189\n-0.977673\n\n\n1\nHUFL\n2017-10-24 00:15:00\n2017-10-23 23:45:00\n-1.021247\n-0.873399\n-0.865730\n-0.865620\n\n\n2\nHUFL\n2017-10-24 00:30:00\n2017-10-23 23:45:00\n-1.057297\n-0.900345\n-0.944296\n-0.961624\n\n\n3\nHUFL\n2017-10-24 00:45:00\n2017-10-23 23:45:00\n-0.886652\n-0.867466\n-0.974849\n-1.049700\n\n\n4\nHUFL\n2017-10-24 01:00:00\n2017-10-23 23:45:00\n-1.000431\n-0.887454\n-1.008530\n-0.953600"
  },
  {
    "objectID": "examples/longhorizon_with_transformers.html#evaluate-results",
    "href": "examples/longhorizon_with_transformers.html#evaluate-results",
    "title": "Transformer models",
    "section": "4. Evaluate Results",
    "text": "4. Evaluate Results\nNext, we plot the forecasts on the test set for the OT variable for all models.\n\nimport matplotlib.pyplot as plt\n\n\nY_plot = Y_hat_df[Y_hat_df['unique_id']=='OT'] # OT dataset\ncutoffs = Y_hat_df['cutoff'].unique()[::horizon]\nY_plot = Y_plot[Y_hat_df['cutoff'].isin(cutoffs)]\n\nplt.figure(figsize=(20,5))\nplt.plot(Y_plot['ds'], Y_plot['y'], label='True')\nplt.plot(Y_plot['ds'], Y_plot['Informer'], label='Informer')\nplt.plot(Y_plot['ds'], Y_plot['Autoformer'], label='Autoformer')\nplt.plot(Y_plot['ds'], Y_plot['PatchTST'], label='PatchTST')\nplt.xlabel('Datestamp')\nplt.ylabel('OT')\nplt.grid()\nplt.legend()\n\n&lt;matplotlib.legend.Legend&gt;\n\n\n\n\n\nFinally, we compute the test errors using the Mean Absolute Error (MAE):\n\\(\\qquad MAE = \\frac{1}{Windows * Horizon} \\sum_{\\tau} |y_{\\tau} - \\hat{y}_{\\tau}| \\qquad\\)\n\nfrom neuralforecast.losses.numpy import mae\n\n\nmae_informer = mae(Y_hat_df['y'], Y_hat_df['Informer'])\nmae_autoformer = mae(Y_hat_df['y'], Y_hat_df['Autoformer'])\nmae_patchtst = mae(Y_hat_df['y'], Y_hat_df['PatchTST'])\n\nprint(f'Informer: {mae_informer:.3f}')\nprint(f'Autoformer: {mae_autoformer:.3f}')\nprint(f'PatchTST: {mae_patchtst:.3f}')\n\nInformer: 0.339\nAutoformer: 0.316\nPatchTST: 0.251\n\n\nFor reference, we can check the performance when compared to self-reported performance in their respective papers.\n\n\n\nHorizon\nPatchTST\nAutoFormer\nInformer\nARIMA\n\n\n\n\n96\n0.256\n0.339\n0.453\n0.301\n\n\n192\n0.296\n0.340\n0.563\n0.345\n\n\n336\n0.329\n0.372\n0.887\n0.386\n\n\n720\n0.385\n0.419\n1.388\n0.445"
  },
  {
    "objectID": "examples/longhorizon_with_transformers.html#next-steps",
    "href": "examples/longhorizon_with_transformers.html#next-steps",
    "title": "Transformer models",
    "section": "Next steps",
    "text": "Next steps\nWe proposed an alternative model for long-horizon forecasting, the NHITS, based on feed-forward networks in (Challu et al. 2023). It achieves on par performance with PatchTST, with a fraction of the computational cost. The NHITS tutorial is available here."
  },
  {
    "objectID": "examples/longhorizon_with_transformers.html#references",
    "href": "examples/longhorizon_with_transformers.html#references",
    "title": "Transformer models",
    "section": "References",
    "text": "References\nZhou, H., Zhang, S., Peng, J., Zhang, S., Li, J., Xiong, H., & Zhang, W. (2021, May). Informer: Beyond efficient transformer for long sequence time-series forecasting. In Proceedings of the AAAI conference on artificial intelligence (Vol. 35, No. 12, pp. 11106-11115)\nWu, H., Xu, J., Wang, J., & Long, M. (2021). Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting. Advances in Neural Information Processing Systems, 34, 22419-22430.\nZhou, T., Ma, Z., Wen, Q., Wang, X., Sun, L., & Jin, R. (2022, June). Fedformer: Frequency enhanced decomposed transformer for long-term series forecasting. In International Conference on Machine Learning (pp. 27268-27286). PMLR.\nNie, Y., Nguyen, N. H., Sinthong, P., & Kalagnanam, J. (2022). A Time Series is Worth 64 Words: Long-term Forecasting with Transformers.\nCristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2021). NHITS: Neural Hierarchical Interpolation for Time Series Forecasting. Accepted at AAAI 2023."
  },
  {
    "objectID": "examples/installation.html",
    "href": "examples/installation.html",
    "title": "Install",
    "section": "",
    "text": "You can install the released version of NeuralForecast from the Python package index with:\npip install neuralforecast\nor\nconda install -c conda-forge neuralforecast\n\n\n\n\n\n\nTip\n\n\n\nNeural Forecasting methods profit from using GPU computation. Be sure to have Cuda installed.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nWe are constantly updating neuralforecast, so we suggest fixing the version to avoid issues. pip install neuralforecast==\"1.0.0\"\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe recommend installing your libraries inside a python virtual or conda environment.\n\n\n\nUser our env (optional)\nIf you don’t have a Conda environment and need tools like Numba, Pandas, NumPy, Jupyter, Tune, and Nbdev you can use ours by following these steps:\n\nClone the NeuralForecast repo:\n\n$ git clone https://github.com/Nixtla/neuralforecast.git && cd neuralforecast\n\nCreate the environment using the environment.yml file:\n\n$ conda env create -f environment.yml\n\nActivate the environment:\n\n$ conda activate neuralforecast\n\nInstall NeuralForecast Dev\n\n$ pip install -e \".[dev]\"\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "🧠 NeuralForecast",
    "section": "",
    "text": "Exogenous Variables: Static, historic and future exogenous support.\nForecast Interpretability: Plot trend, seasonality and exogenous NBEATS, NHITS, TFT, ESRNN prediction components.\nProbabilistic Forecasting: Simple model adapters for quantile losses and parametric distributions.\nTrain and Evaluation Losses Scale-dependent, percentage and scale independent errors, and parametric likelihoods.\nAutomatic Model Selection Parallelized automatic hyperparameter tuning, that efficiently searches best validation configuration.\nSimple Interface Unified SKLearn Interface for StatsForecast and MLForecast compatibility.\nModel Collection: Out of the box implementation of MLP, LSTM, RNN, TCN, DilatedRNN, NBEATS, NHITS, ESRNN, Informer, TFT, PatchTST, VanillaTransformer, StemGNN and HINT. See the entire collection here.\nGive us a ⭐ on Github"
  },
  {
    "objectID": "index.html#features",
    "href": "index.html#features",
    "title": "🧠 NeuralForecast",
    "section": "",
    "text": "Exogenous Variables: Static, historic and future exogenous support.\nForecast Interpretability: Plot trend, seasonality and exogenous NBEATS, NHITS, TFT, ESRNN prediction components.\nProbabilistic Forecasting: Simple model adapters for quantile losses and parametric distributions.\nTrain and Evaluation Losses Scale-dependent, percentage and scale independent errors, and parametric likelihoods.\nAutomatic Model Selection Parallelized automatic hyperparameter tuning, that efficiently searches best validation configuration.\nSimple Interface Unified SKLearn Interface for StatsForecast and MLForecast compatibility.\nModel Collection: Out of the box implementation of MLP, LSTM, RNN, TCN, DilatedRNN, NBEATS, NHITS, ESRNN, Informer, TFT, PatchTST, VanillaTransformer, StemGNN and HINT. See the entire collection here."
  },
  {
    "objectID": "index.html#why",
    "href": "index.html#why",
    "title": "🧠 NeuralForecast",
    "section": "Why?",
    "text": "Why?\nThere is a shared belief in Neural forecasting methods’ capacity to improve our pipeline’s accuracy and efficiency.\nUnfortunately, available implementations and published research are yet to realize neural networks’ potential. They are hard to use and continuously fail to improve over statistical methods while being computationally prohibitive. For this reason, we created NeuralForecast, a library favoring proven accurate and efficient models focusing on their usability."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "🧠 NeuralForecast",
    "section": "💻 Installation",
    "text": "💻 Installation\n\nPyPI\nYou can install NeuralForecast’s released version from the Python package index pip with:\npip install neuralforecast\n(Installing inside a python virtualenvironment or a conda environment is recommended.)\n\n\nConda\nAlso you can install NeuralForecast’s released version from conda with:\nconda install -c conda-forge neuralforecast\n(Installing inside a python virtualenvironment or a conda environment is recommended.)\n\n\nDev Mode\nIf you want to make some modifications to the code and see the effects in real time (without reinstalling), follow the steps below:\ngit clone https://github.com/Nixtla/neuralforecast.git\ncd neuralforecast\npip install -e ."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "🧠 NeuralForecast",
    "section": "How to Use",
    "text": "How to Use\n\nimport numpy as np\nimport pandas as pd\nfrom IPython.display import display, Markdown\n\nimport matplotlib.pyplot as plt\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import NBEATS, NHITS\nfrom neuralforecast.utils import AirPassengersDF\n\n# Split data and declare panel dataset\nY_df = AirPassengersDF\nY_train_df = Y_df[Y_df.ds&lt;='1959-12-31'] # 132 train\nY_test_df = Y_df[Y_df.ds&gt;'1959-12-31'] # 12 test\n\n# Fit and predict with NBEATS and NHITS models\nhorizon = len(Y_test_df)\nmodels = [NBEATS(input_size=2 * horizon, h=horizon, max_epochs=50),\n          NHITS(input_size=2 * horizon, h=horizon, max_epochs=50)]\nnf = NeuralForecast(models=models, freq='M')\nnf.fit(df=Y_train_df)\nY_hat_df = nf.predict().reset_index()\n\n# Plot predictions\nfig, ax = plt.subplots(1, 1, figsize = (20, 7))\nY_hat_df = Y_test_df.merge(Y_hat_df, how='left', on=['unique_id', 'ds'])\nplot_df = pd.concat([Y_train_df, Y_hat_df]).set_index('ds')\n\nplot_df[['y', 'NBEATS', 'NHITS']].plot(ax=ax, linewidth=2)\n\nax.set_title('AirPassengers Forecast', fontsize=22)\nax.set_ylabel('Monthly Passengers', fontsize=20)\nax.set_xlabel('Timestamp [t]', fontsize=20)\nax.legend(prop={'size': 15})\nax.grid()"
  },
  {
    "objectID": "index.html#how-to-cite",
    "href": "index.html#how-to-cite",
    "title": "🧠 NeuralForecast",
    "section": "🙏 How to Cite",
    "text": "🙏 How to Cite\nIf you enjoy or benefit from using these Python implementations, a citation to the repository will be greatly appreciated.\n@misc{olivares2022library_neuralforecast,\n    author={Kin G. Olivares and\n            Cristian Challú and\n            Federico Garza and\n            Max Mergenthaler Canseco and\n            Artur Dubrawski},\n    title = {{NeuralForecast}: User friendly state-of-the-art neural forecasting models.},\n    year={2022},\n    howpublished={{PyCon} Salt Lake City, Utah, US 2022},\n    url={https://github.com/Nixtla/neuralforecast}\n}"
  },
  {
    "objectID": "models.nhits.html",
    "href": "models.nhits.html",
    "title": "NHITS",
    "section": "",
    "text": "Long-horizon forecasting is challenging because of the volatility of the predictions and the computational complexity. To solve this problem we created the Neural Hierarchical Interpolation for Time Series (NHITS). NHITS builds upon NBEATS and specializes its partial outputs in the different frequencies of the time series through hierarchical interpolation and multi-rate input processing. On the long-horizon forecasting task NHITS improved accuracy by 25% on AAAI’s best paper award the Informer, while being 50x faster.\nThe model is composed of several MLPs with ReLU non-linearities. Blocks are connected via doubly residual stacking principle with the backcast \\(\\mathbf{\\tilde{y}}_{t-L:t,l}\\) and forecast \\(\\mathbf{\\hat{y}}_{t+1:t+H,l}\\) outputs of the l-th block. Multi-rate input pooling, hierarchical interpolation and backcast residual connections together induce the specialization of the additive predictions in different signal bands, reducing memory footprint and computational time, thus improving the architecture parsimony and accuracy.\nReferences -Boris N. Oreshkin, Dmitri Carpov, Nicolas Chapados, Yoshua Bengio (2019). “N-BEATS: Neural basis expansion analysis for interpretable time series forecasting”. -Cristian Challu, Kin G. Olivares, Boris N. Oreshkin, Federico Garza, Max Mergenthaler-Canseco, Artur Dubrawski (2023). “NHITS: Neural Hierarchical Interpolation for Time Series Forecasting”. Accepted at the Thirty-Seventh AAAI Conference on Artificial Intelligence. -Zhou, H.; Zhang, S.; Peng, J.; Zhang, S.; Li, J.; Xiong, H.; and Zhang, W. (2020). “Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting”. Association for the Advancement of Artificial Intelligence Conference 2021 (AAAI 2021).\nsource\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.nhits.html#usage-example",
    "href": "models.nhits.html#usage-example",
    "title": "NHITS",
    "section": "Usage Example",
    "text": "Usage Example\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import NHITS\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss, PMM, GMM, NBMM\nfrom neuralforecast.tsdataset import TimeSeriesDataset\nfrom neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic\n\n\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nmodel = NHITS(h=12,\n              input_size=24,\n              loss=DistributionLoss(distribution='StudentT', level=[80, 90], return_params=True),\n              #loss=DistributionLoss(distribution='Normal', level=[80, 90], return_params=True),\n              #loss=DistributionLoss(distribution='Poisson', level=[80, 90], return_params=True),\n              #loss=DistributionLoss(distribution='Tweedie', level=[80, 90], rho=1.5),\n              #loss=DistributionLoss(distribution='NegativeBinomial', level=[80, 90], return_params=True),\n              #loss=NBMM(n_components=2, level=[80,90]),\n              #loss=GMM(n_components=2, level=[80,90]),\n              #loss=PMM(n_components=1, level=[80,90]),\n              stat_exog_list=['airline1'],\n              futr_exog_list=['trend'],\n              n_freq_downsample=[2, 1, 1],\n              scaler_type='robust',\n              max_steps=200,\n              early_stop_patience_steps=2,\n              inference_windows_batch_size=1,\n              val_check_steps=10,\n              learning_rate=1e-3)\n\nfcst = NeuralForecast(models=[model], freq='M')\nfcst.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\nforecasts = fcst.predict(futr_df=Y_test_df)\n\n# Plot quantile predictions\nY_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nplot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\nplt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\nplt.plot(plot_df['ds'], plot_df['NHITS-median'], c='blue', label='median')\nplt.fill_between(x=plot_df['ds'][-12:], \n                 y1=plot_df['NHITS-lo-90'][-12:].values, \n                 y2=plot_df['NHITS-hi-90'][-12:].values,\n                 alpha=0.4, label='level 90')\nplt.legend()\nplt.grid()\nplt.plot()\n\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import NHITS\nfrom neuralforecast.losses.pytorch import DistributionLoss, HuberLoss, MAE\nfrom neuralforecast.tsdataset import TimeSeriesDataset\nfrom neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic\n\n#AirPassengersPanel['y'] = 1 * (AirPassengersPanel['trend'] % 12) &lt; 2\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nmodel = NHITS(h=12,\n              input_size=24,\n              #loss=DistributionLoss(distribution='StudentT', level=[80, 90], return_params=True),\n              loss=HuberLoss(delta=0.5),\n              valid_loss=MAE(),\n              stat_exog_list=['airline1'],\n              scaler_type='robust',\n              max_steps=200,\n              early_stop_patience_steps=2,\n              val_check_steps=10,\n              learning_rate=1e-3)\n\nfcst = NeuralForecast(models=[model], freq='M')\nfcst.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\nforecasts = fcst.predict(futr_df=Y_test_df)\n\n# Plot quantile predictions\nY_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nplot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\nplt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\nplt.plot(plot_df['ds'], plot_df['NHITS'], c='blue', label='median')\n# plt.plot(plot_df['ds'], plot_df['NHITS-median'], c='blue', label='median')\n# plt.fill_between(x=plot_df['ds'][-12:], \n#                  y1=plot_df['NHITS-lo-90'][-12:].values, \n#                  y2=plot_df['NHITS-hi-90'][-12:].values,\n#                  alpha=0.4, label='level 90')\nplt.legend()\nplt.grid()\nplt.plot()"
  },
  {
    "objectID": "models.vanillatransformer.html",
    "href": "models.vanillatransformer.html",
    "title": "Vanilla Transformer",
    "section": "",
    "text": "Vanilla Transformer, following implementation of the Informer paper, used as baseline.\nThe architecture has three distinctive features: - Full-attention mechanism with O(L^2) time and memory complexity. - Classic encoder-decoder proposed by Vaswani et al. (2017) with a multi-head attention mechanism. - An MLP multi-step decoder that predicts long time-series sequences in a single forward operation rather than step-by-step.\nThe Vanilla Transformer model utilizes a three-component approach to define its embedding: - It employs encoded autoregressive features obtained from a convolution network. - It uses window-relative positional embeddings derived from harmonic functions. - Absolute positional embeddings obtained from calendar features are utilized.\nReferences - Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, Wancai Zhang. “Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting”\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.vanillatransformer.html#auxiliary-functions",
    "href": "models.vanillatransformer.html#auxiliary-functions",
    "title": "Vanilla Transformer",
    "section": "1. Auxiliary Functions",
    "text": "1. Auxiliary Functions\n\nsource\n\nFullAttention\n\n FullAttention (mask_flag=True, scale=None, attention_dropout=0.1,\n                output_attention=False)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nsource\n\n\nTriangularCausalMask\n\n TriangularCausalMask (B, L, device='cpu')\n\nInitialize self. See help(type(self)) for accurate signature."
  },
  {
    "objectID": "models.vanillatransformer.html#vanillatransformer",
    "href": "models.vanillatransformer.html#vanillatransformer",
    "title": "Vanilla Transformer",
    "section": "2. VanillaTransformer",
    "text": "2. VanillaTransformer\n\nsource\n\nVanillaTransformer\n\n VanillaTransformer (h:int, input_size:int, stat_exog_list=None,\n                     hist_exog_list=None, futr_exog_list=None,\n                     decoder_input_size_multiplier:float=0.5,\n                     hidden_size:int=128, dropout:float=0.05,\n                     n_head:int=4, conv_hidden_size:int=32,\n                     activation:str='gelu', encoder_layers:int=2,\n                     decoder_layers:int=1, loss=MAE(), valid_loss=None,\n                     max_steps:int=5000, learning_rate:float=0.0001,\n                     num_lr_decays:int=-1,\n                     early_stop_patience_steps:int=-1,\n                     val_check_steps:int=100, batch_size:int=32,\n                     valid_batch_size:Optional[int]=None,\n                     windows_batch_size=1024,\n                     inference_windows_batch_size:int=1024,\n                     start_padding_enabled=False, step_size:int=1,\n                     scaler_type:str='identity', random_seed:int=1,\n                     num_workers_loader:int=0,\n                     drop_last_loader:bool=False, **trainer_kwargs)\n\nVanillaTransformer\nVanilla Transformer, following implementation of the Informer paper, used as baseline.\nThe architecture has three distinctive features: - Full-attention mechanism with O(L^2) time and memory complexity. - An MLP multi-step decoder that predicts long time-series sequences in a single forward operation rather than step-by-step.\nThe Vanilla Transformer model utilizes a three-component approach to define its embedding: - It employs encoded autoregressive features obtained from a convolution network. - It uses window-relative positional embeddings derived from harmonic functions. - Absolute positional embeddings obtained from calendar features are utilized.\nParameters: h: int, forecast horizon. input_size: int, maximum sequence length for truncated train backpropagation. Default -1 uses all history. futr_exog_list: str list, future exogenous columns. hist_exog_list: str list, historic exogenous columns. stat_exog_list: str list, static exogenous columns. decoder_input_size_multiplier: float = 0.5, . hidden_size: int=128, units of embeddings and encoders. n_head: int=4, controls number of multi-head’s attention. dropout: float (0, 1), dropout throughout Informer architecture. conv_hidden_size: int=32, channels of the convolutional encoder. activation: str=GELU, activation from [‘ReLU’, ‘Softplus’, ‘Tanh’, ‘SELU’, ‘LeakyReLU’, ‘PReLU’, ‘Sigmoid’, ‘GELU’]. encoder_layers: int=2, number of layers for the TCN encoder. decoder_layers: int=1, number of layers for the MLP decoder. loss: PyTorch module, instantiated train loss class from losses collection. max_steps: int=1000, maximum number of training steps. learning_rate: float=1e-3, Learning rate between (0, 1). num_lr_decays: int=-1, Number of learning rate decays, evenly distributed across max_steps. early_stop_patience_steps: int=-1, Number of validation iterations before early stopping. val_check_steps: int=100, Number of training steps between every validation loss check. batch_size: int=32, number of different series in each batch. valid_batch_size: int=None, number of different series in each validation and test batch, if None uses batch_size. windows_batch_size: int=1024, number of windows to sample in each training batch, default uses all. inference_windows_batch_size: int=1024, number of windows to sample in each inference batch. start_padding_enabled: bool=False, if True, the model will pad the time series with zeros at the beginning, by input size. scaler_type: str=‘robust’, type of scaler for temporal inputs normalization see temporal scalers. random_seed: int=1, random_seed for pytorch initializer and numpy generators. num_workers_loader: int=os.cpu_count(), workers to be used by TimeSeriesDataLoader. drop_last_loader: bool=False, if True TimeSeriesDataLoader drops last non-full batch. alias: str, optional, Custom name of the model. **trainer_kwargs: int, keyword trainer arguments inherited from PyTorch Lighning’s trainer.\n*References*&lt;br&gt;\n- [Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, Wancai Zhang. \"Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting\"](https://arxiv.org/abs/2012.07436)&lt;br&gt;\n\n\n\nVanillaTransformer.fit\n\n VanillaTransformer.fit (dataset, val_size=0, test_size=0,\n                         random_seed=None)\n\nFit.\nThe fit method, optimizes the neural network’s weights using the initialization parameters (learning_rate, windows_batch_size, …) and the loss function as defined during the initialization. Within fit we use a PyTorch Lightning Trainer that inherits the initialization’s self.trainer_kwargs, to customize its inputs, see PL’s trainer arguments.\nThe method is designed to be compatible with SKLearn-like classes and in particular to be compatible with the StatsForecast library.\nBy default the model is not saving training checkpoints to protect disk memory, to get them change enable_checkpointing=True in __init__.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset, see documentation. val_size: int, validation size for temporal cross-validation. random_seed: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__’s. test_size: int, test size for temporal cross-validation.\n\n\n\nVanillaTransformer.predict\n\n VanillaTransformer.predict (dataset, test_size=None, step_size=1,\n                             random_seed=None, **data_module_kwargs)\n\nPredict.\nNeural network prediction with PL’s Trainer execution of predict_step.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset, see documentation. test_size: int=None, test size for temporal cross-validation. step_size: int=1, Step size between each window. random_seed: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__’s. **data_module_kwargs: PL’s TimeSeriesDataModule args, see documentation."
  },
  {
    "objectID": "models.vanillatransformer.html#usage-example",
    "href": "models.vanillatransformer.html#usage-example",
    "title": "Vanilla Transformer",
    "section": "Usage Example",
    "text": "Usage Example\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import MLP\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss\nfrom neuralforecast.tsdataset import TimeSeriesDataset\nfrom neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic, augment_calendar_df\n\nAirPassengersPanel, calendar_cols = augment_calendar_df(df=AirPassengersPanel, freq='M')\n\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]] # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nmodel = VanillaTransformer(h=12,\n                 input_size=24,\n                 hidden_size=16,\n                 conv_hidden_size=32,\n                 n_head=2,\n                 loss=MAE(),\n                 futr_exog_list=calendar_cols,\n                 scaler_type='robust',\n                 learning_rate=1e-3,\n                 max_steps=500,\n                 val_check_steps=50,\n                 early_stop_patience_steps=2)\n\nnf = NeuralForecast(\n    models=[model],\n    freq='M'\n)\nnf.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\nforecasts = nf.predict(futr_df=Y_test_df)\n\nY_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nif model.loss.is_distribution_output:\n    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n    plt.plot(plot_df['ds'], plot_df['VanillaTransformer-median'], c='blue', label='median')\n    plt.fill_between(x=plot_df['ds'][-12:], \n                    y1=plot_df['VanillaTransformer-lo-90'][-12:].values, \n                    y2=plot_df['VanillaTransformer-hi-90'][-12:].values,\n                    alpha=0.4, label='level 90')\n    plt.grid()\n    plt.legend()\n    plt.plot()\nelse:\n    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n    plt.plot(plot_df['ds'], plot_df['VanillaTransformer'], c='blue', label='Forecast')\n    plt.legend()\n    plt.grid()"
  },
  {
    "objectID": "models.rnn.html",
    "href": "models.rnn.html",
    "title": "RNN",
    "section": "",
    "text": "Elman proposed this classic recurrent neural network (RNN) in 1990, where each layer uses the following recurrent transformation: \\[\\mathbf{h}^{l}_{t} = \\mathrm{Activation}([\\mathbf{y}_{t},\\mathbf{x}^{(h)}_{t},\\mathbf{x}^{(s)}] W^{\\intercal}_{ih} + b_{ih}  +  \\mathbf{h}^{l}_{t-1} W^{\\intercal}_{hh} + b_{hh})\\]\nwhere \\(\\mathbf{h}^{l}_{t}\\), is the hidden state of RNN layer \\(l\\) for time \\(t\\), \\(\\mathbf{y}_{t}\\) is the input at time \\(t\\) and \\(\\mathbf{h}_{t-1}\\) is the hidden state of the previous layer at \\(t-1\\), \\(\\mathbf{x}^{(s)}\\) are static exogenous inputs, \\(\\mathbf{x}^{(h)}_{t}\\) historic exogenous, \\(\\mathbf{x}^{(f)}_{[:t+H]}\\) are future exogenous available at the time of the prediction. The available activations are tanh, and relu. The predictions are obtained by transforming the hidden states into contexts \\(\\mathbf{c}_{[t+1:t+H]}\\), that are decoded and adapted into \\(\\mathbf{\\hat{y}}_{[t+1:t+H],[q]}\\) through MLPs.\n\\[\\begin{align}\n\\mathbf{h}_{t} &= \\textrm{RNN}([\\mathbf{y}_{t},\\mathbf{x}^{(h)}_{t},\\mathbf{x}^{(s)}], \\mathbf{h}_{t-1})\\\\\n\\mathbf{c}_{[t+1:t+H]}&=\\textrm{Linear}([\\mathbf{h}_{t}, \\mathbf{x}^{(f)}_{[:t+H]}]) \\\\\n\\hat{y}_{\\tau,[q]}&=\\textrm{MLP}([\\mathbf{c}_{\\tau},\\mathbf{x}^{(f)}_{\\tau}])\n\\end{align}\\]\nReferences -Jeffrey L. Elman (1990). “Finding Structure in Time”. -Cho, K., van Merrienboer, B., Gülcehre, C., Bougares, F., Schwenk, H., & Bengio, Y. (2014). Learning phrase representations using RNN encoder-decoder for statistical machine translation.\nsource\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.rnn.html#usage-example",
    "href": "models.rnn.html#usage-example",
    "title": "RNN",
    "section": "Usage Example",
    "text": "Usage Example\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import RNN\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss\nfrom neuralforecast.utils import AirPassengersPanel, AirPassengersStatic\nfrom neuralforecast.tsdataset import TimeSeriesDataset, TimeSeriesLoader\n\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]] # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nfcst = NeuralForecast(\n    models=[RNN(h=12,\n                input_size=-1,\n                inference_input_size=24,\n                loss=MQLoss(level=[80, 90]),\n                scaler_type='robust',\n                encoder_n_layers=2,\n                encoder_hidden_size=128,\n                context_size=10,\n                decoder_hidden_size=128,\n                decoder_layers=2,\n                max_steps=300,\n                futr_exog_list=['y_[lag12]'],\n                #hist_exog_list=['y_[lag12]'],\n                stat_exog_list=['airline1'],\n                )\n    ],\n    freq='M'\n)\nfcst.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\nforecasts = fcst.predict(futr_df=Y_test_df)\n\nY_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nplot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\nplt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\nplt.plot(plot_df['ds'], plot_df['RNN-median'], c='blue', label='median')\nplt.fill_between(x=plot_df['ds'][-12:], \n                 y1=plot_df['RNN-lo-90'][-12:].values, \n                 y2=plot_df['RNN-hi-90'][-12:].values,\n                 alpha=0.4, label='level 90')\nplt.legend()\nplt.grid()\nplt.plot()"
  },
  {
    "objectID": "common.base_multivariate.html",
    "href": "common.base_multivariate.html",
    "title": "BaseMultivariate",
    "section": "",
    "text": "BaseMultivariate\n\n BaseMultivariate (h, input_size, loss, valid_loss, learning_rate,\n                   max_steps, val_check_steps, n_series, batch_size,\n                   step_size=1, num_lr_decays=0,\n                   early_stop_patience_steps=-1, scaler_type='robust',\n                   futr_exog_list=None, hist_exog_list=None,\n                   stat_exog_list=None, num_workers_loader=0,\n                   drop_last_loader=False, random_seed=1, alias=None,\n                   **trainer_kwargs)\n\nBase Multivariate\nBase class for all multivariate models. The forecasts for all time-series are produced simultaneously within each window, which are randomly sampled during training.\nThis class implements the basic functionality for all windows-based models, including: - PyTorch Lightning’s methods training_step, validation_step, predict_step. - fit and predict methods used by NeuralForecast.core class. - sampling and wrangling methods to generate multivariate windows.\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.nbeats.html",
    "href": "models.nbeats.html",
    "title": "NBEATS",
    "section": "",
    "text": "The Neural Basis Expansion Analysis (NBEATS) is an MLP-based deep neural architecture with backward and forward residual links. The network has two variants: (1) in its interpretable configuration, NBEATS sequentially projects the signal into polynomials and harmonic basis to learn trend and seasonality components; (2) in its generic configuration, it substitutes the polynomial and harmonic basis for identity basis and larger network’s depth. The Neural Basis Expansion Analysis with Exogenous (NBEATSx), incorporates projections to exogenous temporal variables available at the time of the prediction.\nThis method proved state-of-the-art performance on the M3, M4, and Tourism Competition datasets, improving accuracy by 3% over the ESRNN M4 competition winner.\nReferences -Boris N. Oreshkin, Dmitri Carpov, Nicolas Chapados, Yoshua Bengio (2019). “N-BEATS: Neural basis expansion analysis for interpretable time series forecasting”.\nsource\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.nbeats.html#usage-example",
    "href": "models.nbeats.html#usage-example",
    "title": "NBEATS",
    "section": "Usage Example",
    "text": "Usage Example\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import NBEATS\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss\nfrom neuralforecast.tsdataset import TimeSeriesDataset\nfrom neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic\n\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]] # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nmodel = NBEATS(h=12, input_size=24,\n               loss=DistributionLoss(distribution='Poisson', level=[80, 90]),\n               stack_types = ['identity', 'trend', 'seasonality'],\n               max_steps=100,\n               val_check_steps=10,\n               early_stop_patience_steps=2)\n\nfcst = NeuralForecast(\n    models=[model],\n    freq='M'\n)\nfcst.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\nforecasts = fcst.predict(futr_df=Y_test_df)\n\n# Plot quantile predictions\nY_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nplot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\nplt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\nplt.plot(plot_df['ds'], plot_df['NBEATS-median'], c='blue', label='median')\nplt.fill_between(x=plot_df['ds'][-12:], \n                 y1=plot_df['NBEATS-lo-90'][-12:].values, \n                 y2=plot_df['NBEATS-hi-90'][-12:].values,\n                 alpha=0.4, label='level 90')\nplt.grid()\nplt.legend()\nplt.plot()"
  },
  {
    "objectID": "common.base_auto.html",
    "href": "common.base_auto.html",
    "title": "Hyperparameter Optimization",
    "section": "",
    "text": "Figure 1. Example of dataset split (left), validation (yellow) and test (orange). The hyperparameter optimization guiding signal is obtained from the validation set.\n\n\n\n\nBaseAuto\n\n BaseAuto (cls_model, h, loss, valid_loss, config,\n           search_alg=&lt;ray.tune.search.basic_variant.BasicVariantGenerator\n           object at 0x7f50e09f3eb0&gt;, num_samples=10, cpus=4, gpus=0,\n           refit_with_val=False, verbose=False, alias=None, backend='ray')\n\nClass for Automatic Hyperparameter Optimization, it builds on top of ray to give access to a wide variety of hyperparameter optimization tools ranging from classic grid search, to Bayesian optimization and HyperBand algorithm.\nThe validation loss to be optimized is defined by the config['loss'] dictionary value, the config also contains the rest of the hyperparameter search space.\nIt is important to note that the success of this hyperparameter optimization heavily relies on a strong correlation between the validation and test periods.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncls_model\nPyTorch/PyTorchLightning model\n\nSee neuralforecast.models collection here.\n\n\nh\nint\n\nForecast horizon\n\n\nloss\nPyTorch module\n\nInstantiated train loss class from losses collection.\n\n\nvalid_loss\nPyTorch module\n\nInstantiated valid loss class from losses collection.\n\n\nconfig\ndict or callable\n\nDictionary with ray.tune defined search space or function that takes an optuna trial and returns a configuration dict.\n\n\nsearch_alg\nBasicVariantGenerator\n&lt;ray.tune.search.basic_variant.BasicVariantGenerator object at 0x7f50e09f3eb0&gt;\nFor ray see https://docs.ray.io/en/latest/tune/api_docs/suggestion.htmlFor optuna see https://optuna.readthedocs.io/en/stable/reference/samplers/index.html.\n\n\nnum_samples\nint\n10\nNumber of hyperparameter optimization steps/samples.\n\n\ncpus\nint\n4\nNumber of cpus to use during optimization. Only used with ray tune.\n\n\ngpus\nint\n0\nNumber of gpus to use during optimization, default all available. Only used with ray tune.\n\n\nrefit_with_val\nbool\nFalse\nRefit of best model should preserve val_size.\n\n\nverbose\nbool\nFalse\nTrack progress.\n\n\nalias\nNoneType\nNone\nCustom name of the model.\n\n\nbackend\nstr\nray\nBackend to use for searching the hyperparameter space, can be either ‘ray’ or ‘optuna’.\n\n\n\n\n\n\nBaseAuto.fit\n\n BaseAuto.fit (dataset, val_size=0, test_size=0, random_seed=None)\n\nBaseAuto.fit\nPerform the hyperparameter optimization as specified by the BaseAuto configuration dictionary config.\nThe optimization is performed on the TimeSeriesDataset using temporal cross validation with the validation set that sequentially precedes the test set.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset see details here val_size: int, size of temporal validation set (needs to be bigger than 0). test_size: int, size of temporal test set (default 0). random_seed: int=None, random_seed for hyperparameter exploration algorithms, not yet implemented. Returns: self: fitted instance of BaseAuto with best hyperparameters and results.\n\n\n\nBaseAuto.predict\n\n BaseAuto.predict (dataset, step_size=1, **data_kwargs)\n\nBaseAuto.predict\nPredictions of the best performing model on validation.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset see details here step_size: int, steps between sequential predictions, (default 1). **data_kwarg: additional parameters for the dataset module. random_seed: int=None, random_seed for hyperparameter exploration algorithms (not implemented). Returns: y_hat: numpy predictions of the NeuralForecast model.\n\nconfig = {\n    \"hidden_size\": tune.choice([512]),\n    \"num_layers\": tune.choice([3, 4]),\n    \"input_size\": 12,\n    \"max_steps\": 10,\n    \"val_check_steps\": 5\n}\nauto = BaseAuto(h=12, loss=MAE(), valid_loss=MSE(), cls_model=MLP, config=config, num_samples=2, cpus=1, gpus=0)\nauto.fit(dataset=dataset)\ny_hat = auto.predict(dataset=dataset)\nassert mae(Y_test_df['y'].values, y_hat[:, 0]) &lt; 200\n\n\ndef config_f(trial):\n    return {\n        \"hidden_size\": trial.suggest_categorical('hidden_size', [512]),\n        \"num_layers\": trial.suggest_categorical('num_layers', [3, 4]),\n        \"input_size\": 12,\n        \"max_steps\": 10,\n        \"val_check_steps\": 5\n    }\n\n\nauto2 = BaseAuto(h=12, loss=MAE(), valid_loss=MSE(), cls_model=MLP, config=config_f, search_alg=optuna.samplers.RandomSampler(), num_samples=2, backend='optuna')\nauto2.fit(dataset=dataset)\nassert isinstance(auto2.results, optuna.Study)\ny_hat2 = auto2.predict(dataset=dataset)\nassert mae(Y_test_df['y'].values, y_hat2[:, 0]) &lt; 200\n\n\n\nReferences\n\nJames Bergstra, Remi Bardenet, Yoshua Bengio, and Balazs Kegl (2011). “Algorithms for Hyper-Parameter Optimization”. In: Advances in Neural Information Processing Systems. url: https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf\nKirthevasan Kandasamy, Karun Raju Vysyaraju, Willie Neiswanger, Biswajit Paria, Christopher R. Collins, Jeff Schneider, Barnabas Poczos, Eric P. Xing (2019). “Tuning Hyperparameters without Grad Students: Scalable and Robust Bayesian Optimisation with Dragonfly”. Journal of Machine Learning Research. url: https://arxiv.org/abs/1903.06694\nLisha Li, Kevin Jamieson, Giulia DeSalvo, Afshin Rostamizadeh, Ameet Talwalkar (2016). “Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization”. Journal of Machine Learning Research. url: https://arxiv.org/abs/1603.06560\n\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "losses.pytorch.html",
    "href": "losses.pytorch.html",
    "title": "PyTorch Losses",
    "section": "",
    "text": "source\nGive us a ⭐ on Github"
  },
  {
    "objectID": "losses.pytorch.html#mean-absolute-error-mae",
    "href": "losses.pytorch.html#mean-absolute-error-mae",
    "title": "PyTorch Losses",
    "section": "Mean Absolute Error (MAE)",
    "text": "Mean Absolute Error (MAE)\n\nsource\n\nMAE.__init__\n\n MAE.__init__ (horizon_weight=None)\n\nMean Absolute Error\nCalculates Mean Absolute Error between y and y_hat. MAE measures the relative prediction accuracy of a forecasting method by calculating the deviation of the prediction and the true value at a given time and averages these devations over the length of the series.\n\\[ \\mathrm{MAE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} |y_{\\tau} - \\hat{y}_{\\tau}| \\]\nParameters: horizon_weight: Tensor of size h, weight for each timestamp of the forecasting window. \n\nsource\n\n\nMAE.__call__\n\n MAE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n               mask:Optional[torch.Tensor]=None)\n\nParameters: y: tensor, Actual values. y_hat: tensor, Predicted values. mask: tensor, Specifies datapoints to consider in loss.\nReturns: mae: tensor (single value)."
  },
  {
    "objectID": "losses.pytorch.html#mean-squared-error-mse",
    "href": "losses.pytorch.html#mean-squared-error-mse",
    "title": "PyTorch Losses",
    "section": "Mean Squared Error (MSE)",
    "text": "Mean Squared Error (MSE)\n\nsource\n\nMSE.__init__\n\n MSE.__init__ (horizon_weight=None)\n\nMean Squared Error\nCalculates Mean Squared Error between y and y_hat. MSE measures the relative prediction accuracy of a forecasting method by calculating the squared deviation of the prediction and the true value at a given time, and averages these devations over the length of the series.\n\\[ \\mathrm{MSE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} (y_{\\tau} - \\hat{y}_{\\tau})^{2} \\]\nParameters: horizon_weight: Tensor of size h, weight for each timestamp of the forecasting window. \n\nsource\n\n\nMSE.__call__\n\n MSE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n               mask:Optional[torch.Tensor]=None)\n\nParameters: y: tensor, Actual values. y_hat: tensor, Predicted values. mask: tensor, Specifies datapoints to consider in loss.\nReturns: mse: tensor (single value)."
  },
  {
    "objectID": "losses.pytorch.html#root-mean-squared-error-rmse",
    "href": "losses.pytorch.html#root-mean-squared-error-rmse",
    "title": "PyTorch Losses",
    "section": "Root Mean Squared Error (RMSE)",
    "text": "Root Mean Squared Error (RMSE)\n\nsource\n\nRMSE.__init__\n\n RMSE.__init__ (horizon_weight=None)\n\nRoot Mean Squared Error\nCalculates Root Mean Squared Error between y and y_hat. RMSE measures the relative prediction accuracy of a forecasting method by calculating the squared deviation of the prediction and the observed value at a given time and averages these devations over the length of the series. Finally the RMSE will be in the same scale as the original time series so its comparison with other series is possible only if they share a common scale. RMSE has a direct connection to the L2 norm.\n\\[ \\mathrm{RMSE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\sqrt{\\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} (y_{\\tau} - \\hat{y}_{\\tau})^{2}} \\]\nParameters: horizon_weight: Tensor of size h, weight for each timestamp of the forecasting window. \n\nsource\n\n\nRMSE.__call__\n\n RMSE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n                mask:Optional[torch.Tensor]=None)\n\nParameters: y: tensor, Actual values. y_hat: tensor, Predicted values. mask: tensor, Specifies datapoints to consider in loss.\nReturns: rmse: tensor (single value)."
  },
  {
    "objectID": "losses.pytorch.html#mean-absolute-percentage-error-mape",
    "href": "losses.pytorch.html#mean-absolute-percentage-error-mape",
    "title": "PyTorch Losses",
    "section": "Mean Absolute Percentage Error (MAPE)",
    "text": "Mean Absolute Percentage Error (MAPE)\n\nsource\n\nMAPE.__init__\n\n MAPE.__init__ (horizon_weight=None)\n\nMean Absolute Percentage Error\nCalculates Mean Absolute Percentage Error between y and y_hat. MAPE measures the relative prediction accuracy of a forecasting method by calculating the percentual deviation of the prediction and the observed value at a given time and averages these devations over the length of the series. The closer to zero an observed value is, the higher penalty MAPE loss assigns to the corresponding error.\n\\[ \\mathrm{MAPE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\frac{|y_{\\tau}-\\hat{y}_{\\tau}|}{|y_{\\tau}|} \\]\nParameters: horizon_weight: Tensor of size h, weight for each timestamp of the forecasting window. \nReferences: Makridakis S., “Accuracy measures: theoretical and practical concerns”.\n\nsource\n\n\nMAPE.__call__\n\n MAPE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n                mask:Optional[torch.Tensor]=None)\n\nParameters: y: tensor, Actual values. y_hat: tensor, Predicted values. mask: tensor, Specifies date stamps per serie to consider in loss.\nReturns: mape: tensor (single value)."
  },
  {
    "objectID": "losses.pytorch.html#symmetric-mape-smape",
    "href": "losses.pytorch.html#symmetric-mape-smape",
    "title": "PyTorch Losses",
    "section": "Symmetric MAPE (sMAPE)",
    "text": "Symmetric MAPE (sMAPE)\n\nsource\n\nSMAPE.__init__\n\n SMAPE.__init__ (horizon_weight=None)\n\nSymmetric Mean Absolute Percentage Error\nCalculates Symmetric Mean Absolute Percentage Error between y and y_hat. SMAPE measures the relative prediction accuracy of a forecasting method by calculating the relative deviation of the prediction and the observed value scaled by the sum of the absolute values for the prediction and observed value at a given time, then averages these devations over the length of the series. This allows the SMAPE to have bounds between 0% and 200% which is desireble compared to normal MAPE that may be undetermined when the target is zero.\n\\[ \\mathrm{sMAPE}_{2}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\frac{|y_{\\tau}-\\hat{y}_{\\tau}|}{|y_{\\tau}|+|\\hat{y}_{\\tau}|} \\]\nParameters: horizon_weight: Tensor of size h, weight for each timestamp of the forecasting window. \nReferences: Makridakis S., “Accuracy measures: theoretical and practical concerns”.\n\nsource\n\n\nSMAPE.__call__\n\n SMAPE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n                 mask:Optional[torch.Tensor]=None)\n\nParameters: y: tensor, Actual values. y_hat: tensor, Predicted values. mask: tensor, Specifies date stamps per serie to consider in loss.\nReturns: smape: tensor (single value)."
  },
  {
    "objectID": "losses.pytorch.html#mean-absolute-scaled-error-mase",
    "href": "losses.pytorch.html#mean-absolute-scaled-error-mase",
    "title": "PyTorch Losses",
    "section": "Mean Absolute Scaled Error (MASE)",
    "text": "Mean Absolute Scaled Error (MASE)\n\nsource\n\nMASE.__init__\n\n MASE.__init__ (seasonality:int, horizon_weight=None)\n\nMean Absolute Scaled Error Calculates the Mean Absolute Scaled Error between y and y_hat. MASE measures the relative prediction accuracy of a forecasting method by comparinng the mean absolute errors of the prediction and the observed value against the mean absolute errors of the seasonal naive model. The MASE partially composed the Overall Weighted Average (OWA), used in the M4 Competition.\n\\[ \\mathrm{MASE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}, \\mathbf{\\hat{y}}^{season}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\frac{|y_{\\tau}-\\hat{y}_{\\tau}|}{\\mathrm{MAE}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}^{season}_{\\tau})} \\]\nParameters: seasonality: int. Main frequency of the time series; Hourly 24, Daily 7, Weekly 52, Monthly 12, Quarterly 4, Yearly 1. horizon_weight: Tensor of size h, weight for each timestamp of the forecasting window. \nReferences: Rob J. Hyndman, & Koehler, A. B. “Another look at measures of forecast accuracy”. Spyros Makridakis, Evangelos Spiliotis, Vassilios Assimakopoulos, “The M4 Competition: 100,000 time series and 61 forecasting methods”.\n\nsource\n\n\nMASE.__call__\n\n MASE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n                y_insample:torch.Tensor, mask:Optional[torch.Tensor]=None)\n\nParameters: y: tensor (batch_size, output_size), Actual values. y_hat: tensor (batch_size, output_size)), Predicted values. y_insample: tensor (batch_size, input_size), Actual insample Seasonal Naive predictions. mask: tensor, Specifies date stamps per serie to consider in loss.\nReturns: mase: tensor (single value)."
  },
  {
    "objectID": "losses.pytorch.html#relative-mean-squared-error-relmse",
    "href": "losses.pytorch.html#relative-mean-squared-error-relmse",
    "title": "PyTorch Losses",
    "section": "Relative Mean Squared Error (relMSE)",
    "text": "Relative Mean Squared Error (relMSE)\n\nsource\n\nrelMSE.__init__\n\n relMSE.__init__ (y_train, horizon_weight=None)\n\nRelative Mean Squared Error Computes Relative Mean Squared Error (relMSE), as proposed by Hyndman & Koehler (2006) as an alternative to percentage errors, to avoid measure unstability. \\[ \\mathrm{relMSE}(\\mathbf{y}, \\mathbf{\\hat{y}}, \\mathbf{\\hat{y}}^{naive1}) =\n\\frac{\\mathrm{MSE}(\\mathbf{y}, \\mathbf{\\hat{y}})}{\\mathrm{MSE}(\\mathbf{y}, \\mathbf{\\hat{y}}^{naive1})} \\]\nParameters: y_train: numpy array, Training values. horizon_weight: Tensor of size h, weight for each timestamp of the forecasting window. \nReferences: - Hyndman, R. J and Koehler, A. B. (2006). “Another look at measures of forecast accuracy”, International Journal of Forecasting, Volume 22, Issue 4. - Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker. “Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures. Submitted to the International Journal Forecasting, Working paper available at arxiv.\n\nsource\n\n\nrelMSE.__call__\n\n relMSE.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n                  mask:Optional[torch.Tensor]=None)\n\nParameters: y: tensor (batch_size, output_size), Actual values. y_hat: tensor (batch_size, output_size)), Predicted values. y_insample: tensor (batch_size, input_size), Actual insample Seasonal Naive predictions. mask: tensor, Specifies date stamps per serie to consider in loss.\nReturns: relMSE: tensor (single value)."
  },
  {
    "objectID": "losses.pytorch.html#quantile-loss",
    "href": "losses.pytorch.html#quantile-loss",
    "title": "PyTorch Losses",
    "section": "Quantile Loss",
    "text": "Quantile Loss\n\nsource\n\nQuantileLoss.__init__\n\n QuantileLoss.__init__ (q, horizon_weight=None)\n\nQuantile Loss\nComputes the quantile loss between y and y_hat. QL measures the deviation of a quantile forecast. By weighting the absolute deviation in a non symmetric way, the loss pays more attention to under or over estimation. A common value for q is 0.5 for the deviation from the median (Pinball loss).\n\\[ \\mathrm{QL}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}^{(q)}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\Big( (1-q)\\,( \\hat{y}^{(q)}_{\\tau} - y_{\\tau} )_{+} + q\\,( y_{\\tau} - \\hat{y}^{(q)}_{\\tau} )_{+} \\Big) \\]\nParameters: q: float, between 0 and 1. The slope of the quantile loss, in the context of quantile regression, the q determines the conditional quantile level. horizon_weight: Tensor of size h, weight for each timestamp of the forecasting window. \nReferences: Roger Koenker and Gilbert Bassett, Jr., “Regression Quantiles”.\n\nsource\n\n\nQuantileLoss.__call__\n\n QuantileLoss.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n                        mask:Optional[torch.Tensor]=None)\n\nParameters: y: tensor, Actual values. y_hat: tensor, Predicted values. mask: tensor, Specifies datapoints to consider in loss.\nReturns: quantile_loss: tensor (single value)."
  },
  {
    "objectID": "losses.pytorch.html#multi-quantile-loss-mqloss",
    "href": "losses.pytorch.html#multi-quantile-loss-mqloss",
    "title": "PyTorch Losses",
    "section": "Multi Quantile Loss (MQLoss)",
    "text": "Multi Quantile Loss (MQLoss)\n\nsource\n\nMQLoss.__init__\n\n MQLoss.__init__ (level=[80, 90], quantiles=None, horizon_weight=None)\n\nMulti-Quantile loss\nCalculates the Multi-Quantile loss (MQL) between y and y_hat. MQL calculates the average multi-quantile Loss for a given set of quantiles, based on the absolute difference between predicted quantiles and observed values.\n\\[ \\mathrm{MQL}(\\mathbf{y}_{\\tau},[\\mathbf{\\hat{y}}^{(q_{1})}_{\\tau}, ... ,\\hat{y}^{(q_{n})}_{\\tau}]) = \\frac{1}{n} \\sum_{q_{i}} \\mathrm{QL}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}^{(q_{i})}_{\\tau}) \\]\nThe limit behavior of MQL allows to measure the accuracy of a full predictive distribution \\(\\mathbf{\\hat{F}}_{\\tau}\\) with the continuous ranked probability score (CRPS). This can be achieved through a numerical integration technique, that discretizes the quantiles and treats the CRPS integral with a left Riemann approximation, averaging over uniformly distanced quantiles.\n\\[ \\mathrm{CRPS}(y_{\\tau}, \\mathbf{\\hat{F}}_{\\tau}) = \\int^{1}_{0} \\mathrm{QL}(y_{\\tau}, \\hat{y}^{(q)}_{\\tau}) dq \\]\nParameters: level: int list [0,100]. Probability levels for prediction intervals (Defaults median). quantiles: float list [0., 1.]. Alternative to level, quantiles to estimate from y distribution. horizon_weight: Tensor of size h, weight for each timestamp of the forecasting window. \nReferences: Roger Koenker and Gilbert Bassett, Jr., “Regression Quantiles”. James E. Matheson and Robert L. Winkler, “Scoring Rules for Continuous Probability Distributions”.\n\nsource\n\n\nMQLoss.__call__\n\n MQLoss.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n                  mask:Optional[torch.Tensor]=None)\n\nParameters: y: tensor, Actual values. y_hat: tensor, Predicted values. mask: tensor, Specifies date stamps per serie to consider in loss.\nReturns: mqloss: tensor (single value)."
  },
  {
    "objectID": "losses.pytorch.html#distributionloss",
    "href": "losses.pytorch.html#distributionloss",
    "title": "PyTorch Losses",
    "section": "DistributionLoss",
    "text": "DistributionLoss\n\nsource\n\nDistributionLoss.__init__\n\n DistributionLoss.__init__ (distribution, level=[80, 90], quantiles=None,\n                            num_samples=1000, return_params=False,\n                            **distribution_kwargs)\n\nDistributionLoss\nThis PyTorch module wraps the torch.distribution classes allowing it to interact with NeuralForecast models modularly. It shares the negative log-likelihood as the optimization objective and a sample method to generate empirically the quantiles defined by the level list.\nAdditionally, it implements a distribution transformation that factorizes the scale-dependent likelihood parameters into a base scale and a multiplier efficiently learnable within the network’s non-linearities operating ranges.\nAvailable distributions: - Poisson - Normal - StudentT - NegativeBinomial - Tweedie - Bernoulli (Temporal Classifiers)\nParameters: distribution: str, identifier of a torch.distributions.Distribution class. level: float list [0,100], confidence levels for prediction intervals. quantiles: float list [0,1], alternative to level list, target quantiles. num_samples: int=500, number of samples for the empirical quantiles. return_params: bool=False, wether or not return the Distribution parameters.\nReferences: - PyTorch Probability Distributions Package: StudentT. - David Salinas, Valentin Flunkert, Jan Gasthaus, Tim Januschowski (2020). “DeepAR: Probabilistic forecasting with autoregressive recurrent networks”. International Journal of Forecasting.\n\nsource\n\n\nDistributionLoss.sample\n\n DistributionLoss.sample (distr_args:torch.Tensor,\n                          num_samples:Optional[int]=None)\n\nConstruct the empirical quantiles from the estimated Distribution, sampling from it num_samples independently.\nParameters distr_args: Constructor arguments for the underlying Distribution type. loc: Optional tensor, of the same shape as the batch_shape + event_shape of the resulting distribution. scale: Optional tensor, of the same shape as the batch_shape+event_shape of the resulting distribution. num_samples: int=500, overwrite number of samples for the empirical quantiles.\nReturns samples: tensor, shape [B,H,num_samples]. quantiles: tensor, empirical quantiles defined by levels.\n\nsource\n\n\nDistributionLoss.__call__\n\n DistributionLoss.__call__ (y:torch.Tensor, distr_args:torch.Tensor,\n                            mask:Optional[torch.Tensor]=None)\n\nComputes the negative log-likelihood objective function. To estimate the following predictive distribution:\n\\[\\mathrm{P}(\\mathbf{y}_{\\tau}\\,|\\,\\theta) \\quad \\mathrm{and} \\quad -\\log(\\mathrm{P}(\\mathbf{y}_{\\tau}\\,|\\,\\theta))\\]\nwhere \\(\\theta\\) represents the distributions parameters. It aditionally summarizes the objective signal using a weighted average using the mask tensor.\nParameters y: tensor, Actual values. distr_args: Constructor arguments for the underlying Distribution type. loc: Optional tensor, of the same shape as the batch_shape + event_shape of the resulting distribution. scale: Optional tensor, of the same shape as the batch_shape+event_shape of the resulting distribution. mask: tensor, Specifies date stamps per serie to consider in loss.\nReturns loss: scalar, weighted loss function against which backpropagation will be performed."
  },
  {
    "objectID": "losses.pytorch.html#poisson-mixture-mesh-pmm",
    "href": "losses.pytorch.html#poisson-mixture-mesh-pmm",
    "title": "PyTorch Losses",
    "section": "Poisson Mixture Mesh (PMM)",
    "text": "Poisson Mixture Mesh (PMM)\n\nsource\n\nPMM.__init__\n\n PMM.__init__ (n_components=10, level=[80, 90], quantiles=None,\n               num_samples=1000, return_params=False,\n               batch_correlation=False, horizon_correlation=False)\n\nPoisson Mixture Mesh\nThis Poisson Mixture statistical model assumes independence across groups of data \\(\\mathcal{G}=\\{[g_{i}]\\}\\), and estimates relationships within the group.\n\\[ \\mathrm{P}\\left(\\mathbf{y}_{[b][t+1:t+H]}\\right) =\n\\prod_{ [g_{i}] \\in \\mathcal{G}} \\mathrm{P} \\left(\\mathbf{y}_{[g_{i}][\\tau]} \\right) =\n\\prod_{\\beta\\in[g_{i}]}\n\\left(\\sum_{k=1}^{K} w_k \\prod_{(\\beta,\\tau) \\in [g_i][t+1:t+H]} \\mathrm{Poisson}(y_{\\beta,\\tau}, \\hat{\\lambda}_{\\beta,\\tau,k}) \\right)\\]\nParameters: n_components: int=10, the number of mixture components. level: float list [0,100], confidence levels for prediction intervals. quantiles: float list [0,1], alternative to level list, target quantiles. return_params: bool=False, wether or not return the Distribution parameters. batch_correlation: bool=False, wether or not model batch correlations. horizon_correlation: bool=False, wether or not model horizon correlations.\nReferences: Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker. Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures. Submitted to the International Journal Forecasting, Working paper available at arxiv.\n\nsource\n\n\nPMM.sample\n\n PMM.sample (distr_args, num_samples=None)\n\nConstruct the empirical quantiles from the estimated Distribution, sampling from it num_samples independently.\nParameters distr_args: Constructor arguments for the underlying Distribution type. loc: Optional tensor, of the same shape as the batch_shape + event_shape of the resulting distribution. scale: Optional tensor, of the same shape as the batch_shape+event_shape of the resulting distribution. num_samples: int=500, overwrites number of samples for the empirical quantiles.\nReturns samples: tensor, shape [B,H,num_samples]. quantiles: tensor, empirical quantiles defined by levels.\n\nsource\n\n\nPMM.__call__\n\n PMM.__call__ (y:torch.Tensor, distr_args:Tuple[torch.Tensor],\n               mask:Optional[torch.Tensor]=None)\n\nCall self as a function."
  },
  {
    "objectID": "losses.pytorch.html#gaussian-mixture-mesh-gmm",
    "href": "losses.pytorch.html#gaussian-mixture-mesh-gmm",
    "title": "PyTorch Losses",
    "section": "Gaussian Mixture Mesh (GMM)",
    "text": "Gaussian Mixture Mesh (GMM)\n\nsource\n\nGMM.__init__\n\n GMM.__init__ (n_components=1, level=[80, 90], quantiles=None,\n               num_samples=1000, return_params=False,\n               batch_correlation=False, horizon_correlation=False)\n\nGaussian Mixture Mesh\nThis Gaussian Mixture statistical model assumes independence across groups of data \\(\\mathcal{G}=\\{[g_{i}]\\}\\), and estimates relationships within the group.\n\\[ \\mathrm{P}\\left(\\mathbf{y}_{[b][t+1:t+H]}\\right) =\n\\prod_{ [g_{i}] \\in \\mathcal{G}} \\mathrm{P}\\left(\\mathbf{y}_{[g_{i}][\\tau]}\\right)=\n\\prod_{\\beta\\in[g_{i}]}\n\\left(\\sum_{k=1}^{K} w_k \\prod_{(\\beta,\\tau) \\in [g_i][t+1:t+H]}\n\\mathrm{Gaussian}(y_{\\beta,\\tau}, \\hat{\\mu}_{\\beta,\\tau,k}, \\sigma_{\\beta,\\tau,k})\\right)\\]\nParameters: n_components: int=10, the number of mixture components. level: float list [0,100], confidence levels for prediction intervals. quantiles: float list [0,1], alternative to level list, target quantiles. return_params: bool=False, wether or not return the Distribution parameters. batch_correlation: bool=False, wether or not model batch correlations. horizon_correlation: bool=False, wether or not model horizon correlations.\nReferences: Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker. Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures. Submitted to the International Journal Forecasting, Working paper available at arxiv.\n\nsource\n\n\nGMM.sample\n\n GMM.sample (distr_args, num_samples=None)\n\nConstruct the empirical quantiles from the estimated Distribution, sampling from it num_samples independently.\nParameters distr_args: Constructor arguments for the underlying Distribution type. loc: Optional tensor, of the same shape as the batch_shape + event_shape of the resulting distribution. scale: Optional tensor, of the same shape as the batch_shape+event_shape of the resulting distribution. num_samples: int=500, number of samples for the empirical quantiles.\nReturns samples: tensor, shape [B,H,num_samples]. quantiles: tensor, empirical quantiles defined by levels.\n\nsource\n\n\nGMM.__call__\n\n GMM.__call__ (y:torch.Tensor,\n               distr_args:Tuple[torch.Tensor,torch.Tensor],\n               mask:Optional[torch.Tensor]=None)\n\nCall self as a function."
  },
  {
    "objectID": "losses.pytorch.html#negative-binomial-mixture-mesh-nbmm",
    "href": "losses.pytorch.html#negative-binomial-mixture-mesh-nbmm",
    "title": "PyTorch Losses",
    "section": "Negative Binomial Mixture Mesh (NBMM)",
    "text": "Negative Binomial Mixture Mesh (NBMM)\n\nsource\n\nNBMM.__init__\n\n NBMM.__init__ (n_components=1, level=[80, 90], quantiles=None,\n                num_samples=1000, return_params=False)\n\nNegative Binomial Mixture Mesh\nThis N. Binomial Mixture statistical model assumes independence across groups of data \\(\\mathcal{G}=\\{[g_{i}]\\}\\), and estimates relationships within the group.\n\\[ \\mathrm{P}\\left(\\mathbf{y}_{[b][t+1:t+H]}\\right) =\n\\prod_{ [g_{i}] \\in \\mathcal{G}} \\mathrm{P}\\left(\\mathbf{y}_{[g_{i}][\\tau]}\\right)=\n\\prod_{\\beta\\in[g_{i}]}\n\\left(\\sum_{k=1}^{K} w_k \\prod_{(\\beta,\\tau) \\in [g_i][t+1:t+H]}\n\\mathrm{NBinomial}(y_{\\beta,\\tau}, \\hat{r}_{\\beta,\\tau,k}, \\hat{p}_{\\beta,\\tau,k})\\right)\\]\nParameters: n_components: int=10, the number of mixture components. level: float list [0,100], confidence levels for prediction intervals. quantiles: float list [0,1], alternative to level list, target quantiles. return_params: bool=False, wether or not return the Distribution parameters.\nReferences: Kin G. Olivares, O. Nganba Meetei, Ruijun Ma, Rohan Reddy, Mengfei Cao, Lee Dicker. Probabilistic Hierarchical Forecasting with Deep Poisson Mixtures. Submitted to the International Journal Forecasting, Working paper available at arxiv.\n\nsource\n\n\nNBMM.sample\n\n NBMM.sample (distr_args, num_samples=None)\n\nConstruct the empirical quantiles from the estimated Distribution, sampling from it num_samples independently.\nParameters distr_args: Constructor arguments for the underlying Distribution type. loc: Optional tensor, of the same shape as the batch_shape + event_shape of the resulting distribution. scale: Optional tensor, of the same shape as the batch_shape+event_shape of the resulting distribution. num_samples: int=500, number of samples for the empirical quantiles.\nReturns samples: tensor, shape [B,H,num_samples]. quantiles: tensor, empirical quantiles defined by levels.\n\nsource\n\n\nNBMM.__call__\n\n NBMM.__call__ (y:torch.Tensor,\n                distr_args:Tuple[torch.Tensor,torch.Tensor],\n                mask:Optional[torch.Tensor]=None)\n\nCall self as a function."
  },
  {
    "objectID": "losses.pytorch.html#huber-loss",
    "href": "losses.pytorch.html#huber-loss",
    "title": "PyTorch Losses",
    "section": "Huber Loss",
    "text": "Huber Loss\n\nsource\n\nHuberLoss.__init__\n\n HuberLoss.__init__ (delta:float=1.0, horizon_weight=None)\n\nHuber Loss\nThe Huber loss, employed in robust regression, is a loss function that exhibits reduced sensitivity to outliers in data when compared to the squared error loss. This function is also refered as SmoothL1.\nThe Huber loss function is quadratic for small errors and linear for large errors, with equal values and slopes of the different sections at the two points where \\((y_{\\tau}-\\hat{y}_{\\tau})^{2}\\)=\\(|y_{\\tau}-\\hat{y}_{\\tau}|\\).\n\\[ L_{\\delta}(y_{\\tau},\\; \\hat{y}_{\\tau})\n=\\begin{cases}{\\frac{1}{2}}(y_{\\tau}-\\hat{y}_{\\tau})^{2}\\;{\\text{for }}|y_{\\tau}-\\hat{y}_{\\tau}|\\leq \\delta \\\\\n\\delta \\ \\cdot \\left(|y_{\\tau}-\\hat{y}_{\\tau}|-{\\frac {1}{2}}\\delta \\right),\\;{\\text{otherwise.}}\\end{cases}\\]\nwhere \\(\\delta\\) is a threshold parameter that determines the point at which the loss transitions from quadratic to linear, and can be tuned to control the trade-off between robustness and accuracy in the predictions.\nParameters: delta: float=1.0, Specifies the threshold at which to change between delta-scaled L1 and L2 loss. horizon_weight: Tensor of size h, weight for each timestamp of the forecasting window. \nReferences: Huber Peter, J (1964). “Robust Estimation of a Location Parameter”. Annals of Statistics\n\nsource\n\n\nHuberLoss.__call__\n\n HuberLoss.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n                     mask:Optional[torch.Tensor]=None)\n\nParameters: y: tensor, Actual values. y_hat: tensor, Predicted values. mask: tensor, Specifies date stamps per serie to consider in loss.\nReturns: huber_loss: tensor (single value)."
  },
  {
    "objectID": "losses.pytorch.html#tukey-loss",
    "href": "losses.pytorch.html#tukey-loss",
    "title": "PyTorch Losses",
    "section": "Tukey Loss",
    "text": "Tukey Loss\n\nsource\n\nTukeyLoss.__init__\n\n TukeyLoss.__init__ (c:float=4.685, normalize:bool=True)\n\nTukey Loss\nThe Tukey loss function, also known as Tukey’s biweight function, is a robust statistical loss function used in robust statistics. Tukey’s loss exhibits quadratic behavior near the origin, like the Huber loss; however, it is even more robust to outliers as the loss for large residuals remains constant instead of scaling linearly.\nThe parameter \\(c\\) in Tukey’s loss determines the ‘’saturation’’ point of the function: Higher values of \\(c\\) enhance sensitivity, while lower values increase resistance to outliers.\n\\[ L_{c}(y_{\\tau},\\; \\hat{y}_{\\tau})\n=\\begin{cases}{\n\\frac{c^{2}}{6}} \\left[1-(\\frac{y_{\\tau}-\\hat{y}_{\\tau}}{c})^{2} \\right]^{3}    \\;\\text{for } |y_{\\tau}-\\hat{y}_{\\tau}|\\leq c \\\\\n\\frac{c^{2}}{6} \\qquad \\text{otherwise.}  \\end{cases}\\]\nPlease note that the Tukey loss function assumes the data to be stationary or normalized beforehand. If the error values are excessively large, the algorithm may need help to converge during optimization. It is advisable to employ small learning rates.\nParameters: c: float=4.685, Specifies the Tukey loss’ threshold on which residuals are no longer considered. normalize: bool=True, Wether normalization is performed within Tukey loss’ computation.\nReferences: Beaton, A. E., and Tukey, J. W. (1974). “The Fitting of Power Series, Meaning Polynomials, Illustrated on Band-Spectroscopic Data.”\n\nsource\n\n\nTukeyLoss.__call__\n\n TukeyLoss.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n                     mask:Optional[torch.Tensor]=None)\n\nParameters: y: tensor, Actual values. y_hat: tensor, Predicted values. mask: tensor, Specifies date stamps per serie to consider in loss.\nReturns: tukey_loss: tensor (single value)."
  },
  {
    "objectID": "losses.pytorch.html#huberized-quantile-loss",
    "href": "losses.pytorch.html#huberized-quantile-loss",
    "title": "PyTorch Losses",
    "section": "Huberized Quantile Loss",
    "text": "Huberized Quantile Loss\n\nsource\n\nHuberQLoss.__init__\n\n HuberQLoss.__init__ (q, delta:float=1.0, horizon_weight=None)\n\nHuberized Quantile Loss\nThe Huberized quantile loss is a modified version of the quantile loss function that combines the advantages of the quantile loss and the Huber loss. It is commonly used in regression tasks, especially when dealing with data that contains outliers or heavy tails.\nThe Huberized quantile loss between y and y_hat measure the Huber Loss in a non-symmetric way. The loss pays more attention to under/over-estimation depending on the quantile parameter \\(q\\); and controls the trade-off between robustness and accuracy in the predictions with the parameter \\(delta\\).\n\\[ \\mathrm{HuberQL}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}^{(q)}_{\\tau}) =\n(1-q)\\, L_{\\delta}(y_{\\tau},\\; \\hat{y}^{(q)}_{\\tau}) \\mathbb{1}\\{ \\hat{y}^{(q)}_{\\tau} \\geq y_{\\tau} \\} +\nq\\, L_{\\delta}(y_{\\tau},\\; \\hat{y}^{(q)}_{\\tau}) \\mathbb{1}\\{ \\hat{y}^{(q)}_{\\tau} &lt; y_{\\tau} \\} \\]\nParameters: delta: float=1.0, Specifies the threshold at which to change between delta-scaled L1 and L2 loss. q: float, between 0 and 1. The slope of the quantile loss, in the context of quantile regression, the q determines the conditional quantile level. horizon_weight: Tensor of size h, weight for each timestamp of the forecasting window. \nReferences: Huber Peter, J (1964). “Robust Estimation of a Location Parameter”. Annals of Statistics Roger Koenker and Gilbert Bassett, Jr., “Regression Quantiles”.\n\nsource\n\n\nHuberQLoss.__call__\n\n HuberQLoss.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n                      mask:Optional[torch.Tensor]=None)\n\nParameters: y: tensor, Actual values. y_hat: tensor, Predicted values. mask: tensor, Specifies datapoints to consider in loss.\nReturns: huber_qloss: tensor (single value)."
  },
  {
    "objectID": "losses.pytorch.html#huberized-mqloss",
    "href": "losses.pytorch.html#huberized-mqloss",
    "title": "PyTorch Losses",
    "section": "Huberized MQLoss",
    "text": "Huberized MQLoss\n\nsource\n\nHuberMQLoss.__init__\n\n HuberMQLoss.__init__ (level=[80, 90], quantiles=None, delta:float=1.0,\n                       horizon_weight=None)\n\nHuberized Multi-Quantile loss\nThe Huberized Multi-Quantile loss (HuberMQL) is a modified version of the multi-quantile loss function that combines the advantages of the quantile loss and the Huber loss. HuberMQL is commonly used in regression tasks, especially when dealing with data that contains outliers or heavy tails. The loss function pays more attention to under/over-estimation depending on the quantile list \\([q_{1},q_{2},\\dots]\\) parameter. It controls the trade-off between robustness and prediction accuracy with the parameter \\(\\delta\\).\n\\[ \\mathrm{HuberMQL}_{\\delta}(\\mathbf{y}_{\\tau},[\\mathbf{\\hat{y}}^{(q_{1})}_{\\tau}, ... ,\\hat{y}^{(q_{n})}_{\\tau}]) =\n\\frac{1}{n} \\sum_{q_{i}} \\mathrm{HuberQL}_{\\delta}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}^{(q_{i})}_{\\tau}) \\]\nParameters: level: int list [0,100]. Probability levels for prediction intervals (Defaults median). quantiles: float list [0., 1.]. Alternative to level, quantiles to estimate from y distribution. delta: float=1.0, Specifies the threshold at which to change between delta-scaled L1 and L2 loss.\nhorizon_weight: Tensor of size h, weight for each timestamp of the forecasting window. \nReferences: Huber Peter, J (1964). “Robust Estimation of a Location Parameter”. Annals of Statistics Roger Koenker and Gilbert Bassett, Jr., “Regression Quantiles”.\n\nsource\n\n\nHuberMQLoss.__call__\n\n HuberMQLoss.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n                       mask:Optional[torch.Tensor]=None)\n\nParameters: y: tensor, Actual values. y_hat: tensor, Predicted values. mask: tensor, Specifies date stamps per serie to consider in loss.\nReturns: hmqloss: tensor (single value)."
  },
  {
    "objectID": "losses.pytorch.html#accuracy",
    "href": "losses.pytorch.html#accuracy",
    "title": "PyTorch Losses",
    "section": "Accuracy",
    "text": "Accuracy\n\nsource\n\nAccuracy.__init__\n\n Accuracy.__init__ ()\n\nAccuracy\nComputes the accuracy between categorical y and y_hat. This evaluation metric is only meant for evalution, as it is not differentiable.\n\\[ \\mathrm{Accuracy}(\\mathbf{y}_{\\tau}, \\mathbf{\\hat{y}}_{\\tau}) = \\frac{1}{H} \\sum^{t+H}_{\\tau=t+1} \\mathrm{1}\\{\\mathbf{y}_{\\tau}==\\mathbf{\\hat{y}}_{\\tau}\\} \\]\n\nsource\n\n\nAccuracy.__call__\n\n Accuracy.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n                    mask:Optional[torch.Tensor]=None)\n\nParameters: y: tensor, Actual values. y_hat: tensor, Predicted values. mask: tensor, Specifies date stamps per serie to consider in loss.\nReturns: accuracy: tensor (single value)."
  },
  {
    "objectID": "losses.pytorch.html#scaled-continuous-ranked-probability-score-scrps",
    "href": "losses.pytorch.html#scaled-continuous-ranked-probability-score-scrps",
    "title": "PyTorch Losses",
    "section": "Scaled Continuous Ranked Probability Score (sCRPS)",
    "text": "Scaled Continuous Ranked Probability Score (sCRPS)\n\nsource\n\nsCRPS.__init__\n\n sCRPS.__init__ (level=[80, 90], quantiles=None)\n\nScaled Continues Ranked Probability Score\nCalculates a scaled variation of the CRPS, as proposed by Rangapuram (2021), to measure the accuracy of predicted quantiles y_hat compared to the observation y.\nThis metric averages percentual weighted absolute deviations as defined by the quantile losses.\n\\[ \\mathrm{sCRPS}(\\mathbf{\\hat{y}}^{(q)}_{\\tau}, \\mathbf{y}_{\\tau}) = \\frac{2}{N} \\sum_{i}\n\\int^{1}_{0}\n\\frac{\\mathrm{QL}(\\mathbf{\\hat{y}}^{(q}_{\\tau} y_{i,\\tau})_{q}}{\\sum_{i} | y_{i,\\tau} |} dq \\]\nwhere \\(\\mathbf{\\hat{y}}^{(q}_{\\tau}\\) is the estimated quantile, and \\(y_{i,\\tau}\\) are the target variable realizations.\nParameters: level: int list [0,100]. Probability levels for prediction intervals (Defaults median). quantiles: float list [0., 1.]. Alternative to level, quantiles to estimate from y distribution.\nReferences: - Gneiting, Tilmann. (2011). “Quantiles as optimal point forecasts”. International Journal of Forecasting. - Spyros Makridakis, Evangelos Spiliotis, Vassilios Assimakopoulos, Zhi Chen, Anil Gaba, Ilia Tsetlin, Robert L. Winkler. (2022). “The M5 uncertainty competition: Results, findings and conclusions”. International Journal of Forecasting. - Syama Sundar Rangapuram, Lucien D Werner, Konstantinos Benidis, Pedro Mercado, Jan Gasthaus, Tim Januschowski. (2021). “End-to-End Learning of Coherent Probabilistic Forecasts for Hierarchical Time Series”. Proceedings of the 38th International Conference on Machine Learning (ICML).\n\nsource\n\n\nsCRPS.__call__\n\n sCRPS.__call__ (y:torch.Tensor, y_hat:torch.Tensor,\n                 mask:Optional[torch.Tensor]=None)\n\nParameters: y: tensor, Actual values. y_hat: tensor, Predicted values. mask: tensor, Specifies date stamps per series to consider in loss.\nReturns: scrps: tensor (single value)."
  },
  {
    "objectID": "common.base_windows.html",
    "href": "common.base_windows.html",
    "title": "BaseWindows",
    "section": "",
    "text": "BaseWindows\n\n BaseWindows (h, input_size, loss, valid_loss, learning_rate, max_steps,\n              val_check_steps, batch_size, valid_batch_size,\n              windows_batch_size, inference_windows_batch_size,\n              start_padding_enabled, step_size=1, num_lr_decays=0,\n              early_stop_patience_steps=-1, scaler_type='identity',\n              futr_exog_list=None, hist_exog_list=None,\n              stat_exog_list=None, exclude_insample_y=False,\n              num_workers_loader=0, drop_last_loader=False, random_seed=1,\n              alias=None, **trainer_kwargs)\n\nBase Windows\nBase class for all windows-based models. The forecasts are produced separately for each window, which are randomly sampled during training.\nThis class implements the basic functionality for all windows-based models, including: - PyTorch Lightning’s methods training_step, validation_step, predict_step. - fit and predict methods used by NeuralForecast.core class. - sampling and wrangling methods to generate windows.\n\n\n\nBaseWindows.fit\n\n BaseWindows.fit (dataset, val_size=0, test_size=0, random_seed=None)\n\nFit.\nThe fit method, optimizes the neural network’s weights using the initialization parameters (learning_rate, windows_batch_size, …) and the loss function as defined during the initialization. Within fit we use a PyTorch Lightning Trainer that inherits the initialization’s self.trainer_kwargs, to customize its inputs, see PL’s trainer arguments.\nThe method is designed to be compatible with SKLearn-like classes and in particular to be compatible with the StatsForecast library.\nBy default the model is not saving training checkpoints to protect disk memory, to get them change enable_checkpointing=True in __init__.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset, see documentation. val_size: int, validation size for temporal cross-validation. random_seed: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__’s. test_size: int, test size for temporal cross-validation.\n\n\n\nBaseWindows.predict\n\n BaseWindows.predict (dataset, test_size=None, step_size=1,\n                      random_seed=None, **data_module_kwargs)\n\nPredict.\nNeural network prediction with PL’s Trainer execution of predict_step.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset, see documentation. test_size: int=None, test size for temporal cross-validation. step_size: int=1, Step size between each window. random_seed: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__’s. **data_module_kwargs: PL’s TimeSeriesDataModule args, see documentation.\n\n\n\nBaseWindows.decompose\n\n BaseWindows.decompose (dataset, step_size=1, random_seed=None,\n                        **data_module_kwargs)\n\nDecompose Predictions.\nDecompose the predictions through the network’s layers. Available methods are ESRNN, NHITS, NBEATS, and NBEATSx.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset, see documentation here. step_size: int=1, step size between each window of temporal data. **data_module_kwargs: PL’s TimeSeriesDataModule args, see documentation.\n\n\n\n\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.fedformer.html",
    "href": "models.fedformer.html",
    "title": "FEDformer",
    "section": "",
    "text": "The FEDformer model tackles the challenge of finding reliable dependencies on intricate temporal patterns of long-horizon forecasting.\nThe architecture has the following distinctive features: - In-built progressive decomposition in trend and seasonal components based on a moving average filter. - Frequency Enhanced Block and Frequency Enhanced Attention to perform attention in the sparse representation on basis such as Fourier transform. - Classic encoder-decoder proposed by Vaswani et al. (2017) with a multi-head attention mechanism.\nThe FEDformer model utilizes a three-component approach to define its embedding: - It employs encoded autoregressive features obtained from a convolution network. - Absolute positional embeddings obtained from calendar features are utilized.\nReferences - Zhou, Tian, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, and Rong Jin.. “FEDformer: Frequency enhanced decomposed transformer for long-term series forecasting”\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.fedformer.html#auxiliary-functions",
    "href": "models.fedformer.html#auxiliary-functions",
    "title": "FEDformer",
    "section": "1. Auxiliary functions",
    "text": "1. Auxiliary functions\n\nsource\n\nAutoCorrelationLayer\n\n AutoCorrelationLayer (correlation, hidden_size, n_head, d_keys=None,\n                       d_values=None)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nsource\n\n\nLayerNorm\n\n LayerNorm (channels)\n\nSpecial designed layernorm for the seasonal part\n\nsource\n\n\nSeriesDecomp\n\n SeriesDecomp (kernel_size)\n\nSeries decomposition block\n\nsource\n\n\nMovingAvg\n\n MovingAvg (kernel_size, stride)\n\nMoving average block to highlight the trend of time series\n\nsource\n\n\nDecoder\n\n Decoder (layers, norm_layer=None, projection=None)\n\nFEDformer decoder\n\nsource\n\n\nDecoderLayer\n\n DecoderLayer (self_attention, cross_attention, hidden_size, c_out,\n               conv_hidden_size=None, MovingAvg=25, dropout=0.1,\n               activation='relu')\n\nFEDformer decoder layer with the progressive decomposition architecture\n\nsource\n\n\nEncoder\n\n Encoder (attn_layers, conv_layers=None, norm_layer=None)\n\nFEDformer encoder\n\nsource\n\n\nEncoderLayer\n\n EncoderLayer (attention, hidden_size, conv_hidden_size=None,\n               MovingAvg=25, dropout=0.1, activation='relu')\n\nFEDformer encoder layer with the progressive decomposition architecture\n\nsource\n\n\nFourierCrossAttention\n\n FourierCrossAttention (in_channels, out_channels, seq_len_q, seq_len_kv,\n                        modes=64, mode_select_method='random',\n                        activation='tanh', policy=0)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nsource\n\n\nFourierBlock\n\n FourierBlock (in_channels, out_channels, seq_len, modes=0,\n               mode_select_method='random')\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nsource\n\n\nget_frequency_modes\n\n get_frequency_modes (seq_len, modes=64, mode_select_method='random')\n\nGet modes on frequency domain: ‘random’ for sampling randomly ‘else’ for sampling the lowest modes;"
  },
  {
    "objectID": "models.fedformer.html#model",
    "href": "models.fedformer.html#model",
    "title": "FEDformer",
    "section": "2. Model",
    "text": "2. Model\n\nsource\n\nFEDformer\n\n FEDformer (h:int, input_size:int, stat_exog_list=None,\n            hist_exog_list=None, futr_exog_list=None,\n            decoder_input_size_multiplier:float=0.5,\n            version:str='Fourier', modes:int=64, mode_select:str='random',\n            hidden_size:int=128, dropout:float=0.05, n_head:int=8,\n            conv_hidden_size:int=32, activation:str='gelu',\n            encoder_layers:int=2, decoder_layers:int=1,\n            MovingAvg_window:int=25, loss=MAE(), valid_loss=None,\n            max_steps:int=5000, learning_rate:float=0.0001,\n            num_lr_decays:int=-1, early_stop_patience_steps:int=-1,\n            start_padding_enabled=False, val_check_steps:int=100,\n            batch_size:int=32, valid_batch_size:Optional[int]=None,\n            windows_batch_size=1024, inference_windows_batch_size=1024,\n            step_size:int=1, scaler_type:str='identity',\n            random_seed:int=1, num_workers_loader:int=0,\n            drop_last_loader:bool=False, **trainer_kwargs)\n\nFEDformer\nThe FEDformer model tackles the challenge of finding reliable dependencies on intricate temporal patterns of long-horizon forecasting.\nThe architecture has the following distinctive features: - In-built progressive decomposition in trend and seasonal components based on a moving average filter. - Frequency Enhanced Block and Frequency Enhanced Attention to perform attention in the sparse representation on basis such as Fourier transform. - Classic encoder-decoder proposed by Vaswani et al. (2017) with a multi-head attention mechanism.\nThe FEDformer model utilizes a three-component approach to define its embedding: - It employs encoded autoregressive features obtained from a convolution network. - Absolute positional embeddings obtained from calendar features are utilized.\nParameters: h: int, forecast horizon. input_size: int, maximum sequence length for truncated train backpropagation. Default -1 uses all history. futr_exog_list: str list, future exogenous columns. hist_exog_list: str list, historic exogenous columns. stat_exog_list: str list, static exogenous columns. decoder_input_size_multiplier: float = 0.5, . version: str = ‘Fourier’, version of the model. modes: int = 64, number of modes for the Fourier block. mode_select: str = ‘random’, method to select the modes for the Fourier block. hidden_size: int=128, units of embeddings and encoders. dropout: float (0, 1), dropout throughout Autoformer architecture. n_head: int=8, controls number of multi-head’s attention. conv_hidden_size: int=32, channels of the convolutional encoder. activation: str=GELU, activation from [‘ReLU’, ‘Softplus’, ‘Tanh’, ‘SELU’, ‘LeakyReLU’, ‘PReLU’, ‘Sigmoid’, ‘GELU’]. encoder_layers: int=2, number of layers for the TCN encoder. decoder_layers: int=1, number of layers for the MLP decoder. MovingAvg_window: int=25, window size for the moving average filter. loss: PyTorch module, instantiated train loss class from losses collection. valid_loss: PyTorch module, instantiated validation loss class from losses collection. max_steps: int=1000, maximum number of training steps. learning_rate: float=1e-3, Learning rate between (0, 1). num_lr_decays: int=-1, Number of learning rate decays, evenly distributed across max_steps. early_stop_patience_steps: int=-1, Number of validation iterations before early stopping. val_check_steps: int=100, Number of training steps between every validation loss check. batch_size: int=32, number of different series in each batch. valid_batch_size: int=None, number of different series in each validation and test batch, if None uses batch_size. windows_batch_size: int=1024, number of windows to sample in each training batch, default uses all. inference_windows_batch_size: int=1024, number of windows to sample in each inference batch. start_padding_enabled: bool=False, if True, the model will pad the time series with zeros at the beginning, by input size. scaler_type: str=‘robust’, type of scaler for temporal inputs normalization see temporal scalers. random_seed: int=1, random_seed for pytorch initializer and numpy generators. num_workers_loader: int=os.cpu_count(), workers to be used by TimeSeriesDataLoader. drop_last_loader: bool=False, if True TimeSeriesDataLoader drops last non-full batch. alias: str, optional, Custom name of the model. **trainer_kwargs: int, keyword trainer arguments inherited from PyTorch Lighning’s trainer.\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import MLP\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss, MSE\nfrom neuralforecast.tsdataset import TimeSeriesDataset\nfrom neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic, augment_calendar_df\n\nAirPassengersPanel, calendar_cols = augment_calendar_df(df=AirPassengersPanel, freq='M')\n\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]] # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\n\nmodel = FEDformer(h=12,\n                 input_size=24,\n                 modes=64,\n                 hidden_size=64,\n                 conv_hidden_size=128,\n                 n_head=8,\n                 loss=MAE(),\n                 futr_exog_list=calendar_cols,\n                 scaler_type='robust',\n                 learning_rate=1e-3,\n                 max_steps=500,\n                 batch_size=2,\n                 windows_batch_size=32,\n                 val_check_steps=50,\n                 early_stop_patience_steps=2)\n\nnf = NeuralForecast(\n    models=[model],\n    freq='M',\n)\nnf.fit(df=Y_train_df, static_df=None, val_size=12)\nforecasts = nf.predict(futr_df=Y_test_df)\n\nY_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nif model.loss.is_distribution_output:\n    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n    plt.plot(plot_df['ds'], plot_df['FEDformer-median'], c='blue', label='median')\n    plt.fill_between(x=plot_df['ds'][-12:], \n                    y1=plot_df['FEDformer-lo-90'][-12:].values, \n                    y2=plot_df['FEDformer-hi-90'][-12:].values,\n                    alpha=0.4, label='level 90')\n    plt.grid()\n    plt.legend()\n    plt.plot()\nelse:\n    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n    plt.plot(plot_df['ds'], plot_df['FEDformer'], c='blue', label='Forecast')\n    plt.legend()\n    plt.grid()"
  },
  {
    "objectID": "models.timesnet.html",
    "href": "models.timesnet.html",
    "title": "TimesNet",
    "section": "",
    "text": "The TimesNet univariate model tackles the challenge of modeling multiple intraperiod and interperiod temporal variations.\nThe architecture has the following distinctive features: - An embedding layer that maps the input sequence into a latent space. - Transformation of 1D time seires into 2D tensors, based on periods found by FFT. - A convolutional Inception block that captures temporal variations at different scales and between periods.\nReferences - Haixu Wu and Tengge Hu and Yong Liu and Hang Zhou and Jianmin Wang and Mingsheng Long. TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis - Based on the implementation in https://github.com/thuml/Time-Series-Library (license: https://github.com/thuml/Time-Series-Library/blob/main/LICENSE)\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.timesnet.html#auxiliary-functions",
    "href": "models.timesnet.html#auxiliary-functions",
    "title": "TimesNet",
    "section": "1. Auxiliary Functions",
    "text": "1. Auxiliary Functions\n\nsource\n\nInception_Block_V1\n\n Inception_Block_V1 (in_channels, out_channels, num_kernels=6,\n                     init_weight=True)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nsource\n\n\nTimesBlock\n\n TimesBlock (input_size, h, k, hidden_size, conv_hidden_size, num_kernels)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nsource\n\n\nFFT_for_Period\n\n FFT_for_Period (x, k=2)"
  },
  {
    "objectID": "models.timesnet.html#timesnet",
    "href": "models.timesnet.html#timesnet",
    "title": "TimesNet",
    "section": "2. TimesNet",
    "text": "2. TimesNet\n\nsource\n\nTimesNet\n\n TimesNet (h:int, input_size:int, stat_exog_list=None,\n           hist_exog_list=None, futr_exog_list=None,\n           exclude_insample_y=False, hidden_size:int=64,\n           dropout:float=0.1, conv_hidden_size:int=64, top_k:int=5,\n           num_kernels:int=6, encoder_layers:int=2, loss=MAE(),\n           valid_loss=None, max_steps:int=1000,\n           learning_rate:float=0.0001, num_lr_decays:int=-1,\n           early_stop_patience_steps:int=-1, val_check_steps:int=100,\n           batch_size:int=32, valid_batch_size:Optional[int]=None,\n           windows_batch_size=64, inference_windows_batch_size=256,\n           start_padding_enabled=False, step_size:int=1,\n           scaler_type:str='standard', random_seed:int=1,\n           num_workers_loader:int=0, drop_last_loader:bool=False,\n           **trainer_kwargs)\n\nTimesNet\nThe TimesNet univariate model tackles the challenge of modeling multiple intraperiod and interperiod temporal variations.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nh\nint\n\nForecast horizon.\n\n\ninput_size\nint\n\nLength of input window (lags).\n\n\nstat_exog_list\nNoneType\nNone\nStatic exogenous columns.\n\n\nhist_exog_list\nNoneType\nNone\nHistoric exogenous columns.\n\n\nfutr_exog_list\nNoneType\nNone\nFuture exogenous columns.\n\n\nexclude_insample_y\nbool\nFalse\nThe model skips the autoregressive features y[t-input_size:t] if True\n\n\nhidden_size\nint\n64\nSize of embedding for embedding and encoders.\n\n\ndropout\nfloat\n0.1\nDropout for embeddings.conv_hidden_size: int (default=64)Channels of the Inception block.\n\n\nconv_hidden_size\nint\n64\n\n\n\ntop_k\nint\n5\n\n\n\nnum_kernels\nint\n6\n\n\n\nencoder_layers\nint\n2\nNumber of encoder layers.\n\n\nloss\nMAE\nMAE()\n\n\n\nvalid_loss\nNoneType\nNone\n\n\n\nmax_steps\nint\n1000\n\n\n\nlearning_rate\nfloat\n0.0001\nLearning rate.\n\n\nnum_lr_decays\nint\n-1\n\n\n\nearly_stop_patience_steps\nint\n-1\nNumber of validation iterations before early stopping. If -1, no early stopping is performed.\n\n\nval_check_steps\nint\n100\nNumber of training steps between every validation loss check.\n\n\nbatch_size\nint\n32\nNumber of different series in each batch.\n\n\nvalid_batch_size\ntyping.Optional[int]\nNone\nNumber of different series in each validation and test batch, if None uses batch_size.\n\n\nwindows_batch_size\nint\n64\nNumber of windows to sample in each training batch.\n\n\ninference_windows_batch_size\nint\n256\nNumber of windows to sample in each inference batch.\n\n\nstart_padding_enabled\nbool\nFalse\nIf True, the model will pad the time series with zeros at the beginning by input size.\n\n\nstep_size\nint\n1\n\n\n\nscaler_type\nstr\nstandard\nType of scaler for temporal inputs normalization see temporal scalers.\n\n\nrandom_seed\nint\n1\nRandom_seed for pytorch initializer and numpy generators.\n\n\nnum_workers_loader\nint\n0\nWorkers to be used by TimeSeriesDataLoader.\n\n\ndrop_last_loader\nbool\nFalse\nIf True TimeSeriesDataLoader drops last non-full batch.\n\n\ntrainer_kwargs\n\n\n\n\n\n\n\n\n\nTimesNet.fit\n\n TimesNet.fit (dataset, val_size=0, test_size=0, random_seed=None)\n\nFit.\nThe fit method, optimizes the neural network’s weights using the initialization parameters (learning_rate, windows_batch_size, …) and the loss function as defined during the initialization. Within fit we use a PyTorch Lightning Trainer that inherits the initialization’s self.trainer_kwargs, to customize its inputs, see PL’s trainer arguments.\nThe method is designed to be compatible with SKLearn-like classes and in particular to be compatible with the StatsForecast library.\nBy default the model is not saving training checkpoints to protect disk memory, to get them change enable_checkpointing=True in __init__.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset, see documentation. val_size: int, validation size for temporal cross-validation. random_seed: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__’s. test_size: int, test size for temporal cross-validation.\n\n\n\nTimesNet.predict\n\n TimesNet.predict (dataset, test_size=None, step_size=1, random_seed=None,\n                   **data_module_kwargs)\n\nPredict.\nNeural network prediction with PL’s Trainer execution of predict_step.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset, see documentation. test_size: int=None, test size for temporal cross-validation. step_size: int=1, Step size between each window. random_seed: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__’s. **data_module_kwargs: PL’s TimeSeriesDataModule args, see documentation."
  },
  {
    "objectID": "models.timesnet.html#usage-example",
    "href": "models.timesnet.html#usage-example",
    "title": "TimesNet",
    "section": "Usage Example",
    "text": "Usage Example\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss\nfrom neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic, augment_calendar_df\n\nAirPassengersPanel, calendar_cols = augment_calendar_df(df=AirPassengersPanel, freq='M')\n\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]] # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nmodel = TimesNet(h=12,\n                 input_size=24,\n                 hidden_size = 16,\n                 conv_hidden_size = 32,\n                 #loss=MAE(),\n                 #loss=MQLoss(quantiles=[0.2, 0.5, 0.8]),\n                 loss=DistributionLoss(distribution='Normal', level=[80, 90]),\n                 futr_exog_list=calendar_cols,\n                 scaler_type='standard',\n                 learning_rate=1e-3,\n                 max_steps=5,\n                 val_check_steps=50,\n                 early_stop_patience_steps=2)\n\nnf = NeuralForecast(\n    models=[model],\n    freq='M'\n)\nnf.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\nforecasts = nf.predict(futr_df=Y_test_df)\n\nY_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nif model.loss.is_distribution_output:\n    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n    plt.plot(plot_df['ds'], plot_df['TimesNet-median'], c='blue', label='median')\n    plt.fill_between(x=plot_df['ds'][-12:], \n                    y1=plot_df['TimesNet-lo-90'][-12:].values, \n                    y2=plot_df['TimesNet-hi-90'][-12:].values,\n                    alpha=0.4, label='level 90')\n    plt.grid()\n    plt.legend()\n    plt.plot()\nelse:\n    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n    plt.plot(plot_df['ds'], plot_df['TimesNet'], c='blue', label='Forecast')\n    plt.legend()\n    plt.grid()"
  },
  {
    "objectID": "models.informer.html",
    "href": "models.informer.html",
    "title": "Informer",
    "section": "",
    "text": "The Informer model tackles the vanilla Transformer computational complexity challenges for long-horizon forecasting.\nThe architecture has three distinctive features: - A ProbSparse self-attention mechanism with an O time and memory complexity Llog(L). - A self-attention distilling process that prioritizes attention and efficiently handles long input sequences. - An MLP multi-step decoder that predicts long time-series sequences in a single forward operation rather than step-by-step.\nThe Informer model utilizes a three-component approach to define its embedding: - It employs encoded autoregressive features obtained from a convolution network. - It uses window-relative positional embeddings derived from harmonic functions. - Absolute positional embeddings obtained from calendar features are utilized.\nReferences - Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, Wancai Zhang. “Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting”\nGive us a ⭐ on Github"
  },
  {
    "objectID": "models.informer.html#auxiliary-functions",
    "href": "models.informer.html#auxiliary-functions",
    "title": "Informer",
    "section": "1. Auxiliary Functions",
    "text": "1. Auxiliary Functions\n\nsource\n\nConvLayer\n\n ConvLayer (c_in)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nsource\n\n\nProbAttention\n\n ProbAttention (mask_flag=True, factor=5, scale=None,\n                attention_dropout=0.1, output_attention=False)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nsource\n\n\nProbMask\n\n ProbMask (B, H, L, index, scores, device='cpu')\n\nInitialize self. See help(type(self)) for accurate signature."
  },
  {
    "objectID": "models.informer.html#informer",
    "href": "models.informer.html#informer",
    "title": "Informer",
    "section": "2. Informer",
    "text": "2. Informer\n\nsource\n\nInformer\n\n Informer (h:int, input_size:int, stat_exog_list=None,\n           hist_exog_list=None, futr_exog_list=None,\n           exclude_insample_y=False,\n           decoder_input_size_multiplier:float=0.5, hidden_size:int=128,\n           dropout:float=0.05, factor:int=3, n_head:int=4,\n           conv_hidden_size:int=32, activation:str='gelu',\n           encoder_layers:int=2, decoder_layers:int=1, distil:bool=True,\n           loss=MAE(), valid_loss=None, max_steps:int=5000,\n           learning_rate:float=0.0001, num_lr_decays:int=-1,\n           early_stop_patience_steps:int=-1, val_check_steps:int=100,\n           batch_size:int=32, valid_batch_size:Optional[int]=None,\n           windows_batch_size=1024, inference_windows_batch_size=1024,\n           start_padding_enabled=False, step_size:int=1,\n           scaler_type:str='identity', random_seed:int=1,\n           num_workers_loader:int=0, drop_last_loader:bool=False,\n           **trainer_kwargs)\n\nInformer\nThe Informer model tackles the vanilla Transformer computational complexity challenges for long-horizon forecasting. \nThe architecture has three distinctive features:\n1) A ProbSparse self-attention mechanism with an O time and memory complexity Llog(L).\n2) A self-attention distilling process that prioritizes attention and efficiently handles long input sequences.\n3) An MLP multi-step decoder that predicts long time-series sequences in a single forward operation rather than step-by-step.\nThe Informer model utilizes a three-component approach to define its embedding: 1) It employs encoded autoregressive features obtained from a convolution network. 2) It uses window-relative positional embeddings derived from harmonic functions. 3) Absolute positional embeddings obtained from calendar features are utilized.\nParameters: h: int, forecast horizon. input_size: int, maximum sequence length for truncated train backpropagation. Default -1 uses all history. futr_exog_list: str list, future exogenous columns. hist_exog_list: str list, historic exogenous columns. stat_exog_list: str list, static exogenous columns. exclude_insample_y: bool=False, the model skips the autoregressive features y[t-input_size:t] if True. decoder_input_size_multiplier: float = 0.5, . hidden_size: int=128, units of embeddings and encoders. n_head: int=4, controls number of multi-head’s attention. dropout: float (0, 1), dropout throughout Informer architecture. factor: int=3, Probsparse attention factor. conv_hidden_size: int=32, channels of the convolutional encoder. activation: str=GELU, activation from [‘ReLU’, ‘Softplus’, ‘Tanh’, ‘SELU’, ‘LeakyReLU’, ‘PReLU’, ‘Sigmoid’, ‘GELU’]. encoder_layers: int=2, number of layers for the TCN encoder. decoder_layers: int=1, number of layers for the MLP decoder. distil: bool = True, wether the Informer decoder uses bottlenecks. loss: PyTorch module, instantiated train loss class from losses collection. max_steps: int=1000, maximum number of training steps. learning_rate: float=1e-3, Learning rate between (0, 1). num_lr_decays: int=-1, Number of learning rate decays, evenly distributed across max_steps. early_stop_patience_steps: int=-1, Number of validation iterations before early stopping. val_check_steps: int=100, Number of training steps between every validation loss check. batch_size: int=32, number of different series in each batch. valid_batch_size: int=None, number of different series in each validation and test batch, if None uses batch_size. windows_batch_size: int=1024, number of windows to sample in each training batch, default uses all. inference_windows_batch_size: int=1024, number of windows to sample in each inference batch. start_padding_enabled: bool=False, if True, the model will pad the time series with zeros at the beginning, by input size. scaler_type: str=‘robust’, type of scaler for temporal inputs normalization see temporal scalers. random_seed: int=1, random_seed for pytorch initializer and numpy generators. num_workers_loader: int=os.cpu_count(), workers to be used by TimeSeriesDataLoader. drop_last_loader: bool=False, if True TimeSeriesDataLoader drops last non-full batch. alias: str, optional, Custom name of the model. **trainer_kwargs: int, keyword trainer arguments inherited from PyTorch Lighning’s trainer.\n*References*&lt;br&gt;\n- [Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, Wancai Zhang. \"Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting\"](https://arxiv.org/abs/2012.07436)&lt;br&gt;\n\n\n\nInformer.fit\n\n Informer.fit (dataset, val_size=0, test_size=0, random_seed=None)\n\nFit.\nThe fit method, optimizes the neural network’s weights using the initialization parameters (learning_rate, windows_batch_size, …) and the loss function as defined during the initialization. Within fit we use a PyTorch Lightning Trainer that inherits the initialization’s self.trainer_kwargs, to customize its inputs, see PL’s trainer arguments.\nThe method is designed to be compatible with SKLearn-like classes and in particular to be compatible with the StatsForecast library.\nBy default the model is not saving training checkpoints to protect disk memory, to get them change enable_checkpointing=True in __init__.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset, see documentation. val_size: int, validation size for temporal cross-validation. random_seed: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__’s. test_size: int, test size for temporal cross-validation.\n\n\n\nInformer.predict\n\n Informer.predict (dataset, test_size=None, step_size=1, random_seed=None,\n                   **data_module_kwargs)\n\nPredict.\nNeural network prediction with PL’s Trainer execution of predict_step.\nParameters: dataset: NeuralForecast’s TimeSeriesDataset, see documentation. test_size: int=None, test size for temporal cross-validation. step_size: int=1, Step size between each window. random_seed: int=None, random_seed for pytorch initializer and numpy generators, overwrites model.__init__’s. **data_module_kwargs: PL’s TimeSeriesDataModule args, see documentation."
  },
  {
    "objectID": "models.informer.html#usage-example",
    "href": "models.informer.html#usage-example",
    "title": "Informer",
    "section": "Usage Example",
    "text": "Usage Example\n\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport matplotlib.pyplot as plt\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import MLP\nfrom neuralforecast.losses.pytorch import MQLoss, DistributionLoss\nfrom neuralforecast.tsdataset import TimeSeriesDataset\nfrom neuralforecast.utils import AirPassengers, AirPassengersPanel, AirPassengersStatic, augment_calendar_df\n\nAirPassengersPanel, calendar_cols = augment_calendar_df(df=AirPassengersPanel, freq='M')\n\nY_train_df = AirPassengersPanel[AirPassengersPanel.ds&lt;AirPassengersPanel['ds'].values[-12]] # 132 train\nY_test_df = AirPassengersPanel[AirPassengersPanel.ds&gt;=AirPassengersPanel['ds'].values[-12]].reset_index(drop=True) # 12 test\n\nmodel = Informer(h=12,\n                 input_size=24,\n                 hidden_size = 16,\n                 conv_hidden_size = 32,\n                 n_head = 2,\n                 #loss=DistributionLoss(distribution='StudentT', level=[80, 90]),\n                 loss=MAE(),\n                 futr_exog_list=calendar_cols,\n                 scaler_type='robust',\n                 learning_rate=1e-3,\n                 max_steps=5,\n                 val_check_steps=50,\n                 early_stop_patience_steps=2)\n\nnf = NeuralForecast(\n    models=[model],\n    freq='M'\n)\nnf.fit(df=Y_train_df, static_df=AirPassengersStatic, val_size=12)\nforecasts = nf.predict(futr_df=Y_test_df)\n\nY_hat_df = forecasts.reset_index(drop=False).drop(columns=['unique_id','ds'])\nplot_df = pd.concat([Y_test_df, Y_hat_df], axis=1)\nplot_df = pd.concat([Y_train_df, plot_df])\n\nif model.loss.is_distribution_output:\n    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n    plt.plot(plot_df['ds'], plot_df['Informer-median'], c='blue', label='median')\n    plt.fill_between(x=plot_df['ds'][-12:], \n                    y1=plot_df['Informer-lo-90'][-12:].values, \n                    y2=plot_df['Informer-hi-90'][-12:].values,\n                    alpha=0.4, label='level 90')\n    plt.grid()\n    plt.legend()\n    plt.plot()\nelse:\n    plot_df = plot_df[plot_df.unique_id=='Airline1'].drop('unique_id', axis=1)\n    plt.plot(plot_df['ds'], plot_df['y'], c='black', label='True')\n    plt.plot(plot_df['ds'], plot_df['Informer'], c='blue', label='Forecast')\n    plt.legend()\n    plt.grid()"
  },
  {
    "objectID": "tsdataset.html",
    "href": "tsdataset.html",
    "title": "PyTorch Dataset/Loader",
    "section": "",
    "text": "source\n\nTimeSeriesLoader\n\n TimeSeriesLoader (dataset, **kwargs)\n\nTimeSeriesLoader DataLoader. Source code.\nSmall change to PyTorch’s Data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset.\nThe class ~torch.utils.data.DataLoader supports both map-style and iterable-style datasets with single- or multi-process loading, customizing loading order and optional automatic batching (collation) and memory pinning.\nParameters: batch_size: (int, optional): how many samples per batch to load (default: 1). shuffle: (bool, optional): set to True to have the data reshuffled at every epoch (default: False). sampler: (Sampler or Iterable, optional): defines the strategy to draw samples from the dataset. Can be any Iterable with __len__ implemented. If specified, shuffle must not be specified.\n\nsource\n\n\nTimeSeriesDataset\n\n TimeSeriesDataset (temporal, temporal_cols, indptr, max_size:int,\n                    min_size:int, static=None, static_cols=None,\n                    sorted=False, scaler_type=None)\n\nAn abstract class representing a :class:Dataset.\nAll datasets that represent a map from keys to data samples should subclass it. All subclasses should overwrite :meth:__getitem__, supporting fetching a data sample for a given key. Subclasses could also optionally overwrite :meth:__len__, which is expected to return the size of the dataset by many :class:~torch.utils.data.Sampler implementations and the default options of :class:~torch.utils.data.DataLoader. Subclasses could also optionally implement :meth:__getitems__, for speedup batched samples loading. This method accepts list of indices of samples of batch and returns list of samples.\n.. note:: :class:~torch.utils.data.DataLoader by default constructs a index sampler that yields integral indices. To make it work with a map-style dataset with non-integral indices/keys, a custom sampler must be provided.\n\nsource\n\n\nTimeSeriesDataModule\n\n TimeSeriesDataModule (dataset:__main__.TimeSeriesDataset, batch_size=32,\n                       valid_batch_size=1024, num_workers=0,\n                       drop_last=False)\n\nA DataModule standardizes the training, val, test splits, data preparation and transforms. The main advantage is consistent data splits, data preparation and transforms across models.\nExample::\nimport lightning.pytorch as L\nimport torch.utils.data as data\nfrom pytorch_lightning.demos.boring_classes import RandomDataset\n\nclass MyDataModule(L.LightningDataModule):\n    def prepare_data(self):\n        # download, IO, etc. Useful with shared filesystems\n        # only called on 1 GPU/TPU in distributed\n        ...\n\n    def setup(self, stage):\n        # make assignments here (val/train/test split)\n        # called on every process in DDP\n        dataset = RandomDataset(1, 100)\n        self.train, self.val, self.test = data.random_split(\n            dataset, [80, 10, 10], generator=torch.Generator().manual_seed(42)\n        )\n\n    def train_dataloader(self):\n        return data.DataLoader(self.train)\n\n    def val_dataloader(self):\n        return data.DataLoader(self.val)\n\n    def test_dataloader(self):\n        return data.DataLoader(self.test)\n\n    def teardown(self):\n        # clean up state after the trainer stops, delete files...\n        # called on every process in DDP\n        ...\n\n# To test correct future_df wrangling of the `update_df` method\n# We are checking that we are able to recover the AirPassengers dataset\n# using the dataframe or splitting it into parts and initializing.\n\n\n\n\n\nGive us a ⭐ on Github"
  }
]